{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define ground truth values corresponding to each file\n",
    "# ground_truth_values = ['3.5', '4.0', '4.5', '5.0', '5.5', '6.0', '6.5', '7.0', '7.5']\n",
    "\n",
    "ground_truth_values = ['4.0', '4.5', '5.0', '5.5', '6.0']\n",
    "# Input directory and file names\n",
    "input_dir = 'C:\\\\Users\\\\User\\\\FIBOXVISION2025\\\\'\n",
    "# file_names = [\n",
    "#     'realsense_detections3500', 'realsense_detections4000', 'realsense_detections4500',\n",
    "#     'realsense_detections5000', 'realsense_detections5500', 'realsense_detections6000',\n",
    "#     'realsense_detections6500', 'realsense_detections7000', 'realsense_detections7500'\n",
    "# ]\n",
    "\n",
    "file_names = ['PLC_tracking', 'PLC_tracking_45', 'PLC_tracking_50', \n",
    "              'PLC_tracking_55', 'PLC_tracking_60', ]\n",
    "# Output file for the merged data\n",
    "output_file = os.path.join(input_dir, 'merged_PLC_tracking.csv')\n",
    "\n",
    "# Step 1: First update each file with its ground truth value\n",
    "all_dataframes = []\n",
    "\n",
    "for idx, base_name in enumerate(file_names):\n",
    "    csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "    ground_truth = ground_truth_values[idx]\n",
    "    \n",
    "    if not os.path.exists(csv_file_path):\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Add ground truth column if it doesn't exist\n",
    "        if 'ground_truth' not in df.columns:\n",
    "            df['ground_truth'] = ground_truth\n",
    "        \n",
    "        # Add source filename column for tracking\n",
    "        df['source_file'] = base_name\n",
    "        \n",
    "        # Append to our list of dataframes\n",
    "        all_dataframes.append(df)\n",
    "        \n",
    "        print(f\"Processed {csv_file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file_path}: {str(e)}\")\n",
    "\n",
    "# Step 2: Concatenate all dataframes\n",
    "if all_dataframes:\n",
    "    merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Step 3: Save the merged dataframe to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully merged {len(all_dataframes)} files into {output_file}\")\n",
    "    print(f\"Total rows in merged file: {len(merged_df)}\")\n",
    "else:\n",
    "    print(\"No data to merge. Please check the input files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# input_dir = '../Callback'\n",
    "\n",
    "# ground_truth_values = ['9','8.75','8.5','8','7.75', '7.5','7.25', '7','6.75','6.5', '6.25', '6','5.75', '5.5', '5.25','5', '4.75', '4.5', '4.25', '4']\n",
    "\n",
    "# input_dir = '../Callback'\n",
    "# file_names = ['Day2_9_depth_measurements','Day2_8_7_5_depth_measurements','Day2_8_5_depth_measurements' , 'Day2_8_depth_measurements', 'Day2_7_7_5_depth_measurements', 'Day2_7_5_depth_measurements', 'Day2_7_2_5_depth_measurements','Day2_7_depth_measurements', 'Day2_6_7_5_depth_measurements', 'Day2_6_5_depth_measurements', 'Day2_6_2_5_depth_measurements', 'Day2_6_depth_measurements'\n",
    "#               , 'Day2_5_7_5_depth_measurements', 'Day2_5_5_depth_measurements', 'Day2_5_2_5_depth_measurements', 'Day2_5_depth_measurements', 'Day2_4_7_5_depth_measurements', 'Day2_4_5_depth_measurements', 'Day2_4_2_5_depth_measurements', 'Day2_4_depth_measurements']\n",
    "\n",
    "# Ensure the number of filenames matches the number of ground truth values\n",
    "if len(file_names) != len(ground_truth_values):\n",
    "    raise ValueError(\"Mismatch between number of filenames and ground truth values.\")\n",
    "\n",
    "# headers = [\n",
    "#     'timestamp', 'x', 'y', 'w','h','depth',\n",
    "#     'gyro_data.x', 'gyro_data.y', 'gyro_data.z',\n",
    "#     'accel_data.x', 'accel_data.y', 'accel_data.z',\n",
    "#     'ground_truth'\n",
    "# ]\n",
    "\n",
    "\n",
    "# List to store all dataframes for merging\n",
    "all_dataframes = []\n",
    "\n",
    "# Process each file\n",
    "for idx, base_name in enumerate(file_names):\n",
    "    txt_file_path = os.path.join(input_dir, base_name + '.txt')\n",
    "    ground_truth = ground_truth_values[idx]  # Assign corresponding ground truth value\n",
    "\n",
    "    if not os.path.exists(txt_file_path):\n",
    "        print(f\"File not found: {txt_file_path}\")\n",
    "        continue\n",
    "    # Read the .txt file and prepare data for the .csv\n",
    "    csv_data = []\n",
    "    with open(txt_file_path, 'r') as txt_file:\n",
    "        for line in txt_file:\n",
    "            # Assuming each line contains 10 comma-separated values\n",
    "            data = line.strip().split(',')\n",
    "            if len(data) == 12:  # Ensure correct data format\n",
    "                data.append(ground_truth)  # Add the ground truth value\n",
    "                csv_data.append(data)\n",
    "            else:\n",
    "                print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n",
    "\n",
    "    # Define the output .csv file path\n",
    "    csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "\n",
    "    # Write data to the .csv file\n",
    "    with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)  # Write headers\n",
    "        writer.writerows(csv_data)  # Write data rows\n",
    "\n",
    "    print(f\"Converted: {txt_file_path} → {csv_file_path} with ground_truth = {ground_truth}\")\n",
    "\n",
    "    # Read the CSV file into a dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    all_dataframes.append(df)\n",
    "\n",
    "# Merge all CSVs into one dataframe\n",
    "merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Define the output merged CSV file path\n",
    "merged_csv_path = os.path.join(input_dir, 'merged_output.csv')\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(f\"All files successfully merged into {merged_csv_path}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data) == 10:  # Ensure correct data format\n",
    "    data.append(ground_truth)  # Add the ground truth value\n",
    "    csv_data.append(data)\n",
    "else:\n",
    "    print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define ground truth values corresponding to each file\n",
    "# ground_truth_values = ['8', '7.5', '7', '6.5', '6', '5.5', '5', '4.5', '4', '3.5', '3']\n",
    "\n",
    "# # List of filenames without extensions\n",
    "# file_names = [\n",
    "#     'm8_1_depth_measurements', '7.5_depth_measurements', '7_depth_measurements', \n",
    "#     'm_65_depth_measurements', 'm6_depth_measurements', 'm_5_5depth_measurements', \n",
    "#     'm_5_depth_measurements', 'm_4_5_depth_measurements', 'm_4_depth_measurements', \n",
    "#     'm3_5_depth_measurements', 'm_3_depth_measurements'\n",
    "# ]\n",
    "\n",
    "# # Define the input directory\n",
    "# input_dir = '../Callback'\n",
    "\n",
    "# # Ensure the number of filenames matches the number of ground truth values\n",
    "# if len(file_names) != len(ground_truth_values):\n",
    "#     raise ValueError(\"Mismatch between number of filenames and ground truth values.\")\n",
    "\n",
    "# # Define the headers\n",
    "# headers = [\n",
    "#     'timestamp', 'x', 'y', 'depth',\n",
    "#     'gyro_data.x', 'gyro_data.y', 'gyro_data.z',\n",
    "#     'accel_data.x', 'accel_data.y', 'accel_data.z',\n",
    "#     'ground_truth', 'error'\n",
    "# ]\n",
    "\n",
    "# # List to store all dataframes for merging\n",
    "# all_dataframes = []\n",
    "\n",
    "# # Process each file\n",
    "# for idx, base_name in enumerate(file_names):\n",
    "#     txt_file_path = os.path.join(input_dir, base_name + '.txt')\n",
    "#     ground_truth = float(ground_truth_values[idx])  # Assign corresponding ground truth value\n",
    "\n",
    "#     if not os.path.exists(txt_file_path):\n",
    "#         print(f\"File not found: {txt_file_path}\")\n",
    "#         continue\n",
    "\n",
    "#     # Read the .txt file and prepare data for the .csv\n",
    "#     csv_data = []\n",
    "#     with open(txt_file_path, 'r') as txt_file:\n",
    "#         for line in txt_file:\n",
    "#             # Assuming each line contains 10 comma-separated values\n",
    "#             data = line.strip().split(',')\n",
    "#             if len(data) == 10:  # Ensure correct data format\n",
    "#                 depth_value = float(data[3])  # Convert depth to float\n",
    "#                 error_value = depth_value - ground_truth  # Calculate error\n",
    "#                 data.append(str(ground_truth))  # Add the ground truth value\n",
    "#                 data.append(str(error_value))  # Add the error value\n",
    "#                 csv_data.append(data)\n",
    "#             else:\n",
    "#                 print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n",
    "\n",
    "#     # Define the output .csv file path\n",
    "#     csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "\n",
    "#     # Write data to the .csv file\n",
    "#     with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#         writer = csv.writer(csv_file)\n",
    "#         writer.writerow(headers)  # Write headers\n",
    "#         writer.writerows(csv_data)  # Write data rows\n",
    "\n",
    "#     print(f\"Converted: {txt_file_path} → {csv_file_path} with ground_truth = {ground_truth}\")\n",
    "\n",
    "#     # Read the CSV file into a dataframe\n",
    "#     df = pd.read_csv(csv_file_path)\n",
    "#     all_dataframes.append(df)\n",
    "\n",
    "# # Merge all CSVs into one dataframe\n",
    "# merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# # Define the output merged CSV file path\n",
    "# merged_csv_path = os.path.join(input_dir, 'merged_output.csv')\n",
    "\n",
    "# # Save the merged dataframe to a CSV file\n",
    "# merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "# print(f\"All files successfully merged into {merged_csv_path}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
