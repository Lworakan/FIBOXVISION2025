2025-03-05 11:37:30,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:37:30,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:37:30,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:37:30,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:58:29,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:58:29,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:58:29,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:58:29,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 11:58:29,371:INFO:PyCaret RegressionExperiment
2025-03-05 11:58:29,371:INFO:Logging name: reg-default-name
2025-03-05 11:58:29,371:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 11:58:29,371:INFO:version 3.3.1
2025-03-05 11:58:29,371:INFO:Initializing setup()
2025-03-05 11:58:29,371:INFO:self.USI: 5689
2025-03-05 11:58:29,371:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 11:58:29,371:INFO:Checking environment
2025-03-05 11:58:29,371:INFO:python_version: 3.9.21
2025-03-05 11:58:29,371:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 11:58:29,371:INFO:machine: x86_64
2025-03-05 11:58:29,371:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:58:29,371:INFO:Memory: svmem(total=33374507008, available=18440413184, percent=44.7, used=12385837056, free=2069311488, active=15510822912, inactive=11445407744, buffers=854818816, cached=18064539648, shared=2065305600, slab=1771012096)
2025-03-05 11:58:29,371:INFO:Physical Core: 24
2025-03-05 11:58:29,371:INFO:Logical Core: 32
2025-03-05 11:58:29,371:INFO:Checking libraries
2025-03-05 11:58:29,371:INFO:System:
2025-03-05 11:58:29,372:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 11:58:29,372:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 11:58:29,372:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:58:29,372:INFO:PyCaret required dependencies:
2025-03-05 11:58:29,393:INFO:                 pip: 25.0
2025-03-05 11:58:29,393:INFO:          setuptools: 75.8.0
2025-03-05 11:58:29,393:INFO:             pycaret: 3.3.1
2025-03-05 11:58:29,393:INFO:             IPython: 8.18.1
2025-03-05 11:58:29,393:INFO:          ipywidgets: 8.1.5
2025-03-05 11:58:29,393:INFO:                tqdm: 4.67.1
2025-03-05 11:58:29,393:INFO:               numpy: 1.26.4
2025-03-05 11:58:29,393:INFO:              pandas: 2.1.4
2025-03-05 11:58:29,393:INFO:              jinja2: 3.1.5
2025-03-05 11:58:29,393:INFO:               scipy: 1.11.4
2025-03-05 11:58:29,393:INFO:              joblib: 1.3.2
2025-03-05 11:58:29,394:INFO:             sklearn: 1.4.2
2025-03-05 11:58:29,394:INFO:                pyod: 2.0.3
2025-03-05 11:58:29,394:INFO:            imblearn: 0.12.4
2025-03-05 11:58:29,394:INFO:   category_encoders: 2.6.4
2025-03-05 11:58:29,394:INFO:            lightgbm: 4.6.0
2025-03-05 11:58:29,394:INFO:               numba: 0.60.0
2025-03-05 11:58:29,394:INFO:            requests: 2.32.3
2025-03-05 11:58:29,394:INFO:          matplotlib: 3.7.5
2025-03-05 11:58:29,394:INFO:          scikitplot: 0.3.7
2025-03-05 11:58:29,394:INFO:         yellowbrick: 1.5
2025-03-05 11:58:29,394:INFO:              plotly: 5.24.1
2025-03-05 11:58:29,394:INFO:    plotly-resampler: Not installed
2025-03-05 11:58:29,394:INFO:             kaleido: 0.2.1
2025-03-05 11:58:29,394:INFO:           schemdraw: 0.15
2025-03-05 11:58:29,394:INFO:         statsmodels: 0.14.4
2025-03-05 11:58:29,394:INFO:              sktime: 0.26.0
2025-03-05 11:58:29,394:INFO:               tbats: 1.1.3
2025-03-05 11:58:29,394:INFO:            pmdarima: 2.0.4
2025-03-05 11:58:29,394:INFO:              psutil: 7.0.0
2025-03-05 11:58:29,394:INFO:          markupsafe: 3.0.2
2025-03-05 11:58:29,394:INFO:             pickle5: Not installed
2025-03-05 11:58:29,394:INFO:         cloudpickle: 3.1.1
2025-03-05 11:58:29,394:INFO:         deprecation: 2.1.0
2025-03-05 11:58:29,394:INFO:              xxhash: 3.5.0
2025-03-05 11:58:29,394:INFO:           wurlitzer: 3.1.1
2025-03-05 11:58:29,394:INFO:PyCaret optional dependencies:
2025-03-05 11:58:29,400:INFO:                shap: Not installed
2025-03-05 11:58:29,400:INFO:           interpret: Not installed
2025-03-05 11:58:29,400:INFO:                umap: Not installed
2025-03-05 11:58:29,400:INFO:     ydata_profiling: Not installed
2025-03-05 11:58:29,400:INFO:  explainerdashboard: Not installed
2025-03-05 11:58:29,400:INFO:             autoviz: Not installed
2025-03-05 11:58:29,400:INFO:           fairlearn: Not installed
2025-03-05 11:58:29,400:INFO:          deepchecks: Not installed
2025-03-05 11:58:29,400:INFO:             xgboost: Not installed
2025-03-05 11:58:29,400:INFO:            catboost: Not installed
2025-03-05 11:58:29,400:INFO:              kmodes: Not installed
2025-03-05 11:58:29,400:INFO:             mlxtend: Not installed
2025-03-05 11:58:29,400:INFO:       statsforecast: Not installed
2025-03-05 11:58:29,401:INFO:        tune_sklearn: Not installed
2025-03-05 11:58:29,401:INFO:                 ray: Not installed
2025-03-05 11:58:29,401:INFO:            hyperopt: Not installed
2025-03-05 11:58:29,401:INFO:              optuna: Not installed
2025-03-05 11:58:29,401:INFO:               skopt: Not installed
2025-03-05 11:58:29,401:INFO:              mlflow: Not installed
2025-03-05 11:58:29,401:INFO:              gradio: Not installed
2025-03-05 11:58:29,401:INFO:             fastapi: Not installed
2025-03-05 11:58:29,401:INFO:             uvicorn: Not installed
2025-03-05 11:58:29,401:INFO:              m2cgen: Not installed
2025-03-05 11:58:29,401:INFO:           evidently: Not installed
2025-03-05 11:58:29,401:INFO:               fugue: Not installed
2025-03-05 11:58:29,401:INFO:           streamlit: Not installed
2025-03-05 11:58:29,401:INFO:             prophet: Not installed
2025-03-05 11:58:29,401:INFO:None
2025-03-05 11:58:29,401:INFO:Set up data.
2025-03-05 11:58:57,683:INFO:PyCaret RegressionExperiment
2025-03-05 11:58:57,683:INFO:Logging name: reg-default-name
2025-03-05 11:58:57,683:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 11:58:57,683:INFO:version 3.3.1
2025-03-05 11:58:57,683:INFO:Initializing setup()
2025-03-05 11:58:57,683:INFO:self.USI: 2422
2025-03-05 11:58:57,683:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 11:58:57,683:INFO:Checking environment
2025-03-05 11:58:57,683:INFO:python_version: 3.9.21
2025-03-05 11:58:57,683:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 11:58:57,684:INFO:machine: x86_64
2025-03-05 11:58:57,684:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:58:57,684:INFO:Memory: svmem(total=33374507008, available=18618716160, percent=44.2, used=12227895296, free=2245554176, active=15442518016, inactive=11446575104, buffers=855023616, cached=18046033920, shared=2044936192, slab=1770512384)
2025-03-05 11:58:57,684:INFO:Physical Core: 24
2025-03-05 11:58:57,684:INFO:Logical Core: 32
2025-03-05 11:58:57,684:INFO:Checking libraries
2025-03-05 11:58:57,684:INFO:System:
2025-03-05 11:58:57,684:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 11:58:57,684:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 11:58:57,684:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:58:57,684:INFO:PyCaret required dependencies:
2025-03-05 11:58:57,684:INFO:                 pip: 25.0
2025-03-05 11:58:57,684:INFO:          setuptools: 75.8.0
2025-03-05 11:58:57,684:INFO:             pycaret: 3.3.1
2025-03-05 11:58:57,684:INFO:             IPython: 8.18.1
2025-03-05 11:58:57,684:INFO:          ipywidgets: 8.1.5
2025-03-05 11:58:57,684:INFO:                tqdm: 4.67.1
2025-03-05 11:58:57,684:INFO:               numpy: 1.26.4
2025-03-05 11:58:57,684:INFO:              pandas: 2.1.4
2025-03-05 11:58:57,684:INFO:              jinja2: 3.1.5
2025-03-05 11:58:57,684:INFO:               scipy: 1.11.4
2025-03-05 11:58:57,684:INFO:              joblib: 1.3.2
2025-03-05 11:58:57,684:INFO:             sklearn: 1.4.2
2025-03-05 11:58:57,684:INFO:                pyod: 2.0.3
2025-03-05 11:58:57,684:INFO:            imblearn: 0.12.4
2025-03-05 11:58:57,684:INFO:   category_encoders: 2.6.4
2025-03-05 11:58:57,684:INFO:            lightgbm: 4.6.0
2025-03-05 11:58:57,684:INFO:               numba: 0.60.0
2025-03-05 11:58:57,684:INFO:            requests: 2.32.3
2025-03-05 11:58:57,684:INFO:          matplotlib: 3.7.5
2025-03-05 11:58:57,684:INFO:          scikitplot: 0.3.7
2025-03-05 11:58:57,684:INFO:         yellowbrick: 1.5
2025-03-05 11:58:57,684:INFO:              plotly: 5.24.1
2025-03-05 11:58:57,684:INFO:    plotly-resampler: Not installed
2025-03-05 11:58:57,684:INFO:             kaleido: 0.2.1
2025-03-05 11:58:57,684:INFO:           schemdraw: 0.15
2025-03-05 11:58:57,684:INFO:         statsmodels: 0.14.4
2025-03-05 11:58:57,684:INFO:              sktime: 0.26.0
2025-03-05 11:58:57,684:INFO:               tbats: 1.1.3
2025-03-05 11:58:57,684:INFO:            pmdarima: 2.0.4
2025-03-05 11:58:57,684:INFO:              psutil: 7.0.0
2025-03-05 11:58:57,684:INFO:          markupsafe: 3.0.2
2025-03-05 11:58:57,684:INFO:             pickle5: Not installed
2025-03-05 11:58:57,684:INFO:         cloudpickle: 3.1.1
2025-03-05 11:58:57,684:INFO:         deprecation: 2.1.0
2025-03-05 11:58:57,684:INFO:              xxhash: 3.5.0
2025-03-05 11:58:57,684:INFO:           wurlitzer: 3.1.1
2025-03-05 11:58:57,684:INFO:PyCaret optional dependencies:
2025-03-05 11:58:57,684:INFO:                shap: Not installed
2025-03-05 11:58:57,684:INFO:           interpret: Not installed
2025-03-05 11:58:57,684:INFO:                umap: Not installed
2025-03-05 11:58:57,684:INFO:     ydata_profiling: Not installed
2025-03-05 11:58:57,684:INFO:  explainerdashboard: Not installed
2025-03-05 11:58:57,684:INFO:             autoviz: Not installed
2025-03-05 11:58:57,684:INFO:           fairlearn: Not installed
2025-03-05 11:58:57,684:INFO:          deepchecks: Not installed
2025-03-05 11:58:57,684:INFO:             xgboost: Not installed
2025-03-05 11:58:57,684:INFO:            catboost: Not installed
2025-03-05 11:58:57,684:INFO:              kmodes: Not installed
2025-03-05 11:58:57,685:INFO:             mlxtend: Not installed
2025-03-05 11:58:57,685:INFO:       statsforecast: Not installed
2025-03-05 11:58:57,685:INFO:        tune_sklearn: Not installed
2025-03-05 11:58:57,685:INFO:                 ray: Not installed
2025-03-05 11:58:57,685:INFO:            hyperopt: Not installed
2025-03-05 11:58:57,685:INFO:              optuna: Not installed
2025-03-05 11:58:57,685:INFO:               skopt: Not installed
2025-03-05 11:58:57,685:INFO:              mlflow: Not installed
2025-03-05 11:58:57,685:INFO:              gradio: Not installed
2025-03-05 11:58:57,685:INFO:             fastapi: Not installed
2025-03-05 11:58:57,685:INFO:             uvicorn: Not installed
2025-03-05 11:58:57,685:INFO:              m2cgen: Not installed
2025-03-05 11:58:57,685:INFO:           evidently: Not installed
2025-03-05 11:58:57,685:INFO:               fugue: Not installed
2025-03-05 11:58:57,685:INFO:           streamlit: Not installed
2025-03-05 11:58:57,685:INFO:             prophet: Not installed
2025-03-05 11:58:57,685:INFO:None
2025-03-05 11:58:57,685:INFO:Set up data.
2025-03-05 11:59:58,847:INFO:PyCaret RegressionExperiment
2025-03-05 11:59:58,848:INFO:Logging name: reg-default-name
2025-03-05 11:59:58,848:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 11:59:58,848:INFO:version 3.3.1
2025-03-05 11:59:58,848:INFO:Initializing setup()
2025-03-05 11:59:58,848:INFO:self.USI: 7a63
2025-03-05 11:59:58,848:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 11:59:58,848:INFO:Checking environment
2025-03-05 11:59:58,848:INFO:python_version: 3.9.21
2025-03-05 11:59:58,848:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 11:59:58,848:INFO:machine: x86_64
2025-03-05 11:59:58,848:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:59:58,848:INFO:Memory: svmem(total=33374507008, available=18520756224, percent=44.5, used=12276535296, free=2144657408, active=15513952256, inactive=11446677504, buffers=855216128, cached=18098098176, shared=2094264320, slab=1770401792)
2025-03-05 11:59:58,848:INFO:Physical Core: 24
2025-03-05 11:59:58,848:INFO:Logical Core: 32
2025-03-05 11:59:58,848:INFO:Checking libraries
2025-03-05 11:59:58,848:INFO:System:
2025-03-05 11:59:58,848:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 11:59:58,848:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 11:59:58,848:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 11:59:58,848:INFO:PyCaret required dependencies:
2025-03-05 11:59:58,848:INFO:                 pip: 25.0
2025-03-05 11:59:58,848:INFO:          setuptools: 75.8.0
2025-03-05 11:59:58,848:INFO:             pycaret: 3.3.1
2025-03-05 11:59:58,848:INFO:             IPython: 8.18.1
2025-03-05 11:59:58,848:INFO:          ipywidgets: 8.1.5
2025-03-05 11:59:58,848:INFO:                tqdm: 4.67.1
2025-03-05 11:59:58,848:INFO:               numpy: 1.26.4
2025-03-05 11:59:58,848:INFO:              pandas: 2.1.4
2025-03-05 11:59:58,848:INFO:              jinja2: 3.1.5
2025-03-05 11:59:58,848:INFO:               scipy: 1.11.4
2025-03-05 11:59:58,848:INFO:              joblib: 1.3.2
2025-03-05 11:59:58,848:INFO:             sklearn: 1.4.2
2025-03-05 11:59:58,849:INFO:                pyod: 2.0.3
2025-03-05 11:59:58,849:INFO:            imblearn: 0.12.4
2025-03-05 11:59:58,849:INFO:   category_encoders: 2.6.4
2025-03-05 11:59:58,849:INFO:            lightgbm: 4.6.0
2025-03-05 11:59:58,849:INFO:               numba: 0.60.0
2025-03-05 11:59:58,849:INFO:            requests: 2.32.3
2025-03-05 11:59:58,849:INFO:          matplotlib: 3.7.5
2025-03-05 11:59:58,849:INFO:          scikitplot: 0.3.7
2025-03-05 11:59:58,849:INFO:         yellowbrick: 1.5
2025-03-05 11:59:58,849:INFO:              plotly: 5.24.1
2025-03-05 11:59:58,849:INFO:    plotly-resampler: Not installed
2025-03-05 11:59:58,849:INFO:             kaleido: 0.2.1
2025-03-05 11:59:58,849:INFO:           schemdraw: 0.15
2025-03-05 11:59:58,849:INFO:         statsmodels: 0.14.4
2025-03-05 11:59:58,849:INFO:              sktime: 0.26.0
2025-03-05 11:59:58,849:INFO:               tbats: 1.1.3
2025-03-05 11:59:58,849:INFO:            pmdarima: 2.0.4
2025-03-05 11:59:58,849:INFO:              psutil: 7.0.0
2025-03-05 11:59:58,849:INFO:          markupsafe: 3.0.2
2025-03-05 11:59:58,849:INFO:             pickle5: Not installed
2025-03-05 11:59:58,849:INFO:         cloudpickle: 3.1.1
2025-03-05 11:59:58,849:INFO:         deprecation: 2.1.0
2025-03-05 11:59:58,849:INFO:              xxhash: 3.5.0
2025-03-05 11:59:58,849:INFO:           wurlitzer: 3.1.1
2025-03-05 11:59:58,849:INFO:PyCaret optional dependencies:
2025-03-05 11:59:58,849:INFO:                shap: Not installed
2025-03-05 11:59:58,849:INFO:           interpret: Not installed
2025-03-05 11:59:58,849:INFO:                umap: Not installed
2025-03-05 11:59:58,849:INFO:     ydata_profiling: Not installed
2025-03-05 11:59:58,849:INFO:  explainerdashboard: Not installed
2025-03-05 11:59:58,849:INFO:             autoviz: Not installed
2025-03-05 11:59:58,849:INFO:           fairlearn: Not installed
2025-03-05 11:59:58,849:INFO:          deepchecks: Not installed
2025-03-05 11:59:58,849:INFO:             xgboost: Not installed
2025-03-05 11:59:58,849:INFO:            catboost: Not installed
2025-03-05 11:59:58,849:INFO:              kmodes: Not installed
2025-03-05 11:59:58,849:INFO:             mlxtend: Not installed
2025-03-05 11:59:58,849:INFO:       statsforecast: Not installed
2025-03-05 11:59:58,849:INFO:        tune_sklearn: Not installed
2025-03-05 11:59:58,849:INFO:                 ray: Not installed
2025-03-05 11:59:58,849:INFO:            hyperopt: Not installed
2025-03-05 11:59:58,849:INFO:              optuna: Not installed
2025-03-05 11:59:58,849:INFO:               skopt: Not installed
2025-03-05 11:59:58,849:INFO:              mlflow: Not installed
2025-03-05 11:59:58,849:INFO:              gradio: Not installed
2025-03-05 11:59:58,849:INFO:             fastapi: Not installed
2025-03-05 11:59:58,849:INFO:             uvicorn: Not installed
2025-03-05 11:59:58,849:INFO:              m2cgen: Not installed
2025-03-05 11:59:58,849:INFO:           evidently: Not installed
2025-03-05 11:59:58,849:INFO:               fugue: Not installed
2025-03-05 11:59:58,849:INFO:           streamlit: Not installed
2025-03-05 11:59:58,849:INFO:             prophet: Not installed
2025-03-05 11:59:58,849:INFO:None
2025-03-05 11:59:58,849:INFO:Set up data.
2025-03-05 12:00:13,032:INFO:PyCaret RegressionExperiment
2025-03-05 12:00:13,032:INFO:Logging name: reg-default-name
2025-03-05 12:00:13,032:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:00:13,032:INFO:version 3.3.1
2025-03-05 12:00:13,032:INFO:Initializing setup()
2025-03-05 12:00:13,032:INFO:self.USI: e66c
2025-03-05 12:00:13,032:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 12:00:13,032:INFO:Checking environment
2025-03-05 12:00:13,032:INFO:python_version: 3.9.21
2025-03-05 12:00:13,032:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:00:13,032:INFO:machine: x86_64
2025-03-05 12:00:13,032:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:00:13,032:INFO:Memory: svmem(total=33374507008, available=18497654784, percent=44.6, used=12289814528, free=2121027584, active=15521091584, inactive=11446812672, buffers=855289856, cached=18108375040, shared=2104074240, slab=1770762240)
2025-03-05 12:00:13,033:INFO:Physical Core: 24
2025-03-05 12:00:13,033:INFO:Logical Core: 32
2025-03-05 12:00:13,033:INFO:Checking libraries
2025-03-05 12:00:13,033:INFO:System:
2025-03-05 12:00:13,033:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:00:13,033:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:00:13,033:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:00:13,033:INFO:PyCaret required dependencies:
2025-03-05 12:00:13,033:INFO:                 pip: 25.0
2025-03-05 12:00:13,033:INFO:          setuptools: 75.8.0
2025-03-05 12:00:13,033:INFO:             pycaret: 3.3.1
2025-03-05 12:00:13,033:INFO:             IPython: 8.18.1
2025-03-05 12:00:13,033:INFO:          ipywidgets: 8.1.5
2025-03-05 12:00:13,033:INFO:                tqdm: 4.67.1
2025-03-05 12:00:13,033:INFO:               numpy: 1.26.4
2025-03-05 12:00:13,033:INFO:              pandas: 2.1.4
2025-03-05 12:00:13,033:INFO:              jinja2: 3.1.5
2025-03-05 12:00:13,033:INFO:               scipy: 1.11.4
2025-03-05 12:00:13,033:INFO:              joblib: 1.3.2
2025-03-05 12:00:13,033:INFO:             sklearn: 1.4.2
2025-03-05 12:00:13,033:INFO:                pyod: 2.0.3
2025-03-05 12:00:13,033:INFO:            imblearn: 0.12.4
2025-03-05 12:00:13,033:INFO:   category_encoders: 2.6.4
2025-03-05 12:00:13,033:INFO:            lightgbm: 4.6.0
2025-03-05 12:00:13,033:INFO:               numba: 0.60.0
2025-03-05 12:00:13,033:INFO:            requests: 2.32.3
2025-03-05 12:00:13,033:INFO:          matplotlib: 3.7.5
2025-03-05 12:00:13,033:INFO:          scikitplot: 0.3.7
2025-03-05 12:00:13,033:INFO:         yellowbrick: 1.5
2025-03-05 12:00:13,033:INFO:              plotly: 5.24.1
2025-03-05 12:00:13,033:INFO:    plotly-resampler: Not installed
2025-03-05 12:00:13,033:INFO:             kaleido: 0.2.1
2025-03-05 12:00:13,033:INFO:           schemdraw: 0.15
2025-03-05 12:00:13,033:INFO:         statsmodels: 0.14.4
2025-03-05 12:00:13,033:INFO:              sktime: 0.26.0
2025-03-05 12:00:13,033:INFO:               tbats: 1.1.3
2025-03-05 12:00:13,033:INFO:            pmdarima: 2.0.4
2025-03-05 12:00:13,033:INFO:              psutil: 7.0.0
2025-03-05 12:00:13,033:INFO:          markupsafe: 3.0.2
2025-03-05 12:00:13,033:INFO:             pickle5: Not installed
2025-03-05 12:00:13,033:INFO:         cloudpickle: 3.1.1
2025-03-05 12:00:13,033:INFO:         deprecation: 2.1.0
2025-03-05 12:00:13,033:INFO:              xxhash: 3.5.0
2025-03-05 12:00:13,033:INFO:           wurlitzer: 3.1.1
2025-03-05 12:00:13,033:INFO:PyCaret optional dependencies:
2025-03-05 12:00:13,033:INFO:                shap: Not installed
2025-03-05 12:00:13,033:INFO:           interpret: Not installed
2025-03-05 12:00:13,033:INFO:                umap: Not installed
2025-03-05 12:00:13,033:INFO:     ydata_profiling: Not installed
2025-03-05 12:00:13,033:INFO:  explainerdashboard: Not installed
2025-03-05 12:00:13,033:INFO:             autoviz: Not installed
2025-03-05 12:00:13,033:INFO:           fairlearn: Not installed
2025-03-05 12:00:13,033:INFO:          deepchecks: Not installed
2025-03-05 12:00:13,033:INFO:             xgboost: Not installed
2025-03-05 12:00:13,033:INFO:            catboost: Not installed
2025-03-05 12:00:13,033:INFO:              kmodes: Not installed
2025-03-05 12:00:13,033:INFO:             mlxtend: Not installed
2025-03-05 12:00:13,033:INFO:       statsforecast: Not installed
2025-03-05 12:00:13,033:INFO:        tune_sklearn: Not installed
2025-03-05 12:00:13,033:INFO:                 ray: Not installed
2025-03-05 12:00:13,033:INFO:            hyperopt: Not installed
2025-03-05 12:00:13,033:INFO:              optuna: Not installed
2025-03-05 12:00:13,033:INFO:               skopt: Not installed
2025-03-05 12:00:13,033:INFO:              mlflow: Not installed
2025-03-05 12:00:13,033:INFO:              gradio: Not installed
2025-03-05 12:00:13,033:INFO:             fastapi: Not installed
2025-03-05 12:00:13,033:INFO:             uvicorn: Not installed
2025-03-05 12:00:13,033:INFO:              m2cgen: Not installed
2025-03-05 12:00:13,033:INFO:           evidently: Not installed
2025-03-05 12:00:13,033:INFO:               fugue: Not installed
2025-03-05 12:00:13,033:INFO:           streamlit: Not installed
2025-03-05 12:00:13,033:INFO:             prophet: Not installed
2025-03-05 12:00:13,033:INFO:None
2025-03-05 12:00:13,033:INFO:Set up data.
2025-03-05 12:00:13,043:INFO:Set up folding strategy.
2025-03-05 12:00:13,043:INFO:Set up train/test split.
2025-03-05 12:00:13,048:INFO:Set up index.
2025-03-05 12:00:13,049:INFO:Assigning column types.
2025-03-05 12:00:13,052:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:00:13,052:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,104:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,106:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,159:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,160:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:00:13,162:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,220:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,271:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:00:13,275:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,327:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,354:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,375:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:00:13,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,477:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:00:13,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:00:13,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,592:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:00:13,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:13,712:INFO:Preparing preprocessing pipeline...
2025-03-05 12:00:13,712:INFO:Set up simple imputation.
2025-03-05 12:00:13,715:INFO:Set up encoding of categorical features.
2025-03-05 12:00:13,715:INFO:Set up column name cleaning.
2025-03-05 12:00:13,786:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:00:13,790:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['x', 'y', 'depth', 'gyro_data.x',
                                             'gyro_data.y', 'gyro_data.z',
                                             'accel_data.x', 'accel_data.y',
                                             'accel_data.z'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['timestamp'],
                                    transformer=TargetEncoder(cols=['timestamp'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:00:13,790:INFO:Creating final display dataframe.
2025-03-05 12:00:13,973:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape       (20088, 11)
4        Transformed data shape       (20088, 11)
5   Transformed train set shape       (14061, 11)
6    Transformed test set shape        (6027, 11)
7              Numeric features                 9
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              e66c
2025-03-05 12:00:14,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:14,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:14,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:14,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:00:14,088:INFO:setup() successfully completed in 1.06s...............
2025-03-05 12:00:16,419:INFO:Initializing compare_models()
2025-03-05 12:00:16,420:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:00:16,420:INFO:Checking exceptions
2025-03-05 12:00:16,422:INFO:Preparing display monitor
2025-03-05 12:00:16,433:INFO:Initializing Linear Regression
2025-03-05 12:00:16,433:INFO:Total runtime is 1.422564188639323e-06 minutes
2025-03-05 12:00:16,434:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:16,434:INFO:Initializing create_model()
2025-03-05 12:00:16,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:16,435:INFO:Checking exceptions
2025-03-05 12:00:16,435:INFO:Importing libraries
2025-03-05 12:00:16,435:INFO:Copying training dataset
2025-03-05 12:00:16,438:INFO:Defining folds
2025-03-05 12:00:16,439:INFO:Declaring metric variables
2025-03-05 12:00:16,440:INFO:Importing untrained model
2025-03-05 12:00:16,442:INFO:Linear Regression Imported successfully
2025-03-05 12:00:16,444:INFO:Starting cross validation
2025-03-05 12:00:16,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:18,238:INFO:Calculating mean and std
2025-03-05 12:00:18,240:INFO:Creating metrics dataframe
2025-03-05 12:00:18,242:INFO:Uploading results into container
2025-03-05 12:00:18,242:INFO:Uploading model into container now
2025-03-05 12:00:18,242:INFO:_master_model_container: 1
2025-03-05 12:00:18,242:INFO:_display_container: 2
2025-03-05 12:00:18,242:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:00:18,243:INFO:create_model() successfully completed......................................
2025-03-05 12:00:18,309:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:18,309:INFO:Creating metrics dataframe
2025-03-05 12:00:18,312:INFO:Initializing Lasso Regression
2025-03-05 12:00:18,312:INFO:Total runtime is 0.03132837216059367 minutes
2025-03-05 12:00:18,314:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:18,314:INFO:Initializing create_model()
2025-03-05 12:00:18,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:18,314:INFO:Checking exceptions
2025-03-05 12:00:18,314:INFO:Importing libraries
2025-03-05 12:00:18,314:INFO:Copying training dataset
2025-03-05 12:00:18,318:INFO:Defining folds
2025-03-05 12:00:18,319:INFO:Declaring metric variables
2025-03-05 12:00:18,320:INFO:Importing untrained model
2025-03-05 12:00:18,322:INFO:Lasso Regression Imported successfully
2025-03-05 12:00:18,325:INFO:Starting cross validation
2025-03-05 12:00:18,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:19,749:INFO:Calculating mean and std
2025-03-05 12:00:19,750:INFO:Creating metrics dataframe
2025-03-05 12:00:19,753:INFO:Uploading results into container
2025-03-05 12:00:19,753:INFO:Uploading model into container now
2025-03-05 12:00:19,753:INFO:_master_model_container: 2
2025-03-05 12:00:19,753:INFO:_display_container: 2
2025-03-05 12:00:19,754:INFO:Lasso(random_state=123)
2025-03-05 12:00:19,754:INFO:create_model() successfully completed......................................
2025-03-05 12:00:19,813:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:19,813:INFO:Creating metrics dataframe
2025-03-05 12:00:19,817:INFO:Initializing Ridge Regression
2025-03-05 12:00:19,817:INFO:Total runtime is 0.056412835915883384 minutes
2025-03-05 12:00:19,819:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:19,820:INFO:Initializing create_model()
2025-03-05 12:00:19,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:19,820:INFO:Checking exceptions
2025-03-05 12:00:19,820:INFO:Importing libraries
2025-03-05 12:00:19,820:INFO:Copying training dataset
2025-03-05 12:00:19,823:INFO:Defining folds
2025-03-05 12:00:19,823:INFO:Declaring metric variables
2025-03-05 12:00:19,825:INFO:Importing untrained model
2025-03-05 12:00:19,827:INFO:Ridge Regression Imported successfully
2025-03-05 12:00:19,830:INFO:Starting cross validation
2025-03-05 12:00:19,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:21,243:INFO:Calculating mean and std
2025-03-05 12:00:21,244:INFO:Creating metrics dataframe
2025-03-05 12:00:21,245:INFO:Uploading results into container
2025-03-05 12:00:21,245:INFO:Uploading model into container now
2025-03-05 12:00:21,246:INFO:_master_model_container: 3
2025-03-05 12:00:21,246:INFO:_display_container: 2
2025-03-05 12:00:21,246:INFO:Ridge(random_state=123)
2025-03-05 12:00:21,246:INFO:create_model() successfully completed......................................
2025-03-05 12:00:21,305:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:21,305:INFO:Creating metrics dataframe
2025-03-05 12:00:21,309:INFO:Initializing Elastic Net
2025-03-05 12:00:21,309:INFO:Total runtime is 0.08126809199651083 minutes
2025-03-05 12:00:21,311:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:21,311:INFO:Initializing create_model()
2025-03-05 12:00:21,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:21,311:INFO:Checking exceptions
2025-03-05 12:00:21,311:INFO:Importing libraries
2025-03-05 12:00:21,311:INFO:Copying training dataset
2025-03-05 12:00:21,315:INFO:Defining folds
2025-03-05 12:00:21,315:INFO:Declaring metric variables
2025-03-05 12:00:21,317:INFO:Importing untrained model
2025-03-05 12:00:21,319:INFO:Elastic Net Imported successfully
2025-03-05 12:00:21,322:INFO:Starting cross validation
2025-03-05 12:00:21,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:22,094:INFO:Calculating mean and std
2025-03-05 12:00:22,096:INFO:Creating metrics dataframe
2025-03-05 12:00:22,097:INFO:Uploading results into container
2025-03-05 12:00:22,098:INFO:Uploading model into container now
2025-03-05 12:00:22,098:INFO:_master_model_container: 4
2025-03-05 12:00:22,098:INFO:_display_container: 2
2025-03-05 12:00:22,098:INFO:ElasticNet(random_state=123)
2025-03-05 12:00:22,098:INFO:create_model() successfully completed......................................
2025-03-05 12:00:22,160:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:22,160:INFO:Creating metrics dataframe
2025-03-05 12:00:22,164:INFO:Initializing Least Angle Regression
2025-03-05 12:00:22,164:INFO:Total runtime is 0.0955250104268392 minutes
2025-03-05 12:00:22,166:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:22,166:INFO:Initializing create_model()
2025-03-05 12:00:22,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:22,166:INFO:Checking exceptions
2025-03-05 12:00:22,166:INFO:Importing libraries
2025-03-05 12:00:22,166:INFO:Copying training dataset
2025-03-05 12:00:22,170:INFO:Defining folds
2025-03-05 12:00:22,170:INFO:Declaring metric variables
2025-03-05 12:00:22,172:INFO:Importing untrained model
2025-03-05 12:00:22,173:INFO:Least Angle Regression Imported successfully
2025-03-05 12:00:22,176:INFO:Starting cross validation
2025-03-05 12:00:22,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:22,321:INFO:Calculating mean and std
2025-03-05 12:00:22,322:INFO:Creating metrics dataframe
2025-03-05 12:00:22,325:INFO:Uploading results into container
2025-03-05 12:00:22,325:INFO:Uploading model into container now
2025-03-05 12:00:22,325:INFO:_master_model_container: 5
2025-03-05 12:00:22,326:INFO:_display_container: 2
2025-03-05 12:00:22,326:INFO:Lars(random_state=123)
2025-03-05 12:00:22,326:INFO:create_model() successfully completed......................................
2025-03-05 12:00:22,396:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:22,396:INFO:Creating metrics dataframe
2025-03-05 12:00:22,400:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:00:22,400:INFO:Total runtime is 0.09945633014043173 minutes
2025-03-05 12:00:22,402:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:22,402:INFO:Initializing create_model()
2025-03-05 12:00:22,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:22,402:INFO:Checking exceptions
2025-03-05 12:00:22,402:INFO:Importing libraries
2025-03-05 12:00:22,402:INFO:Copying training dataset
2025-03-05 12:00:22,406:INFO:Defining folds
2025-03-05 12:00:22,406:INFO:Declaring metric variables
2025-03-05 12:00:22,408:INFO:Importing untrained model
2025-03-05 12:00:22,410:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:00:22,412:INFO:Starting cross validation
2025-03-05 12:00:22,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:22,562:INFO:Calculating mean and std
2025-03-05 12:00:22,563:INFO:Creating metrics dataframe
2025-03-05 12:00:22,565:INFO:Uploading results into container
2025-03-05 12:00:22,565:INFO:Uploading model into container now
2025-03-05 12:00:22,566:INFO:_master_model_container: 6
2025-03-05 12:00:22,566:INFO:_display_container: 2
2025-03-05 12:00:22,566:INFO:LassoLars(random_state=123)
2025-03-05 12:00:22,566:INFO:create_model() successfully completed......................................
2025-03-05 12:00:22,629:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:22,629:INFO:Creating metrics dataframe
2025-03-05 12:00:22,634:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:00:22,634:INFO:Total runtime is 0.10334919293721517 minutes
2025-03-05 12:00:22,635:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:22,636:INFO:Initializing create_model()
2025-03-05 12:00:22,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:22,636:INFO:Checking exceptions
2025-03-05 12:00:22,636:INFO:Importing libraries
2025-03-05 12:00:22,636:INFO:Copying training dataset
2025-03-05 12:00:22,640:INFO:Defining folds
2025-03-05 12:00:22,640:INFO:Declaring metric variables
2025-03-05 12:00:22,642:INFO:Importing untrained model
2025-03-05 12:00:22,643:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:00:22,646:INFO:Starting cross validation
2025-03-05 12:00:22,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:22,799:INFO:Calculating mean and std
2025-03-05 12:00:22,801:INFO:Creating metrics dataframe
2025-03-05 12:00:22,804:INFO:Uploading results into container
2025-03-05 12:00:22,804:INFO:Uploading model into container now
2025-03-05 12:00:22,805:INFO:_master_model_container: 7
2025-03-05 12:00:22,805:INFO:_display_container: 2
2025-03-05 12:00:22,805:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:00:22,805:INFO:create_model() successfully completed......................................
2025-03-05 12:00:22,873:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:22,874:INFO:Creating metrics dataframe
2025-03-05 12:00:22,878:INFO:Initializing Bayesian Ridge
2025-03-05 12:00:22,878:INFO:Total runtime is 0.10742787917455038 minutes
2025-03-05 12:00:22,880:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:22,881:INFO:Initializing create_model()
2025-03-05 12:00:22,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:22,881:INFO:Checking exceptions
2025-03-05 12:00:22,881:INFO:Importing libraries
2025-03-05 12:00:22,881:INFO:Copying training dataset
2025-03-05 12:00:22,885:INFO:Defining folds
2025-03-05 12:00:22,885:INFO:Declaring metric variables
2025-03-05 12:00:22,887:INFO:Importing untrained model
2025-03-05 12:00:22,889:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:00:22,893:INFO:Starting cross validation
2025-03-05 12:00:22,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:23,031:INFO:Calculating mean and std
2025-03-05 12:00:23,032:INFO:Creating metrics dataframe
2025-03-05 12:00:23,033:INFO:Uploading results into container
2025-03-05 12:00:23,033:INFO:Uploading model into container now
2025-03-05 12:00:23,033:INFO:_master_model_container: 8
2025-03-05 12:00:23,033:INFO:_display_container: 2
2025-03-05 12:00:23,034:INFO:BayesianRidge()
2025-03-05 12:00:23,034:INFO:create_model() successfully completed......................................
2025-03-05 12:00:23,091:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:23,091:INFO:Creating metrics dataframe
2025-03-05 12:00:23,098:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:00:23,098:INFO:Total runtime is 0.11109408140182496 minutes
2025-03-05 12:00:23,101:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:23,101:INFO:Initializing create_model()
2025-03-05 12:00:23,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:23,101:INFO:Checking exceptions
2025-03-05 12:00:23,101:INFO:Importing libraries
2025-03-05 12:00:23,101:INFO:Copying training dataset
2025-03-05 12:00:23,105:INFO:Defining folds
2025-03-05 12:00:23,105:INFO:Declaring metric variables
2025-03-05 12:00:23,107:INFO:Importing untrained model
2025-03-05 12:00:23,109:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:00:23,112:INFO:Starting cross validation
2025-03-05 12:00:23,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:23,271:INFO:Calculating mean and std
2025-03-05 12:00:23,272:INFO:Creating metrics dataframe
2025-03-05 12:00:23,273:INFO:Uploading results into container
2025-03-05 12:00:23,274:INFO:Uploading model into container now
2025-03-05 12:00:23,274:INFO:_master_model_container: 9
2025-03-05 12:00:23,274:INFO:_display_container: 2
2025-03-05 12:00:23,274:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:00:23,274:INFO:create_model() successfully completed......................................
2025-03-05 12:00:23,332:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:23,332:INFO:Creating metrics dataframe
2025-03-05 12:00:23,337:INFO:Initializing Huber Regressor
2025-03-05 12:00:23,337:INFO:Total runtime is 0.11506925423940023 minutes
2025-03-05 12:00:23,339:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:23,339:INFO:Initializing create_model()
2025-03-05 12:00:23,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:23,339:INFO:Checking exceptions
2025-03-05 12:00:23,339:INFO:Importing libraries
2025-03-05 12:00:23,339:INFO:Copying training dataset
2025-03-05 12:00:23,343:INFO:Defining folds
2025-03-05 12:00:23,343:INFO:Declaring metric variables
2025-03-05 12:00:23,344:INFO:Importing untrained model
2025-03-05 12:00:23,346:INFO:Huber Regressor Imported successfully
2025-03-05 12:00:23,349:INFO:Starting cross validation
2025-03-05 12:00:23,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:23,516:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,527:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,533:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,556:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,559:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,564:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,585:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,626:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,631:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,642:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 12:00:23,663:INFO:Calculating mean and std
2025-03-05 12:00:23,664:INFO:Creating metrics dataframe
2025-03-05 12:00:23,665:INFO:Uploading results into container
2025-03-05 12:00:23,665:INFO:Uploading model into container now
2025-03-05 12:00:23,666:INFO:_master_model_container: 10
2025-03-05 12:00:23,666:INFO:_display_container: 2
2025-03-05 12:00:23,666:INFO:HuberRegressor()
2025-03-05 12:00:23,666:INFO:create_model() successfully completed......................................
2025-03-05 12:00:23,722:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:23,722:INFO:Creating metrics dataframe
2025-03-05 12:00:23,727:INFO:Initializing K Neighbors Regressor
2025-03-05 12:00:23,727:INFO:Total runtime is 0.12156577507654827 minutes
2025-03-05 12:00:23,728:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:23,728:INFO:Initializing create_model()
2025-03-05 12:00:23,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:23,728:INFO:Checking exceptions
2025-03-05 12:00:23,728:INFO:Importing libraries
2025-03-05 12:00:23,728:INFO:Copying training dataset
2025-03-05 12:00:23,732:INFO:Defining folds
2025-03-05 12:00:23,732:INFO:Declaring metric variables
2025-03-05 12:00:23,734:INFO:Importing untrained model
2025-03-05 12:00:23,735:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:00:23,738:INFO:Starting cross validation
2025-03-05 12:00:23,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:24,053:INFO:Calculating mean and std
2025-03-05 12:00:24,053:INFO:Creating metrics dataframe
2025-03-05 12:00:24,055:INFO:Uploading results into container
2025-03-05 12:00:24,055:INFO:Uploading model into container now
2025-03-05 12:00:24,055:INFO:_master_model_container: 11
2025-03-05 12:00:24,055:INFO:_display_container: 2
2025-03-05 12:00:24,056:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:00:24,056:INFO:create_model() successfully completed......................................
2025-03-05 12:00:24,115:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:24,115:INFO:Creating metrics dataframe
2025-03-05 12:00:24,119:INFO:Initializing Decision Tree Regressor
2025-03-05 12:00:24,119:INFO:Total runtime is 0.128112530708313 minutes
2025-03-05 12:00:24,121:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:24,121:INFO:Initializing create_model()
2025-03-05 12:00:24,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:24,121:INFO:Checking exceptions
2025-03-05 12:00:24,121:INFO:Importing libraries
2025-03-05 12:00:24,121:INFO:Copying training dataset
2025-03-05 12:00:24,125:INFO:Defining folds
2025-03-05 12:00:24,125:INFO:Declaring metric variables
2025-03-05 12:00:24,127:INFO:Importing untrained model
2025-03-05 12:00:24,129:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:00:24,131:INFO:Starting cross validation
2025-03-05 12:00:24,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:24,269:INFO:Calculating mean and std
2025-03-05 12:00:24,270:INFO:Creating metrics dataframe
2025-03-05 12:00:24,272:INFO:Uploading results into container
2025-03-05 12:00:24,273:INFO:Uploading model into container now
2025-03-05 12:00:24,273:INFO:_master_model_container: 12
2025-03-05 12:00:24,273:INFO:_display_container: 2
2025-03-05 12:00:24,274:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:00:24,274:INFO:create_model() successfully completed......................................
2025-03-05 12:00:24,332:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:24,332:INFO:Creating metrics dataframe
2025-03-05 12:00:24,337:INFO:Initializing Random Forest Regressor
2025-03-05 12:00:24,337:INFO:Total runtime is 0.13173766136169435 minutes
2025-03-05 12:00:24,339:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:24,339:INFO:Initializing create_model()
2025-03-05 12:00:24,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:24,339:INFO:Checking exceptions
2025-03-05 12:00:24,339:INFO:Importing libraries
2025-03-05 12:00:24,339:INFO:Copying training dataset
2025-03-05 12:00:24,343:INFO:Defining folds
2025-03-05 12:00:24,343:INFO:Declaring metric variables
2025-03-05 12:00:24,344:INFO:Importing untrained model
2025-03-05 12:00:24,346:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:00:24,349:INFO:Starting cross validation
2025-03-05 12:00:24,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:24,943:INFO:Calculating mean and std
2025-03-05 12:00:24,945:INFO:Creating metrics dataframe
2025-03-05 12:00:24,946:INFO:Uploading results into container
2025-03-05 12:00:24,947:INFO:Uploading model into container now
2025-03-05 12:00:24,948:INFO:_master_model_container: 13
2025-03-05 12:00:24,948:INFO:_display_container: 2
2025-03-05 12:00:24,948:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:00:24,948:INFO:create_model() successfully completed......................................
2025-03-05 12:00:25,008:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:25,008:INFO:Creating metrics dataframe
2025-03-05 12:00:25,013:INFO:Initializing Extra Trees Regressor
2025-03-05 12:00:25,013:INFO:Total runtime is 0.1430090109507243 minutes
2025-03-05 12:00:25,015:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:25,015:INFO:Initializing create_model()
2025-03-05 12:00:25,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:25,015:INFO:Checking exceptions
2025-03-05 12:00:25,015:INFO:Importing libraries
2025-03-05 12:00:25,015:INFO:Copying training dataset
2025-03-05 12:00:25,020:INFO:Defining folds
2025-03-05 12:00:25,020:INFO:Declaring metric variables
2025-03-05 12:00:25,021:INFO:Importing untrained model
2025-03-05 12:00:25,023:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:00:25,026:INFO:Starting cross validation
2025-03-05 12:00:25,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:25,422:INFO:Calculating mean and std
2025-03-05 12:00:25,424:INFO:Creating metrics dataframe
2025-03-05 12:00:25,426:INFO:Uploading results into container
2025-03-05 12:00:25,427:INFO:Uploading model into container now
2025-03-05 12:00:25,427:INFO:_master_model_container: 14
2025-03-05 12:00:25,427:INFO:_display_container: 2
2025-03-05 12:00:25,428:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:00:25,428:INFO:create_model() successfully completed......................................
2025-03-05 12:00:25,497:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:25,497:INFO:Creating metrics dataframe
2025-03-05 12:00:25,503:INFO:Initializing AdaBoost Regressor
2025-03-05 12:00:25,503:INFO:Total runtime is 0.15117448568344116 minutes
2025-03-05 12:00:25,505:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:25,506:INFO:Initializing create_model()
2025-03-05 12:00:25,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:25,506:INFO:Checking exceptions
2025-03-05 12:00:25,506:INFO:Importing libraries
2025-03-05 12:00:25,506:INFO:Copying training dataset
2025-03-05 12:00:25,510:INFO:Defining folds
2025-03-05 12:00:25,510:INFO:Declaring metric variables
2025-03-05 12:00:25,512:INFO:Importing untrained model
2025-03-05 12:00:25,514:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:00:25,518:INFO:Starting cross validation
2025-03-05 12:00:25,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:26,345:INFO:Calculating mean and std
2025-03-05 12:00:26,346:INFO:Creating metrics dataframe
2025-03-05 12:00:26,347:INFO:Uploading results into container
2025-03-05 12:00:26,347:INFO:Uploading model into container now
2025-03-05 12:00:26,347:INFO:_master_model_container: 15
2025-03-05 12:00:26,347:INFO:_display_container: 2
2025-03-05 12:00:26,348:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:00:26,348:INFO:create_model() successfully completed......................................
2025-03-05 12:00:26,408:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:26,408:INFO:Creating metrics dataframe
2025-03-05 12:00:26,413:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:00:26,413:INFO:Total runtime is 0.1663382609685262 minutes
2025-03-05 12:00:26,415:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:26,415:INFO:Initializing create_model()
2025-03-05 12:00:26,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:26,415:INFO:Checking exceptions
2025-03-05 12:00:26,415:INFO:Importing libraries
2025-03-05 12:00:26,415:INFO:Copying training dataset
2025-03-05 12:00:26,419:INFO:Defining folds
2025-03-05 12:00:26,419:INFO:Declaring metric variables
2025-03-05 12:00:26,421:INFO:Importing untrained model
2025-03-05 12:00:26,423:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:00:26,426:INFO:Starting cross validation
2025-03-05 12:00:26,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:00:27,594:INFO:Calculating mean and std
2025-03-05 12:00:27,595:INFO:Creating metrics dataframe
2025-03-05 12:00:27,596:INFO:Uploading results into container
2025-03-05 12:00:27,597:INFO:Uploading model into container now
2025-03-05 12:00:27,597:INFO:_master_model_container: 16
2025-03-05 12:00:27,597:INFO:_display_container: 2
2025-03-05 12:00:27,598:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:00:27,598:INFO:create_model() successfully completed......................................
2025-03-05 12:00:27,650:INFO:SubProcess create_model() end ==================================
2025-03-05 12:00:27,650:INFO:Creating metrics dataframe
2025-03-05 12:00:27,655:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:00:27,655:INFO:Total runtime is 0.1870359698931376 minutes
2025-03-05 12:00:27,656:INFO:SubProcess create_model() called ==================================
2025-03-05 12:00:27,657:INFO:Initializing create_model()
2025-03-05 12:00:27,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c832a9d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c7b89d30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:00:27,657:INFO:Checking exceptions
2025-03-05 12:00:27,657:INFO:Importing libraries
2025-03-05 12:00:27,657:INFO:Copying training dataset
2025-03-05 12:00:27,660:INFO:Defining folds
2025-03-05 12:00:27,660:INFO:Declaring metric variables
2025-03-05 12:00:27,662:INFO:Importing untrained model
2025-03-05 12:00:27,664:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:00:27,667:INFO:Starting cross validation
2025-03-05 12:00:27,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:05:58,244:INFO:PyCaret RegressionExperiment
2025-03-05 12:05:58,244:INFO:Logging name: reg-default-name
2025-03-05 12:05:58,244:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:05:58,244:INFO:version 3.3.1
2025-03-05 12:05:58,244:INFO:Initializing setup()
2025-03-05 12:05:58,244:INFO:self.USI: c35f
2025-03-05 12:05:58,244:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 12:05:58,244:INFO:Checking environment
2025-03-05 12:05:58,244:INFO:python_version: 3.9.21
2025-03-05 12:05:58,244:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:05:58,244:INFO:machine: x86_64
2025-03-05 12:05:58,244:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:05:58,244:INFO:Memory: svmem(total=33374507008, available=18317344768, percent=45.1, used=12473077760, free=4635062272, active=15833866240, inactive=8614903808, buffers=608874496, cached=15657492480, shared=2101133312, slab=1735913472)
2025-03-05 12:05:58,245:INFO:Physical Core: 24
2025-03-05 12:05:58,245:INFO:Logical Core: 32
2025-03-05 12:05:58,245:INFO:Checking libraries
2025-03-05 12:05:58,245:INFO:System:
2025-03-05 12:05:58,245:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:05:58,245:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:05:58,245:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:05:58,245:INFO:PyCaret required dependencies:
2025-03-05 12:05:58,245:INFO:                 pip: 25.0
2025-03-05 12:05:58,245:INFO:          setuptools: 75.8.0
2025-03-05 12:05:58,245:INFO:             pycaret: 3.3.1
2025-03-05 12:05:58,245:INFO:             IPython: 8.18.1
2025-03-05 12:05:58,245:INFO:          ipywidgets: 8.1.5
2025-03-05 12:05:58,245:INFO:                tqdm: 4.67.1
2025-03-05 12:05:58,245:INFO:               numpy: 1.26.4
2025-03-05 12:05:58,245:INFO:              pandas: 2.1.4
2025-03-05 12:05:58,245:INFO:              jinja2: 3.1.5
2025-03-05 12:05:58,245:INFO:               scipy: 1.11.4
2025-03-05 12:05:58,245:INFO:              joblib: 1.3.2
2025-03-05 12:05:58,245:INFO:             sklearn: 1.4.2
2025-03-05 12:05:58,245:INFO:                pyod: 2.0.3
2025-03-05 12:05:58,245:INFO:            imblearn: 0.12.4
2025-03-05 12:05:58,245:INFO:   category_encoders: 2.6.4
2025-03-05 12:05:58,245:INFO:            lightgbm: 4.6.0
2025-03-05 12:05:58,245:INFO:               numba: 0.60.0
2025-03-05 12:05:58,245:INFO:            requests: 2.32.3
2025-03-05 12:05:58,245:INFO:          matplotlib: 3.7.5
2025-03-05 12:05:58,245:INFO:          scikitplot: 0.3.7
2025-03-05 12:05:58,245:INFO:         yellowbrick: 1.5
2025-03-05 12:05:58,245:INFO:              plotly: 5.24.1
2025-03-05 12:05:58,245:INFO:    plotly-resampler: Not installed
2025-03-05 12:05:58,245:INFO:             kaleido: 0.2.1
2025-03-05 12:05:58,245:INFO:           schemdraw: 0.15
2025-03-05 12:05:58,245:INFO:         statsmodels: 0.14.4
2025-03-05 12:05:58,245:INFO:              sktime: 0.26.0
2025-03-05 12:05:58,245:INFO:               tbats: 1.1.3
2025-03-05 12:05:58,245:INFO:            pmdarima: 2.0.4
2025-03-05 12:05:58,245:INFO:              psutil: 7.0.0
2025-03-05 12:05:58,245:INFO:          markupsafe: 3.0.2
2025-03-05 12:05:58,245:INFO:             pickle5: Not installed
2025-03-05 12:05:58,245:INFO:         cloudpickle: 3.1.1
2025-03-05 12:05:58,245:INFO:         deprecation: 2.1.0
2025-03-05 12:05:58,245:INFO:              xxhash: 3.5.0
2025-03-05 12:05:58,245:INFO:           wurlitzer: 3.1.1
2025-03-05 12:05:58,245:INFO:PyCaret optional dependencies:
2025-03-05 12:05:58,245:INFO:                shap: Not installed
2025-03-05 12:05:58,245:INFO:           interpret: Not installed
2025-03-05 12:05:58,245:INFO:                umap: Not installed
2025-03-05 12:05:58,245:INFO:     ydata_profiling: Not installed
2025-03-05 12:05:58,245:INFO:  explainerdashboard: Not installed
2025-03-05 12:05:58,245:INFO:             autoviz: Not installed
2025-03-05 12:05:58,245:INFO:           fairlearn: Not installed
2025-03-05 12:05:58,245:INFO:          deepchecks: Not installed
2025-03-05 12:05:58,245:INFO:             xgboost: Not installed
2025-03-05 12:05:58,245:INFO:            catboost: Not installed
2025-03-05 12:05:58,245:INFO:              kmodes: Not installed
2025-03-05 12:05:58,245:INFO:             mlxtend: Not installed
2025-03-05 12:05:58,245:INFO:       statsforecast: Not installed
2025-03-05 12:05:58,245:INFO:        tune_sklearn: Not installed
2025-03-05 12:05:58,245:INFO:                 ray: Not installed
2025-03-05 12:05:58,245:INFO:            hyperopt: Not installed
2025-03-05 12:05:58,245:INFO:              optuna: Not installed
2025-03-05 12:05:58,245:INFO:               skopt: Not installed
2025-03-05 12:05:58,245:INFO:              mlflow: Not installed
2025-03-05 12:05:58,245:INFO:              gradio: Not installed
2025-03-05 12:05:58,245:INFO:             fastapi: Not installed
2025-03-05 12:05:58,245:INFO:             uvicorn: Not installed
2025-03-05 12:05:58,245:INFO:              m2cgen: Not installed
2025-03-05 12:05:58,245:INFO:           evidently: Not installed
2025-03-05 12:05:58,245:INFO:               fugue: Not installed
2025-03-05 12:05:58,245:INFO:           streamlit: Not installed
2025-03-05 12:05:58,245:INFO:             prophet: Not installed
2025-03-05 12:05:58,245:INFO:None
2025-03-05 12:05:58,245:INFO:Set up data.
2025-03-05 12:05:58,247:INFO:Set up folding strategy.
2025-03-05 12:05:58,248:INFO:Set up train/test split.
2025-03-05 12:05:58,249:INFO:Set up index.
2025-03-05 12:05:58,250:INFO:Assigning column types.
2025-03-05 12:05:58,251:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:05:58,251:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,253:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,255:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,299:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,301:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,347:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:05:58,349:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,351:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,397:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,444:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:05:58,448:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,542:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:05:58,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,641:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:05:58,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:05:58,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,738:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:05:58,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,837:INFO:Preparing preprocessing pipeline...
2025-03-05 12:05:58,837:INFO:Set up simple imputation.
2025-03-05 12:05:58,837:INFO:Set up column name cleaning.
2025-03-05 12:05:58,846:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:05:58,848:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:05:58,848:INFO:Creating final display dataframe.
2025-03-05 12:05:58,880:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              c35f
2025-03-05 12:05:58,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:58,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:59,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:59,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:05:59,006:INFO:setup() successfully completed in 0.76s...............
2025-03-05 12:05:59,776:INFO:Initializing compare_models()
2025-03-05 12:05:59,777:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:05:59,777:INFO:Checking exceptions
2025-03-05 12:05:59,778:INFO:Preparing display monitor
2025-03-05 12:05:59,789:INFO:Initializing Linear Regression
2025-03-05 12:05:59,789:INFO:Total runtime is 1.811981201171875e-06 minutes
2025-03-05 12:05:59,791:INFO:SubProcess create_model() called ==================================
2025-03-05 12:05:59,791:INFO:Initializing create_model()
2025-03-05 12:05:59,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:05:59,791:INFO:Checking exceptions
2025-03-05 12:05:59,791:INFO:Importing libraries
2025-03-05 12:05:59,791:INFO:Copying training dataset
2025-03-05 12:05:59,793:INFO:Defining folds
2025-03-05 12:05:59,793:INFO:Declaring metric variables
2025-03-05 12:05:59,795:INFO:Importing untrained model
2025-03-05 12:05:59,797:INFO:Linear Regression Imported successfully
2025-03-05 12:05:59,800:INFO:Starting cross validation
2025-03-05 12:05:59,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:01,457:INFO:Calculating mean and std
2025-03-05 12:06:01,458:INFO:Creating metrics dataframe
2025-03-05 12:06:01,461:INFO:Uploading results into container
2025-03-05 12:06:01,461:INFO:Uploading model into container now
2025-03-05 12:06:01,462:INFO:_master_model_container: 1
2025-03-05 12:06:01,462:INFO:_display_container: 2
2025-03-05 12:06:01,462:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:06:01,462:INFO:create_model() successfully completed......................................
2025-03-05 12:06:01,567:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:01,567:INFO:Creating metrics dataframe
2025-03-05 12:06:01,571:INFO:Initializing Lasso Regression
2025-03-05 12:06:01,571:INFO:Total runtime is 0.0296963373819987 minutes
2025-03-05 12:06:01,572:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:01,572:INFO:Initializing create_model()
2025-03-05 12:06:01,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:01,572:INFO:Checking exceptions
2025-03-05 12:06:01,572:INFO:Importing libraries
2025-03-05 12:06:01,572:INFO:Copying training dataset
2025-03-05 12:06:01,575:INFO:Defining folds
2025-03-05 12:06:01,575:INFO:Declaring metric variables
2025-03-05 12:06:01,577:INFO:Importing untrained model
2025-03-05 12:06:01,578:INFO:Lasso Regression Imported successfully
2025-03-05 12:06:01,581:INFO:Starting cross validation
2025-03-05 12:06:01,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:02,841:INFO:Calculating mean and std
2025-03-05 12:06:02,842:INFO:Creating metrics dataframe
2025-03-05 12:06:02,843:INFO:Uploading results into container
2025-03-05 12:06:02,843:INFO:Uploading model into container now
2025-03-05 12:06:02,844:INFO:_master_model_container: 2
2025-03-05 12:06:02,844:INFO:_display_container: 2
2025-03-05 12:06:02,844:INFO:Lasso(random_state=123)
2025-03-05 12:06:02,844:INFO:create_model() successfully completed......................................
2025-03-05 12:06:02,934:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:02,934:INFO:Creating metrics dataframe
2025-03-05 12:06:02,938:INFO:Initializing Ridge Regression
2025-03-05 12:06:02,938:INFO:Total runtime is 0.052492781480153405 minutes
2025-03-05 12:06:02,940:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:02,940:INFO:Initializing create_model()
2025-03-05 12:06:02,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:02,940:INFO:Checking exceptions
2025-03-05 12:06:02,940:INFO:Importing libraries
2025-03-05 12:06:02,940:INFO:Copying training dataset
2025-03-05 12:06:02,943:INFO:Defining folds
2025-03-05 12:06:02,943:INFO:Declaring metric variables
2025-03-05 12:06:02,945:INFO:Importing untrained model
2025-03-05 12:06:02,947:INFO:Ridge Regression Imported successfully
2025-03-05 12:06:02,949:INFO:Starting cross validation
2025-03-05 12:06:02,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:04,230:INFO:Calculating mean and std
2025-03-05 12:06:04,231:INFO:Creating metrics dataframe
2025-03-05 12:06:04,233:INFO:Uploading results into container
2025-03-05 12:06:04,233:INFO:Uploading model into container now
2025-03-05 12:06:04,233:INFO:_master_model_container: 3
2025-03-05 12:06:04,233:INFO:_display_container: 2
2025-03-05 12:06:04,233:INFO:Ridge(random_state=123)
2025-03-05 12:06:04,233:INFO:create_model() successfully completed......................................
2025-03-05 12:06:04,321:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:04,321:INFO:Creating metrics dataframe
2025-03-05 12:06:04,325:INFO:Initializing Elastic Net
2025-03-05 12:06:04,325:INFO:Total runtime is 0.07560240825017293 minutes
2025-03-05 12:06:04,327:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:04,327:INFO:Initializing create_model()
2025-03-05 12:06:04,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:04,327:INFO:Checking exceptions
2025-03-05 12:06:04,327:INFO:Importing libraries
2025-03-05 12:06:04,327:INFO:Copying training dataset
2025-03-05 12:06:04,329:INFO:Defining folds
2025-03-05 12:06:04,329:INFO:Declaring metric variables
2025-03-05 12:06:04,331:INFO:Importing untrained model
2025-03-05 12:06:04,332:INFO:Elastic Net Imported successfully
2025-03-05 12:06:04,335:INFO:Starting cross validation
2025-03-05 12:06:04,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:04,990:INFO:Calculating mean and std
2025-03-05 12:06:04,990:INFO:Creating metrics dataframe
2025-03-05 12:06:04,992:INFO:Uploading results into container
2025-03-05 12:06:04,992:INFO:Uploading model into container now
2025-03-05 12:06:04,993:INFO:_master_model_container: 4
2025-03-05 12:06:04,993:INFO:_display_container: 2
2025-03-05 12:06:04,993:INFO:ElasticNet(random_state=123)
2025-03-05 12:06:04,993:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,084:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,084:INFO:Creating metrics dataframe
2025-03-05 12:06:05,088:INFO:Initializing Least Angle Regression
2025-03-05 12:06:05,088:INFO:Total runtime is 0.08832751512527466 minutes
2025-03-05 12:06:05,090:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,091:INFO:Initializing create_model()
2025-03-05 12:06:05,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,091:INFO:Checking exceptions
2025-03-05 12:06:05,091:INFO:Importing libraries
2025-03-05 12:06:05,091:INFO:Copying training dataset
2025-03-05 12:06:05,093:INFO:Defining folds
2025-03-05 12:06:05,093:INFO:Declaring metric variables
2025-03-05 12:06:05,095:INFO:Importing untrained model
2025-03-05 12:06:05,096:INFO:Least Angle Regression Imported successfully
2025-03-05 12:06:05,099:INFO:Starting cross validation
2025-03-05 12:06:05,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,148:INFO:Calculating mean and std
2025-03-05 12:06:05,148:INFO:Creating metrics dataframe
2025-03-05 12:06:05,149:INFO:Uploading results into container
2025-03-05 12:06:05,149:INFO:Uploading model into container now
2025-03-05 12:06:05,150:INFO:_master_model_container: 5
2025-03-05 12:06:05,150:INFO:_display_container: 2
2025-03-05 12:06:05,150:INFO:Lars(random_state=123)
2025-03-05 12:06:05,150:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,235:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,235:INFO:Creating metrics dataframe
2025-03-05 12:06:05,239:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:06:05,239:INFO:Total runtime is 0.090841809908549 minutes
2025-03-05 12:06:05,241:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,241:INFO:Initializing create_model()
2025-03-05 12:06:05,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,241:INFO:Checking exceptions
2025-03-05 12:06:05,241:INFO:Importing libraries
2025-03-05 12:06:05,241:INFO:Copying training dataset
2025-03-05 12:06:05,244:INFO:Defining folds
2025-03-05 12:06:05,244:INFO:Declaring metric variables
2025-03-05 12:06:05,246:INFO:Importing untrained model
2025-03-05 12:06:05,248:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:06:05,251:INFO:Starting cross validation
2025-03-05 12:06:05,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,288:INFO:Calculating mean and std
2025-03-05 12:06:05,289:INFO:Creating metrics dataframe
2025-03-05 12:06:05,290:INFO:Uploading results into container
2025-03-05 12:06:05,290:INFO:Uploading model into container now
2025-03-05 12:06:05,290:INFO:_master_model_container: 6
2025-03-05 12:06:05,290:INFO:_display_container: 2
2025-03-05 12:06:05,291:INFO:LassoLars(random_state=123)
2025-03-05 12:06:05,291:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,380:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,380:INFO:Creating metrics dataframe
2025-03-05 12:06:05,384:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:06:05,384:INFO:Total runtime is 0.09326079686482748 minutes
2025-03-05 12:06:05,386:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,387:INFO:Initializing create_model()
2025-03-05 12:06:05,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,387:INFO:Checking exceptions
2025-03-05 12:06:05,387:INFO:Importing libraries
2025-03-05 12:06:05,387:INFO:Copying training dataset
2025-03-05 12:06:05,389:INFO:Defining folds
2025-03-05 12:06:05,390:INFO:Declaring metric variables
2025-03-05 12:06:05,391:INFO:Importing untrained model
2025-03-05 12:06:05,393:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:06:05,396:INFO:Starting cross validation
2025-03-05 12:06:05,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,442:INFO:Calculating mean and std
2025-03-05 12:06:05,443:INFO:Creating metrics dataframe
2025-03-05 12:06:05,444:INFO:Uploading results into container
2025-03-05 12:06:05,445:INFO:Uploading model into container now
2025-03-05 12:06:05,445:INFO:_master_model_container: 7
2025-03-05 12:06:05,445:INFO:_display_container: 2
2025-03-05 12:06:05,445:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:06:05,445:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,547:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,547:INFO:Creating metrics dataframe
2025-03-05 12:06:05,552:INFO:Initializing Bayesian Ridge
2025-03-05 12:06:05,552:INFO:Total runtime is 0.09605356454849244 minutes
2025-03-05 12:06:05,554:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,554:INFO:Initializing create_model()
2025-03-05 12:06:05,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,554:INFO:Checking exceptions
2025-03-05 12:06:05,554:INFO:Importing libraries
2025-03-05 12:06:05,554:INFO:Copying training dataset
2025-03-05 12:06:05,557:INFO:Defining folds
2025-03-05 12:06:05,557:INFO:Declaring metric variables
2025-03-05 12:06:05,559:INFO:Importing untrained model
2025-03-05 12:06:05,561:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:06:05,564:INFO:Starting cross validation
2025-03-05 12:06:05,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,612:INFO:Calculating mean and std
2025-03-05 12:06:05,612:INFO:Creating metrics dataframe
2025-03-05 12:06:05,614:INFO:Uploading results into container
2025-03-05 12:06:05,614:INFO:Uploading model into container now
2025-03-05 12:06:05,614:INFO:_master_model_container: 8
2025-03-05 12:06:05,614:INFO:_display_container: 2
2025-03-05 12:06:05,614:INFO:BayesianRidge()
2025-03-05 12:06:05,614:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,701:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,701:INFO:Creating metrics dataframe
2025-03-05 12:06:05,706:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:06:05,706:INFO:Total runtime is 0.09862056573232016 minutes
2025-03-05 12:06:05,708:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,708:INFO:Initializing create_model()
2025-03-05 12:06:05,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,709:INFO:Checking exceptions
2025-03-05 12:06:05,709:INFO:Importing libraries
2025-03-05 12:06:05,709:INFO:Copying training dataset
2025-03-05 12:06:05,711:INFO:Defining folds
2025-03-05 12:06:05,711:INFO:Declaring metric variables
2025-03-05 12:06:05,713:INFO:Importing untrained model
2025-03-05 12:06:05,715:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:06:05,718:INFO:Starting cross validation
2025-03-05 12:06:05,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,776:INFO:Calculating mean and std
2025-03-05 12:06:05,776:INFO:Creating metrics dataframe
2025-03-05 12:06:05,777:INFO:Uploading results into container
2025-03-05 12:06:05,778:INFO:Uploading model into container now
2025-03-05 12:06:05,778:INFO:_master_model_container: 9
2025-03-05 12:06:05,778:INFO:_display_container: 2
2025-03-05 12:06:05,778:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:06:05,778:INFO:create_model() successfully completed......................................
2025-03-05 12:06:05,861:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:05,862:INFO:Creating metrics dataframe
2025-03-05 12:06:05,866:INFO:Initializing Huber Regressor
2025-03-05 12:06:05,866:INFO:Total runtime is 0.10128026803334554 minutes
2025-03-05 12:06:05,867:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:05,867:INFO:Initializing create_model()
2025-03-05 12:06:05,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:05,867:INFO:Checking exceptions
2025-03-05 12:06:05,867:INFO:Importing libraries
2025-03-05 12:06:05,868:INFO:Copying training dataset
2025-03-05 12:06:05,870:INFO:Defining folds
2025-03-05 12:06:05,870:INFO:Declaring metric variables
2025-03-05 12:06:05,872:INFO:Importing untrained model
2025-03-05 12:06:05,873:INFO:Huber Regressor Imported successfully
2025-03-05 12:06:05,876:INFO:Starting cross validation
2025-03-05 12:06:05,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:05,952:INFO:Calculating mean and std
2025-03-05 12:06:05,953:INFO:Creating metrics dataframe
2025-03-05 12:06:05,954:INFO:Uploading results into container
2025-03-05 12:06:05,954:INFO:Uploading model into container now
2025-03-05 12:06:05,955:INFO:_master_model_container: 10
2025-03-05 12:06:05,955:INFO:_display_container: 2
2025-03-05 12:06:05,955:INFO:HuberRegressor()
2025-03-05 12:06:05,955:INFO:create_model() successfully completed......................................
2025-03-05 12:06:06,043:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:06,043:INFO:Creating metrics dataframe
2025-03-05 12:06:06,048:INFO:Initializing K Neighbors Regressor
2025-03-05 12:06:06,048:INFO:Total runtime is 0.10431437095006307 minutes
2025-03-05 12:06:06,049:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:06,050:INFO:Initializing create_model()
2025-03-05 12:06:06,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:06,050:INFO:Checking exceptions
2025-03-05 12:06:06,050:INFO:Importing libraries
2025-03-05 12:06:06,050:INFO:Copying training dataset
2025-03-05 12:06:06,052:INFO:Defining folds
2025-03-05 12:06:06,052:INFO:Declaring metric variables
2025-03-05 12:06:06,054:INFO:Importing untrained model
2025-03-05 12:06:06,055:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:06:06,058:INFO:Starting cross validation
2025-03-05 12:06:06,059:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:06,138:INFO:Calculating mean and std
2025-03-05 12:06:06,139:INFO:Creating metrics dataframe
2025-03-05 12:06:06,141:INFO:Uploading results into container
2025-03-05 12:06:06,141:INFO:Uploading model into container now
2025-03-05 12:06:06,141:INFO:_master_model_container: 11
2025-03-05 12:06:06,142:INFO:_display_container: 2
2025-03-05 12:06:06,142:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:06:06,142:INFO:create_model() successfully completed......................................
2025-03-05 12:06:06,227:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:06,227:INFO:Creating metrics dataframe
2025-03-05 12:06:06,232:INFO:Initializing Decision Tree Regressor
2025-03-05 12:06:06,232:INFO:Total runtime is 0.1073866883913676 minutes
2025-03-05 12:06:06,234:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:06,234:INFO:Initializing create_model()
2025-03-05 12:06:06,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:06,234:INFO:Checking exceptions
2025-03-05 12:06:06,234:INFO:Importing libraries
2025-03-05 12:06:06,234:INFO:Copying training dataset
2025-03-05 12:06:06,237:INFO:Defining folds
2025-03-05 12:06:06,237:INFO:Declaring metric variables
2025-03-05 12:06:06,238:INFO:Importing untrained model
2025-03-05 12:06:06,240:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:06:06,243:INFO:Starting cross validation
2025-03-05 12:06:06,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:06,282:INFO:Calculating mean and std
2025-03-05 12:06:06,282:INFO:Creating metrics dataframe
2025-03-05 12:06:06,283:INFO:Uploading results into container
2025-03-05 12:06:06,284:INFO:Uploading model into container now
2025-03-05 12:06:06,284:INFO:_master_model_container: 12
2025-03-05 12:06:06,284:INFO:_display_container: 2
2025-03-05 12:06:06,284:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:06:06,284:INFO:create_model() successfully completed......................................
2025-03-05 12:06:06,372:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:06,372:INFO:Creating metrics dataframe
2025-03-05 12:06:06,377:INFO:Initializing Random Forest Regressor
2025-03-05 12:06:06,377:INFO:Total runtime is 0.10979750951131186 minutes
2025-03-05 12:06:06,378:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:06,378:INFO:Initializing create_model()
2025-03-05 12:06:06,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:06,379:INFO:Checking exceptions
2025-03-05 12:06:06,379:INFO:Importing libraries
2025-03-05 12:06:06,379:INFO:Copying training dataset
2025-03-05 12:06:06,381:INFO:Defining folds
2025-03-05 12:06:06,381:INFO:Declaring metric variables
2025-03-05 12:06:06,383:INFO:Importing untrained model
2025-03-05 12:06:06,384:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:06:06,387:INFO:Starting cross validation
2025-03-05 12:06:06,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:06,750:INFO:Calculating mean and std
2025-03-05 12:06:06,750:INFO:Creating metrics dataframe
2025-03-05 12:06:06,752:INFO:Uploading results into container
2025-03-05 12:06:06,753:INFO:Uploading model into container now
2025-03-05 12:06:06,753:INFO:_master_model_container: 13
2025-03-05 12:06:06,754:INFO:_display_container: 2
2025-03-05 12:06:06,754:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:06:06,754:INFO:create_model() successfully completed......................................
2025-03-05 12:06:06,842:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:06,842:INFO:Creating metrics dataframe
2025-03-05 12:06:06,846:INFO:Initializing Extra Trees Regressor
2025-03-05 12:06:06,846:INFO:Total runtime is 0.1176270882288615 minutes
2025-03-05 12:06:06,848:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:06,848:INFO:Initializing create_model()
2025-03-05 12:06:06,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:06,848:INFO:Checking exceptions
2025-03-05 12:06:06,848:INFO:Importing libraries
2025-03-05 12:06:06,848:INFO:Copying training dataset
2025-03-05 12:06:06,850:INFO:Defining folds
2025-03-05 12:06:06,850:INFO:Declaring metric variables
2025-03-05 12:06:06,852:INFO:Importing untrained model
2025-03-05 12:06:06,853:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:06:06,856:INFO:Starting cross validation
2025-03-05 12:06:06,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:07,142:INFO:Calculating mean and std
2025-03-05 12:06:07,143:INFO:Creating metrics dataframe
2025-03-05 12:06:07,145:INFO:Uploading results into container
2025-03-05 12:06:07,146:INFO:Uploading model into container now
2025-03-05 12:06:07,146:INFO:_master_model_container: 14
2025-03-05 12:06:07,146:INFO:_display_container: 2
2025-03-05 12:06:07,147:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:06:07,147:INFO:create_model() successfully completed......................................
2025-03-05 12:06:07,236:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:07,236:INFO:Creating metrics dataframe
2025-03-05 12:06:07,241:INFO:Initializing AdaBoost Regressor
2025-03-05 12:06:07,241:INFO:Total runtime is 0.12420616149902346 minutes
2025-03-05 12:06:07,243:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:07,243:INFO:Initializing create_model()
2025-03-05 12:06:07,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:07,243:INFO:Checking exceptions
2025-03-05 12:06:07,243:INFO:Importing libraries
2025-03-05 12:06:07,243:INFO:Copying training dataset
2025-03-05 12:06:07,245:INFO:Defining folds
2025-03-05 12:06:07,245:INFO:Declaring metric variables
2025-03-05 12:06:07,247:INFO:Importing untrained model
2025-03-05 12:06:07,248:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:06:07,251:INFO:Starting cross validation
2025-03-05 12:06:07,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:07,489:INFO:Calculating mean and std
2025-03-05 12:06:07,490:INFO:Creating metrics dataframe
2025-03-05 12:06:07,491:INFO:Uploading results into container
2025-03-05 12:06:07,491:INFO:Uploading model into container now
2025-03-05 12:06:07,492:INFO:_master_model_container: 15
2025-03-05 12:06:07,492:INFO:_display_container: 2
2025-03-05 12:06:07,492:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:06:07,492:INFO:create_model() successfully completed......................................
2025-03-05 12:06:07,575:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:07,575:INFO:Creating metrics dataframe
2025-03-05 12:06:07,580:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:06:07,580:INFO:Total runtime is 0.12984599272410077 minutes
2025-03-05 12:06:07,581:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:07,581:INFO:Initializing create_model()
2025-03-05 12:06:07,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:07,581:INFO:Checking exceptions
2025-03-05 12:06:07,581:INFO:Importing libraries
2025-03-05 12:06:07,581:INFO:Copying training dataset
2025-03-05 12:06:07,584:INFO:Defining folds
2025-03-05 12:06:07,584:INFO:Declaring metric variables
2025-03-05 12:06:07,585:INFO:Importing untrained model
2025-03-05 12:06:07,587:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:06:07,589:INFO:Starting cross validation
2025-03-05 12:06:07,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:06:08,002:INFO:Calculating mean and std
2025-03-05 12:06:08,003:INFO:Creating metrics dataframe
2025-03-05 12:06:08,005:INFO:Uploading results into container
2025-03-05 12:06:08,005:INFO:Uploading model into container now
2025-03-05 12:06:08,005:INFO:_master_model_container: 16
2025-03-05 12:06:08,005:INFO:_display_container: 2
2025-03-05 12:06:08,005:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:06:08,005:INFO:create_model() successfully completed......................................
2025-03-05 12:06:08,088:INFO:SubProcess create_model() end ==================================
2025-03-05 12:06:08,088:INFO:Creating metrics dataframe
2025-03-05 12:06:08,093:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:06:08,093:INFO:Total runtime is 0.13839810689290366 minutes
2025-03-05 12:06:08,094:INFO:SubProcess create_model() called ==================================
2025-03-05 12:06:08,094:INFO:Initializing create_model()
2025-03-05 12:06:08,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c390be80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3c8282670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:06:08,094:INFO:Checking exceptions
2025-03-05 12:06:08,094:INFO:Importing libraries
2025-03-05 12:06:08,094:INFO:Copying training dataset
2025-03-05 12:06:08,097:INFO:Defining folds
2025-03-05 12:06:08,097:INFO:Declaring metric variables
2025-03-05 12:06:08,098:INFO:Importing untrained model
2025-03-05 12:06:08,100:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:06:08,102:INFO:Starting cross validation
2025-03-05 12:06:08,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:08:57,311:INFO:PyCaret RegressionExperiment
2025-03-05 12:08:57,311:INFO:Logging name: reg-default-name
2025-03-05 12:08:57,311:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:08:57,311:INFO:version 3.3.1
2025-03-05 12:08:57,311:INFO:Initializing setup()
2025-03-05 12:08:57,311:INFO:self.USI: 13fd
2025-03-05 12:08:57,311:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 12:08:57,311:INFO:Checking environment
2025-03-05 12:08:57,311:INFO:python_version: 3.9.21
2025-03-05 12:08:57,311:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:08:57,311:INFO:machine: x86_64
2025-03-05 12:08:57,311:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:08:57,311:INFO:Memory: svmem(total=33374507008, available=18272391168, percent=45.3, used=12422963200, free=4622008320, active=15812911104, inactive=8616181760, buffers=610197504, cached=15719337984, shared=2150064128, slab=1736151040)
2025-03-05 12:08:57,312:INFO:Physical Core: 24
2025-03-05 12:08:57,312:INFO:Logical Core: 32
2025-03-05 12:08:57,312:INFO:Checking libraries
2025-03-05 12:08:57,312:INFO:System:
2025-03-05 12:08:57,312:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:08:57,312:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:08:57,312:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:08:57,312:INFO:PyCaret required dependencies:
2025-03-05 12:08:57,312:INFO:                 pip: 25.0
2025-03-05 12:08:57,312:INFO:          setuptools: 75.8.0
2025-03-05 12:08:57,312:INFO:             pycaret: 3.3.1
2025-03-05 12:08:57,312:INFO:             IPython: 8.18.1
2025-03-05 12:08:57,312:INFO:          ipywidgets: 8.1.5
2025-03-05 12:08:57,312:INFO:                tqdm: 4.67.1
2025-03-05 12:08:57,312:INFO:               numpy: 1.26.4
2025-03-05 12:08:57,312:INFO:              pandas: 2.1.4
2025-03-05 12:08:57,312:INFO:              jinja2: 3.1.5
2025-03-05 12:08:57,312:INFO:               scipy: 1.11.4
2025-03-05 12:08:57,312:INFO:              joblib: 1.3.2
2025-03-05 12:08:57,312:INFO:             sklearn: 1.4.2
2025-03-05 12:08:57,312:INFO:                pyod: 2.0.3
2025-03-05 12:08:57,312:INFO:            imblearn: 0.12.4
2025-03-05 12:08:57,312:INFO:   category_encoders: 2.6.4
2025-03-05 12:08:57,312:INFO:            lightgbm: 4.6.0
2025-03-05 12:08:57,312:INFO:               numba: 0.60.0
2025-03-05 12:08:57,312:INFO:            requests: 2.32.3
2025-03-05 12:08:57,312:INFO:          matplotlib: 3.7.5
2025-03-05 12:08:57,312:INFO:          scikitplot: 0.3.7
2025-03-05 12:08:57,312:INFO:         yellowbrick: 1.5
2025-03-05 12:08:57,312:INFO:              plotly: 5.24.1
2025-03-05 12:08:57,312:INFO:    plotly-resampler: Not installed
2025-03-05 12:08:57,312:INFO:             kaleido: 0.2.1
2025-03-05 12:08:57,312:INFO:           schemdraw: 0.15
2025-03-05 12:08:57,312:INFO:         statsmodels: 0.14.4
2025-03-05 12:08:57,312:INFO:              sktime: 0.26.0
2025-03-05 12:08:57,312:INFO:               tbats: 1.1.3
2025-03-05 12:08:57,312:INFO:            pmdarima: 2.0.4
2025-03-05 12:08:57,312:INFO:              psutil: 7.0.0
2025-03-05 12:08:57,312:INFO:          markupsafe: 3.0.2
2025-03-05 12:08:57,312:INFO:             pickle5: Not installed
2025-03-05 12:08:57,312:INFO:         cloudpickle: 3.1.1
2025-03-05 12:08:57,312:INFO:         deprecation: 2.1.0
2025-03-05 12:08:57,312:INFO:              xxhash: 3.5.0
2025-03-05 12:08:57,312:INFO:           wurlitzer: 3.1.1
2025-03-05 12:08:57,312:INFO:PyCaret optional dependencies:
2025-03-05 12:08:57,312:INFO:                shap: Not installed
2025-03-05 12:08:57,312:INFO:           interpret: Not installed
2025-03-05 12:08:57,312:INFO:                umap: Not installed
2025-03-05 12:08:57,312:INFO:     ydata_profiling: Not installed
2025-03-05 12:08:57,312:INFO:  explainerdashboard: Not installed
2025-03-05 12:08:57,312:INFO:             autoviz: Not installed
2025-03-05 12:08:57,312:INFO:           fairlearn: Not installed
2025-03-05 12:08:57,312:INFO:          deepchecks: Not installed
2025-03-05 12:08:57,312:INFO:             xgboost: Not installed
2025-03-05 12:08:57,312:INFO:            catboost: Not installed
2025-03-05 12:08:57,312:INFO:              kmodes: Not installed
2025-03-05 12:08:57,312:INFO:             mlxtend: Not installed
2025-03-05 12:08:57,312:INFO:       statsforecast: Not installed
2025-03-05 12:08:57,312:INFO:        tune_sklearn: Not installed
2025-03-05 12:08:57,312:INFO:                 ray: Not installed
2025-03-05 12:08:57,312:INFO:            hyperopt: Not installed
2025-03-05 12:08:57,312:INFO:              optuna: Not installed
2025-03-05 12:08:57,312:INFO:               skopt: Not installed
2025-03-05 12:08:57,312:INFO:              mlflow: Not installed
2025-03-05 12:08:57,312:INFO:              gradio: Not installed
2025-03-05 12:08:57,312:INFO:             fastapi: Not installed
2025-03-05 12:08:57,312:INFO:             uvicorn: Not installed
2025-03-05 12:08:57,312:INFO:              m2cgen: Not installed
2025-03-05 12:08:57,312:INFO:           evidently: Not installed
2025-03-05 12:08:57,312:INFO:               fugue: Not installed
2025-03-05 12:08:57,312:INFO:           streamlit: Not installed
2025-03-05 12:08:57,312:INFO:             prophet: Not installed
2025-03-05 12:08:57,312:INFO:None
2025-03-05 12:08:57,312:INFO:Set up data.
2025-03-05 12:09:09,303:INFO:PyCaret RegressionExperiment
2025-03-05 12:09:09,303:INFO:Logging name: reg-default-name
2025-03-05 12:09:09,303:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:09:09,303:INFO:version 3.3.1
2025-03-05 12:09:09,303:INFO:Initializing setup()
2025-03-05 12:09:09,303:INFO:self.USI: 521d
2025-03-05 12:09:09,303:INFO:self._variable_keys: {'X_test', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'transform_target_param', 'y_train', 'exp_id', 'data', 'seed', 'html_param', 'target_param', 'fold_generator', 'gpu_param', 'X_train', 'log_plots_param', 'exp_name_log', 'idx', 'y', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'logging_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'X'}
2025-03-05 12:09:09,303:INFO:Checking environment
2025-03-05 12:09:09,303:INFO:python_version: 3.9.21
2025-03-05 12:09:09,303:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:09:09,303:INFO:machine: x86_64
2025-03-05 12:09:09,303:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:09:09,303:INFO:Memory: svmem(total=33374507008, available=18289786880, percent=45.2, used=12385681408, free=4638945280, active=15787220992, inactive=8616378368, buffers=610275328, cached=15739604992, shared=2169950208, slab=1735974912)
2025-03-05 12:09:09,304:INFO:Physical Core: 24
2025-03-05 12:09:09,304:INFO:Logical Core: 32
2025-03-05 12:09:09,304:INFO:Checking libraries
2025-03-05 12:09:09,304:INFO:System:
2025-03-05 12:09:09,304:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:09:09,304:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:09:09,304:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:09:09,304:INFO:PyCaret required dependencies:
2025-03-05 12:09:09,304:INFO:                 pip: 25.0
2025-03-05 12:09:09,304:INFO:          setuptools: 75.8.0
2025-03-05 12:09:09,304:INFO:             pycaret: 3.3.1
2025-03-05 12:09:09,304:INFO:             IPython: 8.18.1
2025-03-05 12:09:09,304:INFO:          ipywidgets: 8.1.5
2025-03-05 12:09:09,304:INFO:                tqdm: 4.67.1
2025-03-05 12:09:09,304:INFO:               numpy: 1.26.4
2025-03-05 12:09:09,304:INFO:              pandas: 2.1.4
2025-03-05 12:09:09,304:INFO:              jinja2: 3.1.5
2025-03-05 12:09:09,304:INFO:               scipy: 1.11.4
2025-03-05 12:09:09,304:INFO:              joblib: 1.3.2
2025-03-05 12:09:09,304:INFO:             sklearn: 1.4.2
2025-03-05 12:09:09,304:INFO:                pyod: 2.0.3
2025-03-05 12:09:09,304:INFO:            imblearn: 0.12.4
2025-03-05 12:09:09,304:INFO:   category_encoders: 2.6.4
2025-03-05 12:09:09,304:INFO:            lightgbm: 4.6.0
2025-03-05 12:09:09,304:INFO:               numba: 0.60.0
2025-03-05 12:09:09,304:INFO:            requests: 2.32.3
2025-03-05 12:09:09,304:INFO:          matplotlib: 3.7.5
2025-03-05 12:09:09,304:INFO:          scikitplot: 0.3.7
2025-03-05 12:09:09,304:INFO:         yellowbrick: 1.5
2025-03-05 12:09:09,304:INFO:              plotly: 5.24.1
2025-03-05 12:09:09,304:INFO:    plotly-resampler: Not installed
2025-03-05 12:09:09,304:INFO:             kaleido: 0.2.1
2025-03-05 12:09:09,304:INFO:           schemdraw: 0.15
2025-03-05 12:09:09,304:INFO:         statsmodels: 0.14.4
2025-03-05 12:09:09,304:INFO:              sktime: 0.26.0
2025-03-05 12:09:09,304:INFO:               tbats: 1.1.3
2025-03-05 12:09:09,304:INFO:            pmdarima: 2.0.4
2025-03-05 12:09:09,304:INFO:              psutil: 7.0.0
2025-03-05 12:09:09,304:INFO:          markupsafe: 3.0.2
2025-03-05 12:09:09,304:INFO:             pickle5: Not installed
2025-03-05 12:09:09,304:INFO:         cloudpickle: 3.1.1
2025-03-05 12:09:09,304:INFO:         deprecation: 2.1.0
2025-03-05 12:09:09,304:INFO:              xxhash: 3.5.0
2025-03-05 12:09:09,304:INFO:           wurlitzer: 3.1.1
2025-03-05 12:09:09,304:INFO:PyCaret optional dependencies:
2025-03-05 12:09:09,304:INFO:                shap: Not installed
2025-03-05 12:09:09,304:INFO:           interpret: Not installed
2025-03-05 12:09:09,304:INFO:                umap: Not installed
2025-03-05 12:09:09,304:INFO:     ydata_profiling: Not installed
2025-03-05 12:09:09,304:INFO:  explainerdashboard: Not installed
2025-03-05 12:09:09,304:INFO:             autoviz: Not installed
2025-03-05 12:09:09,304:INFO:           fairlearn: Not installed
2025-03-05 12:09:09,304:INFO:          deepchecks: Not installed
2025-03-05 12:09:09,304:INFO:             xgboost: Not installed
2025-03-05 12:09:09,304:INFO:            catboost: Not installed
2025-03-05 12:09:09,304:INFO:              kmodes: Not installed
2025-03-05 12:09:09,304:INFO:             mlxtend: Not installed
2025-03-05 12:09:09,304:INFO:       statsforecast: Not installed
2025-03-05 12:09:09,304:INFO:        tune_sklearn: Not installed
2025-03-05 12:09:09,304:INFO:                 ray: Not installed
2025-03-05 12:09:09,304:INFO:            hyperopt: Not installed
2025-03-05 12:09:09,304:INFO:              optuna: Not installed
2025-03-05 12:09:09,304:INFO:               skopt: Not installed
2025-03-05 12:09:09,304:INFO:              mlflow: Not installed
2025-03-05 12:09:09,304:INFO:              gradio: Not installed
2025-03-05 12:09:09,304:INFO:             fastapi: Not installed
2025-03-05 12:09:09,304:INFO:             uvicorn: Not installed
2025-03-05 12:09:09,304:INFO:              m2cgen: Not installed
2025-03-05 12:09:09,304:INFO:           evidently: Not installed
2025-03-05 12:09:09,304:INFO:               fugue: Not installed
2025-03-05 12:09:09,304:INFO:           streamlit: Not installed
2025-03-05 12:09:09,304:INFO:             prophet: Not installed
2025-03-05 12:09:09,304:INFO:None
2025-03-05 12:09:09,304:INFO:Set up data.
2025-03-05 12:09:09,307:INFO:Set up folding strategy.
2025-03-05 12:09:09,307:INFO:Set up train/test split.
2025-03-05 12:09:09,308:INFO:Set up index.
2025-03-05 12:09:09,308:INFO:Assigning column types.
2025-03-05 12:09:09,310:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:09:09,310:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,354:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,356:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,358:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,400:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:09:09,402:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,451:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,454:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,516:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:09:09,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,620:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:09:09,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,671:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,719:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:09:09,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:09:09,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,813:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:09:09,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,907:INFO:Preparing preprocessing pipeline...
2025-03-05 12:09:09,907:INFO:Set up simple imputation.
2025-03-05 12:09:09,908:INFO:Set up column name cleaning.
2025-03-05 12:09:09,916:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:09:09,918:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:09:09,918:INFO:Creating final display dataframe.
2025-03-05 12:09:09,946:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              521d
2025-03-05 12:09:09,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:09,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:10,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:10,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:09:10,041:INFO:setup() successfully completed in 0.74s...............
2025-03-05 12:09:16,802:INFO:Initializing compare_models()
2025-03-05 12:09:16,802:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:09:16,802:INFO:Checking exceptions
2025-03-05 12:09:16,803:INFO:Preparing display monitor
2025-03-05 12:09:16,817:INFO:Initializing Linear Regression
2025-03-05 12:09:16,818:INFO:Total runtime is 2.0345052083333333e-06 minutes
2025-03-05 12:09:16,820:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:16,820:INFO:Initializing create_model()
2025-03-05 12:09:16,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:16,820:INFO:Checking exceptions
2025-03-05 12:09:16,820:INFO:Importing libraries
2025-03-05 12:09:16,820:INFO:Copying training dataset
2025-03-05 12:09:16,824:INFO:Defining folds
2025-03-05 12:09:16,824:INFO:Declaring metric variables
2025-03-05 12:09:16,826:INFO:Importing untrained model
2025-03-05 12:09:16,828:INFO:Linear Regression Imported successfully
2025-03-05 12:09:16,830:INFO:Starting cross validation
2025-03-05 12:09:16,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:18,480:INFO:Calculating mean and std
2025-03-05 12:09:18,481:INFO:Creating metrics dataframe
2025-03-05 12:09:18,483:INFO:Uploading results into container
2025-03-05 12:09:18,483:INFO:Uploading model into container now
2025-03-05 12:09:18,483:INFO:_master_model_container: 1
2025-03-05 12:09:18,483:INFO:_display_container: 2
2025-03-05 12:09:18,484:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:09:18,484:INFO:create_model() successfully completed......................................
2025-03-05 12:09:18,581:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:18,581:INFO:Creating metrics dataframe
2025-03-05 12:09:18,584:INFO:Initializing Lasso Regression
2025-03-05 12:09:18,584:INFO:Total runtime is 0.02944845755894979 minutes
2025-03-05 12:09:18,586:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:18,586:INFO:Initializing create_model()
2025-03-05 12:09:18,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:18,586:INFO:Checking exceptions
2025-03-05 12:09:18,586:INFO:Importing libraries
2025-03-05 12:09:18,586:INFO:Copying training dataset
2025-03-05 12:09:18,588:INFO:Defining folds
2025-03-05 12:09:18,589:INFO:Declaring metric variables
2025-03-05 12:09:18,590:INFO:Importing untrained model
2025-03-05 12:09:18,591:INFO:Lasso Regression Imported successfully
2025-03-05 12:09:18,594:INFO:Starting cross validation
2025-03-05 12:09:18,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:19,844:INFO:Calculating mean and std
2025-03-05 12:09:19,845:INFO:Creating metrics dataframe
2025-03-05 12:09:19,846:INFO:Uploading results into container
2025-03-05 12:09:19,846:INFO:Uploading model into container now
2025-03-05 12:09:19,846:INFO:_master_model_container: 2
2025-03-05 12:09:19,847:INFO:_display_container: 2
2025-03-05 12:09:19,847:INFO:Lasso(random_state=123)
2025-03-05 12:09:19,847:INFO:create_model() successfully completed......................................
2025-03-05 12:09:19,935:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:19,935:INFO:Creating metrics dataframe
2025-03-05 12:09:19,939:INFO:Initializing Ridge Regression
2025-03-05 12:09:19,939:INFO:Total runtime is 0.05202960173288981 minutes
2025-03-05 12:09:19,941:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:19,941:INFO:Initializing create_model()
2025-03-05 12:09:19,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:19,941:INFO:Checking exceptions
2025-03-05 12:09:19,941:INFO:Importing libraries
2025-03-05 12:09:19,941:INFO:Copying training dataset
2025-03-05 12:09:19,943:INFO:Defining folds
2025-03-05 12:09:19,943:INFO:Declaring metric variables
2025-03-05 12:09:19,945:INFO:Importing untrained model
2025-03-05 12:09:19,946:INFO:Ridge Regression Imported successfully
2025-03-05 12:09:19,949:INFO:Starting cross validation
2025-03-05 12:09:19,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:21,208:INFO:Calculating mean and std
2025-03-05 12:09:21,209:INFO:Creating metrics dataframe
2025-03-05 12:09:21,210:INFO:Uploading results into container
2025-03-05 12:09:21,210:INFO:Uploading model into container now
2025-03-05 12:09:21,211:INFO:_master_model_container: 3
2025-03-05 12:09:21,211:INFO:_display_container: 2
2025-03-05 12:09:21,211:INFO:Ridge(random_state=123)
2025-03-05 12:09:21,211:INFO:create_model() successfully completed......................................
2025-03-05 12:09:21,292:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:21,292:INFO:Creating metrics dataframe
2025-03-05 12:09:21,296:INFO:Initializing Elastic Net
2025-03-05 12:09:21,296:INFO:Total runtime is 0.0746386726697286 minutes
2025-03-05 12:09:21,297:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:21,297:INFO:Initializing create_model()
2025-03-05 12:09:21,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:21,297:INFO:Checking exceptions
2025-03-05 12:09:21,298:INFO:Importing libraries
2025-03-05 12:09:21,298:INFO:Copying training dataset
2025-03-05 12:09:21,300:INFO:Defining folds
2025-03-05 12:09:21,300:INFO:Declaring metric variables
2025-03-05 12:09:21,301:INFO:Importing untrained model
2025-03-05 12:09:21,303:INFO:Elastic Net Imported successfully
2025-03-05 12:09:21,306:INFO:Starting cross validation
2025-03-05 12:09:21,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:21,959:INFO:Calculating mean and std
2025-03-05 12:09:21,960:INFO:Creating metrics dataframe
2025-03-05 12:09:21,962:INFO:Uploading results into container
2025-03-05 12:09:21,963:INFO:Uploading model into container now
2025-03-05 12:09:21,963:INFO:_master_model_container: 4
2025-03-05 12:09:21,963:INFO:_display_container: 2
2025-03-05 12:09:21,963:INFO:ElasticNet(random_state=123)
2025-03-05 12:09:21,963:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,049:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,049:INFO:Creating metrics dataframe
2025-03-05 12:09:22,053:INFO:Initializing Least Angle Regression
2025-03-05 12:09:22,054:INFO:Total runtime is 0.08726859887440999 minutes
2025-03-05 12:09:22,055:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,056:INFO:Initializing create_model()
2025-03-05 12:09:22,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,056:INFO:Checking exceptions
2025-03-05 12:09:22,056:INFO:Importing libraries
2025-03-05 12:09:22,056:INFO:Copying training dataset
2025-03-05 12:09:22,058:INFO:Defining folds
2025-03-05 12:09:22,058:INFO:Declaring metric variables
2025-03-05 12:09:22,059:INFO:Importing untrained model
2025-03-05 12:09:22,061:INFO:Least Angle Regression Imported successfully
2025-03-05 12:09:22,065:INFO:Starting cross validation
2025-03-05 12:09:22,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,103:INFO:Calculating mean and std
2025-03-05 12:09:22,103:INFO:Creating metrics dataframe
2025-03-05 12:09:22,104:INFO:Uploading results into container
2025-03-05 12:09:22,104:INFO:Uploading model into container now
2025-03-05 12:09:22,104:INFO:_master_model_container: 5
2025-03-05 12:09:22,104:INFO:_display_container: 2
2025-03-05 12:09:22,105:INFO:Lars(random_state=123)
2025-03-05 12:09:22,105:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,186:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,186:INFO:Creating metrics dataframe
2025-03-05 12:09:22,190:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:09:22,190:INFO:Total runtime is 0.08954476912816366 minutes
2025-03-05 12:09:22,192:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,192:INFO:Initializing create_model()
2025-03-05 12:09:22,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,192:INFO:Checking exceptions
2025-03-05 12:09:22,192:INFO:Importing libraries
2025-03-05 12:09:22,192:INFO:Copying training dataset
2025-03-05 12:09:22,195:INFO:Defining folds
2025-03-05 12:09:22,195:INFO:Declaring metric variables
2025-03-05 12:09:22,197:INFO:Importing untrained model
2025-03-05 12:09:22,198:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:09:22,201:INFO:Starting cross validation
2025-03-05 12:09:22,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,248:INFO:Calculating mean and std
2025-03-05 12:09:22,248:INFO:Creating metrics dataframe
2025-03-05 12:09:22,249:INFO:Uploading results into container
2025-03-05 12:09:22,249:INFO:Uploading model into container now
2025-03-05 12:09:22,249:INFO:_master_model_container: 6
2025-03-05 12:09:22,249:INFO:_display_container: 2
2025-03-05 12:09:22,250:INFO:LassoLars(random_state=123)
2025-03-05 12:09:22,250:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,330:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,330:INFO:Creating metrics dataframe
2025-03-05 12:09:22,334:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:09:22,334:INFO:Total runtime is 0.09194354216257732 minutes
2025-03-05 12:09:22,336:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,336:INFO:Initializing create_model()
2025-03-05 12:09:22,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,336:INFO:Checking exceptions
2025-03-05 12:09:22,336:INFO:Importing libraries
2025-03-05 12:09:22,336:INFO:Copying training dataset
2025-03-05 12:09:22,339:INFO:Defining folds
2025-03-05 12:09:22,339:INFO:Declaring metric variables
2025-03-05 12:09:22,341:INFO:Importing untrained model
2025-03-05 12:09:22,344:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:09:22,347:INFO:Starting cross validation
2025-03-05 12:09:22,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,385:INFO:Calculating mean and std
2025-03-05 12:09:22,386:INFO:Creating metrics dataframe
2025-03-05 12:09:22,387:INFO:Uploading results into container
2025-03-05 12:09:22,387:INFO:Uploading model into container now
2025-03-05 12:09:22,387:INFO:_master_model_container: 7
2025-03-05 12:09:22,387:INFO:_display_container: 2
2025-03-05 12:09:22,387:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:09:22,387:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,468:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,468:INFO:Creating metrics dataframe
2025-03-05 12:09:22,472:INFO:Initializing Bayesian Ridge
2025-03-05 12:09:22,472:INFO:Total runtime is 0.09425013462702433 minutes
2025-03-05 12:09:22,474:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,474:INFO:Initializing create_model()
2025-03-05 12:09:22,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,474:INFO:Checking exceptions
2025-03-05 12:09:22,474:INFO:Importing libraries
2025-03-05 12:09:22,474:INFO:Copying training dataset
2025-03-05 12:09:22,477:INFO:Defining folds
2025-03-05 12:09:22,477:INFO:Declaring metric variables
2025-03-05 12:09:22,478:INFO:Importing untrained model
2025-03-05 12:09:22,480:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:09:22,483:INFO:Starting cross validation
2025-03-05 12:09:22,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,520:INFO:Calculating mean and std
2025-03-05 12:09:22,520:INFO:Creating metrics dataframe
2025-03-05 12:09:22,521:INFO:Uploading results into container
2025-03-05 12:09:22,522:INFO:Uploading model into container now
2025-03-05 12:09:22,522:INFO:_master_model_container: 8
2025-03-05 12:09:22,522:INFO:_display_container: 2
2025-03-05 12:09:22,522:INFO:BayesianRidge()
2025-03-05 12:09:22,522:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,602:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,602:INFO:Creating metrics dataframe
2025-03-05 12:09:22,607:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:09:22,607:INFO:Total runtime is 0.09648839632670085 minutes
2025-03-05 12:09:22,608:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,609:INFO:Initializing create_model()
2025-03-05 12:09:22,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,609:INFO:Checking exceptions
2025-03-05 12:09:22,609:INFO:Importing libraries
2025-03-05 12:09:22,609:INFO:Copying training dataset
2025-03-05 12:09:22,611:INFO:Defining folds
2025-03-05 12:09:22,612:INFO:Declaring metric variables
2025-03-05 12:09:22,613:INFO:Importing untrained model
2025-03-05 12:09:22,615:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:09:22,618:INFO:Starting cross validation
2025-03-05 12:09:22,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,665:INFO:Calculating mean and std
2025-03-05 12:09:22,666:INFO:Creating metrics dataframe
2025-03-05 12:09:22,667:INFO:Uploading results into container
2025-03-05 12:09:22,667:INFO:Uploading model into container now
2025-03-05 12:09:22,667:INFO:_master_model_container: 9
2025-03-05 12:09:22,667:INFO:_display_container: 2
2025-03-05 12:09:22,667:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:09:22,668:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,749:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,749:INFO:Creating metrics dataframe
2025-03-05 12:09:22,754:INFO:Initializing Huber Regressor
2025-03-05 12:09:22,754:INFO:Total runtime is 0.09894500573476156 minutes
2025-03-05 12:09:22,756:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,756:INFO:Initializing create_model()
2025-03-05 12:09:22,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,756:INFO:Checking exceptions
2025-03-05 12:09:22,756:INFO:Importing libraries
2025-03-05 12:09:22,756:INFO:Copying training dataset
2025-03-05 12:09:22,759:INFO:Defining folds
2025-03-05 12:09:22,759:INFO:Declaring metric variables
2025-03-05 12:09:22,762:INFO:Importing untrained model
2025-03-05 12:09:22,764:INFO:Huber Regressor Imported successfully
2025-03-05 12:09:22,767:INFO:Starting cross validation
2025-03-05 12:09:22,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:22,866:INFO:Calculating mean and std
2025-03-05 12:09:22,866:INFO:Creating metrics dataframe
2025-03-05 12:09:22,868:INFO:Uploading results into container
2025-03-05 12:09:22,868:INFO:Uploading model into container now
2025-03-05 12:09:22,868:INFO:_master_model_container: 10
2025-03-05 12:09:22,868:INFO:_display_container: 2
2025-03-05 12:09:22,868:INFO:HuberRegressor()
2025-03-05 12:09:22,869:INFO:create_model() successfully completed......................................
2025-03-05 12:09:22,953:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:22,953:INFO:Creating metrics dataframe
2025-03-05 12:09:22,957:INFO:Initializing K Neighbors Regressor
2025-03-05 12:09:22,957:INFO:Total runtime is 0.10233388344446818 minutes
2025-03-05 12:09:22,959:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:22,959:INFO:Initializing create_model()
2025-03-05 12:09:22,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:22,959:INFO:Checking exceptions
2025-03-05 12:09:22,959:INFO:Importing libraries
2025-03-05 12:09:22,959:INFO:Copying training dataset
2025-03-05 12:09:22,961:INFO:Defining folds
2025-03-05 12:09:22,961:INFO:Declaring metric variables
2025-03-05 12:09:22,963:INFO:Importing untrained model
2025-03-05 12:09:22,964:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:09:22,967:INFO:Starting cross validation
2025-03-05 12:09:22,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:23,035:INFO:Calculating mean and std
2025-03-05 12:09:23,035:INFO:Creating metrics dataframe
2025-03-05 12:09:23,037:INFO:Uploading results into container
2025-03-05 12:09:23,037:INFO:Uploading model into container now
2025-03-05 12:09:23,038:INFO:_master_model_container: 11
2025-03-05 12:09:23,038:INFO:_display_container: 2
2025-03-05 12:09:23,038:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:09:23,038:INFO:create_model() successfully completed......................................
2025-03-05 12:09:23,117:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:23,118:INFO:Creating metrics dataframe
2025-03-05 12:09:23,122:INFO:Initializing Decision Tree Regressor
2025-03-05 12:09:23,122:INFO:Total runtime is 0.10507755676905314 minutes
2025-03-05 12:09:23,124:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:23,124:INFO:Initializing create_model()
2025-03-05 12:09:23,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:23,124:INFO:Checking exceptions
2025-03-05 12:09:23,124:INFO:Importing libraries
2025-03-05 12:09:23,124:INFO:Copying training dataset
2025-03-05 12:09:23,126:INFO:Defining folds
2025-03-05 12:09:23,126:INFO:Declaring metric variables
2025-03-05 12:09:23,128:INFO:Importing untrained model
2025-03-05 12:09:23,129:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:09:23,132:INFO:Starting cross validation
2025-03-05 12:09:23,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:23,178:INFO:Calculating mean and std
2025-03-05 12:09:23,179:INFO:Creating metrics dataframe
2025-03-05 12:09:23,180:INFO:Uploading results into container
2025-03-05 12:09:23,180:INFO:Uploading model into container now
2025-03-05 12:09:23,181:INFO:_master_model_container: 12
2025-03-05 12:09:23,181:INFO:_display_container: 2
2025-03-05 12:09:23,181:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:09:23,181:INFO:create_model() successfully completed......................................
2025-03-05 12:09:23,259:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:23,259:INFO:Creating metrics dataframe
2025-03-05 12:09:23,263:INFO:Initializing Random Forest Regressor
2025-03-05 12:09:23,264:INFO:Total runtime is 0.10743486086527507 minutes
2025-03-05 12:09:23,265:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:23,265:INFO:Initializing create_model()
2025-03-05 12:09:23,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:23,265:INFO:Checking exceptions
2025-03-05 12:09:23,265:INFO:Importing libraries
2025-03-05 12:09:23,265:INFO:Copying training dataset
2025-03-05 12:09:23,268:INFO:Defining folds
2025-03-05 12:09:23,268:INFO:Declaring metric variables
2025-03-05 12:09:23,269:INFO:Importing untrained model
2025-03-05 12:09:23,271:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:09:23,273:INFO:Starting cross validation
2025-03-05 12:09:23,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:23,627:INFO:Calculating mean and std
2025-03-05 12:09:23,628:INFO:Creating metrics dataframe
2025-03-05 12:09:23,630:INFO:Uploading results into container
2025-03-05 12:09:23,630:INFO:Uploading model into container now
2025-03-05 12:09:23,631:INFO:_master_model_container: 13
2025-03-05 12:09:23,631:INFO:_display_container: 2
2025-03-05 12:09:23,631:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:09:23,631:INFO:create_model() successfully completed......................................
2025-03-05 12:09:23,715:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:23,715:INFO:Creating metrics dataframe
2025-03-05 12:09:23,720:INFO:Initializing Extra Trees Regressor
2025-03-05 12:09:23,720:INFO:Total runtime is 0.11504358450571696 minutes
2025-03-05 12:09:23,721:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:23,722:INFO:Initializing create_model()
2025-03-05 12:09:23,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:23,722:INFO:Checking exceptions
2025-03-05 12:09:23,722:INFO:Importing libraries
2025-03-05 12:09:23,722:INFO:Copying training dataset
2025-03-05 12:09:23,724:INFO:Defining folds
2025-03-05 12:09:23,724:INFO:Declaring metric variables
2025-03-05 12:09:23,725:INFO:Importing untrained model
2025-03-05 12:09:23,727:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:09:23,729:INFO:Starting cross validation
2025-03-05 12:09:23,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:24,001:INFO:Calculating mean and std
2025-03-05 12:09:24,003:INFO:Creating metrics dataframe
2025-03-05 12:09:24,005:INFO:Uploading results into container
2025-03-05 12:09:24,005:INFO:Uploading model into container now
2025-03-05 12:09:24,005:INFO:_master_model_container: 14
2025-03-05 12:09:24,005:INFO:_display_container: 2
2025-03-05 12:09:24,006:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:09:24,006:INFO:create_model() successfully completed......................................
2025-03-05 12:09:24,093:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:24,093:INFO:Creating metrics dataframe
2025-03-05 12:09:24,097:INFO:Initializing AdaBoost Regressor
2025-03-05 12:09:24,097:INFO:Total runtime is 0.12133211692174276 minutes
2025-03-05 12:09:24,099:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:24,099:INFO:Initializing create_model()
2025-03-05 12:09:24,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:24,099:INFO:Checking exceptions
2025-03-05 12:09:24,099:INFO:Importing libraries
2025-03-05 12:09:24,099:INFO:Copying training dataset
2025-03-05 12:09:24,101:INFO:Defining folds
2025-03-05 12:09:24,101:INFO:Declaring metric variables
2025-03-05 12:09:24,103:INFO:Importing untrained model
2025-03-05 12:09:24,104:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:09:24,107:INFO:Starting cross validation
2025-03-05 12:09:24,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:24,355:INFO:Calculating mean and std
2025-03-05 12:09:24,356:INFO:Creating metrics dataframe
2025-03-05 12:09:24,357:INFO:Uploading results into container
2025-03-05 12:09:24,357:INFO:Uploading model into container now
2025-03-05 12:09:24,357:INFO:_master_model_container: 15
2025-03-05 12:09:24,357:INFO:_display_container: 2
2025-03-05 12:09:24,357:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:09:24,357:INFO:create_model() successfully completed......................................
2025-03-05 12:09:24,438:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:24,438:INFO:Creating metrics dataframe
2025-03-05 12:09:24,443:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:09:24,443:INFO:Total runtime is 0.12708998123804727 minutes
2025-03-05 12:09:24,444:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:24,445:INFO:Initializing create_model()
2025-03-05 12:09:24,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:24,445:INFO:Checking exceptions
2025-03-05 12:09:24,445:INFO:Importing libraries
2025-03-05 12:09:24,445:INFO:Copying training dataset
2025-03-05 12:09:24,447:INFO:Defining folds
2025-03-05 12:09:24,447:INFO:Declaring metric variables
2025-03-05 12:09:24,449:INFO:Importing untrained model
2025-03-05 12:09:24,450:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:09:24,453:INFO:Starting cross validation
2025-03-05 12:09:24,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:09:24,873:INFO:Calculating mean and std
2025-03-05 12:09:24,873:INFO:Creating metrics dataframe
2025-03-05 12:09:24,875:INFO:Uploading results into container
2025-03-05 12:09:24,875:INFO:Uploading model into container now
2025-03-05 12:09:24,875:INFO:_master_model_container: 16
2025-03-05 12:09:24,875:INFO:_display_container: 2
2025-03-05 12:09:24,875:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:09:24,875:INFO:create_model() successfully completed......................................
2025-03-05 12:09:24,955:INFO:SubProcess create_model() end ==================================
2025-03-05 12:09:24,955:INFO:Creating metrics dataframe
2025-03-05 12:09:24,960:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:09:24,960:INFO:Total runtime is 0.13571329514185587 minutes
2025-03-05 12:09:24,962:INFO:SubProcess create_model() called ==================================
2025-03-05 12:09:24,962:INFO:Initializing create_model()
2025-03-05 12:09:24,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7cc3c8dd5e50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7cc3cb7c0670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:09:24,962:INFO:Checking exceptions
2025-03-05 12:09:24,962:INFO:Importing libraries
2025-03-05 12:09:24,962:INFO:Copying training dataset
2025-03-05 12:09:24,964:INFO:Defining folds
2025-03-05 12:09:24,964:INFO:Declaring metric variables
2025-03-05 12:09:24,966:INFO:Importing untrained model
2025-03-05 12:09:24,967:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:09:24,970:INFO:Starting cross validation
2025-03-05 12:09:24,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:00,773:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:12:00,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:12:00,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:12:00,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:12:00,825:INFO:PyCaret RegressionExperiment
2025-03-05 12:12:00,825:INFO:Logging name: reg-default-name
2025-03-05 12:12:00,825:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:12:00,825:INFO:version 3.3.1
2025-03-05 12:12:00,825:INFO:Initializing setup()
2025-03-05 12:12:00,825:INFO:self.USI: d7f1
2025-03-05 12:12:00,825:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 12:12:00,825:INFO:Checking environment
2025-03-05 12:12:00,825:INFO:python_version: 3.9.21
2025-03-05 12:12:00,825:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:12:00,825:INFO:machine: x86_64
2025-03-05 12:12:00,825:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:12:00,825:INFO:Memory: svmem(total=33374507008, available=22496460800, percent=32.6, used=8572665856, free=8592830464, active=11527819264, inactive=8872660992, buffers=615903232, cached=15593107456, shared=1776291840, slab=1722724352)
2025-03-05 12:12:00,826:INFO:Physical Core: 24
2025-03-05 12:12:00,826:INFO:Logical Core: 32
2025-03-05 12:12:00,826:INFO:Checking libraries
2025-03-05 12:12:00,826:INFO:System:
2025-03-05 12:12:00,826:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:12:00,826:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:12:00,826:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:12:00,826:INFO:PyCaret required dependencies:
2025-03-05 12:12:00,838:INFO:                 pip: 25.0
2025-03-05 12:12:00,838:INFO:          setuptools: 75.8.0
2025-03-05 12:12:00,838:INFO:             pycaret: 3.3.1
2025-03-05 12:12:00,838:INFO:             IPython: 8.18.1
2025-03-05 12:12:00,838:INFO:          ipywidgets: 8.1.5
2025-03-05 12:12:00,838:INFO:                tqdm: 4.67.1
2025-03-05 12:12:00,838:INFO:               numpy: 1.26.4
2025-03-05 12:12:00,838:INFO:              pandas: 2.1.4
2025-03-05 12:12:00,838:INFO:              jinja2: 3.1.5
2025-03-05 12:12:00,838:INFO:               scipy: 1.11.4
2025-03-05 12:12:00,838:INFO:              joblib: 1.3.2
2025-03-05 12:12:00,838:INFO:             sklearn: 1.4.2
2025-03-05 12:12:00,838:INFO:                pyod: 2.0.3
2025-03-05 12:12:00,838:INFO:            imblearn: 0.12.4
2025-03-05 12:12:00,838:INFO:   category_encoders: 2.6.4
2025-03-05 12:12:00,838:INFO:            lightgbm: 4.6.0
2025-03-05 12:12:00,838:INFO:               numba: 0.60.0
2025-03-05 12:12:00,838:INFO:            requests: 2.32.3
2025-03-05 12:12:00,838:INFO:          matplotlib: 3.7.5
2025-03-05 12:12:00,838:INFO:          scikitplot: 0.3.7
2025-03-05 12:12:00,838:INFO:         yellowbrick: 1.5
2025-03-05 12:12:00,838:INFO:              plotly: 5.24.1
2025-03-05 12:12:00,838:INFO:    plotly-resampler: Not installed
2025-03-05 12:12:00,838:INFO:             kaleido: 0.2.1
2025-03-05 12:12:00,838:INFO:           schemdraw: 0.15
2025-03-05 12:12:00,838:INFO:         statsmodels: 0.14.4
2025-03-05 12:12:00,838:INFO:              sktime: 0.26.0
2025-03-05 12:12:00,838:INFO:               tbats: 1.1.3
2025-03-05 12:12:00,838:INFO:            pmdarima: 2.0.4
2025-03-05 12:12:00,838:INFO:              psutil: 7.0.0
2025-03-05 12:12:00,838:INFO:          markupsafe: 3.0.2
2025-03-05 12:12:00,838:INFO:             pickle5: Not installed
2025-03-05 12:12:00,838:INFO:         cloudpickle: 3.1.1
2025-03-05 12:12:00,838:INFO:         deprecation: 2.1.0
2025-03-05 12:12:00,838:INFO:              xxhash: 3.5.0
2025-03-05 12:12:00,838:INFO:           wurlitzer: 3.1.1
2025-03-05 12:12:00,838:INFO:PyCaret optional dependencies:
2025-03-05 12:12:00,845:INFO:                shap: Not installed
2025-03-05 12:12:00,845:INFO:           interpret: Not installed
2025-03-05 12:12:00,845:INFO:                umap: Not installed
2025-03-05 12:12:00,845:INFO:     ydata_profiling: Not installed
2025-03-05 12:12:00,845:INFO:  explainerdashboard: Not installed
2025-03-05 12:12:00,845:INFO:             autoviz: Not installed
2025-03-05 12:12:00,845:INFO:           fairlearn: Not installed
2025-03-05 12:12:00,845:INFO:          deepchecks: Not installed
2025-03-05 12:12:00,845:INFO:             xgboost: Not installed
2025-03-05 12:12:00,845:INFO:            catboost: Not installed
2025-03-05 12:12:00,845:INFO:              kmodes: Not installed
2025-03-05 12:12:00,845:INFO:             mlxtend: Not installed
2025-03-05 12:12:00,845:INFO:       statsforecast: Not installed
2025-03-05 12:12:00,845:INFO:        tune_sklearn: Not installed
2025-03-05 12:12:00,845:INFO:                 ray: Not installed
2025-03-05 12:12:00,845:INFO:            hyperopt: Not installed
2025-03-05 12:12:00,845:INFO:              optuna: Not installed
2025-03-05 12:12:00,845:INFO:               skopt: Not installed
2025-03-05 12:12:00,845:INFO:              mlflow: Not installed
2025-03-05 12:12:00,845:INFO:              gradio: Not installed
2025-03-05 12:12:00,845:INFO:             fastapi: Not installed
2025-03-05 12:12:00,845:INFO:             uvicorn: Not installed
2025-03-05 12:12:00,845:INFO:              m2cgen: Not installed
2025-03-05 12:12:00,845:INFO:           evidently: Not installed
2025-03-05 12:12:00,845:INFO:               fugue: Not installed
2025-03-05 12:12:00,845:INFO:           streamlit: Not installed
2025-03-05 12:12:00,845:INFO:             prophet: Not installed
2025-03-05 12:12:00,845:INFO:None
2025-03-05 12:12:00,845:INFO:Set up data.
2025-03-05 12:12:00,848:INFO:Set up folding strategy.
2025-03-05 12:12:00,848:INFO:Set up train/test split.
2025-03-05 12:12:00,850:INFO:Set up index.
2025-03-05 12:12:00,850:INFO:Assigning column types.
2025-03-05 12:12:00,851:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:12:00,852:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:00,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:00,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:00,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:00,951:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:12:00,953:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,955:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:00,981:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,051:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:12:01,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,154:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:12:01,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,256:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:12:01,287:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:12:01,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,407:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:12:01,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,510:INFO:Preparing preprocessing pipeline...
2025-03-05 12:12:01,510:INFO:Set up simple imputation.
2025-03-05 12:12:01,510:INFO:Set up column name cleaning.
2025-03-05 12:12:01,521:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:12:01,523:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:12:01,523:INFO:Creating final display dataframe.
2025-03-05 12:12:01,553:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d7f1
2025-03-05 12:12:01,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:12:01,653:INFO:setup() successfully completed in 0.83s...............
2025-03-05 12:12:01,770:INFO:Initializing compare_models()
2025-03-05 12:12:01,770:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:12:01,771:INFO:Checking exceptions
2025-03-05 12:12:01,773:INFO:Preparing display monitor
2025-03-05 12:12:01,784:INFO:Initializing Linear Regression
2025-03-05 12:12:01,784:INFO:Total runtime is 1.5179316202799478e-06 minutes
2025-03-05 12:12:01,785:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:01,786:INFO:Initializing create_model()
2025-03-05 12:12:01,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:01,786:INFO:Checking exceptions
2025-03-05 12:12:01,786:INFO:Importing libraries
2025-03-05 12:12:01,786:INFO:Copying training dataset
2025-03-05 12:12:01,788:INFO:Defining folds
2025-03-05 12:12:01,788:INFO:Declaring metric variables
2025-03-05 12:12:01,790:INFO:Importing untrained model
2025-03-05 12:12:01,792:INFO:Linear Regression Imported successfully
2025-03-05 12:12:01,796:INFO:Starting cross validation
2025-03-05 12:12:01,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:03,513:INFO:Calculating mean and std
2025-03-05 12:12:03,514:INFO:Creating metrics dataframe
2025-03-05 12:12:03,516:INFO:Uploading results into container
2025-03-05 12:12:03,517:INFO:Uploading model into container now
2025-03-05 12:12:03,517:INFO:_master_model_container: 1
2025-03-05 12:12:03,517:INFO:_display_container: 2
2025-03-05 12:12:03,517:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:12:03,517:INFO:create_model() successfully completed......................................
2025-03-05 12:12:03,581:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:03,581:INFO:Creating metrics dataframe
2025-03-05 12:12:03,585:INFO:Initializing Lasso Regression
2025-03-05 12:12:03,585:INFO:Total runtime is 0.03001558780670166 minutes
2025-03-05 12:12:03,587:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:03,587:INFO:Initializing create_model()
2025-03-05 12:12:03,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:03,587:INFO:Checking exceptions
2025-03-05 12:12:03,587:INFO:Importing libraries
2025-03-05 12:12:03,587:INFO:Copying training dataset
2025-03-05 12:12:03,590:INFO:Defining folds
2025-03-05 12:12:03,590:INFO:Declaring metric variables
2025-03-05 12:12:03,592:INFO:Importing untrained model
2025-03-05 12:12:03,593:INFO:Lasso Regression Imported successfully
2025-03-05 12:12:03,597:INFO:Starting cross validation
2025-03-05 12:12:03,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:04,887:INFO:Calculating mean and std
2025-03-05 12:12:04,888:INFO:Creating metrics dataframe
2025-03-05 12:12:04,890:INFO:Uploading results into container
2025-03-05 12:12:04,890:INFO:Uploading model into container now
2025-03-05 12:12:04,890:INFO:_master_model_container: 2
2025-03-05 12:12:04,890:INFO:_display_container: 2
2025-03-05 12:12:04,890:INFO:Lasso(random_state=123)
2025-03-05 12:12:04,890:INFO:create_model() successfully completed......................................
2025-03-05 12:12:04,945:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:04,945:INFO:Creating metrics dataframe
2025-03-05 12:12:04,949:INFO:Initializing Ridge Regression
2025-03-05 12:12:04,949:INFO:Total runtime is 0.052747519810994466 minutes
2025-03-05 12:12:04,950:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:04,951:INFO:Initializing create_model()
2025-03-05 12:12:04,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:04,951:INFO:Checking exceptions
2025-03-05 12:12:04,951:INFO:Importing libraries
2025-03-05 12:12:04,951:INFO:Copying training dataset
2025-03-05 12:12:04,953:INFO:Defining folds
2025-03-05 12:12:04,953:INFO:Declaring metric variables
2025-03-05 12:12:04,955:INFO:Importing untrained model
2025-03-05 12:12:04,957:INFO:Ridge Regression Imported successfully
2025-03-05 12:12:04,960:INFO:Starting cross validation
2025-03-05 12:12:04,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:06,237:INFO:Calculating mean and std
2025-03-05 12:12:06,238:INFO:Creating metrics dataframe
2025-03-05 12:12:06,240:INFO:Uploading results into container
2025-03-05 12:12:06,240:INFO:Uploading model into container now
2025-03-05 12:12:06,240:INFO:_master_model_container: 3
2025-03-05 12:12:06,240:INFO:_display_container: 2
2025-03-05 12:12:06,240:INFO:Ridge(random_state=123)
2025-03-05 12:12:06,240:INFO:create_model() successfully completed......................................
2025-03-05 12:12:06,295:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:06,295:INFO:Creating metrics dataframe
2025-03-05 12:12:06,299:INFO:Initializing Elastic Net
2025-03-05 12:12:06,299:INFO:Total runtime is 0.07525318463643392 minutes
2025-03-05 12:12:06,300:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:06,301:INFO:Initializing create_model()
2025-03-05 12:12:06,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:06,301:INFO:Checking exceptions
2025-03-05 12:12:06,301:INFO:Importing libraries
2025-03-05 12:12:06,301:INFO:Copying training dataset
2025-03-05 12:12:06,303:INFO:Defining folds
2025-03-05 12:12:06,303:INFO:Declaring metric variables
2025-03-05 12:12:06,304:INFO:Importing untrained model
2025-03-05 12:12:06,306:INFO:Elastic Net Imported successfully
2025-03-05 12:12:06,309:INFO:Starting cross validation
2025-03-05 12:12:06,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:06,964:INFO:Calculating mean and std
2025-03-05 12:12:06,965:INFO:Creating metrics dataframe
2025-03-05 12:12:06,966:INFO:Uploading results into container
2025-03-05 12:12:06,967:INFO:Uploading model into container now
2025-03-05 12:12:06,967:INFO:_master_model_container: 4
2025-03-05 12:12:06,967:INFO:_display_container: 2
2025-03-05 12:12:06,967:INFO:ElasticNet(random_state=123)
2025-03-05 12:12:06,967:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,024:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,024:INFO:Creating metrics dataframe
2025-03-05 12:12:07,028:INFO:Initializing Least Angle Regression
2025-03-05 12:12:07,029:INFO:Total runtime is 0.0874142050743103 minutes
2025-03-05 12:12:07,030:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,031:INFO:Initializing create_model()
2025-03-05 12:12:07,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,031:INFO:Checking exceptions
2025-03-05 12:12:07,031:INFO:Importing libraries
2025-03-05 12:12:07,031:INFO:Copying training dataset
2025-03-05 12:12:07,033:INFO:Defining folds
2025-03-05 12:12:07,033:INFO:Declaring metric variables
2025-03-05 12:12:07,035:INFO:Importing untrained model
2025-03-05 12:12:07,036:INFO:Least Angle Regression Imported successfully
2025-03-05 12:12:07,039:INFO:Starting cross validation
2025-03-05 12:12:07,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,087:INFO:Calculating mean and std
2025-03-05 12:12:07,088:INFO:Creating metrics dataframe
2025-03-05 12:12:07,090:INFO:Uploading results into container
2025-03-05 12:12:07,090:INFO:Uploading model into container now
2025-03-05 12:12:07,090:INFO:_master_model_container: 5
2025-03-05 12:12:07,090:INFO:_display_container: 2
2025-03-05 12:12:07,090:INFO:Lars(random_state=123)
2025-03-05 12:12:07,090:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,142:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,143:INFO:Creating metrics dataframe
2025-03-05 12:12:07,147:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:12:07,147:INFO:Total runtime is 0.08938409487406412 minutes
2025-03-05 12:12:07,148:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,149:INFO:Initializing create_model()
2025-03-05 12:12:07,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,149:INFO:Checking exceptions
2025-03-05 12:12:07,149:INFO:Importing libraries
2025-03-05 12:12:07,149:INFO:Copying training dataset
2025-03-05 12:12:07,151:INFO:Defining folds
2025-03-05 12:12:07,151:INFO:Declaring metric variables
2025-03-05 12:12:07,153:INFO:Importing untrained model
2025-03-05 12:12:07,154:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:12:07,157:INFO:Starting cross validation
2025-03-05 12:12:07,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,193:INFO:Calculating mean and std
2025-03-05 12:12:07,194:INFO:Creating metrics dataframe
2025-03-05 12:12:07,195:INFO:Uploading results into container
2025-03-05 12:12:07,196:INFO:Uploading model into container now
2025-03-05 12:12:07,196:INFO:_master_model_container: 6
2025-03-05 12:12:07,196:INFO:_display_container: 2
2025-03-05 12:12:07,196:INFO:LassoLars(random_state=123)
2025-03-05 12:12:07,196:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,252:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,253:INFO:Creating metrics dataframe
2025-03-05 12:12:07,257:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:12:07,257:INFO:Total runtime is 0.09121966361999512 minutes
2025-03-05 12:12:07,259:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,259:INFO:Initializing create_model()
2025-03-05 12:12:07,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,259:INFO:Checking exceptions
2025-03-05 12:12:07,259:INFO:Importing libraries
2025-03-05 12:12:07,259:INFO:Copying training dataset
2025-03-05 12:12:07,261:INFO:Defining folds
2025-03-05 12:12:07,261:INFO:Declaring metric variables
2025-03-05 12:12:07,263:INFO:Importing untrained model
2025-03-05 12:12:07,265:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:12:07,268:INFO:Starting cross validation
2025-03-05 12:12:07,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,305:INFO:Calculating mean and std
2025-03-05 12:12:07,306:INFO:Creating metrics dataframe
2025-03-05 12:12:07,308:INFO:Uploading results into container
2025-03-05 12:12:07,309:INFO:Uploading model into container now
2025-03-05 12:12:07,309:INFO:_master_model_container: 7
2025-03-05 12:12:07,309:INFO:_display_container: 2
2025-03-05 12:12:07,309:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:12:07,309:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,365:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,365:INFO:Creating metrics dataframe
2025-03-05 12:12:07,369:INFO:Initializing Bayesian Ridge
2025-03-05 12:12:07,369:INFO:Total runtime is 0.09308996200561523 minutes
2025-03-05 12:12:07,371:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,371:INFO:Initializing create_model()
2025-03-05 12:12:07,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,371:INFO:Checking exceptions
2025-03-05 12:12:07,371:INFO:Importing libraries
2025-03-05 12:12:07,372:INFO:Copying training dataset
2025-03-05 12:12:07,374:INFO:Defining folds
2025-03-05 12:12:07,374:INFO:Declaring metric variables
2025-03-05 12:12:07,376:INFO:Importing untrained model
2025-03-05 12:12:07,377:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:12:07,380:INFO:Starting cross validation
2025-03-05 12:12:07,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,430:INFO:Calculating mean and std
2025-03-05 12:12:07,431:INFO:Creating metrics dataframe
2025-03-05 12:12:07,432:INFO:Uploading results into container
2025-03-05 12:12:07,433:INFO:Uploading model into container now
2025-03-05 12:12:07,433:INFO:_master_model_container: 8
2025-03-05 12:12:07,433:INFO:_display_container: 2
2025-03-05 12:12:07,433:INFO:BayesianRidge()
2025-03-05 12:12:07,433:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,487:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,487:INFO:Creating metrics dataframe
2025-03-05 12:12:07,492:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:12:07,492:INFO:Total runtime is 0.09513978958129882 minutes
2025-03-05 12:12:07,494:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,494:INFO:Initializing create_model()
2025-03-05 12:12:07,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,494:INFO:Checking exceptions
2025-03-05 12:12:07,494:INFO:Importing libraries
2025-03-05 12:12:07,494:INFO:Copying training dataset
2025-03-05 12:12:07,497:INFO:Defining folds
2025-03-05 12:12:07,497:INFO:Declaring metric variables
2025-03-05 12:12:07,498:INFO:Importing untrained model
2025-03-05 12:12:07,500:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:12:07,503:INFO:Starting cross validation
2025-03-05 12:12:07,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,553:INFO:Calculating mean and std
2025-03-05 12:12:07,555:INFO:Creating metrics dataframe
2025-03-05 12:12:07,557:INFO:Uploading results into container
2025-03-05 12:12:07,557:INFO:Uploading model into container now
2025-03-05 12:12:07,558:INFO:_master_model_container: 9
2025-03-05 12:12:07,558:INFO:_display_container: 2
2025-03-05 12:12:07,558:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:12:07,558:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,618:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,618:INFO:Creating metrics dataframe
2025-03-05 12:12:07,623:INFO:Initializing Huber Regressor
2025-03-05 12:12:07,623:INFO:Total runtime is 0.09732028643290201 minutes
2025-03-05 12:12:07,625:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,625:INFO:Initializing create_model()
2025-03-05 12:12:07,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,625:INFO:Checking exceptions
2025-03-05 12:12:07,625:INFO:Importing libraries
2025-03-05 12:12:07,625:INFO:Copying training dataset
2025-03-05 12:12:07,628:INFO:Defining folds
2025-03-05 12:12:07,628:INFO:Declaring metric variables
2025-03-05 12:12:07,629:INFO:Importing untrained model
2025-03-05 12:12:07,631:INFO:Huber Regressor Imported successfully
2025-03-05 12:12:07,634:INFO:Starting cross validation
2025-03-05 12:12:07,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,712:INFO:Calculating mean and std
2025-03-05 12:12:07,714:INFO:Creating metrics dataframe
2025-03-05 12:12:07,716:INFO:Uploading results into container
2025-03-05 12:12:07,716:INFO:Uploading model into container now
2025-03-05 12:12:07,717:INFO:_master_model_container: 10
2025-03-05 12:12:07,717:INFO:_display_container: 2
2025-03-05 12:12:07,717:INFO:HuberRegressor()
2025-03-05 12:12:07,717:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,777:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,777:INFO:Creating metrics dataframe
2025-03-05 12:12:07,781:INFO:Initializing K Neighbors Regressor
2025-03-05 12:12:07,781:INFO:Total runtime is 0.09996186892191568 minutes
2025-03-05 12:12:07,783:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,784:INFO:Initializing create_model()
2025-03-05 12:12:07,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,784:INFO:Checking exceptions
2025-03-05 12:12:07,784:INFO:Importing libraries
2025-03-05 12:12:07,784:INFO:Copying training dataset
2025-03-05 12:12:07,786:INFO:Defining folds
2025-03-05 12:12:07,786:INFO:Declaring metric variables
2025-03-05 12:12:07,788:INFO:Importing untrained model
2025-03-05 12:12:07,789:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:12:07,792:INFO:Starting cross validation
2025-03-05 12:12:07,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,860:INFO:Calculating mean and std
2025-03-05 12:12:07,861:INFO:Creating metrics dataframe
2025-03-05 12:12:07,862:INFO:Uploading results into container
2025-03-05 12:12:07,863:INFO:Uploading model into container now
2025-03-05 12:12:07,863:INFO:_master_model_container: 11
2025-03-05 12:12:07,863:INFO:_display_container: 2
2025-03-05 12:12:07,863:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:12:07,863:INFO:create_model() successfully completed......................................
2025-03-05 12:12:07,916:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:07,916:INFO:Creating metrics dataframe
2025-03-05 12:12:07,922:INFO:Initializing Decision Tree Regressor
2025-03-05 12:12:07,923:INFO:Total runtime is 0.10231225887934366 minutes
2025-03-05 12:12:07,925:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:07,925:INFO:Initializing create_model()
2025-03-05 12:12:07,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:07,925:INFO:Checking exceptions
2025-03-05 12:12:07,925:INFO:Importing libraries
2025-03-05 12:12:07,925:INFO:Copying training dataset
2025-03-05 12:12:07,928:INFO:Defining folds
2025-03-05 12:12:07,928:INFO:Declaring metric variables
2025-03-05 12:12:07,930:INFO:Importing untrained model
2025-03-05 12:12:07,932:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:12:07,936:INFO:Starting cross validation
2025-03-05 12:12:07,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:07,997:INFO:Calculating mean and std
2025-03-05 12:12:07,998:INFO:Creating metrics dataframe
2025-03-05 12:12:08,000:INFO:Uploading results into container
2025-03-05 12:12:08,000:INFO:Uploading model into container now
2025-03-05 12:12:08,001:INFO:_master_model_container: 12
2025-03-05 12:12:08,001:INFO:_display_container: 2
2025-03-05 12:12:08,001:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:12:08,001:INFO:create_model() successfully completed......................................
2025-03-05 12:12:08,056:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:08,056:INFO:Creating metrics dataframe
2025-03-05 12:12:08,062:INFO:Initializing Random Forest Regressor
2025-03-05 12:12:08,062:INFO:Total runtime is 0.10464496215184528 minutes
2025-03-05 12:12:08,065:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:08,065:INFO:Initializing create_model()
2025-03-05 12:12:08,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:08,065:INFO:Checking exceptions
2025-03-05 12:12:08,065:INFO:Importing libraries
2025-03-05 12:12:08,065:INFO:Copying training dataset
2025-03-05 12:12:08,068:INFO:Defining folds
2025-03-05 12:12:08,068:INFO:Declaring metric variables
2025-03-05 12:12:08,071:INFO:Importing untrained model
2025-03-05 12:12:08,073:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:12:08,077:INFO:Starting cross validation
2025-03-05 12:12:08,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:08,587:INFO:Calculating mean and std
2025-03-05 12:12:08,589:INFO:Creating metrics dataframe
2025-03-05 12:12:08,591:INFO:Uploading results into container
2025-03-05 12:12:08,591:INFO:Uploading model into container now
2025-03-05 12:12:08,592:INFO:_master_model_container: 13
2025-03-05 12:12:08,592:INFO:_display_container: 2
2025-03-05 12:12:08,592:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:12:08,592:INFO:create_model() successfully completed......................................
2025-03-05 12:12:08,650:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:08,650:INFO:Creating metrics dataframe
2025-03-05 12:12:08,657:INFO:Initializing Extra Trees Regressor
2025-03-05 12:12:08,658:INFO:Total runtime is 0.11456231673558552 minutes
2025-03-05 12:12:08,660:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:08,660:INFO:Initializing create_model()
2025-03-05 12:12:08,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:08,660:INFO:Checking exceptions
2025-03-05 12:12:08,660:INFO:Importing libraries
2025-03-05 12:12:08,660:INFO:Copying training dataset
2025-03-05 12:12:08,664:INFO:Defining folds
2025-03-05 12:12:08,664:INFO:Declaring metric variables
2025-03-05 12:12:08,666:INFO:Importing untrained model
2025-03-05 12:12:08,669:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:12:08,674:INFO:Starting cross validation
2025-03-05 12:12:08,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:09,023:INFO:Calculating mean and std
2025-03-05 12:12:09,024:INFO:Creating metrics dataframe
2025-03-05 12:12:09,027:INFO:Uploading results into container
2025-03-05 12:12:09,028:INFO:Uploading model into container now
2025-03-05 12:12:09,028:INFO:_master_model_container: 14
2025-03-05 12:12:09,028:INFO:_display_container: 2
2025-03-05 12:12:09,029:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:12:09,029:INFO:create_model() successfully completed......................................
2025-03-05 12:12:09,088:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:09,088:INFO:Creating metrics dataframe
2025-03-05 12:12:09,095:INFO:Initializing AdaBoost Regressor
2025-03-05 12:12:09,096:INFO:Total runtime is 0.12186323006947834 minutes
2025-03-05 12:12:09,098:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:09,099:INFO:Initializing create_model()
2025-03-05 12:12:09,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:09,099:INFO:Checking exceptions
2025-03-05 12:12:09,099:INFO:Importing libraries
2025-03-05 12:12:09,099:INFO:Copying training dataset
2025-03-05 12:12:09,103:INFO:Defining folds
2025-03-05 12:12:09,103:INFO:Declaring metric variables
2025-03-05 12:12:09,106:INFO:Importing untrained model
2025-03-05 12:12:09,108:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:12:09,113:INFO:Starting cross validation
2025-03-05 12:12:09,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:09,437:INFO:Calculating mean and std
2025-03-05 12:12:09,438:INFO:Creating metrics dataframe
2025-03-05 12:12:09,439:INFO:Uploading results into container
2025-03-05 12:12:09,440:INFO:Uploading model into container now
2025-03-05 12:12:09,440:INFO:_master_model_container: 15
2025-03-05 12:12:09,440:INFO:_display_container: 2
2025-03-05 12:12:09,441:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:12:09,441:INFO:create_model() successfully completed......................................
2025-03-05 12:12:09,495:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:09,495:INFO:Creating metrics dataframe
2025-03-05 12:12:09,502:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:12:09,502:INFO:Total runtime is 0.12864433526992797 minutes
2025-03-05 12:12:09,505:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:09,505:INFO:Initializing create_model()
2025-03-05 12:12:09,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:09,505:INFO:Checking exceptions
2025-03-05 12:12:09,505:INFO:Importing libraries
2025-03-05 12:12:09,505:INFO:Copying training dataset
2025-03-05 12:12:09,509:INFO:Defining folds
2025-03-05 12:12:09,509:INFO:Declaring metric variables
2025-03-05 12:12:09,511:INFO:Importing untrained model
2025-03-05 12:12:09,513:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:12:09,518:INFO:Starting cross validation
2025-03-05 12:12:09,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:12:10,044:INFO:Calculating mean and std
2025-03-05 12:12:10,046:INFO:Creating metrics dataframe
2025-03-05 12:12:10,048:INFO:Uploading results into container
2025-03-05 12:12:10,048:INFO:Uploading model into container now
2025-03-05 12:12:10,049:INFO:_master_model_container: 16
2025-03-05 12:12:10,049:INFO:_display_container: 2
2025-03-05 12:12:10,049:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:12:10,049:INFO:create_model() successfully completed......................................
2025-03-05 12:12:10,105:INFO:SubProcess create_model() end ==================================
2025-03-05 12:12:10,105:INFO:Creating metrics dataframe
2025-03-05 12:12:10,112:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:12:10,112:INFO:Total runtime is 0.13881016572316487 minutes
2025-03-05 12:12:10,115:INFO:SubProcess create_model() called ==================================
2025-03-05 12:12:10,115:INFO:Initializing create_model()
2025-03-05 12:12:10,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:12:10,115:INFO:Checking exceptions
2025-03-05 12:12:10,115:INFO:Importing libraries
2025-03-05 12:12:10,115:INFO:Copying training dataset
2025-03-05 12:12:10,119:INFO:Defining folds
2025-03-05 12:12:10,119:INFO:Declaring metric variables
2025-03-05 12:12:10,121:INFO:Importing untrained model
2025-03-05 12:12:10,124:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:12:10,130:INFO:Starting cross validation
2025-03-05 12:12:10,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:48,194:INFO:Initializing compare_models()
2025-03-05 12:25:48,195:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:25:48,195:INFO:Checking exceptions
2025-03-05 12:25:48,198:INFO:Preparing display monitor
2025-03-05 12:25:48,219:INFO:Initializing Linear Regression
2025-03-05 12:25:48,219:INFO:Total runtime is 2.7338663736979167e-06 minutes
2025-03-05 12:25:48,222:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:48,222:INFO:Initializing create_model()
2025-03-05 12:25:48,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:48,222:INFO:Checking exceptions
2025-03-05 12:25:48,222:INFO:Importing libraries
2025-03-05 12:25:48,223:INFO:Copying training dataset
2025-03-05 12:25:48,230:INFO:Defining folds
2025-03-05 12:25:48,230:INFO:Declaring metric variables
2025-03-05 12:25:48,233:INFO:Importing untrained model
2025-03-05 12:25:48,236:INFO:Linear Regression Imported successfully
2025-03-05 12:25:48,242:INFO:Starting cross validation
2025-03-05 12:25:48,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:50,215:INFO:Calculating mean and std
2025-03-05 12:25:50,217:INFO:Creating metrics dataframe
2025-03-05 12:25:50,220:INFO:Uploading results into container
2025-03-05 12:25:50,220:INFO:Uploading model into container now
2025-03-05 12:25:50,221:INFO:_master_model_container: 17
2025-03-05 12:25:50,221:INFO:_display_container: 2
2025-03-05 12:25:50,221:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:25:50,221:INFO:create_model() successfully completed......................................
2025-03-05 12:25:50,317:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:50,317:INFO:Creating metrics dataframe
2025-03-05 12:25:50,323:INFO:Initializing Lasso Regression
2025-03-05 12:25:50,323:INFO:Total runtime is 0.03508103688557943 minutes
2025-03-05 12:25:50,326:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:50,327:INFO:Initializing create_model()
2025-03-05 12:25:50,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:50,327:INFO:Checking exceptions
2025-03-05 12:25:50,327:INFO:Importing libraries
2025-03-05 12:25:50,327:INFO:Copying training dataset
2025-03-05 12:25:50,332:INFO:Defining folds
2025-03-05 12:25:50,332:INFO:Declaring metric variables
2025-03-05 12:25:50,335:INFO:Importing untrained model
2025-03-05 12:25:50,338:INFO:Lasso Regression Imported successfully
2025-03-05 12:25:50,344:INFO:Starting cross validation
2025-03-05 12:25:50,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:51,956:INFO:Calculating mean and std
2025-03-05 12:25:51,958:INFO:Creating metrics dataframe
2025-03-05 12:25:51,961:INFO:Uploading results into container
2025-03-05 12:25:51,962:INFO:Uploading model into container now
2025-03-05 12:25:51,962:INFO:_master_model_container: 18
2025-03-05 12:25:51,963:INFO:_display_container: 2
2025-03-05 12:25:51,963:INFO:Lasso(random_state=123)
2025-03-05 12:25:51,963:INFO:create_model() successfully completed......................................
2025-03-05 12:25:52,047:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:52,047:INFO:Creating metrics dataframe
2025-03-05 12:25:52,055:INFO:Initializing Ridge Regression
2025-03-05 12:25:52,055:INFO:Total runtime is 0.06394034624099731 minutes
2025-03-05 12:25:52,058:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:52,059:INFO:Initializing create_model()
2025-03-05 12:25:52,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:52,059:INFO:Checking exceptions
2025-03-05 12:25:52,059:INFO:Importing libraries
2025-03-05 12:25:52,059:INFO:Copying training dataset
2025-03-05 12:25:52,064:INFO:Defining folds
2025-03-05 12:25:52,064:INFO:Declaring metric variables
2025-03-05 12:25:52,067:INFO:Importing untrained model
2025-03-05 12:25:52,070:INFO:Ridge Regression Imported successfully
2025-03-05 12:25:52,076:INFO:Starting cross validation
2025-03-05 12:25:52,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:53,751:INFO:Calculating mean and std
2025-03-05 12:25:53,753:INFO:Creating metrics dataframe
2025-03-05 12:25:53,755:INFO:Uploading results into container
2025-03-05 12:25:53,756:INFO:Uploading model into container now
2025-03-05 12:25:53,757:INFO:_master_model_container: 19
2025-03-05 12:25:53,757:INFO:_display_container: 2
2025-03-05 12:25:53,757:INFO:Ridge(random_state=123)
2025-03-05 12:25:53,757:INFO:create_model() successfully completed......................................
2025-03-05 12:25:53,839:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:53,839:INFO:Creating metrics dataframe
2025-03-05 12:25:53,846:INFO:Initializing Elastic Net
2025-03-05 12:25:53,846:INFO:Total runtime is 0.0937916080156962 minutes
2025-03-05 12:25:53,849:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:53,850:INFO:Initializing create_model()
2025-03-05 12:25:53,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:53,850:INFO:Checking exceptions
2025-03-05 12:25:53,850:INFO:Importing libraries
2025-03-05 12:25:53,850:INFO:Copying training dataset
2025-03-05 12:25:53,854:INFO:Defining folds
2025-03-05 12:25:53,855:INFO:Declaring metric variables
2025-03-05 12:25:53,858:INFO:Importing untrained model
2025-03-05 12:25:53,861:INFO:Elastic Net Imported successfully
2025-03-05 12:25:53,867:INFO:Starting cross validation
2025-03-05 12:25:53,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,027:INFO:Calculating mean and std
2025-03-05 12:25:55,029:INFO:Creating metrics dataframe
2025-03-05 12:25:55,031:INFO:Uploading results into container
2025-03-05 12:25:55,031:INFO:Uploading model into container now
2025-03-05 12:25:55,032:INFO:_master_model_container: 20
2025-03-05 12:25:55,032:INFO:_display_container: 2
2025-03-05 12:25:55,032:INFO:ElasticNet(random_state=123)
2025-03-05 12:25:55,032:INFO:create_model() successfully completed......................................
2025-03-05 12:25:55,114:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:55,114:INFO:Creating metrics dataframe
2025-03-05 12:25:55,122:INFO:Initializing Least Angle Regression
2025-03-05 12:25:55,122:INFO:Total runtime is 0.1150622288386027 minutes
2025-03-05 12:25:55,125:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:55,126:INFO:Initializing create_model()
2025-03-05 12:25:55,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:55,126:INFO:Checking exceptions
2025-03-05 12:25:55,126:INFO:Importing libraries
2025-03-05 12:25:55,126:INFO:Copying training dataset
2025-03-05 12:25:55,131:INFO:Defining folds
2025-03-05 12:25:55,131:INFO:Declaring metric variables
2025-03-05 12:25:55,134:INFO:Importing untrained model
2025-03-05 12:25:55,137:INFO:Least Angle Regression Imported successfully
2025-03-05 12:25:55,143:INFO:Starting cross validation
2025-03-05 12:25:55,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,207:INFO:Calculating mean and std
2025-03-05 12:25:55,208:INFO:Creating metrics dataframe
2025-03-05 12:25:55,211:INFO:Uploading results into container
2025-03-05 12:25:55,212:INFO:Uploading model into container now
2025-03-05 12:25:55,212:INFO:_master_model_container: 21
2025-03-05 12:25:55,212:INFO:_display_container: 2
2025-03-05 12:25:55,213:INFO:Lars(random_state=123)
2025-03-05 12:25:55,213:INFO:create_model() successfully completed......................................
2025-03-05 12:25:55,296:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:55,297:INFO:Creating metrics dataframe
2025-03-05 12:25:55,304:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:25:55,304:INFO:Total runtime is 0.11809900999069214 minutes
2025-03-05 12:25:55,308:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:55,308:INFO:Initializing create_model()
2025-03-05 12:25:55,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:55,308:INFO:Checking exceptions
2025-03-05 12:25:55,308:INFO:Importing libraries
2025-03-05 12:25:55,308:INFO:Copying training dataset
2025-03-05 12:25:55,314:INFO:Defining folds
2025-03-05 12:25:55,314:INFO:Declaring metric variables
2025-03-05 12:25:55,318:INFO:Importing untrained model
2025-03-05 12:25:55,321:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:25:55,328:INFO:Starting cross validation
2025-03-05 12:25:55,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,397:INFO:Calculating mean and std
2025-03-05 12:25:55,397:INFO:Creating metrics dataframe
2025-03-05 12:25:55,399:INFO:Uploading results into container
2025-03-05 12:25:55,399:INFO:Uploading model into container now
2025-03-05 12:25:55,400:INFO:_master_model_container: 22
2025-03-05 12:25:55,400:INFO:_display_container: 2
2025-03-05 12:25:55,400:INFO:LassoLars(random_state=123)
2025-03-05 12:25:55,400:INFO:create_model() successfully completed......................................
2025-03-05 12:25:55,482:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:55,482:INFO:Creating metrics dataframe
2025-03-05 12:25:55,490:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:25:55,490:INFO:Total runtime is 0.12118611335754395 minutes
2025-03-05 12:25:55,493:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:55,493:INFO:Initializing create_model()
2025-03-05 12:25:55,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:55,493:INFO:Checking exceptions
2025-03-05 12:25:55,493:INFO:Importing libraries
2025-03-05 12:25:55,494:INFO:Copying training dataset
2025-03-05 12:25:55,498:INFO:Defining folds
2025-03-05 12:25:55,499:INFO:Declaring metric variables
2025-03-05 12:25:55,502:INFO:Importing untrained model
2025-03-05 12:25:55,505:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:25:55,511:INFO:Starting cross validation
2025-03-05 12:25:55,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,576:INFO:Calculating mean and std
2025-03-05 12:25:55,576:INFO:Creating metrics dataframe
2025-03-05 12:25:55,578:INFO:Uploading results into container
2025-03-05 12:25:55,578:INFO:Uploading model into container now
2025-03-05 12:25:55,579:INFO:_master_model_container: 23
2025-03-05 12:25:55,579:INFO:_display_container: 2
2025-03-05 12:25:55,579:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:25:55,579:INFO:create_model() successfully completed......................................
2025-03-05 12:25:55,658:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:55,658:INFO:Creating metrics dataframe
2025-03-05 12:25:55,667:INFO:Initializing Bayesian Ridge
2025-03-05 12:25:55,667:INFO:Total runtime is 0.12413411140441895 minutes
2025-03-05 12:25:55,670:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:55,670:INFO:Initializing create_model()
2025-03-05 12:25:55,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:55,670:INFO:Checking exceptions
2025-03-05 12:25:55,670:INFO:Importing libraries
2025-03-05 12:25:55,670:INFO:Copying training dataset
2025-03-05 12:25:55,675:INFO:Defining folds
2025-03-05 12:25:55,675:INFO:Declaring metric variables
2025-03-05 12:25:55,679:INFO:Importing untrained model
2025-03-05 12:25:55,683:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:25:55,690:INFO:Starting cross validation
2025-03-05 12:25:55,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,768:INFO:Calculating mean and std
2025-03-05 12:25:55,769:INFO:Creating metrics dataframe
2025-03-05 12:25:55,771:INFO:Uploading results into container
2025-03-05 12:25:55,771:INFO:Uploading model into container now
2025-03-05 12:25:55,772:INFO:_master_model_container: 24
2025-03-05 12:25:55,772:INFO:_display_container: 2
2025-03-05 12:25:55,772:INFO:BayesianRidge()
2025-03-05 12:25:55,772:INFO:create_model() successfully completed......................................
2025-03-05 12:25:55,851:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:55,851:INFO:Creating metrics dataframe
2025-03-05 12:25:55,859:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:25:55,859:INFO:Total runtime is 0.1273471196492513 minutes
2025-03-05 12:25:55,863:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:55,863:INFO:Initializing create_model()
2025-03-05 12:25:55,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:55,863:INFO:Checking exceptions
2025-03-05 12:25:55,863:INFO:Importing libraries
2025-03-05 12:25:55,863:INFO:Copying training dataset
2025-03-05 12:25:55,868:INFO:Defining folds
2025-03-05 12:25:55,868:INFO:Declaring metric variables
2025-03-05 12:25:55,872:INFO:Importing untrained model
2025-03-05 12:25:55,876:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:25:55,882:INFO:Starting cross validation
2025-03-05 12:25:55,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:25:55,959:INFO:Calculating mean and std
2025-03-05 12:25:55,960:INFO:Creating metrics dataframe
2025-03-05 12:25:55,961:INFO:Uploading results into container
2025-03-05 12:25:55,962:INFO:Uploading model into container now
2025-03-05 12:25:55,962:INFO:_master_model_container: 25
2025-03-05 12:25:55,962:INFO:_display_container: 2
2025-03-05 12:25:55,962:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:25:55,962:INFO:create_model() successfully completed......................................
2025-03-05 12:25:56,060:INFO:SubProcess create_model() end ==================================
2025-03-05 12:25:56,060:INFO:Creating metrics dataframe
2025-03-05 12:25:56,069:INFO:Initializing Huber Regressor
2025-03-05 12:25:56,069:INFO:Total runtime is 0.13084063529968262 minutes
2025-03-05 12:25:56,072:INFO:SubProcess create_model() called ==================================
2025-03-05 12:25:56,073:INFO:Initializing create_model()
2025-03-05 12:25:56,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74462f4d9c10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x744615cc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:25:56,073:INFO:Checking exceptions
2025-03-05 12:25:56,073:INFO:Importing libraries
2025-03-05 12:25:56,073:INFO:Copying training dataset
2025-03-05 12:25:56,078:INFO:Defining folds
2025-03-05 12:25:56,078:INFO:Declaring metric variables
2025-03-05 12:25:56,082:INFO:Importing untrained model
2025-03-05 12:25:56,086:INFO:Huber Regressor Imported successfully
2025-03-05 12:25:56,093:INFO:Starting cross validation
2025-03-05 12:25:56,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-05 12:26:02,239:INFO:PyCaret RegressionExperiment
2025-03-05 12:26:02,246:INFO:Logging name: reg-default-name
2025-03-05 12:26:02,246:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:26:02,246:INFO:version 3.3.1
2025-03-05 12:26:02,246:INFO:Initializing setup()
2025-03-05 12:26:02,246:INFO:self.USI: b1a7
2025-03-05 12:26:02,247:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 12:26:02,247:INFO:Checking environment
2025-03-05 12:26:02,247:INFO:python_version: 3.9.21
2025-03-05 12:26:02,247:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:26:02,247:INFO:machine: x86_64
2025-03-05 12:26:02,247:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:26:02,247:INFO:Memory: svmem(total=33374507008, available=22774108160, percent=31.8, used=8281612288, free=5893332992, active=11761905664, inactive=11626049536, buffers=640651264, cached=18558910464, shared=1789689856, slab=1801764864)
2025-03-05 12:26:02,248:INFO:Physical Core: 24
2025-03-05 12:26:02,248:INFO:Logical Core: 32
2025-03-05 12:26:02,248:INFO:Checking libraries
2025-03-05 12:26:02,248:INFO:System:
2025-03-05 12:26:02,248:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:26:02,248:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:26:02,248:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:26:02,248:INFO:PyCaret required dependencies:
2025-03-05 12:26:02,248:INFO:                 pip: 25.0
2025-03-05 12:26:02,248:INFO:          setuptools: 75.8.0
2025-03-05 12:26:02,248:INFO:             pycaret: 3.3.1
2025-03-05 12:26:02,248:INFO:             IPython: 8.18.1
2025-03-05 12:26:02,248:INFO:          ipywidgets: 8.1.5
2025-03-05 12:26:02,248:INFO:                tqdm: 4.67.1
2025-03-05 12:26:02,248:INFO:               numpy: 1.26.4
2025-03-05 12:26:02,248:INFO:              pandas: 2.1.4
2025-03-05 12:26:02,248:INFO:              jinja2: 3.1.5
2025-03-05 12:26:02,248:INFO:               scipy: 1.11.4
2025-03-05 12:26:02,248:INFO:              joblib: 1.3.2
2025-03-05 12:26:02,248:INFO:             sklearn: 1.4.2
2025-03-05 12:26:02,248:INFO:                pyod: 2.0.3
2025-03-05 12:26:02,248:INFO:            imblearn: 0.12.4
2025-03-05 12:26:02,248:INFO:   category_encoders: 2.6.4
2025-03-05 12:26:02,248:INFO:            lightgbm: 4.6.0
2025-03-05 12:26:02,248:INFO:               numba: 0.60.0
2025-03-05 12:26:02,248:INFO:            requests: 2.32.3
2025-03-05 12:26:02,248:INFO:          matplotlib: 3.7.5
2025-03-05 12:26:02,248:INFO:          scikitplot: 0.3.7
2025-03-05 12:26:02,248:INFO:         yellowbrick: 1.5
2025-03-05 12:26:02,248:INFO:              plotly: 5.24.1
2025-03-05 12:26:02,248:INFO:    plotly-resampler: Not installed
2025-03-05 12:26:02,248:INFO:             kaleido: 0.2.1
2025-03-05 12:26:02,248:INFO:           schemdraw: 0.15
2025-03-05 12:26:02,248:INFO:         statsmodels: 0.14.4
2025-03-05 12:26:02,248:INFO:              sktime: 0.26.0
2025-03-05 12:26:02,248:INFO:               tbats: 1.1.3
2025-03-05 12:26:02,248:INFO:            pmdarima: 2.0.4
2025-03-05 12:26:02,248:INFO:              psutil: 7.0.0
2025-03-05 12:26:02,248:INFO:          markupsafe: 3.0.2
2025-03-05 12:26:02,248:INFO:             pickle5: Not installed
2025-03-05 12:26:02,249:INFO:         cloudpickle: 3.1.1
2025-03-05 12:26:02,249:INFO:         deprecation: 2.1.0
2025-03-05 12:26:02,249:INFO:              xxhash: 3.5.0
2025-03-05 12:26:02,249:INFO:           wurlitzer: 3.1.1
2025-03-05 12:26:02,249:INFO:PyCaret optional dependencies:
2025-03-05 12:26:02,249:INFO:                shap: Not installed
2025-03-05 12:26:02,249:INFO:           interpret: Not installed
2025-03-05 12:26:02,249:INFO:                umap: Not installed
2025-03-05 12:26:02,249:INFO:     ydata_profiling: Not installed
2025-03-05 12:26:02,249:INFO:  explainerdashboard: Not installed
2025-03-05 12:26:02,249:INFO:             autoviz: Not installed
2025-03-05 12:26:02,249:INFO:           fairlearn: Not installed
2025-03-05 12:26:02,249:INFO:          deepchecks: Not installed
2025-03-05 12:26:02,249:INFO:             xgboost: Not installed
2025-03-05 12:26:02,249:INFO:            catboost: Not installed
2025-03-05 12:26:02,249:INFO:              kmodes: Not installed
2025-03-05 12:26:02,249:INFO:             mlxtend: Not installed
2025-03-05 12:26:02,249:INFO:       statsforecast: Not installed
2025-03-05 12:26:02,249:INFO:        tune_sklearn: Not installed
2025-03-05 12:26:02,249:INFO:                 ray: Not installed
2025-03-05 12:26:02,249:INFO:            hyperopt: Not installed
2025-03-05 12:26:02,249:INFO:              optuna: Not installed
2025-03-05 12:26:02,249:INFO:               skopt: Not installed
2025-03-05 12:26:02,249:INFO:              mlflow: Not installed
2025-03-05 12:26:02,249:INFO:              gradio: Not installed
2025-03-05 12:26:02,249:INFO:             fastapi: Not installed
2025-03-05 12:26:02,249:INFO:             uvicorn: Not installed
2025-03-05 12:26:02,249:INFO:              m2cgen: Not installed
2025-03-05 12:26:02,249:INFO:           evidently: Not installed
2025-03-05 12:26:02,249:INFO:               fugue: Not installed
2025-03-05 12:26:02,249:INFO:           streamlit: Not installed
2025-03-05 12:26:02,249:INFO:             prophet: Not installed
2025-03-05 12:26:02,249:INFO:None
2025-03-05 12:26:02,249:INFO:Set up GPU usage.
2025-03-05 12:26:02,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,249:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 12:26:02,249:INFO:Set up data.
2025-03-05 12:26:02,253:INFO:Set up folding strategy.
2025-03-05 12:26:02,253:INFO:Set up train/test split.
2025-03-05 12:26:02,256:INFO:Set up index.
2025-03-05 12:26:02,257:INFO:Assigning column types.
2025-03-05 12:26:02,260:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:26:02,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,260:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,264:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,389:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,400:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,498:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:26:02,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,515:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,570:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,628:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,734:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:26:02,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,754:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,874:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:02,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:02,973:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:26:02,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:02,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,203:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:26:03,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:26:03,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,410:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:26:03,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,635:INFO:Preparing preprocessing pipeline...
2025-03-05 12:26:03,635:INFO:Set up simple imputation.
2025-03-05 12:26:03,636:INFO:Set up column name cleaning.
2025-03-05 12:26:03,656:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:26:03,660:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:26:03,660:INFO:Creating final display dataframe.
2025-03-05 12:26:03,719:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b1a7
2025-03-05 12:26:03,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:26:03,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:26:03,937:INFO:setup() successfully completed in 1.7s...............
2025-03-05 12:26:04,007:INFO:Initializing compare_models()
2025-03-05 12:26:04,007:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:26:04,007:INFO:Checking exceptions
2025-03-05 12:26:04,010:INFO:Preparing display monitor
2025-03-05 12:26:04,043:INFO:Initializing Linear Regression
2025-03-05 12:26:04,043:INFO:Total runtime is 3.7829081217447918e-06 minutes
2025-03-05 12:26:04,047:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:04,048:INFO:Initializing create_model()
2025-03-05 12:26:04,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:04,048:INFO:Checking exceptions
2025-03-05 12:26:04,048:INFO:Importing libraries
2025-03-05 12:26:04,049:INFO:Copying training dataset
2025-03-05 12:26:04,057:INFO:Defining folds
2025-03-05 12:26:04,057:INFO:Declaring metric variables
2025-03-05 12:26:04,063:INFO:Importing untrained model
2025-03-05 12:26:04,068:INFO:Linear Regression Imported successfully
2025-03-05 12:26:04,076:INFO:Starting cross validation
2025-03-05 12:26:04,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:04,299:INFO:Calculating mean and std
2025-03-05 12:26:04,300:INFO:Creating metrics dataframe
2025-03-05 12:26:04,301:INFO:Uploading results into container
2025-03-05 12:26:04,302:INFO:Uploading model into container now
2025-03-05 12:26:04,302:INFO:_master_model_container: 1
2025-03-05 12:26:04,302:INFO:_display_container: 2
2025-03-05 12:26:04,302:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:26:04,302:INFO:create_model() successfully completed......................................
2025-03-05 12:26:04,405:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:04,406:INFO:Creating metrics dataframe
2025-03-05 12:26:04,412:INFO:Initializing Lasso Regression
2025-03-05 12:26:04,412:INFO:Total runtime is 0.006143136819203694 minutes
2025-03-05 12:26:04,415:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:04,415:INFO:Initializing create_model()
2025-03-05 12:26:04,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:04,415:INFO:Checking exceptions
2025-03-05 12:26:04,415:INFO:Importing libraries
2025-03-05 12:26:04,415:INFO:Copying training dataset
2025-03-05 12:26:04,419:INFO:Defining folds
2025-03-05 12:26:04,420:INFO:Declaring metric variables
2025-03-05 12:26:04,422:INFO:Importing untrained model
2025-03-05 12:26:04,426:INFO:Lasso Regression Imported successfully
2025-03-05 12:26:04,431:INFO:Starting cross validation
2025-03-05 12:26:04,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:04,658:INFO:Calculating mean and std
2025-03-05 12:26:04,658:INFO:Creating metrics dataframe
2025-03-05 12:26:04,660:INFO:Uploading results into container
2025-03-05 12:26:04,661:INFO:Uploading model into container now
2025-03-05 12:26:04,661:INFO:_master_model_container: 2
2025-03-05 12:26:04,661:INFO:_display_container: 2
2025-03-05 12:26:04,661:INFO:Lasso(random_state=123)
2025-03-05 12:26:04,661:INFO:create_model() successfully completed......................................
2025-03-05 12:26:04,753:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:04,754:INFO:Creating metrics dataframe
2025-03-05 12:26:04,762:INFO:Initializing Ridge Regression
2025-03-05 12:26:04,762:INFO:Total runtime is 0.011974136034647623 minutes
2025-03-05 12:26:04,765:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:04,765:INFO:Initializing create_model()
2025-03-05 12:26:04,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:04,765:INFO:Checking exceptions
2025-03-05 12:26:04,765:INFO:Importing libraries
2025-03-05 12:26:04,766:INFO:Copying training dataset
2025-03-05 12:26:04,770:INFO:Defining folds
2025-03-05 12:26:04,770:INFO:Declaring metric variables
2025-03-05 12:26:04,773:INFO:Importing untrained model
2025-03-05 12:26:04,778:INFO:Ridge Regression Imported successfully
2025-03-05 12:26:04,786:INFO:Starting cross validation
2025-03-05 12:26:04,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:04,990:INFO:Calculating mean and std
2025-03-05 12:26:04,990:INFO:Creating metrics dataframe
2025-03-05 12:26:04,992:INFO:Uploading results into container
2025-03-05 12:26:04,992:INFO:Uploading model into container now
2025-03-05 12:26:04,992:INFO:_master_model_container: 3
2025-03-05 12:26:04,992:INFO:_display_container: 2
2025-03-05 12:26:04,993:INFO:Ridge(random_state=123)
2025-03-05 12:26:04,993:INFO:create_model() successfully completed......................................
2025-03-05 12:26:05,071:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:05,071:INFO:Creating metrics dataframe
2025-03-05 12:26:05,078:INFO:Initializing Elastic Net
2025-03-05 12:26:05,078:INFO:Total runtime is 0.01725013256072998 minutes
2025-03-05 12:26:05,081:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:05,082:INFO:Initializing create_model()
2025-03-05 12:26:05,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:05,082:INFO:Checking exceptions
2025-03-05 12:26:05,082:INFO:Importing libraries
2025-03-05 12:26:05,082:INFO:Copying training dataset
2025-03-05 12:26:05,087:INFO:Defining folds
2025-03-05 12:26:05,087:INFO:Declaring metric variables
2025-03-05 12:26:05,090:INFO:Importing untrained model
2025-03-05 12:26:05,093:INFO:Elastic Net Imported successfully
2025-03-05 12:26:05,098:INFO:Starting cross validation
2025-03-05 12:26:05,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:05,336:INFO:Calculating mean and std
2025-03-05 12:26:05,337:INFO:Creating metrics dataframe
2025-03-05 12:26:05,340:INFO:Uploading results into container
2025-03-05 12:26:05,341:INFO:Uploading model into container now
2025-03-05 12:26:05,341:INFO:_master_model_container: 4
2025-03-05 12:26:05,345:INFO:_display_container: 2
2025-03-05 12:26:05,346:INFO:ElasticNet(random_state=123)
2025-03-05 12:26:05,346:INFO:create_model() successfully completed......................................
2025-03-05 12:26:05,439:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:05,439:INFO:Creating metrics dataframe
2025-03-05 12:26:05,446:INFO:Initializing Least Angle Regression
2025-03-05 12:26:05,446:INFO:Total runtime is 0.023387320836385093 minutes
2025-03-05 12:26:05,450:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:05,450:INFO:Initializing create_model()
2025-03-05 12:26:05,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:05,450:INFO:Checking exceptions
2025-03-05 12:26:05,450:INFO:Importing libraries
2025-03-05 12:26:05,450:INFO:Copying training dataset
2025-03-05 12:26:05,455:INFO:Defining folds
2025-03-05 12:26:05,455:INFO:Declaring metric variables
2025-03-05 12:26:05,458:INFO:Importing untrained model
2025-03-05 12:26:05,461:INFO:Least Angle Regression Imported successfully
2025-03-05 12:26:05,466:INFO:Starting cross validation
2025-03-05 12:26:05,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:05,618:INFO:Calculating mean and std
2025-03-05 12:26:05,619:INFO:Creating metrics dataframe
2025-03-05 12:26:05,621:INFO:Uploading results into container
2025-03-05 12:26:05,621:INFO:Uploading model into container now
2025-03-05 12:26:05,621:INFO:_master_model_container: 5
2025-03-05 12:26:05,622:INFO:_display_container: 2
2025-03-05 12:26:05,622:INFO:Lars(random_state=123)
2025-03-05 12:26:05,622:INFO:create_model() successfully completed......................................
2025-03-05 12:26:05,707:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:05,707:INFO:Creating metrics dataframe
2025-03-05 12:26:05,714:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:26:05,714:INFO:Total runtime is 0.027848621209462486 minutes
2025-03-05 12:26:05,717:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:05,717:INFO:Initializing create_model()
2025-03-05 12:26:05,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:05,718:INFO:Checking exceptions
2025-03-05 12:26:05,718:INFO:Importing libraries
2025-03-05 12:26:05,718:INFO:Copying training dataset
2025-03-05 12:26:05,722:INFO:Defining folds
2025-03-05 12:26:05,722:INFO:Declaring metric variables
2025-03-05 12:26:05,725:INFO:Importing untrained model
2025-03-05 12:26:05,729:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:26:05,734:INFO:Starting cross validation
2025-03-05 12:26:05,735:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:05,883:INFO:Calculating mean and std
2025-03-05 12:26:05,884:INFO:Creating metrics dataframe
2025-03-05 12:26:05,886:INFO:Uploading results into container
2025-03-05 12:26:05,886:INFO:Uploading model into container now
2025-03-05 12:26:05,887:INFO:_master_model_container: 6
2025-03-05 12:26:05,887:INFO:_display_container: 2
2025-03-05 12:26:05,887:INFO:LassoLars(random_state=123)
2025-03-05 12:26:05,887:INFO:create_model() successfully completed......................................
2025-03-05 12:26:05,966:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:05,966:INFO:Creating metrics dataframe
2025-03-05 12:26:05,973:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:26:05,974:INFO:Total runtime is 0.03217125733693441 minutes
2025-03-05 12:26:05,977:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:05,977:INFO:Initializing create_model()
2025-03-05 12:26:05,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:05,978:INFO:Checking exceptions
2025-03-05 12:26:05,978:INFO:Importing libraries
2025-03-05 12:26:05,978:INFO:Copying training dataset
2025-03-05 12:26:05,982:INFO:Defining folds
2025-03-05 12:26:05,982:INFO:Declaring metric variables
2025-03-05 12:26:05,985:INFO:Importing untrained model
2025-03-05 12:26:05,988:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:26:05,995:INFO:Starting cross validation
2025-03-05 12:26:05,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:06,145:INFO:Calculating mean and std
2025-03-05 12:26:06,145:INFO:Creating metrics dataframe
2025-03-05 12:26:06,148:INFO:Uploading results into container
2025-03-05 12:26:06,148:INFO:Uploading model into container now
2025-03-05 12:26:06,149:INFO:_master_model_container: 7
2025-03-05 12:26:06,149:INFO:_display_container: 2
2025-03-05 12:26:06,149:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:26:06,149:INFO:create_model() successfully completed......................................
2025-03-05 12:26:06,229:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:06,229:INFO:Creating metrics dataframe
2025-03-05 12:26:06,237:INFO:Initializing Bayesian Ridge
2025-03-05 12:26:06,238:INFO:Total runtime is 0.03657161394755046 minutes
2025-03-05 12:26:06,241:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:06,241:INFO:Initializing create_model()
2025-03-05 12:26:06,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:06,241:INFO:Checking exceptions
2025-03-05 12:26:06,241:INFO:Importing libraries
2025-03-05 12:26:06,241:INFO:Copying training dataset
2025-03-05 12:26:06,245:INFO:Defining folds
2025-03-05 12:26:06,245:INFO:Declaring metric variables
2025-03-05 12:26:06,248:INFO:Importing untrained model
2025-03-05 12:26:06,251:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:26:06,258:INFO:Starting cross validation
2025-03-05 12:26:06,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:06,488:INFO:Calculating mean and std
2025-03-05 12:26:06,488:INFO:Creating metrics dataframe
2025-03-05 12:26:06,491:INFO:Uploading results into container
2025-03-05 12:26:06,496:INFO:Uploading model into container now
2025-03-05 12:26:06,496:INFO:_master_model_container: 8
2025-03-05 12:26:06,499:INFO:_display_container: 2
2025-03-05 12:26:06,500:INFO:BayesianRidge()
2025-03-05 12:26:06,500:INFO:create_model() successfully completed......................................
2025-03-05 12:26:06,631:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:06,631:INFO:Creating metrics dataframe
2025-03-05 12:26:06,639:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:26:06,640:INFO:Total runtime is 0.04327521721522014 minutes
2025-03-05 12:26:06,643:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:06,643:INFO:Initializing create_model()
2025-03-05 12:26:06,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:06,644:INFO:Checking exceptions
2025-03-05 12:26:06,644:INFO:Importing libraries
2025-03-05 12:26:06,644:INFO:Copying training dataset
2025-03-05 12:26:06,648:INFO:Defining folds
2025-03-05 12:26:06,648:INFO:Declaring metric variables
2025-03-05 12:26:06,651:INFO:Importing untrained model
2025-03-05 12:26:06,654:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:26:06,662:INFO:Starting cross validation
2025-03-05 12:26:06,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:06,879:INFO:Calculating mean and std
2025-03-05 12:26:06,879:INFO:Creating metrics dataframe
2025-03-05 12:26:06,881:INFO:Uploading results into container
2025-03-05 12:26:06,882:INFO:Uploading model into container now
2025-03-05 12:26:06,882:INFO:_master_model_container: 9
2025-03-05 12:26:06,883:INFO:_display_container: 2
2025-03-05 12:26:06,883:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:26:06,883:INFO:create_model() successfully completed......................................
2025-03-05 12:26:06,966:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:06,966:INFO:Creating metrics dataframe
2025-03-05 12:26:06,974:INFO:Initializing Huber Regressor
2025-03-05 12:26:06,974:INFO:Total runtime is 0.04885096152623495 minutes
2025-03-05 12:26:06,977:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:06,978:INFO:Initializing create_model()
2025-03-05 12:26:06,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:06,978:INFO:Checking exceptions
2025-03-05 12:26:06,978:INFO:Importing libraries
2025-03-05 12:26:06,978:INFO:Copying training dataset
2025-03-05 12:26:06,983:INFO:Defining folds
2025-03-05 12:26:06,983:INFO:Declaring metric variables
2025-03-05 12:26:06,986:INFO:Importing untrained model
2025-03-05 12:26:06,989:INFO:Huber Regressor Imported successfully
2025-03-05 12:26:06,996:INFO:Starting cross validation
2025-03-05 12:26:06,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:08,164:INFO:Calculating mean and std
2025-03-05 12:26:08,164:INFO:Creating metrics dataframe
2025-03-05 12:26:08,167:INFO:Uploading results into container
2025-03-05 12:26:08,171:INFO:Uploading model into container now
2025-03-05 12:26:08,171:INFO:_master_model_container: 10
2025-03-05 12:26:08,172:INFO:_display_container: 2
2025-03-05 12:26:08,172:INFO:HuberRegressor()
2025-03-05 12:26:08,172:INFO:create_model() successfully completed......................................
2025-03-05 12:26:08,307:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:08,308:INFO:Creating metrics dataframe
2025-03-05 12:26:08,316:INFO:Initializing K Neighbors Regressor
2025-03-05 12:26:08,316:INFO:Total runtime is 0.0712161938349406 minutes
2025-03-05 12:26:08,320:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:08,320:INFO:Initializing create_model()
2025-03-05 12:26:08,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:08,320:INFO:Checking exceptions
2025-03-05 12:26:08,320:INFO:Importing libraries
2025-03-05 12:26:08,320:INFO:Copying training dataset
2025-03-05 12:26:08,325:INFO:Defining folds
2025-03-05 12:26:08,325:INFO:Declaring metric variables
2025-03-05 12:26:08,328:INFO:Importing untrained model
2025-03-05 12:26:08,331:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:26:08,344:INFO:Starting cross validation
2025-03-05 12:26:08,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:08,821:INFO:Calculating mean and std
2025-03-05 12:26:08,822:INFO:Creating metrics dataframe
2025-03-05 12:26:08,824:INFO:Uploading results into container
2025-03-05 12:26:08,825:INFO:Uploading model into container now
2025-03-05 12:26:08,825:INFO:_master_model_container: 11
2025-03-05 12:26:08,825:INFO:_display_container: 2
2025-03-05 12:26:08,825:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:26:08,826:INFO:create_model() successfully completed......................................
2025-03-05 12:26:08,906:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:08,907:INFO:Creating metrics dataframe
2025-03-05 12:26:08,916:INFO:Initializing Decision Tree Regressor
2025-03-05 12:26:08,917:INFO:Total runtime is 0.08122245868047079 minutes
2025-03-05 12:26:08,920:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:08,920:INFO:Initializing create_model()
2025-03-05 12:26:08,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:08,920:INFO:Checking exceptions
2025-03-05 12:26:08,920:INFO:Importing libraries
2025-03-05 12:26:08,920:INFO:Copying training dataset
2025-03-05 12:26:08,925:INFO:Defining folds
2025-03-05 12:26:08,926:INFO:Declaring metric variables
2025-03-05 12:26:08,929:INFO:Importing untrained model
2025-03-05 12:26:08,933:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:26:08,939:INFO:Starting cross validation
2025-03-05 12:26:08,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:09,142:INFO:Calculating mean and std
2025-03-05 12:26:09,143:INFO:Creating metrics dataframe
2025-03-05 12:26:09,144:INFO:Uploading results into container
2025-03-05 12:26:09,145:INFO:Uploading model into container now
2025-03-05 12:26:09,146:INFO:_master_model_container: 12
2025-03-05 12:26:09,146:INFO:_display_container: 2
2025-03-05 12:26:09,146:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:26:09,146:INFO:create_model() successfully completed......................................
2025-03-05 12:26:09,227:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:09,228:INFO:Creating metrics dataframe
2025-03-05 12:26:09,236:INFO:Initializing Random Forest Regressor
2025-03-05 12:26:09,237:INFO:Total runtime is 0.08655754725138347 minutes
2025-03-05 12:26:09,240:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:09,240:INFO:Initializing create_model()
2025-03-05 12:26:09,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:09,241:INFO:Checking exceptions
2025-03-05 12:26:09,241:INFO:Importing libraries
2025-03-05 12:26:09,241:INFO:Copying training dataset
2025-03-05 12:26:09,245:INFO:Defining folds
2025-03-05 12:26:09,246:INFO:Declaring metric variables
2025-03-05 12:26:09,249:INFO:Importing untrained model
2025-03-05 12:26:09,252:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:26:09,257:INFO:Starting cross validation
2025-03-05 12:26:09,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:11,772:INFO:Calculating mean and std
2025-03-05 12:26:11,773:INFO:Creating metrics dataframe
2025-03-05 12:26:11,775:INFO:Uploading results into container
2025-03-05 12:26:11,776:INFO:Uploading model into container now
2025-03-05 12:26:11,776:INFO:_master_model_container: 13
2025-03-05 12:26:11,776:INFO:_display_container: 2
2025-03-05 12:26:11,777:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:26:11,777:INFO:create_model() successfully completed......................................
2025-03-05 12:26:11,861:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:11,861:INFO:Creating metrics dataframe
2025-03-05 12:26:11,871:INFO:Initializing Extra Trees Regressor
2025-03-05 12:26:11,871:INFO:Total runtime is 0.13046449820200604 minutes
2025-03-05 12:26:11,875:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:11,875:INFO:Initializing create_model()
2025-03-05 12:26:11,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:11,875:INFO:Checking exceptions
2025-03-05 12:26:11,875:INFO:Importing libraries
2025-03-05 12:26:11,875:INFO:Copying training dataset
2025-03-05 12:26:11,880:INFO:Defining folds
2025-03-05 12:26:11,880:INFO:Declaring metric variables
2025-03-05 12:26:11,883:INFO:Importing untrained model
2025-03-05 12:26:11,886:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:26:11,892:INFO:Starting cross validation
2025-03-05 12:26:11,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:13,607:INFO:Calculating mean and std
2025-03-05 12:26:13,608:INFO:Creating metrics dataframe
2025-03-05 12:26:13,609:INFO:Uploading results into container
2025-03-05 12:26:13,610:INFO:Uploading model into container now
2025-03-05 12:26:13,611:INFO:_master_model_container: 14
2025-03-05 12:26:13,611:INFO:_display_container: 2
2025-03-05 12:26:13,611:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:26:13,611:INFO:create_model() successfully completed......................................
2025-03-05 12:26:13,691:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:13,692:INFO:Creating metrics dataframe
2025-03-05 12:26:13,702:INFO:Initializing AdaBoost Regressor
2025-03-05 12:26:13,702:INFO:Total runtime is 0.160985537370046 minutes
2025-03-05 12:26:13,706:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:13,706:INFO:Initializing create_model()
2025-03-05 12:26:13,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:13,706:INFO:Checking exceptions
2025-03-05 12:26:13,706:INFO:Importing libraries
2025-03-05 12:26:13,706:INFO:Copying training dataset
2025-03-05 12:26:13,711:INFO:Defining folds
2025-03-05 12:26:13,711:INFO:Declaring metric variables
2025-03-05 12:26:13,714:INFO:Importing untrained model
2025-03-05 12:26:13,717:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:26:13,723:INFO:Starting cross validation
2025-03-05 12:26:13,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:15,644:INFO:Calculating mean and std
2025-03-05 12:26:15,645:INFO:Creating metrics dataframe
2025-03-05 12:26:15,647:INFO:Uploading results into container
2025-03-05 12:26:15,647:INFO:Uploading model into container now
2025-03-05 12:26:15,647:INFO:_master_model_container: 15
2025-03-05 12:26:15,647:INFO:_display_container: 2
2025-03-05 12:26:15,648:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:26:15,648:INFO:create_model() successfully completed......................................
2025-03-05 12:26:15,728:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:15,728:INFO:Creating metrics dataframe
2025-03-05 12:26:15,737:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:26:15,737:INFO:Total runtime is 0.19490051666895553 minutes
2025-03-05 12:26:15,742:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:15,742:INFO:Initializing create_model()
2025-03-05 12:26:15,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:15,742:INFO:Checking exceptions
2025-03-05 12:26:15,742:INFO:Importing libraries
2025-03-05 12:26:15,742:INFO:Copying training dataset
2025-03-05 12:26:15,747:INFO:Defining folds
2025-03-05 12:26:15,747:INFO:Declaring metric variables
2025-03-05 12:26:15,750:INFO:Importing untrained model
2025-03-05 12:26:15,754:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:26:15,760:INFO:Starting cross validation
2025-03-05 12:26:15,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:19,672:INFO:Calculating mean and std
2025-03-05 12:26:19,673:INFO:Creating metrics dataframe
2025-03-05 12:26:19,675:INFO:Uploading results into container
2025-03-05 12:26:19,675:INFO:Uploading model into container now
2025-03-05 12:26:19,676:INFO:_master_model_container: 16
2025-03-05 12:26:19,676:INFO:_display_container: 2
2025-03-05 12:26:19,676:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:26:19,676:INFO:create_model() successfully completed......................................
2025-03-05 12:26:19,756:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:19,756:INFO:Creating metrics dataframe
2025-03-05 12:26:19,766:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:26:19,766:INFO:Total runtime is 0.2620404998461406 minutes
2025-03-05 12:26:19,769:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:19,770:INFO:Initializing create_model()
2025-03-05 12:26:19,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:19,770:INFO:Checking exceptions
2025-03-05 12:26:19,770:INFO:Importing libraries
2025-03-05 12:26:19,770:INFO:Copying training dataset
2025-03-05 12:26:19,776:INFO:Defining folds
2025-03-05 12:26:19,776:INFO:Declaring metric variables
2025-03-05 12:26:19,779:INFO:Importing untrained model
2025-03-05 12:26:19,783:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:26:19,789:INFO:Starting cross validation
2025-03-05 12:26:19,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:19,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025504 seconds.
2025-03-05 12:26:19,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:19,849:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:26:19,854:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 2
2025-03-05 12:26:19,868:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 12:26:20,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043522 seconds.
2025-03-05 12:26:20,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:20,600:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:26:20,606:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:20,619:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 12:26:21,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.
2025-03-05 12:26:21,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:21,464:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:26:21,464:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:21,464:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 12:26:21,971:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027596 seconds.
2025-03-05 12:26:21,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:21,972:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:26:21,979:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:21,993:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 12:26:22,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031619 seconds.
2025-03-05 12:26:22,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:22,779:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:26:22,786:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:22,800:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 12:26:23,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025703 seconds.
2025-03-05 12:26:23,588:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:23,588:INFO:[LightGBM] [Info] Total Bins 232
2025-03-05 12:26:23,593:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:23,606:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 12:26:24,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025681 seconds.
2025-03-05 12:26:24,492:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:24,492:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:26:24,498:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:24,512:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 12:26:24,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028700 seconds.
2025-03-05 12:26:24,761:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:24,761:INFO:[LightGBM] [Info] Total Bins 232
2025-03-05 12:26:24,767:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:24,787:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 12:26:26,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029584 seconds.
2025-03-05 12:26:26,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:26,155:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:26:26,161:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:26,174:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 12:26:28,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035540 seconds.
2025-03-05 12:26:28,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:26:28,468:INFO:[LightGBM] [Info] Total Bins 231
2025-03-05 12:26:28,473:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:26:28,487:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 12:26:29,124:INFO:Calculating mean and std
2025-03-05 12:26:29,126:INFO:Creating metrics dataframe
2025-03-05 12:26:29,129:INFO:Uploading results into container
2025-03-05 12:26:29,129:INFO:Uploading model into container now
2025-03-05 12:26:29,130:INFO:_master_model_container: 17
2025-03-05 12:26:29,130:INFO:_display_container: 2
2025-03-05 12:26:29,131:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:26:29,131:INFO:create_model() successfully completed......................................
2025-03-05 12:26:29,227:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:29,227:INFO:Creating metrics dataframe
2025-03-05 12:26:29,237:INFO:Initializing Dummy Regressor
2025-03-05 12:26:29,238:INFO:Total runtime is 0.41990534067153934 minutes
2025-03-05 12:26:29,241:INFO:SubProcess create_model() called ==================================
2025-03-05 12:26:29,241:INFO:Initializing create_model()
2025-03-05 12:26:29,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f54e04f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:29,241:INFO:Checking exceptions
2025-03-05 12:26:29,241:INFO:Importing libraries
2025-03-05 12:26:29,241:INFO:Copying training dataset
2025-03-05 12:26:29,246:INFO:Defining folds
2025-03-05 12:26:29,246:INFO:Declaring metric variables
2025-03-05 12:26:29,249:INFO:Importing untrained model
2025-03-05 12:26:29,253:INFO:Dummy Regressor Imported successfully
2025-03-05 12:26:29,259:INFO:Starting cross validation
2025-03-05 12:26:29,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:26:29,392:INFO:Calculating mean and std
2025-03-05 12:26:29,393:INFO:Creating metrics dataframe
2025-03-05 12:26:29,395:INFO:Uploading results into container
2025-03-05 12:26:29,395:INFO:Uploading model into container now
2025-03-05 12:26:29,395:INFO:_master_model_container: 18
2025-03-05 12:26:29,395:INFO:_display_container: 2
2025-03-05 12:26:29,396:INFO:DummyRegressor()
2025-03-05 12:26:29,396:INFO:create_model() successfully completed......................................
2025-03-05 12:26:29,480:INFO:SubProcess create_model() end ==================================
2025-03-05 12:26:29,480:INFO:Creating metrics dataframe
2025-03-05 12:26:29,490:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 12:26:29,498:INFO:Initializing create_model()
2025-03-05 12:26:29,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:26:29,499:INFO:Checking exceptions
2025-03-05 12:26:29,500:INFO:Importing libraries
2025-03-05 12:26:29,500:INFO:Copying training dataset
2025-03-05 12:26:29,504:INFO:Defining folds
2025-03-05 12:26:29,504:INFO:Declaring metric variables
2025-03-05 12:26:29,504:INFO:Importing untrained model
2025-03-05 12:26:29,504:INFO:Declaring custom model
2025-03-05 12:26:29,505:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:26:29,506:INFO:Cross validation set to False
2025-03-05 12:26:29,506:INFO:Fitting Model
2025-03-05 12:26:29,925:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:26:29,925:INFO:create_model() successfully completed......................................
2025-03-05 12:26:30,031:INFO:_master_model_container: 18
2025-03-05 12:26:30,031:INFO:_display_container: 2
2025-03-05 12:26:30,032:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:26:30,032:INFO:compare_models() successfully completed......................................
2025-03-05 12:26:34,048:INFO:Initializing evaluate_model()
2025-03-05 12:26:34,048:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 12:26:34,058:INFO:Initializing plot_model()
2025-03-05 12:26:34,058:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, system=True)
2025-03-05 12:26:34,058:INFO:Checking exceptions
2025-03-05 12:26:34,061:INFO:Preloading libraries
2025-03-05 12:26:34,066:INFO:Copying training dataset
2025-03-05 12:26:34,067:INFO:Plot type: pipeline
2025-03-05 12:26:34,171:INFO:Visual Rendered Successfully
2025-03-05 12:26:34,253:INFO:plot_model() successfully completed......................................
2025-03-05 12:27:00,985:INFO:Initializing plot_model()
2025-03-05 12:27:00,986:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, system=True)
2025-03-05 12:27:00,986:INFO:Checking exceptions
2025-03-05 12:27:00,990:INFO:Preloading libraries
2025-03-05 12:27:00,997:INFO:Copying training dataset
2025-03-05 12:27:00,997:INFO:Plot type: residuals
2025-03-05 12:27:01,091:INFO:Fitting Model
2025-03-05 12:27:01,091:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 12:27:01,176:INFO:Scoring test/hold-out set
2025-03-05 12:27:01,738:INFO:Visual Rendered Successfully
2025-03-05 12:27:01,837:INFO:plot_model() successfully completed......................................
2025-03-05 12:27:08,005:INFO:Initializing plot_model()
2025-03-05 12:27:08,006:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, system=True)
2025-03-05 12:27:08,006:INFO:Checking exceptions
2025-03-05 12:27:08,010:INFO:Preloading libraries
2025-03-05 12:27:08,016:INFO:Copying training dataset
2025-03-05 12:27:08,017:INFO:Plot type: feature
2025-03-05 12:27:08,021:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 12:27:08,130:INFO:Visual Rendered Successfully
2025-03-05 12:27:08,216:INFO:plot_model() successfully completed......................................
2025-03-05 12:27:15,403:INFO:Initializing predict_model()
2025-03-05 12:27:15,403:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb48c790>)
2025-03-05 12:27:15,403:INFO:Checking exceptions
2025-03-05 12:27:15,403:INFO:Preloading libraries
2025-03-05 12:27:15,461:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:28:30,023:INFO:Initializing predict_model()
2025-03-05 12:28:30,023:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb6103d0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb48c3a0>)
2025-03-05 12:28:30,023:INFO:Checking exceptions
2025-03-05 12:28:30,023:INFO:Preloading libraries
2025-03-05 12:28:30,026:INFO:Set up data.
2025-03-05 12:28:30,030:INFO:Set up index.
2025-03-05 12:28:30,061:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:46:52,618:INFO:PyCaret RegressionExperiment
2025-03-05 12:46:52,618:INFO:Logging name: reg-default-name
2025-03-05 12:46:52,618:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:46:52,619:INFO:version 3.3.1
2025-03-05 12:46:52,619:INFO:Initializing setup()
2025-03-05 12:46:52,619:INFO:self.USI: 583b
2025-03-05 12:46:52,619:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 12:46:52,619:INFO:Checking environment
2025-03-05 12:46:52,619:INFO:python_version: 3.9.21
2025-03-05 12:46:52,619:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:46:52,619:INFO:machine: x86_64
2025-03-05 12:46:52,619:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:46:52,619:INFO:Memory: svmem(total=33374507008, available=22097862656, percent=33.8, used=8831795200, free=5141561344, active=12456988672, inactive=11655499776, buffers=645566464, cached=18755584000, shared=1915756544, slab=1802522624)
2025-03-05 12:46:52,620:INFO:Physical Core: 24
2025-03-05 12:46:52,620:INFO:Logical Core: 32
2025-03-05 12:46:52,620:INFO:Checking libraries
2025-03-05 12:46:52,620:INFO:System:
2025-03-05 12:46:52,620:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:46:52,620:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:46:52,620:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:46:52,620:INFO:PyCaret required dependencies:
2025-03-05 12:46:52,620:INFO:                 pip: 25.0
2025-03-05 12:46:52,620:INFO:          setuptools: 75.8.0
2025-03-05 12:46:52,620:INFO:             pycaret: 3.3.1
2025-03-05 12:46:52,620:INFO:             IPython: 8.18.1
2025-03-05 12:46:52,620:INFO:          ipywidgets: 8.1.5
2025-03-05 12:46:52,620:INFO:                tqdm: 4.67.1
2025-03-05 12:46:52,620:INFO:               numpy: 1.26.4
2025-03-05 12:46:52,620:INFO:              pandas: 2.1.4
2025-03-05 12:46:52,620:INFO:              jinja2: 3.1.5
2025-03-05 12:46:52,620:INFO:               scipy: 1.11.4
2025-03-05 12:46:52,620:INFO:              joblib: 1.3.2
2025-03-05 12:46:52,620:INFO:             sklearn: 1.4.2
2025-03-05 12:46:52,620:INFO:                pyod: 2.0.3
2025-03-05 12:46:52,620:INFO:            imblearn: 0.12.4
2025-03-05 12:46:52,620:INFO:   category_encoders: 2.6.4
2025-03-05 12:46:52,620:INFO:            lightgbm: 4.6.0
2025-03-05 12:46:52,620:INFO:               numba: 0.60.0
2025-03-05 12:46:52,620:INFO:            requests: 2.32.3
2025-03-05 12:46:52,620:INFO:          matplotlib: 3.7.5
2025-03-05 12:46:52,620:INFO:          scikitplot: 0.3.7
2025-03-05 12:46:52,620:INFO:         yellowbrick: 1.5
2025-03-05 12:46:52,620:INFO:              plotly: 5.24.1
2025-03-05 12:46:52,620:INFO:    plotly-resampler: Not installed
2025-03-05 12:46:52,620:INFO:             kaleido: 0.2.1
2025-03-05 12:46:52,620:INFO:           schemdraw: 0.15
2025-03-05 12:46:52,620:INFO:         statsmodels: 0.14.4
2025-03-05 12:46:52,620:INFO:              sktime: 0.26.0
2025-03-05 12:46:52,620:INFO:               tbats: 1.1.3
2025-03-05 12:46:52,620:INFO:            pmdarima: 2.0.4
2025-03-05 12:46:52,620:INFO:              psutil: 7.0.0
2025-03-05 12:46:52,620:INFO:          markupsafe: 3.0.2
2025-03-05 12:46:52,620:INFO:             pickle5: Not installed
2025-03-05 12:46:52,620:INFO:         cloudpickle: 3.1.1
2025-03-05 12:46:52,620:INFO:         deprecation: 2.1.0
2025-03-05 12:46:52,620:INFO:              xxhash: 3.5.0
2025-03-05 12:46:52,620:INFO:           wurlitzer: 3.1.1
2025-03-05 12:46:52,620:INFO:PyCaret optional dependencies:
2025-03-05 12:46:52,621:INFO:                shap: Not installed
2025-03-05 12:46:52,621:INFO:           interpret: Not installed
2025-03-05 12:46:52,621:INFO:                umap: Not installed
2025-03-05 12:46:52,621:INFO:     ydata_profiling: Not installed
2025-03-05 12:46:52,621:INFO:  explainerdashboard: Not installed
2025-03-05 12:46:52,621:INFO:             autoviz: Not installed
2025-03-05 12:46:52,621:INFO:           fairlearn: Not installed
2025-03-05 12:46:52,621:INFO:          deepchecks: Not installed
2025-03-05 12:46:52,621:INFO:             xgboost: Not installed
2025-03-05 12:46:52,621:INFO:            catboost: Not installed
2025-03-05 12:46:52,621:INFO:              kmodes: Not installed
2025-03-05 12:46:52,621:INFO:             mlxtend: Not installed
2025-03-05 12:46:52,621:INFO:       statsforecast: Not installed
2025-03-05 12:46:52,621:INFO:        tune_sklearn: Not installed
2025-03-05 12:46:52,621:INFO:                 ray: Not installed
2025-03-05 12:46:52,621:INFO:            hyperopt: Not installed
2025-03-05 12:46:52,621:INFO:              optuna: Not installed
2025-03-05 12:46:52,621:INFO:               skopt: Not installed
2025-03-05 12:46:52,621:INFO:              mlflow: Not installed
2025-03-05 12:46:52,621:INFO:              gradio: Not installed
2025-03-05 12:46:52,621:INFO:             fastapi: Not installed
2025-03-05 12:46:52,621:INFO:             uvicorn: Not installed
2025-03-05 12:46:52,621:INFO:              m2cgen: Not installed
2025-03-05 12:46:52,621:INFO:           evidently: Not installed
2025-03-05 12:46:52,621:INFO:               fugue: Not installed
2025-03-05 12:46:52,621:INFO:           streamlit: Not installed
2025-03-05 12:46:52,621:INFO:             prophet: Not installed
2025-03-05 12:46:52,621:INFO:None
2025-03-05 12:46:52,621:INFO:Set up GPU usage.
2025-03-05 12:46:52,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,621:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 12:46:52,621:INFO:Set up data.
2025-03-05 12:46:52,625:INFO:Set up folding strategy.
2025-03-05 12:46:52,625:INFO:Set up train/test split.
2025-03-05 12:46:52,628:INFO:Set up index.
2025-03-05 12:46:52,629:INFO:Assigning column types.
2025-03-05 12:46:52,632:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:46:52,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,633:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,734:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,861:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:46:52,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:52,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:52,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:46:52,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,106:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:46:53,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,342:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:46:53,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:46:53,588:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,588:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:46:53,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,794:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:46:53,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:53,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:53,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,004:INFO:Preparing preprocessing pipeline...
2025-03-05 12:46:54,004:INFO:Set up simple imputation.
2025-03-05 12:46:54,005:INFO:Set up column name cleaning.
2025-03-05 12:46:54,035:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:46:54,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x', 'error'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:46:54,040:INFO:Creating final display dataframe.
2025-03-05 12:46:54,103:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 4)
4        Transformed data shape        (20088, 4)
5   Transformed train set shape        (14061, 4)
6    Transformed test set shape         (6027, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              583b
2025-03-05 12:46:54,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,324:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:46:54,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:46:54,328:INFO:setup() successfully completed in 1.71s...............
2025-03-05 12:46:57,209:INFO:Initializing compare_models()
2025-03-05 12:46:57,209:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:46:57,209:INFO:Checking exceptions
2025-03-05 12:46:57,212:INFO:Preparing display monitor
2025-03-05 12:46:57,231:INFO:Initializing Linear Regression
2025-03-05 12:46:57,232:INFO:Total runtime is 3.9299329121907554e-06 minutes
2025-03-05 12:46:57,234:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:57,235:INFO:Initializing create_model()
2025-03-05 12:46:57,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:57,235:INFO:Checking exceptions
2025-03-05 12:46:57,235:INFO:Importing libraries
2025-03-05 12:46:57,235:INFO:Copying training dataset
2025-03-05 12:46:57,239:INFO:Defining folds
2025-03-05 12:46:57,240:INFO:Declaring metric variables
2025-03-05 12:46:57,243:INFO:Importing untrained model
2025-03-05 12:46:57,246:INFO:Linear Regression Imported successfully
2025-03-05 12:46:57,251:INFO:Starting cross validation
2025-03-05 12:46:57,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:57,413:INFO:Calculating mean and std
2025-03-05 12:46:57,413:INFO:Creating metrics dataframe
2025-03-05 12:46:57,415:INFO:Uploading results into container
2025-03-05 12:46:57,415:INFO:Uploading model into container now
2025-03-05 12:46:57,416:INFO:_master_model_container: 1
2025-03-05 12:46:57,416:INFO:_display_container: 2
2025-03-05 12:46:57,416:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:46:57,416:INFO:create_model() successfully completed......................................
2025-03-05 12:46:57,508:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:57,509:INFO:Creating metrics dataframe
2025-03-05 12:46:57,515:INFO:Initializing Lasso Regression
2025-03-05 12:46:57,515:INFO:Total runtime is 0.004722380638122558 minutes
2025-03-05 12:46:57,518:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:57,518:INFO:Initializing create_model()
2025-03-05 12:46:57,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:57,518:INFO:Checking exceptions
2025-03-05 12:46:57,518:INFO:Importing libraries
2025-03-05 12:46:57,518:INFO:Copying training dataset
2025-03-05 12:46:57,522:INFO:Defining folds
2025-03-05 12:46:57,523:INFO:Declaring metric variables
2025-03-05 12:46:57,525:INFO:Importing untrained model
2025-03-05 12:46:57,528:INFO:Lasso Regression Imported successfully
2025-03-05 12:46:57,534:INFO:Starting cross validation
2025-03-05 12:46:57,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:57,740:INFO:Calculating mean and std
2025-03-05 12:46:57,740:INFO:Creating metrics dataframe
2025-03-05 12:46:57,742:INFO:Uploading results into container
2025-03-05 12:46:57,743:INFO:Uploading model into container now
2025-03-05 12:46:57,743:INFO:_master_model_container: 2
2025-03-05 12:46:57,743:INFO:_display_container: 2
2025-03-05 12:46:57,743:INFO:Lasso(random_state=123)
2025-03-05 12:46:57,744:INFO:create_model() successfully completed......................................
2025-03-05 12:46:57,838:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:57,839:INFO:Creating metrics dataframe
2025-03-05 12:46:57,846:INFO:Initializing Ridge Regression
2025-03-05 12:46:57,847:INFO:Total runtime is 0.010253552595774332 minutes
2025-03-05 12:46:57,850:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:57,850:INFO:Initializing create_model()
2025-03-05 12:46:57,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:57,850:INFO:Checking exceptions
2025-03-05 12:46:57,850:INFO:Importing libraries
2025-03-05 12:46:57,850:INFO:Copying training dataset
2025-03-05 12:46:57,854:INFO:Defining folds
2025-03-05 12:46:57,855:INFO:Declaring metric variables
2025-03-05 12:46:57,857:INFO:Importing untrained model
2025-03-05 12:46:57,861:INFO:Ridge Regression Imported successfully
2025-03-05 12:46:57,869:INFO:Starting cross validation
2025-03-05 12:46:57,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:58,026:INFO:Calculating mean and std
2025-03-05 12:46:58,026:INFO:Creating metrics dataframe
2025-03-05 12:46:58,027:INFO:Uploading results into container
2025-03-05 12:46:58,028:INFO:Uploading model into container now
2025-03-05 12:46:58,028:INFO:_master_model_container: 3
2025-03-05 12:46:58,028:INFO:_display_container: 2
2025-03-05 12:46:58,028:INFO:Ridge(random_state=123)
2025-03-05 12:46:58,028:INFO:create_model() successfully completed......................................
2025-03-05 12:46:58,113:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:58,113:INFO:Creating metrics dataframe
2025-03-05 12:46:58,120:INFO:Initializing Elastic Net
2025-03-05 12:46:58,120:INFO:Total runtime is 0.014815906683603922 minutes
2025-03-05 12:46:58,124:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:58,124:INFO:Initializing create_model()
2025-03-05 12:46:58,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:58,124:INFO:Checking exceptions
2025-03-05 12:46:58,124:INFO:Importing libraries
2025-03-05 12:46:58,124:INFO:Copying training dataset
2025-03-05 12:46:58,128:INFO:Defining folds
2025-03-05 12:46:58,129:INFO:Declaring metric variables
2025-03-05 12:46:58,131:INFO:Importing untrained model
2025-03-05 12:46:58,134:INFO:Elastic Net Imported successfully
2025-03-05 12:46:58,140:INFO:Starting cross validation
2025-03-05 12:46:58,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:58,343:INFO:Calculating mean and std
2025-03-05 12:46:58,344:INFO:Creating metrics dataframe
2025-03-05 12:46:58,347:INFO:Uploading results into container
2025-03-05 12:46:58,348:INFO:Uploading model into container now
2025-03-05 12:46:58,350:INFO:_master_model_container: 4
2025-03-05 12:46:58,350:INFO:_display_container: 2
2025-03-05 12:46:58,350:INFO:ElasticNet(random_state=123)
2025-03-05 12:46:58,350:INFO:create_model() successfully completed......................................
2025-03-05 12:46:58,464:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:58,464:INFO:Creating metrics dataframe
2025-03-05 12:46:58,471:INFO:Initializing Least Angle Regression
2025-03-05 12:46:58,471:INFO:Total runtime is 0.020655147234598794 minutes
2025-03-05 12:46:58,474:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:58,474:INFO:Initializing create_model()
2025-03-05 12:46:58,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:58,474:INFO:Checking exceptions
2025-03-05 12:46:58,474:INFO:Importing libraries
2025-03-05 12:46:58,474:INFO:Copying training dataset
2025-03-05 12:46:58,479:INFO:Defining folds
2025-03-05 12:46:58,479:INFO:Declaring metric variables
2025-03-05 12:46:58,482:INFO:Importing untrained model
2025-03-05 12:46:58,485:INFO:Least Angle Regression Imported successfully
2025-03-05 12:46:58,491:INFO:Starting cross validation
2025-03-05 12:46:58,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:58,664:INFO:Calculating mean and std
2025-03-05 12:46:58,665:INFO:Creating metrics dataframe
2025-03-05 12:46:58,666:INFO:Uploading results into container
2025-03-05 12:46:58,667:INFO:Uploading model into container now
2025-03-05 12:46:58,667:INFO:_master_model_container: 5
2025-03-05 12:46:58,667:INFO:_display_container: 2
2025-03-05 12:46:58,668:INFO:Lars(random_state=123)
2025-03-05 12:46:58,668:INFO:create_model() successfully completed......................................
2025-03-05 12:46:58,753:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:58,753:INFO:Creating metrics dataframe
2025-03-05 12:46:58,760:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:46:58,760:INFO:Total runtime is 0.025479118029276528 minutes
2025-03-05 12:46:58,763:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:58,764:INFO:Initializing create_model()
2025-03-05 12:46:58,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:58,764:INFO:Checking exceptions
2025-03-05 12:46:58,764:INFO:Importing libraries
2025-03-05 12:46:58,764:INFO:Copying training dataset
2025-03-05 12:46:58,769:INFO:Defining folds
2025-03-05 12:46:58,769:INFO:Declaring metric variables
2025-03-05 12:46:58,773:INFO:Importing untrained model
2025-03-05 12:46:58,776:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:46:58,784:INFO:Starting cross validation
2025-03-05 12:46:58,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:58,939:INFO:Calculating mean and std
2025-03-05 12:46:58,940:INFO:Creating metrics dataframe
2025-03-05 12:46:58,942:INFO:Uploading results into container
2025-03-05 12:46:58,943:INFO:Uploading model into container now
2025-03-05 12:46:58,943:INFO:_master_model_container: 6
2025-03-05 12:46:58,943:INFO:_display_container: 2
2025-03-05 12:46:58,943:INFO:LassoLars(random_state=123)
2025-03-05 12:46:58,943:INFO:create_model() successfully completed......................................
2025-03-05 12:46:59,030:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:59,030:INFO:Creating metrics dataframe
2025-03-05 12:46:59,038:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:46:59,038:INFO:Total runtime is 0.030112985769907633 minutes
2025-03-05 12:46:59,041:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:59,041:INFO:Initializing create_model()
2025-03-05 12:46:59,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:59,042:INFO:Checking exceptions
2025-03-05 12:46:59,042:INFO:Importing libraries
2025-03-05 12:46:59,042:INFO:Copying training dataset
2025-03-05 12:46:59,047:INFO:Defining folds
2025-03-05 12:46:59,047:INFO:Declaring metric variables
2025-03-05 12:46:59,050:INFO:Importing untrained model
2025-03-05 12:46:59,053:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:46:59,059:INFO:Starting cross validation
2025-03-05 12:46:59,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:59,211:INFO:Calculating mean and std
2025-03-05 12:46:59,212:INFO:Creating metrics dataframe
2025-03-05 12:46:59,214:INFO:Uploading results into container
2025-03-05 12:46:59,214:INFO:Uploading model into container now
2025-03-05 12:46:59,214:INFO:_master_model_container: 7
2025-03-05 12:46:59,215:INFO:_display_container: 2
2025-03-05 12:46:59,215:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:46:59,215:INFO:create_model() successfully completed......................................
2025-03-05 12:46:59,297:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:59,297:INFO:Creating metrics dataframe
2025-03-05 12:46:59,304:INFO:Initializing Bayesian Ridge
2025-03-05 12:46:59,305:INFO:Total runtime is 0.03455376625061035 minutes
2025-03-05 12:46:59,308:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:59,308:INFO:Initializing create_model()
2025-03-05 12:46:59,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:59,308:INFO:Checking exceptions
2025-03-05 12:46:59,308:INFO:Importing libraries
2025-03-05 12:46:59,308:INFO:Copying training dataset
2025-03-05 12:46:59,313:INFO:Defining folds
2025-03-05 12:46:59,314:INFO:Declaring metric variables
2025-03-05 12:46:59,317:INFO:Importing untrained model
2025-03-05 12:46:59,320:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:46:59,325:INFO:Starting cross validation
2025-03-05 12:46:59,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:59,533:INFO:Calculating mean and std
2025-03-05 12:46:59,534:INFO:Creating metrics dataframe
2025-03-05 12:46:59,537:INFO:Uploading results into container
2025-03-05 12:46:59,539:INFO:Uploading model into container now
2025-03-05 12:46:59,540:INFO:_master_model_container: 8
2025-03-05 12:46:59,540:INFO:_display_container: 2
2025-03-05 12:46:59,541:INFO:BayesianRidge()
2025-03-05 12:46:59,541:INFO:create_model() successfully completed......................................
2025-03-05 12:46:59,686:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:59,686:INFO:Creating metrics dataframe
2025-03-05 12:46:59,694:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:46:59,694:INFO:Total runtime is 0.04104165633519491 minutes
2025-03-05 12:46:59,697:INFO:SubProcess create_model() called ==================================
2025-03-05 12:46:59,697:INFO:Initializing create_model()
2025-03-05 12:46:59,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:46:59,697:INFO:Checking exceptions
2025-03-05 12:46:59,698:INFO:Importing libraries
2025-03-05 12:46:59,698:INFO:Copying training dataset
2025-03-05 12:46:59,703:INFO:Defining folds
2025-03-05 12:46:59,703:INFO:Declaring metric variables
2025-03-05 12:46:59,706:INFO:Importing untrained model
2025-03-05 12:46:59,710:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:46:59,716:INFO:Starting cross validation
2025-03-05 12:46:59,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:46:59,910:INFO:Calculating mean and std
2025-03-05 12:46:59,911:INFO:Creating metrics dataframe
2025-03-05 12:46:59,913:INFO:Uploading results into container
2025-03-05 12:46:59,913:INFO:Uploading model into container now
2025-03-05 12:46:59,914:INFO:_master_model_container: 9
2025-03-05 12:46:59,914:INFO:_display_container: 2
2025-03-05 12:46:59,914:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:46:59,914:INFO:create_model() successfully completed......................................
2025-03-05 12:46:59,998:INFO:SubProcess create_model() end ==================================
2025-03-05 12:46:59,999:INFO:Creating metrics dataframe
2025-03-05 12:47:00,008:INFO:Initializing Huber Regressor
2025-03-05 12:47:00,008:INFO:Total runtime is 0.046284413337707525 minutes
2025-03-05 12:47:00,011:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:00,012:INFO:Initializing create_model()
2025-03-05 12:47:00,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:00,012:INFO:Checking exceptions
2025-03-05 12:47:00,012:INFO:Importing libraries
2025-03-05 12:47:00,012:INFO:Copying training dataset
2025-03-05 12:47:00,017:INFO:Defining folds
2025-03-05 12:47:00,017:INFO:Declaring metric variables
2025-03-05 12:47:00,020:INFO:Importing untrained model
2025-03-05 12:47:00,023:INFO:Huber Regressor Imported successfully
2025-03-05 12:47:00,029:INFO:Starting cross validation
2025-03-05 12:47:00,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:02,306:INFO:Calculating mean and std
2025-03-05 12:47:02,308:INFO:Creating metrics dataframe
2025-03-05 12:47:02,314:INFO:Uploading results into container
2025-03-05 12:47:02,316:INFO:Uploading model into container now
2025-03-05 12:47:02,316:INFO:_master_model_container: 10
2025-03-05 12:47:02,317:INFO:_display_container: 2
2025-03-05 12:47:02,317:INFO:HuberRegressor()
2025-03-05 12:47:02,317:INFO:create_model() successfully completed......................................
2025-03-05 12:47:02,455:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:02,455:INFO:Creating metrics dataframe
2025-03-05 12:47:02,464:INFO:Initializing K Neighbors Regressor
2025-03-05 12:47:02,464:INFO:Total runtime is 0.0872139890988668 minutes
2025-03-05 12:47:02,467:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:02,467:INFO:Initializing create_model()
2025-03-05 12:47:02,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:02,468:INFO:Checking exceptions
2025-03-05 12:47:02,468:INFO:Importing libraries
2025-03-05 12:47:02,468:INFO:Copying training dataset
2025-03-05 12:47:02,473:INFO:Defining folds
2025-03-05 12:47:02,473:INFO:Declaring metric variables
2025-03-05 12:47:02,476:INFO:Importing untrained model
2025-03-05 12:47:02,479:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:47:02,485:INFO:Starting cross validation
2025-03-05 12:47:02,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:03,002:INFO:Calculating mean and std
2025-03-05 12:47:03,003:INFO:Creating metrics dataframe
2025-03-05 12:47:03,004:INFO:Uploading results into container
2025-03-05 12:47:03,005:INFO:Uploading model into container now
2025-03-05 12:47:03,005:INFO:_master_model_container: 11
2025-03-05 12:47:03,006:INFO:_display_container: 2
2025-03-05 12:47:03,006:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:47:03,006:INFO:create_model() successfully completed......................................
2025-03-05 12:47:03,090:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:03,090:INFO:Creating metrics dataframe
2025-03-05 12:47:03,098:INFO:Initializing Decision Tree Regressor
2025-03-05 12:47:03,099:INFO:Total runtime is 0.09778852065404257 minutes
2025-03-05 12:47:03,102:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:03,102:INFO:Initializing create_model()
2025-03-05 12:47:03,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:03,102:INFO:Checking exceptions
2025-03-05 12:47:03,102:INFO:Importing libraries
2025-03-05 12:47:03,102:INFO:Copying training dataset
2025-03-05 12:47:03,108:INFO:Defining folds
2025-03-05 12:47:03,108:INFO:Declaring metric variables
2025-03-05 12:47:03,112:INFO:Importing untrained model
2025-03-05 12:47:03,115:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:47:03,122:INFO:Starting cross validation
2025-03-05 12:47:03,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:03,344:INFO:Calculating mean and std
2025-03-05 12:47:03,345:INFO:Creating metrics dataframe
2025-03-05 12:47:03,347:INFO:Uploading results into container
2025-03-05 12:47:03,347:INFO:Uploading model into container now
2025-03-05 12:47:03,348:INFO:_master_model_container: 12
2025-03-05 12:47:03,348:INFO:_display_container: 2
2025-03-05 12:47:03,348:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:47:03,348:INFO:create_model() successfully completed......................................
2025-03-05 12:47:03,430:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:03,430:INFO:Creating metrics dataframe
2025-03-05 12:47:03,438:INFO:Initializing Random Forest Regressor
2025-03-05 12:47:03,439:INFO:Total runtime is 0.10345293283462526 minutes
2025-03-05 12:47:03,441:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:03,442:INFO:Initializing create_model()
2025-03-05 12:47:03,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:03,442:INFO:Checking exceptions
2025-03-05 12:47:03,442:INFO:Importing libraries
2025-03-05 12:47:03,442:INFO:Copying training dataset
2025-03-05 12:47:03,447:INFO:Defining folds
2025-03-05 12:47:03,447:INFO:Declaring metric variables
2025-03-05 12:47:03,450:INFO:Importing untrained model
2025-03-05 12:47:03,453:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:47:03,459:INFO:Starting cross validation
2025-03-05 12:47:03,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:06,045:INFO:Calculating mean and std
2025-03-05 12:47:06,046:INFO:Creating metrics dataframe
2025-03-05 12:47:06,048:INFO:Uploading results into container
2025-03-05 12:47:06,048:INFO:Uploading model into container now
2025-03-05 12:47:06,049:INFO:_master_model_container: 13
2025-03-05 12:47:06,049:INFO:_display_container: 2
2025-03-05 12:47:06,049:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:47:06,049:INFO:create_model() successfully completed......................................
2025-03-05 12:47:06,133:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:06,133:INFO:Creating metrics dataframe
2025-03-05 12:47:06,144:INFO:Initializing Extra Trees Regressor
2025-03-05 12:47:06,144:INFO:Total runtime is 0.14854143857955934 minutes
2025-03-05 12:47:06,148:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:06,148:INFO:Initializing create_model()
2025-03-05 12:47:06,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:06,148:INFO:Checking exceptions
2025-03-05 12:47:06,148:INFO:Importing libraries
2025-03-05 12:47:06,148:INFO:Copying training dataset
2025-03-05 12:47:06,153:INFO:Defining folds
2025-03-05 12:47:06,153:INFO:Declaring metric variables
2025-03-05 12:47:06,156:INFO:Importing untrained model
2025-03-05 12:47:06,160:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:47:06,166:INFO:Starting cross validation
2025-03-05 12:47:06,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:07,860:INFO:Calculating mean and std
2025-03-05 12:47:07,861:INFO:Creating metrics dataframe
2025-03-05 12:47:07,863:INFO:Uploading results into container
2025-03-05 12:47:07,863:INFO:Uploading model into container now
2025-03-05 12:47:07,864:INFO:_master_model_container: 14
2025-03-05 12:47:07,864:INFO:_display_container: 2
2025-03-05 12:47:07,864:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:47:07,864:INFO:create_model() successfully completed......................................
2025-03-05 12:47:07,946:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:07,946:INFO:Creating metrics dataframe
2025-03-05 12:47:07,956:INFO:Initializing AdaBoost Regressor
2025-03-05 12:47:07,956:INFO:Total runtime is 0.1787399172782898 minutes
2025-03-05 12:47:07,959:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:07,959:INFO:Initializing create_model()
2025-03-05 12:47:07,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:07,959:INFO:Checking exceptions
2025-03-05 12:47:07,959:INFO:Importing libraries
2025-03-05 12:47:07,959:INFO:Copying training dataset
2025-03-05 12:47:07,964:INFO:Defining folds
2025-03-05 12:47:07,964:INFO:Declaring metric variables
2025-03-05 12:47:07,967:INFO:Importing untrained model
2025-03-05 12:47:07,970:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:47:07,976:INFO:Starting cross validation
2025-03-05 12:47:07,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:11,006:INFO:Calculating mean and std
2025-03-05 12:47:11,007:INFO:Creating metrics dataframe
2025-03-05 12:47:11,009:INFO:Uploading results into container
2025-03-05 12:47:11,010:INFO:Uploading model into container now
2025-03-05 12:47:11,010:INFO:_master_model_container: 15
2025-03-05 12:47:11,010:INFO:_display_container: 2
2025-03-05 12:47:11,010:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:47:11,010:INFO:create_model() successfully completed......................................
2025-03-05 12:47:11,094:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:11,094:INFO:Creating metrics dataframe
2025-03-05 12:47:11,104:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:47:11,104:INFO:Total runtime is 0.23120575348536174 minutes
2025-03-05 12:47:11,107:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:11,107:INFO:Initializing create_model()
2025-03-05 12:47:11,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:11,107:INFO:Checking exceptions
2025-03-05 12:47:11,107:INFO:Importing libraries
2025-03-05 12:47:11,107:INFO:Copying training dataset
2025-03-05 12:47:11,112:INFO:Defining folds
2025-03-05 12:47:11,112:INFO:Declaring metric variables
2025-03-05 12:47:11,115:INFO:Importing untrained model
2025-03-05 12:47:11,119:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:47:11,124:INFO:Starting cross validation
2025-03-05 12:47:11,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:16,174:INFO:Calculating mean and std
2025-03-05 12:47:16,175:INFO:Creating metrics dataframe
2025-03-05 12:47:16,177:INFO:Uploading results into container
2025-03-05 12:47:16,177:INFO:Uploading model into container now
2025-03-05 12:47:16,177:INFO:_master_model_container: 16
2025-03-05 12:47:16,177:INFO:_display_container: 2
2025-03-05 12:47:16,178:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:47:16,178:INFO:create_model() successfully completed......................................
2025-03-05 12:47:16,273:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:16,273:INFO:Creating metrics dataframe
2025-03-05 12:47:16,282:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:47:16,282:INFO:Total runtime is 0.3175171375274658 minutes
2025-03-05 12:47:16,286:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:16,286:INFO:Initializing create_model()
2025-03-05 12:47:16,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:16,286:INFO:Checking exceptions
2025-03-05 12:47:16,286:INFO:Importing libraries
2025-03-05 12:47:16,286:INFO:Copying training dataset
2025-03-05 12:47:16,291:INFO:Defining folds
2025-03-05 12:47:16,292:INFO:Declaring metric variables
2025-03-05 12:47:16,295:INFO:Importing untrained model
2025-03-05 12:47:16,299:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:47:16,306:INFO:Starting cross validation
2025-03-05 12:47:16,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:16,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026602 seconds.
2025-03-05 12:47:16,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:16,366:INFO:[LightGBM] [Info] Total Bins 472
2025-03-05 12:47:16,371:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 3
2025-03-05 12:47:16,385:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 12:47:17,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029574 seconds.
2025-03-05 12:47:17,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:17,723:INFO:[LightGBM] [Info] Total Bins 474
2025-03-05 12:47:17,730:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:17,746:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 12:47:18,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040622 seconds.
2025-03-05 12:47:18,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:18,475:INFO:[LightGBM] [Info] Total Bins 475
2025-03-05 12:47:18,482:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:18,497:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 12:47:19,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036589 seconds.
2025-03-05 12:47:19,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:19,886:INFO:[LightGBM] [Info] Total Bins 476
2025-03-05 12:47:19,895:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:19,917:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 12:47:21,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040622 seconds.
2025-03-05 12:47:21,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:21,355:INFO:[LightGBM] [Info] Total Bins 471
2025-03-05 12:47:21,359:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:21,374:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 12:47:21,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036618 seconds.
2025-03-05 12:47:22,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:22,000:INFO:[LightGBM] [Info] Total Bins 474
2025-03-05 12:47:22,006:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:22,026:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 12:47:22,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034594 seconds.
2025-03-05 12:47:22,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:22,817:INFO:[LightGBM] [Info] Total Bins 471
2025-03-05 12:47:22,824:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:22,840:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 12:47:23,707:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043606 seconds.
2025-03-05 12:47:23,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:23,708:INFO:[LightGBM] [Info] Total Bins 474
2025-03-05 12:47:23,714:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:23,733:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 12:47:25,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028685 seconds.
2025-03-05 12:47:25,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:25,756:INFO:[LightGBM] [Info] Total Bins 476
2025-03-05 12:47:25,757:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:25,771:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 12:47:26,541:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037624 seconds.
2025-03-05 12:47:26,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:47:26,542:INFO:[LightGBM] [Info] Total Bins 473
2025-03-05 12:47:26,554:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 12:47:26,571:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 12:47:27,477:INFO:Calculating mean and std
2025-03-05 12:47:27,478:INFO:Creating metrics dataframe
2025-03-05 12:47:27,484:INFO:Uploading results into container
2025-03-05 12:47:27,485:INFO:Uploading model into container now
2025-03-05 12:47:27,485:INFO:_master_model_container: 17
2025-03-05 12:47:27,486:INFO:_display_container: 2
2025-03-05 12:47:27,486:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:47:27,487:INFO:create_model() successfully completed......................................
2025-03-05 12:47:27,586:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:27,586:INFO:Creating metrics dataframe
2025-03-05 12:47:27,596:INFO:Initializing Dummy Regressor
2025-03-05 12:47:27,596:INFO:Total runtime is 0.5060803850491842 minutes
2025-03-05 12:47:27,600:INFO:SubProcess create_model() called ==================================
2025-03-05 12:47:27,600:INFO:Initializing create_model()
2025-03-05 12:47:27,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb58dd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:27,600:INFO:Checking exceptions
2025-03-05 12:47:27,600:INFO:Importing libraries
2025-03-05 12:47:27,600:INFO:Copying training dataset
2025-03-05 12:47:27,605:INFO:Defining folds
2025-03-05 12:47:27,606:INFO:Declaring metric variables
2025-03-05 12:47:27,608:INFO:Importing untrained model
2025-03-05 12:47:27,611:INFO:Dummy Regressor Imported successfully
2025-03-05 12:47:27,617:INFO:Starting cross validation
2025-03-05 12:47:27,618:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:47:27,752:INFO:Calculating mean and std
2025-03-05 12:47:27,753:INFO:Creating metrics dataframe
2025-03-05 12:47:27,755:INFO:Uploading results into container
2025-03-05 12:47:27,756:INFO:Uploading model into container now
2025-03-05 12:47:27,756:INFO:_master_model_container: 18
2025-03-05 12:47:27,756:INFO:_display_container: 2
2025-03-05 12:47:27,756:INFO:DummyRegressor()
2025-03-05 12:47:27,756:INFO:create_model() successfully completed......................................
2025-03-05 12:47:27,838:INFO:SubProcess create_model() end ==================================
2025-03-05 12:47:27,838:INFO:Creating metrics dataframe
2025-03-05 12:47:27,848:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 12:47:27,856:INFO:Initializing create_model()
2025-03-05 12:47:27,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:47:27,856:INFO:Checking exceptions
2025-03-05 12:47:27,858:INFO:Importing libraries
2025-03-05 12:47:27,858:INFO:Copying training dataset
2025-03-05 12:47:27,862:INFO:Defining folds
2025-03-05 12:47:27,862:INFO:Declaring metric variables
2025-03-05 12:47:27,863:INFO:Importing untrained model
2025-03-05 12:47:27,863:INFO:Declaring custom model
2025-03-05 12:47:27,863:INFO:Linear Regression Imported successfully
2025-03-05 12:47:27,864:INFO:Cross validation set to False
2025-03-05 12:47:27,864:INFO:Fitting Model
2025-03-05 12:47:27,873:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:47:27,873:INFO:create_model() successfully completed......................................
2025-03-05 12:47:27,985:INFO:_master_model_container: 18
2025-03-05 12:47:27,985:INFO:_display_container: 2
2025-03-05 12:47:27,985:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:47:27,985:INFO:compare_models() successfully completed......................................
2025-03-05 12:47:37,728:INFO:Initializing evaluate_model()
2025-03-05 12:47:37,729:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 12:47:37,737:INFO:Initializing plot_model()
2025-03-05 12:47:37,738:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, system=True)
2025-03-05 12:47:37,738:INFO:Checking exceptions
2025-03-05 12:47:37,740:INFO:Preloading libraries
2025-03-05 12:47:37,740:INFO:Copying training dataset
2025-03-05 12:47:37,740:INFO:Plot type: pipeline
2025-03-05 12:47:37,822:INFO:Visual Rendered Successfully
2025-03-05 12:47:37,907:INFO:plot_model() successfully completed......................................
2025-03-05 12:47:38,463:INFO:Initializing plot_model()
2025-03-05 12:47:38,463:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, system=True)
2025-03-05 12:47:38,463:INFO:Checking exceptions
2025-03-05 12:47:38,467:INFO:Preloading libraries
2025-03-05 12:47:38,467:INFO:Copying training dataset
2025-03-05 12:47:38,467:INFO:Plot type: residuals
2025-03-05 12:47:38,554:INFO:Fitting Model
2025-03-05 12:47:38,554:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-03-05 12:47:38,602:INFO:Scoring test/hold-out set
2025-03-05 12:47:39,142:INFO:Visual Rendered Successfully
2025-03-05 12:47:39,229:INFO:plot_model() successfully completed......................................
2025-03-05 12:47:39,577:INFO:Initializing plot_model()
2025-03-05 12:47:39,577:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, system=True)
2025-03-05 12:47:39,577:INFO:Checking exceptions
2025-03-05 12:47:39,581:INFO:Preloading libraries
2025-03-05 12:47:39,581:INFO:Copying training dataset
2025-03-05 12:47:39,582:INFO:Plot type: feature
2025-03-05 12:47:39,709:INFO:Visual Rendered Successfully
2025-03-05 12:47:39,801:INFO:plot_model() successfully completed......................................
2025-03-05 12:47:40,425:INFO:Initializing predict_model()
2025-03-05 12:47:40,425:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445f57810d0>)
2025-03-05 12:47:40,425:INFO:Checking exceptions
2025-03-05 12:47:40,425:INFO:Preloading libraries
2025-03-05 12:47:40,467:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:47:47,966:INFO:Initializing predict_model()
2025-03-05 12:47:47,966:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb5a5ca0>)
2025-03-05 12:47:47,966:INFO:Checking exceptions
2025-03-05 12:47:47,966:INFO:Preloading libraries
2025-03-05 12:47:47,968:INFO:Set up data.
2025-03-05 12:47:47,972:INFO:Set up index.
2025-03-05 12:47:47,990:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:48:07,130:INFO:Initializing predict_model()
2025-03-05 12:48:07,130:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445eb26ee80>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb5c83a0>)
2025-03-05 12:48:07,130:INFO:Checking exceptions
2025-03-05 12:48:07,130:INFO:Preloading libraries
2025-03-05 12:48:07,133:INFO:Set up data.
2025-03-05 12:48:07,136:INFO:Set up index.
2025-03-05 12:48:07,157:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:58:10,299:INFO:PyCaret RegressionExperiment
2025-03-05 12:58:10,299:INFO:Logging name: reg-default-name
2025-03-05 12:58:10,299:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 12:58:10,299:INFO:version 3.3.1
2025-03-05 12:58:10,299:INFO:Initializing setup()
2025-03-05 12:58:10,299:INFO:self.USI: 6de8
2025-03-05 12:58:10,299:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 12:58:10,299:INFO:Checking environment
2025-03-05 12:58:10,299:INFO:python_version: 3.9.21
2025-03-05 12:58:10,299:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 12:58:10,299:INFO:machine: x86_64
2025-03-05 12:58:10,299:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:58:10,299:INFO:Memory: svmem(total=33374507008, available=22173749248, percent=33.6, used=8787058688, free=5191958528, active=12447535104, inactive=11656085504, buffers=647413760, cached=18748076032, shared=1884585984, slab=1803243520)
2025-03-05 12:58:10,300:INFO:Physical Core: 24
2025-03-05 12:58:10,300:INFO:Logical Core: 32
2025-03-05 12:58:10,300:INFO:Checking libraries
2025-03-05 12:58:10,300:INFO:System:
2025-03-05 12:58:10,300:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 12:58:10,300:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 12:58:10,300:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 12:58:10,300:INFO:PyCaret required dependencies:
2025-03-05 12:58:10,300:INFO:                 pip: 25.0
2025-03-05 12:58:10,300:INFO:          setuptools: 75.8.0
2025-03-05 12:58:10,300:INFO:             pycaret: 3.3.1
2025-03-05 12:58:10,300:INFO:             IPython: 8.18.1
2025-03-05 12:58:10,300:INFO:          ipywidgets: 8.1.5
2025-03-05 12:58:10,300:INFO:                tqdm: 4.67.1
2025-03-05 12:58:10,300:INFO:               numpy: 1.26.4
2025-03-05 12:58:10,300:INFO:              pandas: 2.1.4
2025-03-05 12:58:10,300:INFO:              jinja2: 3.1.5
2025-03-05 12:58:10,300:INFO:               scipy: 1.11.4
2025-03-05 12:58:10,300:INFO:              joblib: 1.3.2
2025-03-05 12:58:10,300:INFO:             sklearn: 1.4.2
2025-03-05 12:58:10,300:INFO:                pyod: 2.0.3
2025-03-05 12:58:10,300:INFO:            imblearn: 0.12.4
2025-03-05 12:58:10,300:INFO:   category_encoders: 2.6.4
2025-03-05 12:58:10,300:INFO:            lightgbm: 4.6.0
2025-03-05 12:58:10,300:INFO:               numba: 0.60.0
2025-03-05 12:58:10,300:INFO:            requests: 2.32.3
2025-03-05 12:58:10,300:INFO:          matplotlib: 3.7.5
2025-03-05 12:58:10,300:INFO:          scikitplot: 0.3.7
2025-03-05 12:58:10,300:INFO:         yellowbrick: 1.5
2025-03-05 12:58:10,300:INFO:              plotly: 5.24.1
2025-03-05 12:58:10,300:INFO:    plotly-resampler: Not installed
2025-03-05 12:58:10,300:INFO:             kaleido: 0.2.1
2025-03-05 12:58:10,301:INFO:           schemdraw: 0.15
2025-03-05 12:58:10,301:INFO:         statsmodels: 0.14.4
2025-03-05 12:58:10,301:INFO:              sktime: 0.26.0
2025-03-05 12:58:10,301:INFO:               tbats: 1.1.3
2025-03-05 12:58:10,301:INFO:            pmdarima: 2.0.4
2025-03-05 12:58:10,301:INFO:              psutil: 7.0.0
2025-03-05 12:58:10,301:INFO:          markupsafe: 3.0.2
2025-03-05 12:58:10,301:INFO:             pickle5: Not installed
2025-03-05 12:58:10,301:INFO:         cloudpickle: 3.1.1
2025-03-05 12:58:10,301:INFO:         deprecation: 2.1.0
2025-03-05 12:58:10,301:INFO:              xxhash: 3.5.0
2025-03-05 12:58:10,301:INFO:           wurlitzer: 3.1.1
2025-03-05 12:58:10,301:INFO:PyCaret optional dependencies:
2025-03-05 12:58:10,301:INFO:                shap: Not installed
2025-03-05 12:58:10,301:INFO:           interpret: Not installed
2025-03-05 12:58:10,301:INFO:                umap: Not installed
2025-03-05 12:58:10,301:INFO:     ydata_profiling: Not installed
2025-03-05 12:58:10,301:INFO:  explainerdashboard: Not installed
2025-03-05 12:58:10,301:INFO:             autoviz: Not installed
2025-03-05 12:58:10,301:INFO:           fairlearn: Not installed
2025-03-05 12:58:10,301:INFO:          deepchecks: Not installed
2025-03-05 12:58:10,301:INFO:             xgboost: Not installed
2025-03-05 12:58:10,301:INFO:            catboost: Not installed
2025-03-05 12:58:10,301:INFO:              kmodes: Not installed
2025-03-05 12:58:10,301:INFO:             mlxtend: Not installed
2025-03-05 12:58:10,301:INFO:       statsforecast: Not installed
2025-03-05 12:58:10,301:INFO:        tune_sklearn: Not installed
2025-03-05 12:58:10,301:INFO:                 ray: Not installed
2025-03-05 12:58:10,301:INFO:            hyperopt: Not installed
2025-03-05 12:58:10,301:INFO:              optuna: Not installed
2025-03-05 12:58:10,301:INFO:               skopt: Not installed
2025-03-05 12:58:10,301:INFO:              mlflow: Not installed
2025-03-05 12:58:10,301:INFO:              gradio: Not installed
2025-03-05 12:58:10,301:INFO:             fastapi: Not installed
2025-03-05 12:58:10,301:INFO:             uvicorn: Not installed
2025-03-05 12:58:10,301:INFO:              m2cgen: Not installed
2025-03-05 12:58:10,301:INFO:           evidently: Not installed
2025-03-05 12:58:10,301:INFO:               fugue: Not installed
2025-03-05 12:58:10,301:INFO:           streamlit: Not installed
2025-03-05 12:58:10,301:INFO:             prophet: Not installed
2025-03-05 12:58:10,301:INFO:None
2025-03-05 12:58:10,301:INFO:Set up GPU usage.
2025-03-05 12:58:10,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,301:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 12:58:10,301:INFO:Set up data.
2025-03-05 12:58:10,305:INFO:Set up folding strategy.
2025-03-05 12:58:10,305:INFO:Set up train/test split.
2025-03-05 12:58:10,308:INFO:Set up index.
2025-03-05 12:58:10,308:INFO:Assigning column types.
2025-03-05 12:58:10,311:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 12:58:10,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,312:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,316:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,319:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,410:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,416:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,540:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 12:58:10,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,552:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,659:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,688:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,780:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 12:58:10,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,804:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:10,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:10,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:10,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,031:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 12:58:11,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,207:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,250:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 12:58:11,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,387:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 12:58:11,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,492:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 12:58:11,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,588:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,709:INFO:Preparing preprocessing pipeline...
2025-03-05 12:58:11,709:INFO:Set up simple imputation.
2025-03-05 12:58:11,710:INFO:Set up column name cleaning.
2025-03-05 12:58:11,742:INFO:Finished creating preprocessing pipeline.
2025-03-05 12:58:11,746:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 12:58:11,746:INFO:Creating final display dataframe.
2025-03-05 12:58:11,806:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6de8
2025-03-05 12:58:11,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:11,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:11,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:12,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:12,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 12:58:12,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:12,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 12:58:12,029:INFO:setup() successfully completed in 1.73s...............
2025-03-05 12:58:12,045:INFO:Initializing compare_models()
2025-03-05 12:58:12,045:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 12:58:12,046:INFO:Checking exceptions
2025-03-05 12:58:12,048:INFO:Preparing display monitor
2025-03-05 12:58:12,071:INFO:Initializing Linear Regression
2025-03-05 12:58:12,071:INFO:Total runtime is 4.97897466023763e-06 minutes
2025-03-05 12:58:12,074:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:12,075:INFO:Initializing create_model()
2025-03-05 12:58:12,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:12,075:INFO:Checking exceptions
2025-03-05 12:58:12,075:INFO:Importing libraries
2025-03-05 12:58:12,075:INFO:Copying training dataset
2025-03-05 12:58:12,079:INFO:Defining folds
2025-03-05 12:58:12,079:INFO:Declaring metric variables
2025-03-05 12:58:12,082:INFO:Importing untrained model
2025-03-05 12:58:12,085:INFO:Linear Regression Imported successfully
2025-03-05 12:58:12,091:INFO:Starting cross validation
2025-03-05 12:58:12,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:12,242:INFO:Calculating mean and std
2025-03-05 12:58:12,243:INFO:Creating metrics dataframe
2025-03-05 12:58:12,244:INFO:Uploading results into container
2025-03-05 12:58:12,245:INFO:Uploading model into container now
2025-03-05 12:58:12,245:INFO:_master_model_container: 1
2025-03-05 12:58:12,245:INFO:_display_container: 2
2025-03-05 12:58:12,245:INFO:LinearRegression(n_jobs=-1)
2025-03-05 12:58:12,245:INFO:create_model() successfully completed......................................
2025-03-05 12:58:12,332:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:12,332:INFO:Creating metrics dataframe
2025-03-05 12:58:12,338:INFO:Initializing Lasso Regression
2025-03-05 12:58:12,338:INFO:Total runtime is 0.004451243082682292 minutes
2025-03-05 12:58:12,341:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:12,341:INFO:Initializing create_model()
2025-03-05 12:58:12,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:12,341:INFO:Checking exceptions
2025-03-05 12:58:12,341:INFO:Importing libraries
2025-03-05 12:58:12,341:INFO:Copying training dataset
2025-03-05 12:58:12,345:INFO:Defining folds
2025-03-05 12:58:12,345:INFO:Declaring metric variables
2025-03-05 12:58:12,348:INFO:Importing untrained model
2025-03-05 12:58:12,351:INFO:Lasso Regression Imported successfully
2025-03-05 12:58:12,357:INFO:Starting cross validation
2025-03-05 12:58:12,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:12,620:INFO:Calculating mean and std
2025-03-05 12:58:12,621:INFO:Creating metrics dataframe
2025-03-05 12:58:12,623:INFO:Uploading results into container
2025-03-05 12:58:12,623:INFO:Uploading model into container now
2025-03-05 12:58:12,624:INFO:_master_model_container: 2
2025-03-05 12:58:12,624:INFO:_display_container: 2
2025-03-05 12:58:12,624:INFO:Lasso(random_state=123)
2025-03-05 12:58:12,624:INFO:create_model() successfully completed......................................
2025-03-05 12:58:12,720:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:12,721:INFO:Creating metrics dataframe
2025-03-05 12:58:12,728:INFO:Initializing Ridge Regression
2025-03-05 12:58:12,728:INFO:Total runtime is 0.010950434207916259 minutes
2025-03-05 12:58:12,731:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:12,731:INFO:Initializing create_model()
2025-03-05 12:58:12,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:12,731:INFO:Checking exceptions
2025-03-05 12:58:12,731:INFO:Importing libraries
2025-03-05 12:58:12,731:INFO:Copying training dataset
2025-03-05 12:58:12,735:INFO:Defining folds
2025-03-05 12:58:12,735:INFO:Declaring metric variables
2025-03-05 12:58:12,738:INFO:Importing untrained model
2025-03-05 12:58:12,742:INFO:Ridge Regression Imported successfully
2025-03-05 12:58:12,747:INFO:Starting cross validation
2025-03-05 12:58:12,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:12,895:INFO:Calculating mean and std
2025-03-05 12:58:12,896:INFO:Creating metrics dataframe
2025-03-05 12:58:12,897:INFO:Uploading results into container
2025-03-05 12:58:12,898:INFO:Uploading model into container now
2025-03-05 12:58:12,898:INFO:_master_model_container: 3
2025-03-05 12:58:12,898:INFO:_display_container: 2
2025-03-05 12:58:12,898:INFO:Ridge(random_state=123)
2025-03-05 12:58:12,898:INFO:create_model() successfully completed......................................
2025-03-05 12:58:12,980:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:12,980:INFO:Creating metrics dataframe
2025-03-05 12:58:12,987:INFO:Initializing Elastic Net
2025-03-05 12:58:12,987:INFO:Total runtime is 0.015277647972106933 minutes
2025-03-05 12:58:12,990:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:12,991:INFO:Initializing create_model()
2025-03-05 12:58:12,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:12,991:INFO:Checking exceptions
2025-03-05 12:58:12,991:INFO:Importing libraries
2025-03-05 12:58:12,991:INFO:Copying training dataset
2025-03-05 12:58:12,995:INFO:Defining folds
2025-03-05 12:58:12,995:INFO:Declaring metric variables
2025-03-05 12:58:12,998:INFO:Importing untrained model
2025-03-05 12:58:13,000:INFO:Elastic Net Imported successfully
2025-03-05 12:58:13,006:INFO:Starting cross validation
2025-03-05 12:58:13,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:13,201:INFO:Calculating mean and std
2025-03-05 12:58:13,203:INFO:Creating metrics dataframe
2025-03-05 12:58:13,205:INFO:Uploading results into container
2025-03-05 12:58:13,207:INFO:Uploading model into container now
2025-03-05 12:58:13,208:INFO:_master_model_container: 4
2025-03-05 12:58:13,208:INFO:_display_container: 2
2025-03-05 12:58:13,209:INFO:ElasticNet(random_state=123)
2025-03-05 12:58:13,209:INFO:create_model() successfully completed......................................
2025-03-05 12:58:13,334:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:13,334:INFO:Creating metrics dataframe
2025-03-05 12:58:13,341:INFO:Initializing Least Angle Regression
2025-03-05 12:58:13,341:INFO:Total runtime is 0.021179862817128497 minutes
2025-03-05 12:58:13,345:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:13,345:INFO:Initializing create_model()
2025-03-05 12:58:13,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:13,345:INFO:Checking exceptions
2025-03-05 12:58:13,345:INFO:Importing libraries
2025-03-05 12:58:13,345:INFO:Copying training dataset
2025-03-05 12:58:13,350:INFO:Defining folds
2025-03-05 12:58:13,350:INFO:Declaring metric variables
2025-03-05 12:58:13,353:INFO:Importing untrained model
2025-03-05 12:58:13,356:INFO:Least Angle Regression Imported successfully
2025-03-05 12:58:13,361:INFO:Starting cross validation
2025-03-05 12:58:13,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:13,516:INFO:Calculating mean and std
2025-03-05 12:58:13,517:INFO:Creating metrics dataframe
2025-03-05 12:58:13,519:INFO:Uploading results into container
2025-03-05 12:58:13,519:INFO:Uploading model into container now
2025-03-05 12:58:13,519:INFO:_master_model_container: 5
2025-03-05 12:58:13,520:INFO:_display_container: 2
2025-03-05 12:58:13,520:INFO:Lars(random_state=123)
2025-03-05 12:58:13,520:INFO:create_model() successfully completed......................................
2025-03-05 12:58:13,605:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:13,605:INFO:Creating metrics dataframe
2025-03-05 12:58:13,612:INFO:Initializing Lasso Least Angle Regression
2025-03-05 12:58:13,613:INFO:Total runtime is 0.025698312123616535 minutes
2025-03-05 12:58:13,616:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:13,616:INFO:Initializing create_model()
2025-03-05 12:58:13,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:13,616:INFO:Checking exceptions
2025-03-05 12:58:13,616:INFO:Importing libraries
2025-03-05 12:58:13,617:INFO:Copying training dataset
2025-03-05 12:58:13,621:INFO:Defining folds
2025-03-05 12:58:13,622:INFO:Declaring metric variables
2025-03-05 12:58:13,625:INFO:Importing untrained model
2025-03-05 12:58:13,628:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 12:58:13,634:INFO:Starting cross validation
2025-03-05 12:58:13,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:13,787:INFO:Calculating mean and std
2025-03-05 12:58:13,788:INFO:Creating metrics dataframe
2025-03-05 12:58:13,790:INFO:Uploading results into container
2025-03-05 12:58:13,790:INFO:Uploading model into container now
2025-03-05 12:58:13,790:INFO:_master_model_container: 6
2025-03-05 12:58:13,790:INFO:_display_container: 2
2025-03-05 12:58:13,791:INFO:LassoLars(random_state=123)
2025-03-05 12:58:13,791:INFO:create_model() successfully completed......................................
2025-03-05 12:58:13,875:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:13,875:INFO:Creating metrics dataframe
2025-03-05 12:58:13,882:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 12:58:13,883:INFO:Total runtime is 0.03019968271255493 minutes
2025-03-05 12:58:13,886:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:13,886:INFO:Initializing create_model()
2025-03-05 12:58:13,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:13,886:INFO:Checking exceptions
2025-03-05 12:58:13,887:INFO:Importing libraries
2025-03-05 12:58:13,887:INFO:Copying training dataset
2025-03-05 12:58:13,891:INFO:Defining folds
2025-03-05 12:58:13,891:INFO:Declaring metric variables
2025-03-05 12:58:13,894:INFO:Importing untrained model
2025-03-05 12:58:13,897:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 12:58:13,903:INFO:Starting cross validation
2025-03-05 12:58:13,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:14,049:INFO:Calculating mean and std
2025-03-05 12:58:14,050:INFO:Creating metrics dataframe
2025-03-05 12:58:14,052:INFO:Uploading results into container
2025-03-05 12:58:14,052:INFO:Uploading model into container now
2025-03-05 12:58:14,053:INFO:_master_model_container: 7
2025-03-05 12:58:14,053:INFO:_display_container: 2
2025-03-05 12:58:14,053:INFO:OrthogonalMatchingPursuit()
2025-03-05 12:58:14,053:INFO:create_model() successfully completed......................................
2025-03-05 12:58:14,136:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:14,136:INFO:Creating metrics dataframe
2025-03-05 12:58:14,144:INFO:Initializing Bayesian Ridge
2025-03-05 12:58:14,145:INFO:Total runtime is 0.0345647652943929 minutes
2025-03-05 12:58:14,148:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:14,148:INFO:Initializing create_model()
2025-03-05 12:58:14,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:14,148:INFO:Checking exceptions
2025-03-05 12:58:14,148:INFO:Importing libraries
2025-03-05 12:58:14,148:INFO:Copying training dataset
2025-03-05 12:58:14,153:INFO:Defining folds
2025-03-05 12:58:14,153:INFO:Declaring metric variables
2025-03-05 12:58:14,156:INFO:Importing untrained model
2025-03-05 12:58:14,160:INFO:Bayesian Ridge Imported successfully
2025-03-05 12:58:14,165:INFO:Starting cross validation
2025-03-05 12:58:14,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:14,367:INFO:Calculating mean and std
2025-03-05 12:58:14,368:INFO:Creating metrics dataframe
2025-03-05 12:58:14,370:INFO:Uploading results into container
2025-03-05 12:58:14,372:INFO:Uploading model into container now
2025-03-05 12:58:14,373:INFO:_master_model_container: 8
2025-03-05 12:58:14,374:INFO:_display_container: 2
2025-03-05 12:58:14,374:INFO:BayesianRidge()
2025-03-05 12:58:14,374:INFO:create_model() successfully completed......................................
2025-03-05 12:58:14,500:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:14,501:INFO:Creating metrics dataframe
2025-03-05 12:58:14,509:INFO:Initializing Passive Aggressive Regressor
2025-03-05 12:58:14,509:INFO:Total runtime is 0.04063382943471273 minutes
2025-03-05 12:58:14,512:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:14,512:INFO:Initializing create_model()
2025-03-05 12:58:14,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:14,513:INFO:Checking exceptions
2025-03-05 12:58:14,513:INFO:Importing libraries
2025-03-05 12:58:14,513:INFO:Copying training dataset
2025-03-05 12:58:14,517:INFO:Defining folds
2025-03-05 12:58:14,517:INFO:Declaring metric variables
2025-03-05 12:58:14,520:INFO:Importing untrained model
2025-03-05 12:58:14,524:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 12:58:14,535:INFO:Starting cross validation
2025-03-05 12:58:14,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:14,745:INFO:Calculating mean and std
2025-03-05 12:58:14,746:INFO:Creating metrics dataframe
2025-03-05 12:58:14,748:INFO:Uploading results into container
2025-03-05 12:58:14,748:INFO:Uploading model into container now
2025-03-05 12:58:14,748:INFO:_master_model_container: 9
2025-03-05 12:58:14,749:INFO:_display_container: 2
2025-03-05 12:58:14,749:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 12:58:14,749:INFO:create_model() successfully completed......................................
2025-03-05 12:58:14,832:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:14,832:INFO:Creating metrics dataframe
2025-03-05 12:58:14,841:INFO:Initializing Huber Regressor
2025-03-05 12:58:14,841:INFO:Total runtime is 0.04617437918980916 minutes
2025-03-05 12:58:14,844:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:14,844:INFO:Initializing create_model()
2025-03-05 12:58:14,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:14,844:INFO:Checking exceptions
2025-03-05 12:58:14,844:INFO:Importing libraries
2025-03-05 12:58:14,844:INFO:Copying training dataset
2025-03-05 12:58:14,849:INFO:Defining folds
2025-03-05 12:58:14,849:INFO:Declaring metric variables
2025-03-05 12:58:14,852:INFO:Importing untrained model
2025-03-05 12:58:14,855:INFO:Huber Regressor Imported successfully
2025-03-05 12:58:14,861:INFO:Starting cross validation
2025-03-05 12:58:14,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:15,714:INFO:Calculating mean and std
2025-03-05 12:58:15,716:INFO:Creating metrics dataframe
2025-03-05 12:58:15,723:INFO:Uploading results into container
2025-03-05 12:58:15,724:INFO:Uploading model into container now
2025-03-05 12:58:15,725:INFO:_master_model_container: 10
2025-03-05 12:58:15,725:INFO:_display_container: 2
2025-03-05 12:58:15,726:INFO:HuberRegressor()
2025-03-05 12:58:15,726:INFO:create_model() successfully completed......................................
2025-03-05 12:58:15,865:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:15,865:INFO:Creating metrics dataframe
2025-03-05 12:58:15,873:INFO:Initializing K Neighbors Regressor
2025-03-05 12:58:15,874:INFO:Total runtime is 0.06338285605112712 minutes
2025-03-05 12:58:15,877:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:15,877:INFO:Initializing create_model()
2025-03-05 12:58:15,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:15,877:INFO:Checking exceptions
2025-03-05 12:58:15,877:INFO:Importing libraries
2025-03-05 12:58:15,877:INFO:Copying training dataset
2025-03-05 12:58:15,882:INFO:Defining folds
2025-03-05 12:58:15,882:INFO:Declaring metric variables
2025-03-05 12:58:15,886:INFO:Importing untrained model
2025-03-05 12:58:15,890:INFO:K Neighbors Regressor Imported successfully
2025-03-05 12:58:15,897:INFO:Starting cross validation
2025-03-05 12:58:15,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:16,392:INFO:Calculating mean and std
2025-03-05 12:58:16,394:INFO:Creating metrics dataframe
2025-03-05 12:58:16,396:INFO:Uploading results into container
2025-03-05 12:58:16,396:INFO:Uploading model into container now
2025-03-05 12:58:16,397:INFO:_master_model_container: 11
2025-03-05 12:58:16,397:INFO:_display_container: 2
2025-03-05 12:58:16,397:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 12:58:16,397:INFO:create_model() successfully completed......................................
2025-03-05 12:58:16,483:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:16,483:INFO:Creating metrics dataframe
2025-03-05 12:58:16,493:INFO:Initializing Decision Tree Regressor
2025-03-05 12:58:16,493:INFO:Total runtime is 0.07371137539545695 minutes
2025-03-05 12:58:16,496:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:16,497:INFO:Initializing create_model()
2025-03-05 12:58:16,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:16,497:INFO:Checking exceptions
2025-03-05 12:58:16,497:INFO:Importing libraries
2025-03-05 12:58:16,497:INFO:Copying training dataset
2025-03-05 12:58:16,502:INFO:Defining folds
2025-03-05 12:58:16,502:INFO:Declaring metric variables
2025-03-05 12:58:16,505:INFO:Importing untrained model
2025-03-05 12:58:16,508:INFO:Decision Tree Regressor Imported successfully
2025-03-05 12:58:16,514:INFO:Starting cross validation
2025-03-05 12:58:16,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:16,712:INFO:Calculating mean and std
2025-03-05 12:58:16,713:INFO:Creating metrics dataframe
2025-03-05 12:58:16,714:INFO:Uploading results into container
2025-03-05 12:58:16,715:INFO:Uploading model into container now
2025-03-05 12:58:16,716:INFO:_master_model_container: 12
2025-03-05 12:58:16,716:INFO:_display_container: 2
2025-03-05 12:58:16,716:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 12:58:16,716:INFO:create_model() successfully completed......................................
2025-03-05 12:58:16,799:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:16,799:INFO:Creating metrics dataframe
2025-03-05 12:58:16,807:INFO:Initializing Random Forest Regressor
2025-03-05 12:58:16,808:INFO:Total runtime is 0.07894919713338217 minutes
2025-03-05 12:58:16,811:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:16,811:INFO:Initializing create_model()
2025-03-05 12:58:16,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:16,811:INFO:Checking exceptions
2025-03-05 12:58:16,811:INFO:Importing libraries
2025-03-05 12:58:16,811:INFO:Copying training dataset
2025-03-05 12:58:16,816:INFO:Defining folds
2025-03-05 12:58:16,816:INFO:Declaring metric variables
2025-03-05 12:58:16,820:INFO:Importing untrained model
2025-03-05 12:58:16,823:INFO:Random Forest Regressor Imported successfully
2025-03-05 12:58:16,829:INFO:Starting cross validation
2025-03-05 12:58:16,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:19,365:INFO:Calculating mean and std
2025-03-05 12:58:19,366:INFO:Creating metrics dataframe
2025-03-05 12:58:19,368:INFO:Uploading results into container
2025-03-05 12:58:19,368:INFO:Uploading model into container now
2025-03-05 12:58:19,369:INFO:_master_model_container: 13
2025-03-05 12:58:19,369:INFO:_display_container: 2
2025-03-05 12:58:19,369:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:58:19,369:INFO:create_model() successfully completed......................................
2025-03-05 12:58:19,453:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:19,453:INFO:Creating metrics dataframe
2025-03-05 12:58:19,463:INFO:Initializing Extra Trees Regressor
2025-03-05 12:58:19,463:INFO:Total runtime is 0.1232129176457723 minutes
2025-03-05 12:58:19,467:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:19,468:INFO:Initializing create_model()
2025-03-05 12:58:19,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:19,469:INFO:Checking exceptions
2025-03-05 12:58:19,469:INFO:Importing libraries
2025-03-05 12:58:19,469:INFO:Copying training dataset
2025-03-05 12:58:19,474:INFO:Defining folds
2025-03-05 12:58:19,474:INFO:Declaring metric variables
2025-03-05 12:58:19,478:INFO:Importing untrained model
2025-03-05 12:58:19,481:INFO:Extra Trees Regressor Imported successfully
2025-03-05 12:58:19,488:INFO:Starting cross validation
2025-03-05 12:58:19,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:21,187:INFO:Calculating mean and std
2025-03-05 12:58:21,188:INFO:Creating metrics dataframe
2025-03-05 12:58:21,190:INFO:Uploading results into container
2025-03-05 12:58:21,190:INFO:Uploading model into container now
2025-03-05 12:58:21,191:INFO:_master_model_container: 14
2025-03-05 12:58:21,191:INFO:_display_container: 2
2025-03-05 12:58:21,191:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:58:21,191:INFO:create_model() successfully completed......................................
2025-03-05 12:58:21,275:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:21,275:INFO:Creating metrics dataframe
2025-03-05 12:58:21,286:INFO:Initializing AdaBoost Regressor
2025-03-05 12:58:21,286:INFO:Total runtime is 0.15359239180882772 minutes
2025-03-05 12:58:21,289:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:21,290:INFO:Initializing create_model()
2025-03-05 12:58:21,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:21,290:INFO:Checking exceptions
2025-03-05 12:58:21,290:INFO:Importing libraries
2025-03-05 12:58:21,290:INFO:Copying training dataset
2025-03-05 12:58:21,295:INFO:Defining folds
2025-03-05 12:58:21,295:INFO:Declaring metric variables
2025-03-05 12:58:21,299:INFO:Importing untrained model
2025-03-05 12:58:21,303:INFO:AdaBoost Regressor Imported successfully
2025-03-05 12:58:21,309:INFO:Starting cross validation
2025-03-05 12:58:21,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:23,240:INFO:Calculating mean and std
2025-03-05 12:58:23,241:INFO:Creating metrics dataframe
2025-03-05 12:58:23,243:INFO:Uploading results into container
2025-03-05 12:58:23,243:INFO:Uploading model into container now
2025-03-05 12:58:23,244:INFO:_master_model_container: 15
2025-03-05 12:58:23,244:INFO:_display_container: 2
2025-03-05 12:58:23,244:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 12:58:23,244:INFO:create_model() successfully completed......................................
2025-03-05 12:58:23,328:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:23,328:INFO:Creating metrics dataframe
2025-03-05 12:58:23,337:INFO:Initializing Gradient Boosting Regressor
2025-03-05 12:58:23,337:INFO:Total runtime is 0.18778072198232015 minutes
2025-03-05 12:58:23,341:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:23,341:INFO:Initializing create_model()
2025-03-05 12:58:23,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:23,341:INFO:Checking exceptions
2025-03-05 12:58:23,341:INFO:Importing libraries
2025-03-05 12:58:23,341:INFO:Copying training dataset
2025-03-05 12:58:23,346:INFO:Defining folds
2025-03-05 12:58:23,346:INFO:Declaring metric variables
2025-03-05 12:58:23,349:INFO:Importing untrained model
2025-03-05 12:58:23,352:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:58:23,357:INFO:Starting cross validation
2025-03-05 12:58:23,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:27,280:INFO:Calculating mean and std
2025-03-05 12:58:27,281:INFO:Creating metrics dataframe
2025-03-05 12:58:27,283:INFO:Uploading results into container
2025-03-05 12:58:27,284:INFO:Uploading model into container now
2025-03-05 12:58:27,284:INFO:_master_model_container: 16
2025-03-05 12:58:27,284:INFO:_display_container: 2
2025-03-05 12:58:27,285:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:58:27,285:INFO:create_model() successfully completed......................................
2025-03-05 12:58:27,371:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:27,371:INFO:Creating metrics dataframe
2025-03-05 12:58:27,381:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 12:58:27,381:INFO:Total runtime is 0.2551715056101481 minutes
2025-03-05 12:58:27,384:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:27,384:INFO:Initializing create_model()
2025-03-05 12:58:27,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:27,384:INFO:Checking exceptions
2025-03-05 12:58:27,385:INFO:Importing libraries
2025-03-05 12:58:27,385:INFO:Copying training dataset
2025-03-05 12:58:27,390:INFO:Defining folds
2025-03-05 12:58:27,390:INFO:Declaring metric variables
2025-03-05 12:58:27,393:INFO:Importing untrained model
2025-03-05 12:58:27,397:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 12:58:27,403:INFO:Starting cross validation
2025-03-05 12:58:27,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:27,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040417 seconds.
2025-03-05 12:58:27,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:27,478:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:58:27,485:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 2
2025-03-05 12:58:27,499:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 12:58:29,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2025-03-05 12:58:29,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 12:58:29,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 12:58:29,703:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:58:29,703:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:29,704:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 12:58:30,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014041 seconds.
2025-03-05 12:58:30,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 12:58:30,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 12:58:30,257:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:58:30,258:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:30,258:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 12:58:30,929:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.
2025-03-05 12:58:30,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 12:58:30,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 12:58:30,930:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:58:30,931:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:30,941:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 12:58:31,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032601 seconds.
2025-03-05 12:58:31,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:31,725:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:58:31,731:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:31,749:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 12:58:33,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028690 seconds.
2025-03-05 12:58:33,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:33,427:INFO:[LightGBM] [Info] Total Bins 232
2025-03-05 12:58:33,433:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:33,449:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 12:58:34,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049573 seconds.
2025-03-05 12:58:34,606:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:34,606:INFO:[LightGBM] [Info] Total Bins 230
2025-03-05 12:58:34,613:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:34,638:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 12:58:36,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030589 seconds.
2025-03-05 12:58:36,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:36,311:INFO:[LightGBM] [Info] Total Bins 232
2025-03-05 12:58:36,316:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:36,319:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 12:58:36,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027616 seconds.
2025-03-05 12:58:36,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:36,885:INFO:[LightGBM] [Info] Total Bins 233
2025-03-05 12:58:36,892:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:36,911:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 12:58:37,495:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034518 seconds.
2025-03-05 12:58:37,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 12:58:37,496:INFO:[LightGBM] [Info] Total Bins 231
2025-03-05 12:58:37,503:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 12:58:37,518:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 12:58:39,833:INFO:Calculating mean and std
2025-03-05 12:58:39,837:INFO:Creating metrics dataframe
2025-03-05 12:58:39,840:INFO:Uploading results into container
2025-03-05 12:58:39,841:INFO:Uploading model into container now
2025-03-05 12:58:39,842:INFO:_master_model_container: 17
2025-03-05 12:58:39,842:INFO:_display_container: 2
2025-03-05 12:58:39,843:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 12:58:39,843:INFO:create_model() successfully completed......................................
2025-03-05 12:58:39,930:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:39,930:INFO:Creating metrics dataframe
2025-03-05 12:58:39,939:INFO:Initializing Dummy Regressor
2025-03-05 12:58:39,940:INFO:Total runtime is 0.4644821325937907 minutes
2025-03-05 12:58:39,943:INFO:SubProcess create_model() called ==================================
2025-03-05 12:58:39,943:INFO:Initializing create_model()
2025-03-05 12:58:39,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445e0e4d9a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:39,943:INFO:Checking exceptions
2025-03-05 12:58:39,943:INFO:Importing libraries
2025-03-05 12:58:39,943:INFO:Copying training dataset
2025-03-05 12:58:39,948:INFO:Defining folds
2025-03-05 12:58:39,948:INFO:Declaring metric variables
2025-03-05 12:58:39,951:INFO:Importing untrained model
2025-03-05 12:58:39,954:INFO:Dummy Regressor Imported successfully
2025-03-05 12:58:39,962:INFO:Starting cross validation
2025-03-05 12:58:39,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 12:58:40,092:INFO:Calculating mean and std
2025-03-05 12:58:40,093:INFO:Creating metrics dataframe
2025-03-05 12:58:40,095:INFO:Uploading results into container
2025-03-05 12:58:40,095:INFO:Uploading model into container now
2025-03-05 12:58:40,096:INFO:_master_model_container: 18
2025-03-05 12:58:40,096:INFO:_display_container: 2
2025-03-05 12:58:40,096:INFO:DummyRegressor()
2025-03-05 12:58:40,096:INFO:create_model() successfully completed......................................
2025-03-05 12:58:40,182:INFO:SubProcess create_model() end ==================================
2025-03-05 12:58:40,182:INFO:Creating metrics dataframe
2025-03-05 12:58:40,193:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 12:58:40,200:INFO:Initializing create_model()
2025-03-05 12:58:40,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 12:58:40,201:INFO:Checking exceptions
2025-03-05 12:58:40,202:INFO:Importing libraries
2025-03-05 12:58:40,202:INFO:Copying training dataset
2025-03-05 12:58:40,206:INFO:Defining folds
2025-03-05 12:58:40,206:INFO:Declaring metric variables
2025-03-05 12:58:40,206:INFO:Importing untrained model
2025-03-05 12:58:40,206:INFO:Declaring custom model
2025-03-05 12:58:40,207:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 12:58:40,208:INFO:Cross validation set to False
2025-03-05 12:58:40,208:INFO:Fitting Model
2025-03-05 12:58:40,628:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:58:40,628:INFO:create_model() successfully completed......................................
2025-03-05 12:58:40,739:INFO:_master_model_container: 18
2025-03-05 12:58:40,739:INFO:_display_container: 2
2025-03-05 12:58:40,740:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 12:58:40,740:INFO:compare_models() successfully completed......................................
2025-03-05 12:58:40,771:INFO:Initializing evaluate_model()
2025-03-05 12:58:40,771:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 12:58:40,785:INFO:Initializing plot_model()
2025-03-05 12:58:40,786:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 12:58:40,786:INFO:Checking exceptions
2025-03-05 12:58:40,788:INFO:Preloading libraries
2025-03-05 12:58:40,794:INFO:Copying training dataset
2025-03-05 12:58:40,795:INFO:Plot type: pipeline
2025-03-05 12:58:40,896:INFO:Visual Rendered Successfully
2025-03-05 12:58:40,978:INFO:plot_model() successfully completed......................................
2025-03-05 12:58:41,010:INFO:Initializing plot_model()
2025-03-05 12:58:41,011:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 12:58:41,011:INFO:Checking exceptions
2025-03-05 12:58:41,016:INFO:Preloading libraries
2025-03-05 12:58:41,022:INFO:Copying training dataset
2025-03-05 12:58:41,022:INFO:Plot type: residuals
2025-03-05 12:58:41,105:INFO:Fitting Model
2025-03-05 12:58:41,105:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 12:58:41,188:INFO:Scoring test/hold-out set
2025-03-05 12:58:41,661:INFO:Visual Rendered Successfully
2025-03-05 12:58:41,751:INFO:plot_model() successfully completed......................................
2025-03-05 12:58:41,771:INFO:Initializing plot_model()
2025-03-05 12:58:41,772:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 12:58:41,772:INFO:Checking exceptions
2025-03-05 12:58:41,776:INFO:Preloading libraries
2025-03-05 12:58:41,782:INFO:Copying training dataset
2025-03-05 12:58:41,782:INFO:Plot type: feature
2025-03-05 12:58:41,783:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 12:58:41,890:INFO:Visual Rendered Successfully
2025-03-05 12:58:41,980:INFO:plot_model() successfully completed......................................
2025-03-05 12:58:41,994:INFO:Initializing predict_model()
2025-03-05 12:58:41,994:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb36b9d0>)
2025-03-05 12:58:41,994:INFO:Checking exceptions
2025-03-05 12:58:41,995:INFO:Preloading libraries
2025-03-05 12:58:42,046:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 12:58:42,160:INFO:Initializing predict_model()
2025-03-05 12:58:42,161:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb36b9d0>)
2025-03-05 12:58:42,161:INFO:Checking exceptions
2025-03-05 12:58:42,161:INFO:Preloading libraries
2025-03-05 12:58:42,163:INFO:Set up data.
2025-03-05 12:58:42,166:INFO:Set up index.
2025-03-05 12:58:42,197:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 13:01:25,984:INFO:Initializing evaluate_model()
2025-03-05 13:01:25,984:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 13:01:25,993:INFO:Initializing plot_model()
2025-03-05 13:01:25,993:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 13:01:25,994:INFO:Checking exceptions
2025-03-05 13:01:25,996:INFO:Preloading libraries
2025-03-05 13:01:26,001:INFO:Copying training dataset
2025-03-05 13:01:26,001:INFO:Plot type: pipeline
2025-03-05 13:01:26,084:INFO:Visual Rendered Successfully
2025-03-05 13:01:26,168:INFO:plot_model() successfully completed......................................
2025-03-05 13:01:26,309:INFO:Initializing plot_model()
2025-03-05 13:01:26,309:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 13:01:26,309:INFO:Checking exceptions
2025-03-05 13:01:26,314:INFO:Preloading libraries
2025-03-05 13:01:26,320:INFO:Copying training dataset
2025-03-05 13:01:26,320:INFO:Plot type: residuals
2025-03-05 13:01:26,402:INFO:Fitting Model
2025-03-05 13:01:26,402:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 13:01:26,484:INFO:Scoring test/hold-out set
2025-03-05 13:01:26,952:INFO:Visual Rendered Successfully
2025-03-05 13:01:27,042:INFO:plot_model() successfully completed......................................
2025-03-05 13:01:27,082:INFO:Initializing plot_model()
2025-03-05 13:01:27,083:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, system=True)
2025-03-05 13:01:27,083:INFO:Checking exceptions
2025-03-05 13:01:27,088:INFO:Preloading libraries
2025-03-05 13:01:27,095:INFO:Copying training dataset
2025-03-05 13:01:27,095:INFO:Plot type: feature
2025-03-05 13:01:27,096:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 13:01:27,205:INFO:Visual Rendered Successfully
2025-03-05 13:01:27,293:INFO:plot_model() successfully completed......................................
2025-03-05 13:01:27,803:INFO:Initializing predict_model()
2025-03-05 13:01:27,804:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb3a48b0>)
2025-03-05 13:01:27,804:INFO:Checking exceptions
2025-03-05 13:01:27,804:INFO:Preloading libraries
2025-03-05 13:01:27,854:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 13:01:30,495:INFO:Initializing predict_model()
2025-03-05 13:01:30,495:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445e0e4dd90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445f02eb9d0>)
2025-03-05 13:01:30,495:INFO:Checking exceptions
2025-03-05 13:01:30,495:INFO:Preloading libraries
2025-03-05 13:01:30,498:INFO:Set up data.
2025-03-05 13:01:30,502:INFO:Set up index.
2025-03-05 13:01:30,533:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 13:02:08,753:INFO:PyCaret RegressionExperiment
2025-03-05 13:02:08,753:INFO:Logging name: reg-default-name
2025-03-05 13:02:08,753:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 13:02:08,753:INFO:version 3.3.1
2025-03-05 13:02:08,753:INFO:Initializing setup()
2025-03-05 13:02:08,753:INFO:self.USI: b5c8
2025-03-05 13:02:08,753:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 13:02:08,753:INFO:Checking environment
2025-03-05 13:02:08,753:INFO:python_version: 3.9.21
2025-03-05 13:02:08,753:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 13:02:08,753:INFO:machine: x86_64
2025-03-05 13:02:08,753:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 13:02:08,753:INFO:Memory: svmem(total=33374507008, available=22197661696, percent=33.5, used=8790454272, free=5205487616, active=12474949632, inactive=11658584064, buffers=648544256, cached=18730020864, shared=1856856064, slab=1803993088)
2025-03-05 13:02:08,754:INFO:Physical Core: 24
2025-03-05 13:02:08,754:INFO:Logical Core: 32
2025-03-05 13:02:08,754:INFO:Checking libraries
2025-03-05 13:02:08,754:INFO:System:
2025-03-05 13:02:08,754:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 13:02:08,754:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 13:02:08,754:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 13:02:08,754:INFO:PyCaret required dependencies:
2025-03-05 13:02:08,754:INFO:                 pip: 25.0
2025-03-05 13:02:08,754:INFO:          setuptools: 75.8.0
2025-03-05 13:02:08,754:INFO:             pycaret: 3.3.1
2025-03-05 13:02:08,754:INFO:             IPython: 8.18.1
2025-03-05 13:02:08,755:INFO:          ipywidgets: 8.1.5
2025-03-05 13:02:08,755:INFO:                tqdm: 4.67.1
2025-03-05 13:02:08,755:INFO:               numpy: 1.26.4
2025-03-05 13:02:08,755:INFO:              pandas: 2.1.4
2025-03-05 13:02:08,755:INFO:              jinja2: 3.1.5
2025-03-05 13:02:08,755:INFO:               scipy: 1.11.4
2025-03-05 13:02:08,755:INFO:              joblib: 1.3.2
2025-03-05 13:02:08,755:INFO:             sklearn: 1.4.2
2025-03-05 13:02:08,755:INFO:                pyod: 2.0.3
2025-03-05 13:02:08,755:INFO:            imblearn: 0.12.4
2025-03-05 13:02:08,755:INFO:   category_encoders: 2.6.4
2025-03-05 13:02:08,755:INFO:            lightgbm: 4.6.0
2025-03-05 13:02:08,755:INFO:               numba: 0.60.0
2025-03-05 13:02:08,755:INFO:            requests: 2.32.3
2025-03-05 13:02:08,755:INFO:          matplotlib: 3.7.5
2025-03-05 13:02:08,755:INFO:          scikitplot: 0.3.7
2025-03-05 13:02:08,755:INFO:         yellowbrick: 1.5
2025-03-05 13:02:08,755:INFO:              plotly: 5.24.1
2025-03-05 13:02:08,755:INFO:    plotly-resampler: Not installed
2025-03-05 13:02:08,755:INFO:             kaleido: 0.2.1
2025-03-05 13:02:08,755:INFO:           schemdraw: 0.15
2025-03-05 13:02:08,755:INFO:         statsmodels: 0.14.4
2025-03-05 13:02:08,755:INFO:              sktime: 0.26.0
2025-03-05 13:02:08,755:INFO:               tbats: 1.1.3
2025-03-05 13:02:08,755:INFO:            pmdarima: 2.0.4
2025-03-05 13:02:08,755:INFO:              psutil: 7.0.0
2025-03-05 13:02:08,755:INFO:          markupsafe: 3.0.2
2025-03-05 13:02:08,755:INFO:             pickle5: Not installed
2025-03-05 13:02:08,755:INFO:         cloudpickle: 3.1.1
2025-03-05 13:02:08,755:INFO:         deprecation: 2.1.0
2025-03-05 13:02:08,755:INFO:              xxhash: 3.5.0
2025-03-05 13:02:08,755:INFO:           wurlitzer: 3.1.1
2025-03-05 13:02:08,755:INFO:PyCaret optional dependencies:
2025-03-05 13:02:08,755:INFO:                shap: Not installed
2025-03-05 13:02:08,755:INFO:           interpret: Not installed
2025-03-05 13:02:08,755:INFO:                umap: Not installed
2025-03-05 13:02:08,755:INFO:     ydata_profiling: Not installed
2025-03-05 13:02:08,755:INFO:  explainerdashboard: Not installed
2025-03-05 13:02:08,755:INFO:             autoviz: Not installed
2025-03-05 13:02:08,755:INFO:           fairlearn: Not installed
2025-03-05 13:02:08,755:INFO:          deepchecks: Not installed
2025-03-05 13:02:08,755:INFO:             xgboost: Not installed
2025-03-05 13:02:08,755:INFO:            catboost: Not installed
2025-03-05 13:02:08,755:INFO:              kmodes: Not installed
2025-03-05 13:02:08,755:INFO:             mlxtend: Not installed
2025-03-05 13:02:08,755:INFO:       statsforecast: Not installed
2025-03-05 13:02:08,755:INFO:        tune_sklearn: Not installed
2025-03-05 13:02:08,755:INFO:                 ray: Not installed
2025-03-05 13:02:08,755:INFO:            hyperopt: Not installed
2025-03-05 13:02:08,755:INFO:              optuna: Not installed
2025-03-05 13:02:08,755:INFO:               skopt: Not installed
2025-03-05 13:02:08,755:INFO:              mlflow: Not installed
2025-03-05 13:02:08,755:INFO:              gradio: Not installed
2025-03-05 13:02:08,755:INFO:             fastapi: Not installed
2025-03-05 13:02:08,755:INFO:             uvicorn: Not installed
2025-03-05 13:02:08,755:INFO:              m2cgen: Not installed
2025-03-05 13:02:08,755:INFO:           evidently: Not installed
2025-03-05 13:02:08,755:INFO:               fugue: Not installed
2025-03-05 13:02:08,756:INFO:           streamlit: Not installed
2025-03-05 13:02:08,756:INFO:             prophet: Not installed
2025-03-05 13:02:08,756:INFO:None
2025-03-05 13:02:08,756:INFO:Set up GPU usage.
2025-03-05 13:02:08,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,756:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 13:02:08,756:INFO:Set up data.
2025-03-05 13:02:08,759:INFO:Set up folding strategy.
2025-03-05 13:02:08,759:INFO:Set up train/test split.
2025-03-05 13:02:08,762:INFO:Set up index.
2025-03-05 13:02:08,762:INFO:Assigning column types.
2025-03-05 13:02:08,765:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 13:02:08,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,765:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,769:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,773:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,773:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:08,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:08,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,864:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,876:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:08,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:08,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:08,999:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 13:02:08,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:08,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,011:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,124:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,224:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 13:02:09,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,233:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,442:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 13:02:09,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,617:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,661:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 13:02:09,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 13:02:09,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,877:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 13:02:09,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:09,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:09,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,100:INFO:Preparing preprocessing pipeline...
2025-03-05 13:02:10,100:INFO:Set up simple imputation.
2025-03-05 13:02:10,122:INFO:Finished creating preprocessing pipeline.
2025-03-05 13:02:10,125:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-03-05 13:02:10,125:INFO:Creating final display dataframe.
2025-03-05 13:02:10,173:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 2)
5   Transformed train set shape        (14061, 2)
6    Transformed test set shape         (6027, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b5c8
2025-03-05 13:02:10,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 13:02:10,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 13:02:10,396:INFO:setup() successfully completed in 1.64s...............
2025-03-05 13:02:10,411:INFO:Initializing compare_models()
2025-03-05 13:02:10,411:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 13:02:10,411:INFO:Checking exceptions
2025-03-05 13:02:10,414:INFO:Preparing display monitor
2025-03-05 13:02:10,441:INFO:Initializing Linear Regression
2025-03-05 13:02:10,441:INFO:Total runtime is 4.673004150390625e-06 minutes
2025-03-05 13:02:10,445:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:10,445:INFO:Initializing create_model()
2025-03-05 13:02:10,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:10,445:INFO:Checking exceptions
2025-03-05 13:02:10,445:INFO:Importing libraries
2025-03-05 13:02:10,445:INFO:Copying training dataset
2025-03-05 13:02:10,449:INFO:Defining folds
2025-03-05 13:02:10,449:INFO:Declaring metric variables
2025-03-05 13:02:10,452:INFO:Importing untrained model
2025-03-05 13:02:10,456:INFO:Linear Regression Imported successfully
2025-03-05 13:02:10,462:INFO:Starting cross validation
2025-03-05 13:02:10,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:10,585:INFO:Calculating mean and std
2025-03-05 13:02:10,586:INFO:Creating metrics dataframe
2025-03-05 13:02:10,587:INFO:Uploading results into container
2025-03-05 13:02:10,588:INFO:Uploading model into container now
2025-03-05 13:02:10,588:INFO:_master_model_container: 1
2025-03-05 13:02:10,588:INFO:_display_container: 2
2025-03-05 13:02:10,588:INFO:LinearRegression(n_jobs=-1)
2025-03-05 13:02:10,588:INFO:create_model() successfully completed......................................
2025-03-05 13:02:10,675:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:10,675:INFO:Creating metrics dataframe
2025-03-05 13:02:10,681:INFO:Initializing Lasso Regression
2025-03-05 13:02:10,682:INFO:Total runtime is 0.00401089588801066 minutes
2025-03-05 13:02:10,685:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:10,685:INFO:Initializing create_model()
2025-03-05 13:02:10,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:10,685:INFO:Checking exceptions
2025-03-05 13:02:10,685:INFO:Importing libraries
2025-03-05 13:02:10,685:INFO:Copying training dataset
2025-03-05 13:02:10,689:INFO:Defining folds
2025-03-05 13:02:10,689:INFO:Declaring metric variables
2025-03-05 13:02:10,692:INFO:Importing untrained model
2025-03-05 13:02:10,695:INFO:Lasso Regression Imported successfully
2025-03-05 13:02:10,701:INFO:Starting cross validation
2025-03-05 13:02:10,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:10,981:INFO:Calculating mean and std
2025-03-05 13:02:10,981:INFO:Creating metrics dataframe
2025-03-05 13:02:10,995:INFO:Uploading results into container
2025-03-05 13:02:10,996:INFO:Uploading model into container now
2025-03-05 13:02:10,996:INFO:_master_model_container: 2
2025-03-05 13:02:10,996:INFO:_display_container: 2
2025-03-05 13:02:10,996:INFO:Lasso(random_state=123)
2025-03-05 13:02:10,997:INFO:create_model() successfully completed......................................
2025-03-05 13:02:11,124:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:11,124:INFO:Creating metrics dataframe
2025-03-05 13:02:11,131:INFO:Initializing Ridge Regression
2025-03-05 13:02:11,131:INFO:Total runtime is 0.011501781145731606 minutes
2025-03-05 13:02:11,134:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:11,135:INFO:Initializing create_model()
2025-03-05 13:02:11,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:11,135:INFO:Checking exceptions
2025-03-05 13:02:11,135:INFO:Importing libraries
2025-03-05 13:02:11,135:INFO:Copying training dataset
2025-03-05 13:02:11,139:INFO:Defining folds
2025-03-05 13:02:11,139:INFO:Declaring metric variables
2025-03-05 13:02:11,142:INFO:Importing untrained model
2025-03-05 13:02:11,145:INFO:Ridge Regression Imported successfully
2025-03-05 13:02:11,151:INFO:Starting cross validation
2025-03-05 13:02:11,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:11,274:INFO:Calculating mean and std
2025-03-05 13:02:11,275:INFO:Creating metrics dataframe
2025-03-05 13:02:11,276:INFO:Uploading results into container
2025-03-05 13:02:11,277:INFO:Uploading model into container now
2025-03-05 13:02:11,277:INFO:_master_model_container: 3
2025-03-05 13:02:11,277:INFO:_display_container: 2
2025-03-05 13:02:11,277:INFO:Ridge(random_state=123)
2025-03-05 13:02:11,277:INFO:create_model() successfully completed......................................
2025-03-05 13:02:11,363:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:11,363:INFO:Creating metrics dataframe
2025-03-05 13:02:11,370:INFO:Initializing Elastic Net
2025-03-05 13:02:11,370:INFO:Total runtime is 0.015479902426401772 minutes
2025-03-05 13:02:11,373:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:11,373:INFO:Initializing create_model()
2025-03-05 13:02:11,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:11,373:INFO:Checking exceptions
2025-03-05 13:02:11,373:INFO:Importing libraries
2025-03-05 13:02:11,373:INFO:Copying training dataset
2025-03-05 13:02:11,377:INFO:Defining folds
2025-03-05 13:02:11,377:INFO:Declaring metric variables
2025-03-05 13:02:11,380:INFO:Importing untrained model
2025-03-05 13:02:11,383:INFO:Elastic Net Imported successfully
2025-03-05 13:02:11,389:INFO:Starting cross validation
2025-03-05 13:02:11,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:11,552:INFO:Calculating mean and std
2025-03-05 13:02:11,554:INFO:Creating metrics dataframe
2025-03-05 13:02:11,556:INFO:Uploading results into container
2025-03-05 13:02:11,557:INFO:Uploading model into container now
2025-03-05 13:02:11,559:INFO:_master_model_container: 4
2025-03-05 13:02:11,559:INFO:_display_container: 2
2025-03-05 13:02:11,560:INFO:ElasticNet(random_state=123)
2025-03-05 13:02:11,560:INFO:create_model() successfully completed......................................
2025-03-05 13:02:11,667:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:11,668:INFO:Creating metrics dataframe
2025-03-05 13:02:11,675:INFO:Initializing Least Angle Regression
2025-03-05 13:02:11,675:INFO:Total runtime is 0.020562275250752764 minutes
2025-03-05 13:02:11,678:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:11,678:INFO:Initializing create_model()
2025-03-05 13:02:11,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:11,678:INFO:Checking exceptions
2025-03-05 13:02:11,678:INFO:Importing libraries
2025-03-05 13:02:11,678:INFO:Copying training dataset
2025-03-05 13:02:11,683:INFO:Defining folds
2025-03-05 13:02:11,683:INFO:Declaring metric variables
2025-03-05 13:02:11,686:INFO:Importing untrained model
2025-03-05 13:02:11,690:INFO:Least Angle Regression Imported successfully
2025-03-05 13:02:11,696:INFO:Starting cross validation
2025-03-05 13:02:11,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:11,822:INFO:Calculating mean and std
2025-03-05 13:02:11,823:INFO:Creating metrics dataframe
2025-03-05 13:02:11,825:INFO:Uploading results into container
2025-03-05 13:02:11,825:INFO:Uploading model into container now
2025-03-05 13:02:11,826:INFO:_master_model_container: 5
2025-03-05 13:02:11,826:INFO:_display_container: 2
2025-03-05 13:02:11,826:INFO:Lars(random_state=123)
2025-03-05 13:02:11,826:INFO:create_model() successfully completed......................................
2025-03-05 13:02:11,912:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:11,912:INFO:Creating metrics dataframe
2025-03-05 13:02:11,919:INFO:Initializing Lasso Least Angle Regression
2025-03-05 13:02:11,919:INFO:Total runtime is 0.024633606274922684 minutes
2025-03-05 13:02:11,922:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:11,922:INFO:Initializing create_model()
2025-03-05 13:02:11,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:11,922:INFO:Checking exceptions
2025-03-05 13:02:11,922:INFO:Importing libraries
2025-03-05 13:02:11,922:INFO:Copying training dataset
2025-03-05 13:02:11,927:INFO:Defining folds
2025-03-05 13:02:11,927:INFO:Declaring metric variables
2025-03-05 13:02:11,930:INFO:Importing untrained model
2025-03-05 13:02:11,933:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 13:02:11,939:INFO:Starting cross validation
2025-03-05 13:02:11,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:12,065:INFO:Calculating mean and std
2025-03-05 13:02:12,066:INFO:Creating metrics dataframe
2025-03-05 13:02:12,067:INFO:Uploading results into container
2025-03-05 13:02:12,068:INFO:Uploading model into container now
2025-03-05 13:02:12,068:INFO:_master_model_container: 6
2025-03-05 13:02:12,068:INFO:_display_container: 2
2025-03-05 13:02:12,069:INFO:LassoLars(random_state=123)
2025-03-05 13:02:12,069:INFO:create_model() successfully completed......................................
2025-03-05 13:02:12,154:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:12,154:INFO:Creating metrics dataframe
2025-03-05 13:02:12,161:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 13:02:12,161:INFO:Total runtime is 0.028667294979095453 minutes
2025-03-05 13:02:12,164:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:12,164:INFO:Initializing create_model()
2025-03-05 13:02:12,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:12,164:INFO:Checking exceptions
2025-03-05 13:02:12,164:INFO:Importing libraries
2025-03-05 13:02:12,164:INFO:Copying training dataset
2025-03-05 13:02:12,169:INFO:Defining folds
2025-03-05 13:02:12,169:INFO:Declaring metric variables
2025-03-05 13:02:12,172:INFO:Importing untrained model
2025-03-05 13:02:12,175:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 13:02:12,181:INFO:Starting cross validation
2025-03-05 13:02:12,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:12,302:INFO:Calculating mean and std
2025-03-05 13:02:12,303:INFO:Creating metrics dataframe
2025-03-05 13:02:12,305:INFO:Uploading results into container
2025-03-05 13:02:12,306:INFO:Uploading model into container now
2025-03-05 13:02:12,306:INFO:_master_model_container: 7
2025-03-05 13:02:12,306:INFO:_display_container: 2
2025-03-05 13:02:12,306:INFO:OrthogonalMatchingPursuit()
2025-03-05 13:02:12,306:INFO:create_model() successfully completed......................................
2025-03-05 13:02:12,391:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:12,391:INFO:Creating metrics dataframe
2025-03-05 13:02:12,399:INFO:Initializing Bayesian Ridge
2025-03-05 13:02:12,399:INFO:Total runtime is 0.032628365357716876 minutes
2025-03-05 13:02:12,402:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:12,402:INFO:Initializing create_model()
2025-03-05 13:02:12,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:12,402:INFO:Checking exceptions
2025-03-05 13:02:12,402:INFO:Importing libraries
2025-03-05 13:02:12,402:INFO:Copying training dataset
2025-03-05 13:02:12,406:INFO:Defining folds
2025-03-05 13:02:12,407:INFO:Declaring metric variables
2025-03-05 13:02:12,410:INFO:Importing untrained model
2025-03-05 13:02:12,413:INFO:Bayesian Ridge Imported successfully
2025-03-05 13:02:12,418:INFO:Starting cross validation
2025-03-05 13:02:12,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:12,584:INFO:Calculating mean and std
2025-03-05 13:02:12,586:INFO:Creating metrics dataframe
2025-03-05 13:02:12,589:INFO:Uploading results into container
2025-03-05 13:02:12,591:INFO:Uploading model into container now
2025-03-05 13:02:12,591:INFO:_master_model_container: 8
2025-03-05 13:02:12,591:INFO:_display_container: 2
2025-03-05 13:02:12,591:INFO:BayesianRidge()
2025-03-05 13:02:12,591:INFO:create_model() successfully completed......................................
2025-03-05 13:02:12,710:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:12,711:INFO:Creating metrics dataframe
2025-03-05 13:02:12,718:INFO:Initializing Passive Aggressive Regressor
2025-03-05 13:02:12,718:INFO:Total runtime is 0.03795574903488159 minutes
2025-03-05 13:02:12,721:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:12,721:INFO:Initializing create_model()
2025-03-05 13:02:12,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:12,722:INFO:Checking exceptions
2025-03-05 13:02:12,722:INFO:Importing libraries
2025-03-05 13:02:12,722:INFO:Copying training dataset
2025-03-05 13:02:12,726:INFO:Defining folds
2025-03-05 13:02:12,726:INFO:Declaring metric variables
2025-03-05 13:02:12,729:INFO:Importing untrained model
2025-03-05 13:02:12,732:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 13:02:12,738:INFO:Starting cross validation
2025-03-05 13:02:12,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:12,929:INFO:Calculating mean and std
2025-03-05 13:02:12,930:INFO:Creating metrics dataframe
2025-03-05 13:02:12,931:INFO:Uploading results into container
2025-03-05 13:02:12,932:INFO:Uploading model into container now
2025-03-05 13:02:12,932:INFO:_master_model_container: 9
2025-03-05 13:02:12,932:INFO:_display_container: 2
2025-03-05 13:02:12,932:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 13:02:12,933:INFO:create_model() successfully completed......................................
2025-03-05 13:02:13,017:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:13,017:INFO:Creating metrics dataframe
2025-03-05 13:02:13,025:INFO:Initializing Huber Regressor
2025-03-05 13:02:13,026:INFO:Total runtime is 0.04307805299758911 minutes
2025-03-05 13:02:13,029:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:13,029:INFO:Initializing create_model()
2025-03-05 13:02:13,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:13,029:INFO:Checking exceptions
2025-03-05 13:02:13,029:INFO:Importing libraries
2025-03-05 13:02:13,029:INFO:Copying training dataset
2025-03-05 13:02:13,033:INFO:Defining folds
2025-03-05 13:02:13,033:INFO:Declaring metric variables
2025-03-05 13:02:13,037:INFO:Importing untrained model
2025-03-05 13:02:13,040:INFO:Huber Regressor Imported successfully
2025-03-05 13:02:13,045:INFO:Starting cross validation
2025-03-05 13:02:13,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:13,371:INFO:Calculating mean and std
2025-03-05 13:02:13,372:INFO:Creating metrics dataframe
2025-03-05 13:02:13,374:INFO:Uploading results into container
2025-03-05 13:02:13,374:INFO:Uploading model into container now
2025-03-05 13:02:13,374:INFO:_master_model_container: 10
2025-03-05 13:02:13,374:INFO:_display_container: 2
2025-03-05 13:02:13,375:INFO:HuberRegressor()
2025-03-05 13:02:13,375:INFO:create_model() successfully completed......................................
2025-03-05 13:02:13,462:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:13,462:INFO:Creating metrics dataframe
2025-03-05 13:02:13,470:INFO:Initializing K Neighbors Regressor
2025-03-05 13:02:13,470:INFO:Total runtime is 0.050487848122914625 minutes
2025-03-05 13:02:13,473:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:13,474:INFO:Initializing create_model()
2025-03-05 13:02:13,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:13,474:INFO:Checking exceptions
2025-03-05 13:02:13,474:INFO:Importing libraries
2025-03-05 13:02:13,474:INFO:Copying training dataset
2025-03-05 13:02:13,478:INFO:Defining folds
2025-03-05 13:02:13,478:INFO:Declaring metric variables
2025-03-05 13:02:13,481:INFO:Importing untrained model
2025-03-05 13:02:13,484:INFO:K Neighbors Regressor Imported successfully
2025-03-05 13:02:13,489:INFO:Starting cross validation
2025-03-05 13:02:13,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:13,883:INFO:Calculating mean and std
2025-03-05 13:02:13,884:INFO:Creating metrics dataframe
2025-03-05 13:02:13,885:INFO:Uploading results into container
2025-03-05 13:02:13,886:INFO:Uploading model into container now
2025-03-05 13:02:13,887:INFO:_master_model_container: 11
2025-03-05 13:02:13,887:INFO:_display_container: 2
2025-03-05 13:02:13,887:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 13:02:13,887:INFO:create_model() successfully completed......................................
2025-03-05 13:02:13,972:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:13,973:INFO:Creating metrics dataframe
2025-03-05 13:02:13,982:INFO:Initializing Decision Tree Regressor
2025-03-05 13:02:13,982:INFO:Total runtime is 0.059022978941599524 minutes
2025-03-05 13:02:13,985:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:13,986:INFO:Initializing create_model()
2025-03-05 13:02:13,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:13,986:INFO:Checking exceptions
2025-03-05 13:02:13,986:INFO:Importing libraries
2025-03-05 13:02:13,986:INFO:Copying training dataset
2025-03-05 13:02:13,990:INFO:Defining folds
2025-03-05 13:02:13,990:INFO:Declaring metric variables
2025-03-05 13:02:13,994:INFO:Importing untrained model
2025-03-05 13:02:13,998:INFO:Decision Tree Regressor Imported successfully
2025-03-05 13:02:14,003:INFO:Starting cross validation
2025-03-05 13:02:14,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:14,175:INFO:Calculating mean and std
2025-03-05 13:02:14,176:INFO:Creating metrics dataframe
2025-03-05 13:02:14,178:INFO:Uploading results into container
2025-03-05 13:02:14,178:INFO:Uploading model into container now
2025-03-05 13:02:14,179:INFO:_master_model_container: 12
2025-03-05 13:02:14,179:INFO:_display_container: 2
2025-03-05 13:02:14,179:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 13:02:14,179:INFO:create_model() successfully completed......................................
2025-03-05 13:02:14,264:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:14,264:INFO:Creating metrics dataframe
2025-03-05 13:02:14,273:INFO:Initializing Random Forest Regressor
2025-03-05 13:02:14,273:INFO:Total runtime is 0.06387016773223876 minutes
2025-03-05 13:02:14,276:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:14,277:INFO:Initializing create_model()
2025-03-05 13:02:14,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:14,277:INFO:Checking exceptions
2025-03-05 13:02:14,277:INFO:Importing libraries
2025-03-05 13:02:14,277:INFO:Copying training dataset
2025-03-05 13:02:14,282:INFO:Defining folds
2025-03-05 13:02:14,282:INFO:Declaring metric variables
2025-03-05 13:02:14,285:INFO:Importing untrained model
2025-03-05 13:02:14,288:INFO:Random Forest Regressor Imported successfully
2025-03-05 13:02:14,294:INFO:Starting cross validation
2025-03-05 13:02:14,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:16,773:INFO:Calculating mean and std
2025-03-05 13:02:16,774:INFO:Creating metrics dataframe
2025-03-05 13:02:16,776:INFO:Uploading results into container
2025-03-05 13:02:16,777:INFO:Uploading model into container now
2025-03-05 13:02:16,777:INFO:_master_model_container: 13
2025-03-05 13:02:16,778:INFO:_display_container: 2
2025-03-05 13:02:16,778:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 13:02:16,778:INFO:create_model() successfully completed......................................
2025-03-05 13:02:16,867:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:16,867:INFO:Creating metrics dataframe
2025-03-05 13:02:16,877:INFO:Initializing Extra Trees Regressor
2025-03-05 13:02:16,877:INFO:Total runtime is 0.1072701613108317 minutes
2025-03-05 13:02:16,881:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:16,881:INFO:Initializing create_model()
2025-03-05 13:02:16,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:16,881:INFO:Checking exceptions
2025-03-05 13:02:16,881:INFO:Importing libraries
2025-03-05 13:02:16,882:INFO:Copying training dataset
2025-03-05 13:02:16,886:INFO:Defining folds
2025-03-05 13:02:16,886:INFO:Declaring metric variables
2025-03-05 13:02:16,889:INFO:Importing untrained model
2025-03-05 13:02:16,893:INFO:Extra Trees Regressor Imported successfully
2025-03-05 13:02:16,898:INFO:Starting cross validation
2025-03-05 13:02:16,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:18,452:INFO:Calculating mean and std
2025-03-05 13:02:18,453:INFO:Creating metrics dataframe
2025-03-05 13:02:18,455:INFO:Uploading results into container
2025-03-05 13:02:18,455:INFO:Uploading model into container now
2025-03-05 13:02:18,456:INFO:_master_model_container: 14
2025-03-05 13:02:18,456:INFO:_display_container: 2
2025-03-05 13:02:18,456:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 13:02:18,456:INFO:create_model() successfully completed......................................
2025-03-05 13:02:18,542:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:18,543:INFO:Creating metrics dataframe
2025-03-05 13:02:18,552:INFO:Initializing AdaBoost Regressor
2025-03-05 13:02:18,552:INFO:Total runtime is 0.13517935276031492 minutes
2025-03-05 13:02:18,555:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:18,555:INFO:Initializing create_model()
2025-03-05 13:02:18,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:18,556:INFO:Checking exceptions
2025-03-05 13:02:18,556:INFO:Importing libraries
2025-03-05 13:02:18,556:INFO:Copying training dataset
2025-03-05 13:02:18,560:INFO:Defining folds
2025-03-05 13:02:18,560:INFO:Declaring metric variables
2025-03-05 13:02:18,563:INFO:Importing untrained model
2025-03-05 13:02:18,566:INFO:AdaBoost Regressor Imported successfully
2025-03-05 13:02:18,571:INFO:Starting cross validation
2025-03-05 13:02:18,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:19,609:INFO:Calculating mean and std
2025-03-05 13:02:19,610:INFO:Creating metrics dataframe
2025-03-05 13:02:19,612:INFO:Uploading results into container
2025-03-05 13:02:19,613:INFO:Uploading model into container now
2025-03-05 13:02:19,613:INFO:_master_model_container: 15
2025-03-05 13:02:19,613:INFO:_display_container: 2
2025-03-05 13:02:19,613:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 13:02:19,613:INFO:create_model() successfully completed......................................
2025-03-05 13:02:19,698:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:19,698:INFO:Creating metrics dataframe
2025-03-05 13:02:19,707:INFO:Initializing Gradient Boosting Regressor
2025-03-05 13:02:19,707:INFO:Total runtime is 0.154437522093455 minutes
2025-03-05 13:02:19,710:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:19,711:INFO:Initializing create_model()
2025-03-05 13:02:19,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:19,711:INFO:Checking exceptions
2025-03-05 13:02:19,711:INFO:Importing libraries
2025-03-05 13:02:19,711:INFO:Copying training dataset
2025-03-05 13:02:19,715:INFO:Defining folds
2025-03-05 13:02:19,715:INFO:Declaring metric variables
2025-03-05 13:02:19,719:INFO:Importing untrained model
2025-03-05 13:02:19,722:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 13:02:19,728:INFO:Starting cross validation
2025-03-05 13:02:19,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:24,079:INFO:Calculating mean and std
2025-03-05 13:02:24,080:INFO:Creating metrics dataframe
2025-03-05 13:02:24,083:INFO:Uploading results into container
2025-03-05 13:02:24,083:INFO:Uploading model into container now
2025-03-05 13:02:24,083:INFO:_master_model_container: 16
2025-03-05 13:02:24,083:INFO:_display_container: 2
2025-03-05 13:02:24,084:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 13:02:24,084:INFO:create_model() successfully completed......................................
2025-03-05 13:02:24,175:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:24,175:INFO:Creating metrics dataframe
2025-03-05 13:02:24,184:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 13:02:24,184:INFO:Total runtime is 0.22905139128367105 minutes
2025-03-05 13:02:24,187:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:24,188:INFO:Initializing create_model()
2025-03-05 13:02:24,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:24,188:INFO:Checking exceptions
2025-03-05 13:02:24,188:INFO:Importing libraries
2025-03-05 13:02:24,188:INFO:Copying training dataset
2025-03-05 13:02:24,192:INFO:Defining folds
2025-03-05 13:02:24,193:INFO:Declaring metric variables
2025-03-05 13:02:24,196:INFO:Importing untrained model
2025-03-05 13:02:24,199:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 13:02:24,208:INFO:Starting cross validation
2025-03-05 13:02:24,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:24,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038442 seconds.
2025-03-05 13:02:24,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:24,291:INFO:[LightGBM] [Info] Total Bins 219
2025-03-05 13:02:24,302:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 1
2025-03-05 13:02:24,319:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 13:02:27,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041653 seconds.
2025-03-05 13:02:27,514:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:27,514:INFO:[LightGBM] [Info] Total Bins 218
2025-03-05 13:02:27,520:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:27,534:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 13:02:29,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2025-03-05 13:02:29,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:29,164:INFO:[LightGBM] [Info] Total Bins 216
2025-03-05 13:02:29,164:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:29,164:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 13:02:29,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-03-05 13:02:29,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 13:02:29,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 13:02:29,527:INFO:[LightGBM] [Info] Total Bins 218
2025-03-05 13:02:29,527:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:29,527:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 13:02:29,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031712 seconds.
2025-03-05 13:02:29,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:29,937:INFO:[LightGBM] [Info] Total Bins 216
2025-03-05 13:02:29,943:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:29,959:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 13:02:30,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2025-03-05 13:02:30,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:30,732:INFO:[LightGBM] [Info] Total Bins 218
2025-03-05 13:02:30,732:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:30,732:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 13:02:31,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042554 seconds.
2025-03-05 13:02:31,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:31,151:INFO:[LightGBM] [Info] Total Bins 215
2025-03-05 13:02:31,158:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:31,174:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 13:02:32,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030617 seconds.
2025-03-05 13:02:32,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:32,356:INFO:[LightGBM] [Info] Total Bins 218
2025-03-05 13:02:32,363:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:32,382:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 13:02:32,889:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026624 seconds.
2025-03-05 13:02:32,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:32,890:INFO:[LightGBM] [Info] Total Bins 218
2025-03-05 13:02:32,896:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:32,910:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 13:02:33,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040633 seconds.
2025-03-05 13:02:33,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 13:02:33,635:INFO:[LightGBM] [Info] Total Bins 217
2025-03-05 13:02:33,644:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 1
2025-03-05 13:02:33,665:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 13:02:34,515:INFO:Calculating mean and std
2025-03-05 13:02:34,517:INFO:Creating metrics dataframe
2025-03-05 13:02:34,519:INFO:Uploading results into container
2025-03-05 13:02:34,520:INFO:Uploading model into container now
2025-03-05 13:02:34,520:INFO:_master_model_container: 17
2025-03-05 13:02:34,520:INFO:_display_container: 2
2025-03-05 13:02:34,521:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 13:02:34,521:INFO:create_model() successfully completed......................................
2025-03-05 13:02:34,606:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:34,606:INFO:Creating metrics dataframe
2025-03-05 13:02:34,615:INFO:Initializing Dummy Regressor
2025-03-05 13:02:34,615:INFO:Total runtime is 0.40290420055389403 minutes
2025-03-05 13:02:34,619:INFO:SubProcess create_model() called ==================================
2025-03-05 13:02:34,619:INFO:Initializing create_model()
2025-03-05 13:02:34,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445f5693250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:34,619:INFO:Checking exceptions
2025-03-05 13:02:34,619:INFO:Importing libraries
2025-03-05 13:02:34,619:INFO:Copying training dataset
2025-03-05 13:02:34,623:INFO:Defining folds
2025-03-05 13:02:34,624:INFO:Declaring metric variables
2025-03-05 13:02:34,627:INFO:Importing untrained model
2025-03-05 13:02:34,630:INFO:Dummy Regressor Imported successfully
2025-03-05 13:02:34,636:INFO:Starting cross validation
2025-03-05 13:02:34,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 13:02:34,740:INFO:Calculating mean and std
2025-03-05 13:02:34,741:INFO:Creating metrics dataframe
2025-03-05 13:02:34,742:INFO:Uploading results into container
2025-03-05 13:02:34,743:INFO:Uploading model into container now
2025-03-05 13:02:34,743:INFO:_master_model_container: 18
2025-03-05 13:02:34,743:INFO:_display_container: 2
2025-03-05 13:02:34,743:INFO:DummyRegressor()
2025-03-05 13:02:34,744:INFO:create_model() successfully completed......................................
2025-03-05 13:02:34,832:INFO:SubProcess create_model() end ==================================
2025-03-05 13:02:34,832:INFO:Creating metrics dataframe
2025-03-05 13:02:34,842:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 13:02:34,850:INFO:Initializing create_model()
2025-03-05 13:02:34,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 13:02:34,850:INFO:Checking exceptions
2025-03-05 13:02:34,851:INFO:Importing libraries
2025-03-05 13:02:34,851:INFO:Copying training dataset
2025-03-05 13:02:34,855:INFO:Defining folds
2025-03-05 13:02:34,855:INFO:Declaring metric variables
2025-03-05 13:02:34,855:INFO:Importing untrained model
2025-03-05 13:02:34,855:INFO:Declaring custom model
2025-03-05 13:02:34,856:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 13:02:34,857:INFO:Cross validation set to False
2025-03-05 13:02:34,857:INFO:Fitting Model
2025-03-05 13:02:35,330:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 13:02:35,330:INFO:create_model() successfully completed......................................
2025-03-05 13:02:35,443:INFO:_master_model_container: 18
2025-03-05 13:02:35,443:INFO:_display_container: 2
2025-03-05 13:02:35,444:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 13:02:35,444:INFO:compare_models() successfully completed......................................
2025-03-05 13:02:35,467:INFO:Initializing evaluate_model()
2025-03-05 13:02:35,467:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 13:02:35,476:INFO:Initializing plot_model()
2025-03-05 13:02:35,476:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:02:35,476:INFO:Checking exceptions
2025-03-05 13:02:35,478:INFO:Preloading libraries
2025-03-05 13:02:35,484:INFO:Copying training dataset
2025-03-05 13:02:35,484:INFO:Plot type: pipeline
2025-03-05 13:02:35,587:INFO:Visual Rendered Successfully
2025-03-05 13:02:35,683:INFO:plot_model() successfully completed......................................
2025-03-05 13:02:35,704:INFO:Initializing plot_model()
2025-03-05 13:02:35,705:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:02:35,705:INFO:Checking exceptions
2025-03-05 13:02:35,709:INFO:Preloading libraries
2025-03-05 13:02:35,716:INFO:Copying training dataset
2025-03-05 13:02:35,716:INFO:Plot type: residuals
2025-03-05 13:02:35,785:INFO:Fitting Model
2025-03-05 13:02:35,785:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 13:02:35,876:INFO:Scoring test/hold-out set
2025-03-05 13:02:36,363:INFO:Visual Rendered Successfully
2025-03-05 13:02:36,456:INFO:plot_model() successfully completed......................................
2025-03-05 13:02:36,471:INFO:Initializing plot_model()
2025-03-05 13:02:36,471:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:02:36,471:INFO:Checking exceptions
2025-03-05 13:02:36,476:INFO:Preloading libraries
2025-03-05 13:02:36,482:INFO:Copying training dataset
2025-03-05 13:02:36,482:INFO:Plot type: feature
2025-03-05 13:02:36,483:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 13:02:36,589:INFO:Visual Rendered Successfully
2025-03-05 13:02:36,678:INFO:plot_model() successfully completed......................................
2025-03-05 13:02:36,690:INFO:Initializing predict_model()
2025-03-05 13:02:36,691:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb3fab80>)
2025-03-05 13:02:36,691:INFO:Checking exceptions
2025-03-05 13:02:36,691:INFO:Preloading libraries
2025-03-05 13:02:36,736:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 13:02:36,877:INFO:Initializing predict_model()
2025-03-05 13:02:36,877:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445eb3fae50>)
2025-03-05 13:02:36,877:INFO:Checking exceptions
2025-03-05 13:02:36,877:INFO:Preloading libraries
2025-03-05 13:02:36,881:INFO:Set up data.
2025-03-05 13:02:36,884:INFO:Set up index.
2025-03-05 13:02:36,912:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 13:07:44,554:INFO:Initializing plot_model()
2025-03-05 13:07:44,554:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:07:44,554:INFO:Checking exceptions
2025-03-05 13:07:44,556:INFO:Preloading libraries
2025-03-05 13:07:44,562:INFO:Copying training dataset
2025-03-05 13:07:44,562:INFO:Plot type: parameter
2025-03-05 13:07:44,566:INFO:Visual Rendered Successfully
2025-03-05 13:07:44,657:INFO:plot_model() successfully completed......................................
2025-03-05 13:07:47,447:INFO:Initializing plot_model()
2025-03-05 13:07:47,448:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:07:47,448:INFO:Checking exceptions
2025-03-05 13:07:47,450:INFO:Preloading libraries
2025-03-05 13:07:47,456:INFO:Copying training dataset
2025-03-05 13:07:47,456:INFO:Plot type: residuals
2025-03-05 13:07:47,528:INFO:Fitting Model
2025-03-05 13:07:47,528:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 13:07:47,622:INFO:Scoring test/hold-out set
2025-03-05 13:07:48,115:INFO:Visual Rendered Successfully
2025-03-05 13:07:48,208:INFO:plot_model() successfully completed......................................
2025-03-05 13:07:48,871:INFO:Initializing plot_model()
2025-03-05 13:07:48,871:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:07:48,871:INFO:Checking exceptions
2025-03-05 13:07:48,873:INFO:Preloading libraries
2025-03-05 13:07:48,880:INFO:Copying training dataset
2025-03-05 13:07:48,880:INFO:Plot type: error
2025-03-05 13:07:48,928:INFO:Fitting Model
2025-03-05 13:07:48,928:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 13:07:48,928:INFO:Scoring test/hold-out set
2025-03-05 13:07:49,198:INFO:Visual Rendered Successfully
2025-03-05 13:07:49,290:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:03,784:INFO:Initializing plot_model()
2025-03-05 13:08:03,784:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:03,784:INFO:Checking exceptions
2025-03-05 13:08:03,786:INFO:Preloading libraries
2025-03-05 13:08:03,792:INFO:Copying training dataset
2025-03-05 13:08:03,792:INFO:Plot type: cooks
2025-03-05 13:08:03,839:INFO:Fitting Model
2025-03-05 13:08:04,315:INFO:Visual Rendered Successfully
2025-03-05 13:08:04,429:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:04,510:INFO:Initializing plot_model()
2025-03-05 13:08:04,510:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:04,510:INFO:Checking exceptions
2025-03-05 13:08:04,512:INFO:Preloading libraries
2025-03-05 13:08:04,518:INFO:Copying training dataset
2025-03-05 13:08:04,518:INFO:Plot type: rfe
2025-03-05 13:08:04,565:INFO:Fitting Model
2025-03-05 13:08:05,940:INFO:Initializing plot_model()
2025-03-05 13:08:05,940:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:05,940:INFO:Checking exceptions
2025-03-05 13:08:05,943:INFO:Preloading libraries
2025-03-05 13:08:05,949:INFO:Copying training dataset
2025-03-05 13:08:05,949:INFO:Plot type: cooks
2025-03-05 13:08:05,994:INFO:Fitting Model
2025-03-05 13:08:06,477:INFO:Visual Rendered Successfully
2025-03-05 13:08:06,593:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:08,341:INFO:Initializing plot_model()
2025-03-05 13:08:08,341:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:08,341:INFO:Checking exceptions
2025-03-05 13:08:08,344:INFO:Preloading libraries
2025-03-05 13:08:08,350:INFO:Copying training dataset
2025-03-05 13:08:08,350:INFO:Plot type: rfe
2025-03-05 13:08:08,395:INFO:Fitting Model
2025-03-05 13:08:11,602:INFO:Initializing plot_model()
2025-03-05 13:08:11,602:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:11,602:INFO:Checking exceptions
2025-03-05 13:08:11,605:INFO:Preloading libraries
2025-03-05 13:08:11,611:INFO:Copying training dataset
2025-03-05 13:08:11,611:INFO:Plot type: learning
2025-03-05 13:08:11,656:INFO:Fitting Model
2025-03-05 13:08:43,721:INFO:Initializing evaluate_model()
2025-03-05 13:08:43,721:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 13:08:43,731:INFO:Initializing plot_model()
2025-03-05 13:08:43,731:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:43,731:INFO:Checking exceptions
2025-03-05 13:08:43,734:INFO:Preloading libraries
2025-03-05 13:08:43,739:INFO:Copying training dataset
2025-03-05 13:08:43,739:INFO:Plot type: pipeline
2025-03-05 13:08:43,813:INFO:Visual Rendered Successfully
2025-03-05 13:08:43,951:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:43,961:INFO:Initializing plot_model()
2025-03-05 13:08:43,961:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:43,961:INFO:Checking exceptions
2025-03-05 13:08:43,964:INFO:Preloading libraries
2025-03-05 13:08:43,969:INFO:Copying training dataset
2025-03-05 13:08:43,969:INFO:Plot type: pipeline
2025-03-05 13:08:44,034:INFO:Visual Rendered Successfully
2025-03-05 13:08:44,148:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:46,571:INFO:Initializing plot_model()
2025-03-05 13:08:46,572:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:46,572:INFO:Checking exceptions
2025-03-05 13:08:46,574:INFO:Preloading libraries
2025-03-05 13:08:46,580:INFO:Copying training dataset
2025-03-05 13:08:46,580:INFO:Plot type: parameter
2025-03-05 13:08:46,584:INFO:Visual Rendered Successfully
2025-03-05 13:08:46,701:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:47,425:INFO:Initializing plot_model()
2025-03-05 13:08:47,425:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:47,425:INFO:Checking exceptions
2025-03-05 13:08:47,427:INFO:Preloading libraries
2025-03-05 13:08:47,433:INFO:Copying training dataset
2025-03-05 13:08:47,433:INFO:Plot type: residuals
2025-03-05 13:08:47,503:INFO:Fitting Model
2025-03-05 13:08:47,503:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 13:08:47,594:INFO:Scoring test/hold-out set
2025-03-05 13:08:48,094:INFO:Visual Rendered Successfully
2025-03-05 13:08:48,217:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:48,227:INFO:Initializing plot_model()
2025-03-05 13:08:48,228:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:48,228:INFO:Checking exceptions
2025-03-05 13:08:48,230:INFO:Preloading libraries
2025-03-05 13:08:48,235:INFO:Copying training dataset
2025-03-05 13:08:48,235:INFO:Plot type: cooks
2025-03-05 13:08:48,280:INFO:Fitting Model
2025-03-05 13:08:48,761:INFO:Visual Rendered Successfully
2025-03-05 13:08:48,895:INFO:plot_model() successfully completed......................................
2025-03-05 13:08:49,425:INFO:Initializing plot_model()
2025-03-05 13:08:49,426:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:08:49,426:INFO:Checking exceptions
2025-03-05 13:08:49,428:INFO:Preloading libraries
2025-03-05 13:08:49,434:INFO:Copying training dataset
2025-03-05 13:08:49,434:INFO:Plot type: learning
2025-03-05 13:08:49,478:INFO:Fitting Model
2025-03-05 13:09:20,300:INFO:Visual Rendered Successfully
2025-03-05 13:09:20,417:INFO:plot_model() successfully completed......................................
2025-03-05 13:09:20,428:INFO:Initializing plot_model()
2025-03-05 13:09:20,428:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445f56934c0>, system=True)
2025-03-05 13:09:20,428:INFO:Checking exceptions
2025-03-05 13:09:20,430:INFO:Preloading libraries
2025-03-05 13:09:20,436:INFO:Copying training dataset
2025-03-05 13:09:20,436:INFO:Plot type: manifold
2025-03-05 13:09:20,505:INFO:Fitting & Transforming Model
2025-03-05 15:18:27,775:INFO:PyCaret RegressionExperiment
2025-03-05 15:18:27,775:INFO:Logging name: reg-default-name
2025-03-05 15:18:27,775:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:18:27,775:INFO:version 3.3.1
2025-03-05 15:18:27,775:INFO:Initializing setup()
2025-03-05 15:18:27,775:INFO:self.USI: dbfd
2025-03-05 15:18:27,775:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:18:27,775:INFO:Checking environment
2025-03-05 15:18:27,775:INFO:python_version: 3.9.21
2025-03-05 15:18:27,775:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:18:27,775:INFO:machine: x86_64
2025-03-05 15:18:27,775:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:18:27,775:INFO:Memory: svmem(total=33374507008, available=21376364544, percent=36.0, used=9321320448, free=3969691648, active=13362266112, inactive=11757125632, buffers=672440320, cached=19411054592, shared=2147733504, slab=1818243072)
2025-03-05 15:18:27,776:INFO:Physical Core: 24
2025-03-05 15:18:27,776:INFO:Logical Core: 32
2025-03-05 15:18:27,776:INFO:Checking libraries
2025-03-05 15:18:27,776:INFO:System:
2025-03-05 15:18:27,776:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:18:27,776:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:18:27,776:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:18:27,776:INFO:PyCaret required dependencies:
2025-03-05 15:18:27,776:INFO:                 pip: 25.0
2025-03-05 15:18:27,776:INFO:          setuptools: 75.8.0
2025-03-05 15:18:27,776:INFO:             pycaret: 3.3.1
2025-03-05 15:18:27,776:INFO:             IPython: 8.18.1
2025-03-05 15:18:27,776:INFO:          ipywidgets: 8.1.5
2025-03-05 15:18:27,776:INFO:                tqdm: 4.67.1
2025-03-05 15:18:27,776:INFO:               numpy: 1.26.4
2025-03-05 15:18:27,776:INFO:              pandas: 2.1.4
2025-03-05 15:18:27,776:INFO:              jinja2: 3.1.5
2025-03-05 15:18:27,776:INFO:               scipy: 1.11.4
2025-03-05 15:18:27,776:INFO:              joblib: 1.3.2
2025-03-05 15:18:27,776:INFO:             sklearn: 1.4.2
2025-03-05 15:18:27,776:INFO:                pyod: 2.0.3
2025-03-05 15:18:27,776:INFO:            imblearn: 0.12.4
2025-03-05 15:18:27,776:INFO:   category_encoders: 2.6.4
2025-03-05 15:18:27,776:INFO:            lightgbm: 4.6.0
2025-03-05 15:18:27,776:INFO:               numba: 0.60.0
2025-03-05 15:18:27,776:INFO:            requests: 2.32.3
2025-03-05 15:18:27,776:INFO:          matplotlib: 3.7.5
2025-03-05 15:18:27,776:INFO:          scikitplot: 0.3.7
2025-03-05 15:18:27,776:INFO:         yellowbrick: 1.5
2025-03-05 15:18:27,776:INFO:              plotly: 5.24.1
2025-03-05 15:18:27,776:INFO:    plotly-resampler: Not installed
2025-03-05 15:18:27,776:INFO:             kaleido: 0.2.1
2025-03-05 15:18:27,777:INFO:           schemdraw: 0.15
2025-03-05 15:18:27,777:INFO:         statsmodels: 0.14.4
2025-03-05 15:18:27,777:INFO:              sktime: 0.26.0
2025-03-05 15:18:27,777:INFO:               tbats: 1.1.3
2025-03-05 15:18:27,777:INFO:            pmdarima: 2.0.4
2025-03-05 15:18:27,777:INFO:              psutil: 7.0.0
2025-03-05 15:18:27,777:INFO:          markupsafe: 3.0.2
2025-03-05 15:18:27,777:INFO:             pickle5: Not installed
2025-03-05 15:18:27,777:INFO:         cloudpickle: 3.1.1
2025-03-05 15:18:27,777:INFO:         deprecation: 2.1.0
2025-03-05 15:18:27,777:INFO:              xxhash: 3.5.0
2025-03-05 15:18:27,777:INFO:           wurlitzer: 3.1.1
2025-03-05 15:18:27,777:INFO:PyCaret optional dependencies:
2025-03-05 15:18:27,777:INFO:                shap: Not installed
2025-03-05 15:18:27,777:INFO:           interpret: Not installed
2025-03-05 15:18:27,777:INFO:                umap: Not installed
2025-03-05 15:18:27,777:INFO:     ydata_profiling: Not installed
2025-03-05 15:18:27,777:INFO:  explainerdashboard: Not installed
2025-03-05 15:18:27,777:INFO:             autoviz: Not installed
2025-03-05 15:18:27,777:INFO:           fairlearn: Not installed
2025-03-05 15:18:27,777:INFO:          deepchecks: Not installed
2025-03-05 15:18:27,777:INFO:             xgboost: Not installed
2025-03-05 15:18:27,777:INFO:            catboost: Not installed
2025-03-05 15:18:27,777:INFO:              kmodes: Not installed
2025-03-05 15:18:27,777:INFO:             mlxtend: Not installed
2025-03-05 15:18:27,777:INFO:       statsforecast: Not installed
2025-03-05 15:18:27,777:INFO:        tune_sklearn: Not installed
2025-03-05 15:18:27,777:INFO:                 ray: Not installed
2025-03-05 15:18:27,777:INFO:            hyperopt: Not installed
2025-03-05 15:18:27,777:INFO:              optuna: Not installed
2025-03-05 15:18:27,777:INFO:               skopt: Not installed
2025-03-05 15:18:27,777:INFO:              mlflow: Not installed
2025-03-05 15:18:27,777:INFO:              gradio: Not installed
2025-03-05 15:18:27,777:INFO:             fastapi: Not installed
2025-03-05 15:18:27,777:INFO:             uvicorn: Not installed
2025-03-05 15:18:27,777:INFO:              m2cgen: Not installed
2025-03-05 15:18:27,777:INFO:           evidently: Not installed
2025-03-05 15:18:27,777:INFO:               fugue: Not installed
2025-03-05 15:18:27,777:INFO:           streamlit: Not installed
2025-03-05 15:18:27,777:INFO:             prophet: Not installed
2025-03-05 15:18:27,777:INFO:None
2025-03-05 15:18:27,777:INFO:Set up GPU usage.
2025-03-05 15:18:27,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,777:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:18:27,777:INFO:Set up data.
2025-03-05 15:18:27,781:INFO:Set up folding strategy.
2025-03-05 15:18:27,781:INFO:Set up train/test split.
2025-03-05 15:18:27,784:INFO:Set up index.
2025-03-05 15:18:27,784:INFO:Assigning column types.
2025-03-05 15:18:27,787:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:18:27,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,787:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,791:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,795:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:27,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:27,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,891:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:27,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:27,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:27,988:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:18:27,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:27,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,000:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,131:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,245:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:18:28,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,259:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,383:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,475:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:18:28,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,695:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:18:28,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:18:28,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:28,901:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:18:28,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:28,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,119:INFO:Preparing preprocessing pipeline...
2025-03-05 15:18:29,119:INFO:Set up simple imputation.
2025-03-05 15:18:29,119:INFO:Set up polynomial features.
2025-03-05 15:18:29,143:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:18:29,147:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-03-05 15:18:29,147:INFO:Creating final display dataframe.
2025-03-05 15:18:29,212:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              dbfd
2025-03-05 15:18:29,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:18:29,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:18:29,417:INFO:setup() successfully completed in 1.64s...............
2025-03-05 15:18:30,364:INFO:Initializing compare_models()
2025-03-05 15:18:30,364:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:18:30,365:INFO:Checking exceptions
2025-03-05 15:18:30,368:INFO:Preparing display monitor
2025-03-05 15:18:30,388:INFO:Initializing Linear Regression
2025-03-05 15:18:30,388:INFO:Total runtime is 2.157688140869141e-06 minutes
2025-03-05 15:18:30,391:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:30,391:INFO:Initializing create_model()
2025-03-05 15:18:30,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:30,392:INFO:Checking exceptions
2025-03-05 15:18:30,392:INFO:Importing libraries
2025-03-05 15:18:30,392:INFO:Copying training dataset
2025-03-05 15:18:30,396:INFO:Defining folds
2025-03-05 15:18:30,396:INFO:Declaring metric variables
2025-03-05 15:18:30,399:INFO:Importing untrained model
2025-03-05 15:18:30,402:INFO:Linear Regression Imported successfully
2025-03-05 15:18:30,410:INFO:Starting cross validation
2025-03-05 15:18:30,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:30,586:INFO:Calculating mean and std
2025-03-05 15:18:30,586:INFO:Creating metrics dataframe
2025-03-05 15:18:30,588:INFO:Uploading results into container
2025-03-05 15:18:30,588:INFO:Uploading model into container now
2025-03-05 15:18:30,589:INFO:_master_model_container: 1
2025-03-05 15:18:30,589:INFO:_display_container: 2
2025-03-05 15:18:30,589:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:18:30,589:INFO:create_model() successfully completed......................................
2025-03-05 15:18:30,711:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:30,711:INFO:Creating metrics dataframe
2025-03-05 15:18:30,717:INFO:Initializing Lasso Regression
2025-03-05 15:18:30,717:INFO:Total runtime is 0.005496827761332194 minutes
2025-03-05 15:18:30,720:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:30,721:INFO:Initializing create_model()
2025-03-05 15:18:30,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:30,721:INFO:Checking exceptions
2025-03-05 15:18:30,721:INFO:Importing libraries
2025-03-05 15:18:30,721:INFO:Copying training dataset
2025-03-05 15:18:30,724:INFO:Defining folds
2025-03-05 15:18:30,725:INFO:Declaring metric variables
2025-03-05 15:18:30,727:INFO:Importing untrained model
2025-03-05 15:18:30,730:INFO:Lasso Regression Imported successfully
2025-03-05 15:18:30,736:INFO:Starting cross validation
2025-03-05 15:18:30,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:31,012:INFO:Calculating mean and std
2025-03-05 15:18:31,012:INFO:Creating metrics dataframe
2025-03-05 15:18:31,015:INFO:Uploading results into container
2025-03-05 15:18:31,015:INFO:Uploading model into container now
2025-03-05 15:18:31,020:INFO:_master_model_container: 2
2025-03-05 15:18:31,020:INFO:_display_container: 2
2025-03-05 15:18:31,020:INFO:Lasso(random_state=123)
2025-03-05 15:18:31,020:INFO:create_model() successfully completed......................................
2025-03-05 15:18:31,153:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:31,153:INFO:Creating metrics dataframe
2025-03-05 15:18:31,160:INFO:Initializing Ridge Regression
2025-03-05 15:18:31,160:INFO:Total runtime is 0.012869199117024738 minutes
2025-03-05 15:18:31,163:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:31,163:INFO:Initializing create_model()
2025-03-05 15:18:31,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:31,164:INFO:Checking exceptions
2025-03-05 15:18:31,164:INFO:Importing libraries
2025-03-05 15:18:31,164:INFO:Copying training dataset
2025-03-05 15:18:31,167:INFO:Defining folds
2025-03-05 15:18:31,167:INFO:Declaring metric variables
2025-03-05 15:18:31,170:INFO:Importing untrained model
2025-03-05 15:18:31,173:INFO:Ridge Regression Imported successfully
2025-03-05 15:18:31,179:INFO:Starting cross validation
2025-03-05 15:18:31,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:31,350:INFO:Calculating mean and std
2025-03-05 15:18:31,350:INFO:Creating metrics dataframe
2025-03-05 15:18:31,351:INFO:Uploading results into container
2025-03-05 15:18:31,352:INFO:Uploading model into container now
2025-03-05 15:18:31,352:INFO:_master_model_container: 3
2025-03-05 15:18:31,352:INFO:_display_container: 2
2025-03-05 15:18:31,353:INFO:Ridge(random_state=123)
2025-03-05 15:18:31,353:INFO:create_model() successfully completed......................................
2025-03-05 15:18:31,469:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:31,469:INFO:Creating metrics dataframe
2025-03-05 15:18:31,476:INFO:Initializing Elastic Net
2025-03-05 15:18:31,476:INFO:Total runtime is 0.018147647380828857 minutes
2025-03-05 15:18:31,480:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:31,480:INFO:Initializing create_model()
2025-03-05 15:18:31,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:31,480:INFO:Checking exceptions
2025-03-05 15:18:31,480:INFO:Importing libraries
2025-03-05 15:18:31,480:INFO:Copying training dataset
2025-03-05 15:18:31,484:INFO:Defining folds
2025-03-05 15:18:31,485:INFO:Declaring metric variables
2025-03-05 15:18:31,488:INFO:Importing untrained model
2025-03-05 15:18:31,491:INFO:Elastic Net Imported successfully
2025-03-05 15:18:31,497:INFO:Starting cross validation
2025-03-05 15:18:31,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:31,849:INFO:Calculating mean and std
2025-03-05 15:18:31,851:INFO:Creating metrics dataframe
2025-03-05 15:18:31,854:INFO:Uploading results into container
2025-03-05 15:18:31,854:INFO:Uploading model into container now
2025-03-05 15:18:31,855:INFO:_master_model_container: 4
2025-03-05 15:18:31,855:INFO:_display_container: 2
2025-03-05 15:18:31,855:INFO:ElasticNet(random_state=123)
2025-03-05 15:18:31,855:INFO:create_model() successfully completed......................................
2025-03-05 15:18:32,008:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:32,008:INFO:Creating metrics dataframe
2025-03-05 15:18:32,015:INFO:Initializing Least Angle Regression
2025-03-05 15:18:32,015:INFO:Total runtime is 0.027121150493621828 minutes
2025-03-05 15:18:32,018:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:32,019:INFO:Initializing create_model()
2025-03-05 15:18:32,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:32,019:INFO:Checking exceptions
2025-03-05 15:18:32,019:INFO:Importing libraries
2025-03-05 15:18:32,019:INFO:Copying training dataset
2025-03-05 15:18:32,023:INFO:Defining folds
2025-03-05 15:18:32,023:INFO:Declaring metric variables
2025-03-05 15:18:32,026:INFO:Importing untrained model
2025-03-05 15:18:32,029:INFO:Least Angle Regression Imported successfully
2025-03-05 15:18:32,035:INFO:Starting cross validation
2025-03-05 15:18:32,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:32,212:INFO:Calculating mean and std
2025-03-05 15:18:32,213:INFO:Creating metrics dataframe
2025-03-05 15:18:32,215:INFO:Uploading results into container
2025-03-05 15:18:32,215:INFO:Uploading model into container now
2025-03-05 15:18:32,216:INFO:_master_model_container: 5
2025-03-05 15:18:32,216:INFO:_display_container: 2
2025-03-05 15:18:32,216:INFO:Lars(random_state=123)
2025-03-05 15:18:32,216:INFO:create_model() successfully completed......................................
2025-03-05 15:18:32,334:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:32,334:INFO:Creating metrics dataframe
2025-03-05 15:18:32,341:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:18:32,342:INFO:Total runtime is 0.03256791432698568 minutes
2025-03-05 15:18:32,345:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:32,345:INFO:Initializing create_model()
2025-03-05 15:18:32,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:32,345:INFO:Checking exceptions
2025-03-05 15:18:32,345:INFO:Importing libraries
2025-03-05 15:18:32,345:INFO:Copying training dataset
2025-03-05 15:18:32,350:INFO:Defining folds
2025-03-05 15:18:32,350:INFO:Declaring metric variables
2025-03-05 15:18:32,354:INFO:Importing untrained model
2025-03-05 15:18:32,357:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:18:32,364:INFO:Starting cross validation
2025-03-05 15:18:32,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:32,537:INFO:Calculating mean and std
2025-03-05 15:18:32,539:INFO:Creating metrics dataframe
2025-03-05 15:18:32,540:INFO:Uploading results into container
2025-03-05 15:18:32,541:INFO:Uploading model into container now
2025-03-05 15:18:32,541:INFO:_master_model_container: 6
2025-03-05 15:18:32,541:INFO:_display_container: 2
2025-03-05 15:18:32,541:INFO:LassoLars(random_state=123)
2025-03-05 15:18:32,542:INFO:create_model() successfully completed......................................
2025-03-05 15:18:32,656:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:32,656:INFO:Creating metrics dataframe
2025-03-05 15:18:32,663:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:18:32,664:INFO:Total runtime is 0.03793503840764364 minutes
2025-03-05 15:18:32,667:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:32,667:INFO:Initializing create_model()
2025-03-05 15:18:32,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:32,667:INFO:Checking exceptions
2025-03-05 15:18:32,667:INFO:Importing libraries
2025-03-05 15:18:32,667:INFO:Copying training dataset
2025-03-05 15:18:32,671:INFO:Defining folds
2025-03-05 15:18:32,671:INFO:Declaring metric variables
2025-03-05 15:18:32,674:INFO:Importing untrained model
2025-03-05 15:18:32,677:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:18:32,684:INFO:Starting cross validation
2025-03-05 15:18:32,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:32,853:INFO:Calculating mean and std
2025-03-05 15:18:32,854:INFO:Creating metrics dataframe
2025-03-05 15:18:32,855:INFO:Uploading results into container
2025-03-05 15:18:32,856:INFO:Uploading model into container now
2025-03-05 15:18:32,856:INFO:_master_model_container: 7
2025-03-05 15:18:32,856:INFO:_display_container: 2
2025-03-05 15:18:32,856:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:18:32,856:INFO:create_model() successfully completed......................................
2025-03-05 15:18:32,975:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:32,975:INFO:Creating metrics dataframe
2025-03-05 15:18:32,983:INFO:Initializing Bayesian Ridge
2025-03-05 15:18:32,983:INFO:Total runtime is 0.04325660467147827 minutes
2025-03-05 15:18:32,986:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:32,987:INFO:Initializing create_model()
2025-03-05 15:18:32,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:32,987:INFO:Checking exceptions
2025-03-05 15:18:32,987:INFO:Importing libraries
2025-03-05 15:18:32,987:INFO:Copying training dataset
2025-03-05 15:18:32,991:INFO:Defining folds
2025-03-05 15:18:32,991:INFO:Declaring metric variables
2025-03-05 15:18:32,994:INFO:Importing untrained model
2025-03-05 15:18:32,998:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:18:33,003:INFO:Starting cross validation
2025-03-05 15:18:33,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:33,257:INFO:Calculating mean and std
2025-03-05 15:18:33,258:INFO:Creating metrics dataframe
2025-03-05 15:18:33,263:INFO:Uploading results into container
2025-03-05 15:18:33,264:INFO:Uploading model into container now
2025-03-05 15:18:33,264:INFO:_master_model_container: 8
2025-03-05 15:18:33,264:INFO:_display_container: 2
2025-03-05 15:18:33,270:INFO:BayesianRidge()
2025-03-05 15:18:33,270:INFO:create_model() successfully completed......................................
2025-03-05 15:18:33,401:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:33,402:INFO:Creating metrics dataframe
2025-03-05 15:18:33,410:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:18:33,410:INFO:Total runtime is 0.05037295420964559 minutes
2025-03-05 15:18:33,413:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:33,414:INFO:Initializing create_model()
2025-03-05 15:18:33,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:33,414:INFO:Checking exceptions
2025-03-05 15:18:33,414:INFO:Importing libraries
2025-03-05 15:18:33,414:INFO:Copying training dataset
2025-03-05 15:18:33,418:INFO:Defining folds
2025-03-05 15:18:33,418:INFO:Declaring metric variables
2025-03-05 15:18:33,422:INFO:Importing untrained model
2025-03-05 15:18:33,425:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:18:33,431:INFO:Starting cross validation
2025-03-05 15:18:33,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:33,703:INFO:Calculating mean and std
2025-03-05 15:18:33,704:INFO:Creating metrics dataframe
2025-03-05 15:18:33,706:INFO:Uploading results into container
2025-03-05 15:18:33,706:INFO:Uploading model into container now
2025-03-05 15:18:33,707:INFO:_master_model_container: 9
2025-03-05 15:18:33,707:INFO:_display_container: 2
2025-03-05 15:18:33,707:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:18:33,707:INFO:create_model() successfully completed......................................
2025-03-05 15:18:33,823:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:33,823:INFO:Creating metrics dataframe
2025-03-05 15:18:33,831:INFO:Initializing Huber Regressor
2025-03-05 15:18:33,831:INFO:Total runtime is 0.057396745681762694 minutes
2025-03-05 15:18:33,834:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:33,835:INFO:Initializing create_model()
2025-03-05 15:18:33,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:33,835:INFO:Checking exceptions
2025-03-05 15:18:33,835:INFO:Importing libraries
2025-03-05 15:18:33,835:INFO:Copying training dataset
2025-03-05 15:18:33,839:INFO:Defining folds
2025-03-05 15:18:33,839:INFO:Declaring metric variables
2025-03-05 15:18:33,842:INFO:Importing untrained model
2025-03-05 15:18:33,845:INFO:Huber Regressor Imported successfully
2025-03-05 15:18:33,851:INFO:Starting cross validation
2025-03-05 15:18:33,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:34,931:INFO:Calculating mean and std
2025-03-05 15:18:34,932:INFO:Creating metrics dataframe
2025-03-05 15:18:34,935:INFO:Uploading results into container
2025-03-05 15:18:34,935:INFO:Uploading model into container now
2025-03-05 15:18:34,936:INFO:_master_model_container: 10
2025-03-05 15:18:34,936:INFO:_display_container: 2
2025-03-05 15:18:34,936:INFO:HuberRegressor()
2025-03-05 15:18:34,936:INFO:create_model() successfully completed......................................
2025-03-05 15:18:35,074:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:35,074:INFO:Creating metrics dataframe
2025-03-05 15:18:35,084:INFO:Initializing K Neighbors Regressor
2025-03-05 15:18:35,084:INFO:Total runtime is 0.07826879421869913 minutes
2025-03-05 15:18:35,087:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:35,087:INFO:Initializing create_model()
2025-03-05 15:18:35,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:35,087:INFO:Checking exceptions
2025-03-05 15:18:35,087:INFO:Importing libraries
2025-03-05 15:18:35,087:INFO:Copying training dataset
2025-03-05 15:18:35,092:INFO:Defining folds
2025-03-05 15:18:35,092:INFO:Declaring metric variables
2025-03-05 15:18:35,095:INFO:Importing untrained model
2025-03-05 15:18:35,098:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:18:35,104:INFO:Starting cross validation
2025-03-05 15:18:35,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:35,598:INFO:Calculating mean and std
2025-03-05 15:18:35,599:INFO:Creating metrics dataframe
2025-03-05 15:18:35,601:INFO:Uploading results into container
2025-03-05 15:18:35,602:INFO:Uploading model into container now
2025-03-05 15:18:35,602:INFO:_master_model_container: 11
2025-03-05 15:18:35,602:INFO:_display_container: 2
2025-03-05 15:18:35,603:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:18:35,603:INFO:create_model() successfully completed......................................
2025-03-05 15:18:35,722:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:35,722:INFO:Creating metrics dataframe
2025-03-05 15:18:35,731:INFO:Initializing Decision Tree Regressor
2025-03-05 15:18:35,731:INFO:Total runtime is 0.08905285596847534 minutes
2025-03-05 15:18:35,734:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:35,734:INFO:Initializing create_model()
2025-03-05 15:18:35,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:35,734:INFO:Checking exceptions
2025-03-05 15:18:35,734:INFO:Importing libraries
2025-03-05 15:18:35,734:INFO:Copying training dataset
2025-03-05 15:18:35,739:INFO:Defining folds
2025-03-05 15:18:35,740:INFO:Declaring metric variables
2025-03-05 15:18:35,743:INFO:Importing untrained model
2025-03-05 15:18:35,747:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:18:35,755:INFO:Starting cross validation
2025-03-05 15:18:35,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:36,007:INFO:Calculating mean and std
2025-03-05 15:18:36,008:INFO:Creating metrics dataframe
2025-03-05 15:18:36,010:INFO:Uploading results into container
2025-03-05 15:18:36,010:INFO:Uploading model into container now
2025-03-05 15:18:36,011:INFO:_master_model_container: 12
2025-03-05 15:18:36,011:INFO:_display_container: 2
2025-03-05 15:18:36,011:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:18:36,011:INFO:create_model() successfully completed......................................
2025-03-05 15:18:36,125:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:36,125:INFO:Creating metrics dataframe
2025-03-05 15:18:36,134:INFO:Initializing Random Forest Regressor
2025-03-05 15:18:36,134:INFO:Total runtime is 0.09578025341033936 minutes
2025-03-05 15:18:36,138:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:36,138:INFO:Initializing create_model()
2025-03-05 15:18:36,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:36,138:INFO:Checking exceptions
2025-03-05 15:18:36,138:INFO:Importing libraries
2025-03-05 15:18:36,138:INFO:Copying training dataset
2025-03-05 15:18:36,142:INFO:Defining folds
2025-03-05 15:18:36,143:INFO:Declaring metric variables
2025-03-05 15:18:36,146:INFO:Importing untrained model
2025-03-05 15:18:36,149:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:18:36,156:INFO:Starting cross validation
2025-03-05 15:18:36,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:38,741:INFO:Calculating mean and std
2025-03-05 15:18:38,742:INFO:Creating metrics dataframe
2025-03-05 15:18:38,744:INFO:Uploading results into container
2025-03-05 15:18:38,745:INFO:Uploading model into container now
2025-03-05 15:18:38,745:INFO:_master_model_container: 13
2025-03-05 15:18:38,745:INFO:_display_container: 2
2025-03-05 15:18:38,746:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:18:38,746:INFO:create_model() successfully completed......................................
2025-03-05 15:18:38,870:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:38,870:INFO:Creating metrics dataframe
2025-03-05 15:18:38,880:INFO:Initializing Extra Trees Regressor
2025-03-05 15:18:38,880:INFO:Total runtime is 0.14153807163238524 minutes
2025-03-05 15:18:38,883:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:38,884:INFO:Initializing create_model()
2025-03-05 15:18:38,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:38,884:INFO:Checking exceptions
2025-03-05 15:18:38,884:INFO:Importing libraries
2025-03-05 15:18:38,884:INFO:Copying training dataset
2025-03-05 15:18:38,888:INFO:Defining folds
2025-03-05 15:18:38,888:INFO:Declaring metric variables
2025-03-05 15:18:38,891:INFO:Importing untrained model
2025-03-05 15:18:38,895:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:18:38,900:INFO:Starting cross validation
2025-03-05 15:18:38,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:40,619:INFO:Calculating mean and std
2025-03-05 15:18:40,621:INFO:Creating metrics dataframe
2025-03-05 15:18:40,622:INFO:Uploading results into container
2025-03-05 15:18:40,623:INFO:Uploading model into container now
2025-03-05 15:18:40,623:INFO:_master_model_container: 14
2025-03-05 15:18:40,624:INFO:_display_container: 2
2025-03-05 15:18:40,624:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:18:40,624:INFO:create_model() successfully completed......................................
2025-03-05 15:18:40,744:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:40,744:INFO:Creating metrics dataframe
2025-03-05 15:18:40,754:INFO:Initializing AdaBoost Regressor
2025-03-05 15:18:40,754:INFO:Total runtime is 0.17277993361155192 minutes
2025-03-05 15:18:40,758:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:40,758:INFO:Initializing create_model()
2025-03-05 15:18:40,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:40,758:INFO:Checking exceptions
2025-03-05 15:18:40,758:INFO:Importing libraries
2025-03-05 15:18:40,758:INFO:Copying training dataset
2025-03-05 15:18:40,763:INFO:Defining folds
2025-03-05 15:18:40,763:INFO:Declaring metric variables
2025-03-05 15:18:40,766:INFO:Importing untrained model
2025-03-05 15:18:40,769:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:18:40,776:INFO:Starting cross validation
2025-03-05 15:18:40,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:42,132:INFO:Calculating mean and std
2025-03-05 15:18:42,133:INFO:Creating metrics dataframe
2025-03-05 15:18:42,135:INFO:Uploading results into container
2025-03-05 15:18:42,136:INFO:Uploading model into container now
2025-03-05 15:18:42,136:INFO:_master_model_container: 15
2025-03-05 15:18:42,136:INFO:_display_container: 2
2025-03-05 15:18:42,136:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:18:42,136:INFO:create_model() successfully completed......................................
2025-03-05 15:18:42,252:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:42,252:INFO:Creating metrics dataframe
2025-03-05 15:18:42,261:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:18:42,261:INFO:Total runtime is 0.19789745807647705 minutes
2025-03-05 15:18:42,264:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:42,265:INFO:Initializing create_model()
2025-03-05 15:18:42,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:42,265:INFO:Checking exceptions
2025-03-05 15:18:42,265:INFO:Importing libraries
2025-03-05 15:18:42,265:INFO:Copying training dataset
2025-03-05 15:18:42,269:INFO:Defining folds
2025-03-05 15:18:42,269:INFO:Declaring metric variables
2025-03-05 15:18:42,273:INFO:Importing untrained model
2025-03-05 15:18:42,276:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:18:42,282:INFO:Starting cross validation
2025-03-05 15:18:42,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:49,073:INFO:Calculating mean and std
2025-03-05 15:18:49,074:INFO:Creating metrics dataframe
2025-03-05 15:18:49,076:INFO:Uploading results into container
2025-03-05 15:18:49,077:INFO:Uploading model into container now
2025-03-05 15:18:49,077:INFO:_master_model_container: 16
2025-03-05 15:18:49,077:INFO:_display_container: 2
2025-03-05 15:18:49,077:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:18:49,078:INFO:create_model() successfully completed......................................
2025-03-05 15:18:49,197:INFO:SubProcess create_model() end ==================================
2025-03-05 15:18:49,197:INFO:Creating metrics dataframe
2025-03-05 15:18:49,206:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:18:49,206:INFO:Total runtime is 0.3136459946632385 minutes
2025-03-05 15:18:49,209:INFO:SubProcess create_model() called ==================================
2025-03-05 15:18:49,210:INFO:Initializing create_model()
2025-03-05 15:18:49,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:18:49,210:INFO:Checking exceptions
2025-03-05 15:18:49,210:INFO:Importing libraries
2025-03-05 15:18:49,210:INFO:Copying training dataset
2025-03-05 15:18:49,214:INFO:Defining folds
2025-03-05 15:18:49,214:INFO:Declaring metric variables
2025-03-05 15:18:49,217:INFO:Importing untrained model
2025-03-05 15:18:49,221:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:18:49,227:INFO:Starting cross validation
2025-03-05 15:18:49,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:18:49,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031598 seconds.
2025-03-05 15:18:49,293:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:49,293:INFO:[LightGBM] [Info] Total Bins 438
2025-03-05 15:18:49,299:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 2
2025-03-05 15:18:49,317:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:18:49,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027624 seconds.
2025-03-05 15:18:49,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:49,942:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:18:49,949:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:49,963:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:18:50,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042640 seconds.
2025-03-05 15:18:50,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:50,779:INFO:[LightGBM] [Info] Total Bins 432
2025-03-05 15:18:50,786:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:50,803:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:18:52,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034628 seconds.
2025-03-05 15:18:52,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:52,163:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:18:52,169:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:52,184:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:18:56,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032631 seconds.
2025-03-05 15:18:56,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:56,942:INFO:[LightGBM] [Info] Total Bins 432
2025-03-05 15:18:56,952:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:56,966:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:18:58,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2025-03-05 15:18:58,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:58,786:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:18:58,786:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:58,787:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:18:59,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-03-05 15:18:59,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:59,071:INFO:[LightGBM] [Info] Total Bins 430
2025-03-05 15:18:59,071:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:59,072:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:18:59,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032631 seconds.
2025-03-05 15:18:59,530:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:18:59,530:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:18:59,536:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:18:59,551:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:19:02,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032686 seconds.
2025-03-05 15:19:02,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:19:02,079:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:19:02,084:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:19:02,101:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:19:03,889:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033678 seconds.
2025-03-05 15:19:03,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:19:03,890:INFO:[LightGBM] [Info] Total Bins 434
2025-03-05 15:19:03,899:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:19:03,912:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:19:04,962:INFO:Calculating mean and std
2025-03-05 15:19:04,964:INFO:Creating metrics dataframe
2025-03-05 15:19:04,966:INFO:Uploading results into container
2025-03-05 15:19:04,967:INFO:Uploading model into container now
2025-03-05 15:19:04,967:INFO:_master_model_container: 17
2025-03-05 15:19:04,967:INFO:_display_container: 2
2025-03-05 15:19:04,968:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:19:04,968:INFO:create_model() successfully completed......................................
2025-03-05 15:19:05,094:INFO:SubProcess create_model() end ==================================
2025-03-05 15:19:05,094:INFO:Creating metrics dataframe
2025-03-05 15:19:05,105:INFO:Initializing Dummy Regressor
2025-03-05 15:19:05,106:INFO:Total runtime is 0.5786338726679483 minutes
2025-03-05 15:19:05,108:INFO:SubProcess create_model() called ==================================
2025-03-05 15:19:05,109:INFO:Initializing create_model()
2025-03-05 15:19:05,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445dfad3d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:19:05,109:INFO:Checking exceptions
2025-03-05 15:19:05,109:INFO:Importing libraries
2025-03-05 15:19:05,109:INFO:Copying training dataset
2025-03-05 15:19:05,113:INFO:Defining folds
2025-03-05 15:19:05,113:INFO:Declaring metric variables
2025-03-05 15:19:05,117:INFO:Importing untrained model
2025-03-05 15:19:05,120:INFO:Dummy Regressor Imported successfully
2025-03-05 15:19:05,125:INFO:Starting cross validation
2025-03-05 15:19:05,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:19:05,279:INFO:Calculating mean and std
2025-03-05 15:19:05,280:INFO:Creating metrics dataframe
2025-03-05 15:19:05,282:INFO:Uploading results into container
2025-03-05 15:19:05,283:INFO:Uploading model into container now
2025-03-05 15:19:05,283:INFO:_master_model_container: 18
2025-03-05 15:19:05,283:INFO:_display_container: 2
2025-03-05 15:19:05,283:INFO:DummyRegressor()
2025-03-05 15:19:05,284:INFO:create_model() successfully completed......................................
2025-03-05 15:19:05,403:INFO:SubProcess create_model() end ==================================
2025-03-05 15:19:05,403:INFO:Creating metrics dataframe
2025-03-05 15:19:05,414:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:19:05,422:INFO:Initializing create_model()
2025-03-05 15:19:05,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d1176430>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:19:05,422:INFO:Checking exceptions
2025-03-05 15:19:05,423:INFO:Importing libraries
2025-03-05 15:19:05,424:INFO:Copying training dataset
2025-03-05 15:19:05,427:INFO:Defining folds
2025-03-05 15:19:05,428:INFO:Declaring metric variables
2025-03-05 15:19:05,428:INFO:Importing untrained model
2025-03-05 15:19:05,428:INFO:Declaring custom model
2025-03-05 15:19:05,428:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:19:05,429:INFO:Cross validation set to False
2025-03-05 15:19:05,429:INFO:Fitting Model
2025-03-05 15:19:06,168:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:19:06,168:INFO:create_model() successfully completed......................................
2025-03-05 15:19:06,312:INFO:_master_model_container: 18
2025-03-05 15:19:06,312:INFO:_display_container: 2
2025-03-05 15:19:06,312:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:19:06,312:INFO:compare_models() successfully completed......................................
2025-03-05 15:33:07,969:INFO:PyCaret RegressionExperiment
2025-03-05 15:33:07,969:INFO:Logging name: reg-default-name
2025-03-05 15:33:07,970:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:33:07,970:INFO:version 3.3.1
2025-03-05 15:33:07,970:INFO:Initializing setup()
2025-03-05 15:33:07,970:INFO:self.USI: 5828
2025-03-05 15:33:07,970:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:33:07,970:INFO:Checking environment
2025-03-05 15:33:07,970:INFO:python_version: 3.9.21
2025-03-05 15:33:07,970:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:33:07,970:INFO:machine: x86_64
2025-03-05 15:33:07,970:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:33:07,970:INFO:Memory: svmem(total=33374507008, available=21300514816, percent=36.2, used=9507028992, free=3759525888, active=13566885888, inactive=11842379776, buffers=678891520, cached=19429060608, shared=2037866496, slab=1828761600)
2025-03-05 15:33:07,972:INFO:Physical Core: 24
2025-03-05 15:33:07,972:INFO:Logical Core: 32
2025-03-05 15:33:07,972:INFO:Checking libraries
2025-03-05 15:33:07,972:INFO:System:
2025-03-05 15:33:07,972:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:33:07,972:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:33:07,972:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:33:07,972:INFO:PyCaret required dependencies:
2025-03-05 15:33:07,972:INFO:                 pip: 25.0
2025-03-05 15:33:07,972:INFO:          setuptools: 75.8.0
2025-03-05 15:33:07,972:INFO:             pycaret: 3.3.1
2025-03-05 15:33:07,972:INFO:             IPython: 8.18.1
2025-03-05 15:33:07,972:INFO:          ipywidgets: 8.1.5
2025-03-05 15:33:07,972:INFO:                tqdm: 4.67.1
2025-03-05 15:33:07,972:INFO:               numpy: 1.26.4
2025-03-05 15:33:07,972:INFO:              pandas: 2.1.4
2025-03-05 15:33:07,972:INFO:              jinja2: 3.1.5
2025-03-05 15:33:07,972:INFO:               scipy: 1.11.4
2025-03-05 15:33:07,972:INFO:              joblib: 1.3.2
2025-03-05 15:33:07,972:INFO:             sklearn: 1.4.2
2025-03-05 15:33:07,972:INFO:                pyod: 2.0.3
2025-03-05 15:33:07,972:INFO:            imblearn: 0.12.4
2025-03-05 15:33:07,972:INFO:   category_encoders: 2.6.4
2025-03-05 15:33:07,972:INFO:            lightgbm: 4.6.0
2025-03-05 15:33:07,972:INFO:               numba: 0.60.0
2025-03-05 15:33:07,972:INFO:            requests: 2.32.3
2025-03-05 15:33:07,972:INFO:          matplotlib: 3.7.5
2025-03-05 15:33:07,972:INFO:          scikitplot: 0.3.7
2025-03-05 15:33:07,972:INFO:         yellowbrick: 1.5
2025-03-05 15:33:07,972:INFO:              plotly: 5.24.1
2025-03-05 15:33:07,972:INFO:    plotly-resampler: Not installed
2025-03-05 15:33:07,972:INFO:             kaleido: 0.2.1
2025-03-05 15:33:07,972:INFO:           schemdraw: 0.15
2025-03-05 15:33:07,972:INFO:         statsmodels: 0.14.4
2025-03-05 15:33:07,973:INFO:              sktime: 0.26.0
2025-03-05 15:33:07,973:INFO:               tbats: 1.1.3
2025-03-05 15:33:07,973:INFO:            pmdarima: 2.0.4
2025-03-05 15:33:07,973:INFO:              psutil: 7.0.0
2025-03-05 15:33:07,973:INFO:          markupsafe: 3.0.2
2025-03-05 15:33:07,973:INFO:             pickle5: Not installed
2025-03-05 15:33:07,973:INFO:         cloudpickle: 3.1.1
2025-03-05 15:33:07,973:INFO:         deprecation: 2.1.0
2025-03-05 15:33:07,973:INFO:              xxhash: 3.5.0
2025-03-05 15:33:07,973:INFO:           wurlitzer: 3.1.1
2025-03-05 15:33:07,973:INFO:PyCaret optional dependencies:
2025-03-05 15:33:07,973:INFO:                shap: Not installed
2025-03-05 15:33:07,973:INFO:           interpret: Not installed
2025-03-05 15:33:07,973:INFO:                umap: Not installed
2025-03-05 15:33:07,973:INFO:     ydata_profiling: Not installed
2025-03-05 15:33:07,973:INFO:  explainerdashboard: Not installed
2025-03-05 15:33:07,973:INFO:             autoviz: Not installed
2025-03-05 15:33:07,973:INFO:           fairlearn: Not installed
2025-03-05 15:33:07,973:INFO:          deepchecks: Not installed
2025-03-05 15:33:07,973:INFO:             xgboost: Not installed
2025-03-05 15:33:07,973:INFO:            catboost: Not installed
2025-03-05 15:33:07,973:INFO:              kmodes: Not installed
2025-03-05 15:33:07,973:INFO:             mlxtend: Not installed
2025-03-05 15:33:07,973:INFO:       statsforecast: Not installed
2025-03-05 15:33:07,973:INFO:        tune_sklearn: Not installed
2025-03-05 15:33:07,973:INFO:                 ray: Not installed
2025-03-05 15:33:07,973:INFO:            hyperopt: Not installed
2025-03-05 15:33:07,973:INFO:              optuna: Not installed
2025-03-05 15:33:07,973:INFO:               skopt: Not installed
2025-03-05 15:33:07,973:INFO:              mlflow: Not installed
2025-03-05 15:33:07,973:INFO:              gradio: Not installed
2025-03-05 15:33:07,973:INFO:             fastapi: Not installed
2025-03-05 15:33:07,973:INFO:             uvicorn: Not installed
2025-03-05 15:33:07,973:INFO:              m2cgen: Not installed
2025-03-05 15:33:07,973:INFO:           evidently: Not installed
2025-03-05 15:33:07,973:INFO:               fugue: Not installed
2025-03-05 15:33:07,973:INFO:           streamlit: Not installed
2025-03-05 15:33:07,973:INFO:             prophet: Not installed
2025-03-05 15:33:07,973:INFO:None
2025-03-05 15:33:07,973:INFO:Set up GPU usage.
2025-03-05 15:33:07,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:07,973:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:33:07,973:INFO:Set up data.
2025-03-05 15:33:07,977:INFO:Set up folding strategy.
2025-03-05 15:33:07,977:INFO:Set up train/test split.
2025-03-05 15:33:07,981:INFO:Set up index.
2025-03-05 15:33:07,981:INFO:Assigning column types.
2025-03-05 15:33:07,984:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:33:07,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:07,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:33:07,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:07,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:33:07,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:07,993:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:07,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,086:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,186:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:33:08,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,190:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,293:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,385:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:33:08,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,582:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,620:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,625:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:33:08,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,862:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:33:08,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:08,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:08,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:08,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:33:09,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,089:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:33:09,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,341:INFO:Preparing preprocessing pipeline...
2025-03-05 15:33:09,342:INFO:Set up simple imputation.
2025-03-05 15:33:09,342:INFO:Set up polynomial features.
2025-03-05 15:33:09,342:INFO:Set up feature normalization.
2025-03-05 15:33:09,374:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:33:09,379:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-03-05 15:33:09,379:INFO:Creating final display dataframe.
2025-03-05 15:33:09,456:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU              True
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              5828
2025-03-05 15:33:09,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:33:09,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:33:09,676:INFO:setup() successfully completed in 1.71s...............
2025-03-05 15:33:09,700:INFO:Initializing compare_models()
2025-03-05 15:33:09,700:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:33:09,700:INFO:Checking exceptions
2025-03-05 15:33:09,703:INFO:Preparing display monitor
2025-03-05 15:33:09,729:INFO:Initializing Linear Regression
2025-03-05 15:33:09,729:INFO:Total runtime is 3.973642985026042e-06 minutes
2025-03-05 15:33:09,734:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:09,734:INFO:Initializing create_model()
2025-03-05 15:33:09,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:09,734:INFO:Checking exceptions
2025-03-05 15:33:09,735:INFO:Importing libraries
2025-03-05 15:33:09,735:INFO:Copying training dataset
2025-03-05 15:33:09,740:INFO:Defining folds
2025-03-05 15:33:09,741:INFO:Declaring metric variables
2025-03-05 15:33:09,746:INFO:Importing untrained model
2025-03-05 15:33:09,749:INFO:Linear Regression Imported successfully
2025-03-05 15:33:09,756:INFO:Starting cross validation
2025-03-05 15:33:09,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:09,992:INFO:Calculating mean and std
2025-03-05 15:33:09,993:INFO:Creating metrics dataframe
2025-03-05 15:33:09,997:INFO:Uploading results into container
2025-03-05 15:33:09,998:INFO:Uploading model into container now
2025-03-05 15:33:09,998:INFO:_master_model_container: 1
2025-03-05 15:33:09,998:INFO:_display_container: 2
2025-03-05 15:33:09,999:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:33:09,999:INFO:create_model() successfully completed......................................
2025-03-05 15:33:10,135:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:10,135:INFO:Creating metrics dataframe
2025-03-05 15:33:10,141:INFO:Initializing Lasso Regression
2025-03-05 15:33:10,142:INFO:Total runtime is 0.006882969538370768 minutes
2025-03-05 15:33:10,145:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:10,145:INFO:Initializing create_model()
2025-03-05 15:33:10,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:10,145:INFO:Checking exceptions
2025-03-05 15:33:10,145:INFO:Importing libraries
2025-03-05 15:33:10,146:INFO:Copying training dataset
2025-03-05 15:33:10,149:INFO:Defining folds
2025-03-05 15:33:10,149:INFO:Declaring metric variables
2025-03-05 15:33:10,152:INFO:Importing untrained model
2025-03-05 15:33:10,155:INFO:Lasso Regression Imported successfully
2025-03-05 15:33:10,161:INFO:Starting cross validation
2025-03-05 15:33:10,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:10,541:INFO:Calculating mean and std
2025-03-05 15:33:10,541:INFO:Creating metrics dataframe
2025-03-05 15:33:10,543:INFO:Uploading results into container
2025-03-05 15:33:10,544:INFO:Uploading model into container now
2025-03-05 15:33:10,544:INFO:_master_model_container: 2
2025-03-05 15:33:10,545:INFO:_display_container: 2
2025-03-05 15:33:10,546:INFO:Lasso(random_state=123)
2025-03-05 15:33:10,546:INFO:create_model() successfully completed......................................
2025-03-05 15:33:10,696:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:10,697:INFO:Creating metrics dataframe
2025-03-05 15:33:10,703:INFO:Initializing Ridge Regression
2025-03-05 15:33:10,703:INFO:Total runtime is 0.0162459135055542 minutes
2025-03-05 15:33:10,707:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:10,707:INFO:Initializing create_model()
2025-03-05 15:33:10,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:10,707:INFO:Checking exceptions
2025-03-05 15:33:10,707:INFO:Importing libraries
2025-03-05 15:33:10,707:INFO:Copying training dataset
2025-03-05 15:33:10,711:INFO:Defining folds
2025-03-05 15:33:10,711:INFO:Declaring metric variables
2025-03-05 15:33:10,714:INFO:Importing untrained model
2025-03-05 15:33:10,717:INFO:Ridge Regression Imported successfully
2025-03-05 15:33:10,723:INFO:Starting cross validation
2025-03-05 15:33:10,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:10,941:INFO:Calculating mean and std
2025-03-05 15:33:10,941:INFO:Creating metrics dataframe
2025-03-05 15:33:10,943:INFO:Uploading results into container
2025-03-05 15:33:10,944:INFO:Uploading model into container now
2025-03-05 15:33:10,944:INFO:_master_model_container: 3
2025-03-05 15:33:10,944:INFO:_display_container: 2
2025-03-05 15:33:10,944:INFO:Ridge(random_state=123)
2025-03-05 15:33:10,944:INFO:create_model() successfully completed......................................
2025-03-05 15:33:11,062:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:11,062:INFO:Creating metrics dataframe
2025-03-05 15:33:11,069:INFO:Initializing Elastic Net
2025-03-05 15:33:11,069:INFO:Total runtime is 0.02234429121017456 minutes
2025-03-05 15:33:11,073:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:11,073:INFO:Initializing create_model()
2025-03-05 15:33:11,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:11,073:INFO:Checking exceptions
2025-03-05 15:33:11,073:INFO:Importing libraries
2025-03-05 15:33:11,073:INFO:Copying training dataset
2025-03-05 15:33:11,077:INFO:Defining folds
2025-03-05 15:33:11,077:INFO:Declaring metric variables
2025-03-05 15:33:11,080:INFO:Importing untrained model
2025-03-05 15:33:11,083:INFO:Elastic Net Imported successfully
2025-03-05 15:33:11,089:INFO:Starting cross validation
2025-03-05 15:33:11,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:11,382:INFO:Calculating mean and std
2025-03-05 15:33:11,382:INFO:Creating metrics dataframe
2025-03-05 15:33:11,387:INFO:Uploading results into container
2025-03-05 15:33:11,389:INFO:Uploading model into container now
2025-03-05 15:33:11,389:INFO:_master_model_container: 4
2025-03-05 15:33:11,390:INFO:_display_container: 2
2025-03-05 15:33:11,390:INFO:ElasticNet(random_state=123)
2025-03-05 15:33:11,390:INFO:create_model() successfully completed......................................
2025-03-05 15:33:11,532:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:11,532:INFO:Creating metrics dataframe
2025-03-05 15:33:11,539:INFO:Initializing Least Angle Regression
2025-03-05 15:33:11,539:INFO:Total runtime is 0.030166908105214437 minutes
2025-03-05 15:33:11,542:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:11,542:INFO:Initializing create_model()
2025-03-05 15:33:11,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:11,542:INFO:Checking exceptions
2025-03-05 15:33:11,542:INFO:Importing libraries
2025-03-05 15:33:11,542:INFO:Copying training dataset
2025-03-05 15:33:11,546:INFO:Defining folds
2025-03-05 15:33:11,547:INFO:Declaring metric variables
2025-03-05 15:33:11,550:INFO:Importing untrained model
2025-03-05 15:33:11,553:INFO:Least Angle Regression Imported successfully
2025-03-05 15:33:11,562:INFO:Starting cross validation
2025-03-05 15:33:11,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:11,783:INFO:Calculating mean and std
2025-03-05 15:33:11,784:INFO:Creating metrics dataframe
2025-03-05 15:33:11,786:INFO:Uploading results into container
2025-03-05 15:33:11,786:INFO:Uploading model into container now
2025-03-05 15:33:11,787:INFO:_master_model_container: 5
2025-03-05 15:33:11,787:INFO:_display_container: 2
2025-03-05 15:33:11,787:INFO:Lars(random_state=123)
2025-03-05 15:33:11,787:INFO:create_model() successfully completed......................................
2025-03-05 15:33:11,900:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:11,901:INFO:Creating metrics dataframe
2025-03-05 15:33:11,908:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:33:11,908:INFO:Total runtime is 0.036321043968200684 minutes
2025-03-05 15:33:11,911:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:11,911:INFO:Initializing create_model()
2025-03-05 15:33:11,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:11,911:INFO:Checking exceptions
2025-03-05 15:33:11,911:INFO:Importing libraries
2025-03-05 15:33:11,911:INFO:Copying training dataset
2025-03-05 15:33:11,915:INFO:Defining folds
2025-03-05 15:33:11,916:INFO:Declaring metric variables
2025-03-05 15:33:11,919:INFO:Importing untrained model
2025-03-05 15:33:11,922:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:33:11,927:INFO:Starting cross validation
2025-03-05 15:33:11,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:12,151:INFO:Calculating mean and std
2025-03-05 15:33:12,152:INFO:Creating metrics dataframe
2025-03-05 15:33:12,153:INFO:Uploading results into container
2025-03-05 15:33:12,154:INFO:Uploading model into container now
2025-03-05 15:33:12,154:INFO:_master_model_container: 6
2025-03-05 15:33:12,154:INFO:_display_container: 2
2025-03-05 15:33:12,154:INFO:LassoLars(random_state=123)
2025-03-05 15:33:12,155:INFO:create_model() successfully completed......................................
2025-03-05 15:33:12,272:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:12,272:INFO:Creating metrics dataframe
2025-03-05 15:33:12,280:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:33:12,280:INFO:Total runtime is 0.042527488867441815 minutes
2025-03-05 15:33:12,284:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:12,284:INFO:Initializing create_model()
2025-03-05 15:33:12,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:12,284:INFO:Checking exceptions
2025-03-05 15:33:12,285:INFO:Importing libraries
2025-03-05 15:33:12,285:INFO:Copying training dataset
2025-03-05 15:33:12,289:INFO:Defining folds
2025-03-05 15:33:12,289:INFO:Declaring metric variables
2025-03-05 15:33:12,292:INFO:Importing untrained model
2025-03-05 15:33:12,295:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:33:12,301:INFO:Starting cross validation
2025-03-05 15:33:12,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:12,518:INFO:Calculating mean and std
2025-03-05 15:33:12,519:INFO:Creating metrics dataframe
2025-03-05 15:33:12,521:INFO:Uploading results into container
2025-03-05 15:33:12,522:INFO:Uploading model into container now
2025-03-05 15:33:12,522:INFO:_master_model_container: 7
2025-03-05 15:33:12,522:INFO:_display_container: 2
2025-03-05 15:33:12,522:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:33:12,522:INFO:create_model() successfully completed......................................
2025-03-05 15:33:12,640:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:12,641:INFO:Creating metrics dataframe
2025-03-05 15:33:12,648:INFO:Initializing Bayesian Ridge
2025-03-05 15:33:12,648:INFO:Total runtime is 0.04866174459457398 minutes
2025-03-05 15:33:12,651:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:12,652:INFO:Initializing create_model()
2025-03-05 15:33:12,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:12,652:INFO:Checking exceptions
2025-03-05 15:33:12,652:INFO:Importing libraries
2025-03-05 15:33:12,652:INFO:Copying training dataset
2025-03-05 15:33:12,656:INFO:Defining folds
2025-03-05 15:33:12,656:INFO:Declaring metric variables
2025-03-05 15:33:12,659:INFO:Importing untrained model
2025-03-05 15:33:12,662:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:33:12,669:INFO:Starting cross validation
2025-03-05 15:33:12,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:12,968:INFO:Calculating mean and std
2025-03-05 15:33:12,969:INFO:Creating metrics dataframe
2025-03-05 15:33:12,972:INFO:Uploading results into container
2025-03-05 15:33:12,974:INFO:Uploading model into container now
2025-03-05 15:33:12,975:INFO:_master_model_container: 8
2025-03-05 15:33:12,976:INFO:_display_container: 2
2025-03-05 15:33:12,976:INFO:BayesianRidge()
2025-03-05 15:33:12,976:INFO:create_model() successfully completed......................................
2025-03-05 15:33:13,125:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:13,125:INFO:Creating metrics dataframe
2025-03-05 15:33:13,133:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:33:13,133:INFO:Total runtime is 0.056737565994262704 minutes
2025-03-05 15:33:13,136:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:13,137:INFO:Initializing create_model()
2025-03-05 15:33:13,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:13,137:INFO:Checking exceptions
2025-03-05 15:33:13,137:INFO:Importing libraries
2025-03-05 15:33:13,137:INFO:Copying training dataset
2025-03-05 15:33:13,141:INFO:Defining folds
2025-03-05 15:33:13,141:INFO:Declaring metric variables
2025-03-05 15:33:13,144:INFO:Importing untrained model
2025-03-05 15:33:13,148:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:33:13,153:INFO:Starting cross validation
2025-03-05 15:33:13,154:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:13,436:INFO:Calculating mean and std
2025-03-05 15:33:13,438:INFO:Creating metrics dataframe
2025-03-05 15:33:13,439:INFO:Uploading results into container
2025-03-05 15:33:13,440:INFO:Uploading model into container now
2025-03-05 15:33:13,440:INFO:_master_model_container: 9
2025-03-05 15:33:13,440:INFO:_display_container: 2
2025-03-05 15:33:13,440:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:33:13,440:INFO:create_model() successfully completed......................................
2025-03-05 15:33:13,559:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:13,559:INFO:Creating metrics dataframe
2025-03-05 15:33:13,567:INFO:Initializing Huber Regressor
2025-03-05 15:33:13,567:INFO:Total runtime is 0.06396789550781251 minutes
2025-03-05 15:33:13,570:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:13,570:INFO:Initializing create_model()
2025-03-05 15:33:13,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:13,570:INFO:Checking exceptions
2025-03-05 15:33:13,570:INFO:Importing libraries
2025-03-05 15:33:13,570:INFO:Copying training dataset
2025-03-05 15:33:13,574:INFO:Defining folds
2025-03-05 15:33:13,575:INFO:Declaring metric variables
2025-03-05 15:33:13,578:INFO:Importing untrained model
2025-03-05 15:33:13,580:INFO:Huber Regressor Imported successfully
2025-03-05 15:33:13,586:INFO:Starting cross validation
2025-03-05 15:33:13,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:14,314:INFO:Calculating mean and std
2025-03-05 15:33:14,316:INFO:Creating metrics dataframe
2025-03-05 15:33:14,319:INFO:Uploading results into container
2025-03-05 15:33:14,319:INFO:Uploading model into container now
2025-03-05 15:33:14,320:INFO:_master_model_container: 10
2025-03-05 15:33:14,320:INFO:_display_container: 2
2025-03-05 15:33:14,320:INFO:HuberRegressor()
2025-03-05 15:33:14,320:INFO:create_model() successfully completed......................................
2025-03-05 15:33:14,459:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:14,459:INFO:Creating metrics dataframe
2025-03-05 15:33:14,467:INFO:Initializing K Neighbors Regressor
2025-03-05 15:33:14,467:INFO:Total runtime is 0.07897661129633587 minutes
2025-03-05 15:33:14,471:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:14,471:INFO:Initializing create_model()
2025-03-05 15:33:14,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:14,471:INFO:Checking exceptions
2025-03-05 15:33:14,471:INFO:Importing libraries
2025-03-05 15:33:14,471:INFO:Copying training dataset
2025-03-05 15:33:14,476:INFO:Defining folds
2025-03-05 15:33:14,476:INFO:Declaring metric variables
2025-03-05 15:33:14,479:INFO:Importing untrained model
2025-03-05 15:33:14,482:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:33:14,489:INFO:Starting cross validation
2025-03-05 15:33:14,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:15,033:INFO:Calculating mean and std
2025-03-05 15:33:15,034:INFO:Creating metrics dataframe
2025-03-05 15:33:15,036:INFO:Uploading results into container
2025-03-05 15:33:15,037:INFO:Uploading model into container now
2025-03-05 15:33:15,038:INFO:_master_model_container: 11
2025-03-05 15:33:15,038:INFO:_display_container: 2
2025-03-05 15:33:15,039:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:33:15,039:INFO:create_model() successfully completed......................................
2025-03-05 15:33:15,164:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:15,164:INFO:Creating metrics dataframe
2025-03-05 15:33:15,173:INFO:Initializing Decision Tree Regressor
2025-03-05 15:33:15,173:INFO:Total runtime is 0.09073597590128582 minutes
2025-03-05 15:33:15,176:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:15,177:INFO:Initializing create_model()
2025-03-05 15:33:15,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:15,177:INFO:Checking exceptions
2025-03-05 15:33:15,177:INFO:Importing libraries
2025-03-05 15:33:15,177:INFO:Copying training dataset
2025-03-05 15:33:15,183:INFO:Defining folds
2025-03-05 15:33:15,184:INFO:Declaring metric variables
2025-03-05 15:33:15,187:INFO:Importing untrained model
2025-03-05 15:33:15,191:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:33:15,197:INFO:Starting cross validation
2025-03-05 15:33:15,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:15,505:INFO:Calculating mean and std
2025-03-05 15:33:15,506:INFO:Creating metrics dataframe
2025-03-05 15:33:15,507:INFO:Uploading results into container
2025-03-05 15:33:15,508:INFO:Uploading model into container now
2025-03-05 15:33:15,508:INFO:_master_model_container: 12
2025-03-05 15:33:15,508:INFO:_display_container: 2
2025-03-05 15:33:15,509:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:33:15,509:INFO:create_model() successfully completed......................................
2025-03-05 15:33:15,628:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:15,628:INFO:Creating metrics dataframe
2025-03-05 15:33:15,638:INFO:Initializing Random Forest Regressor
2025-03-05 15:33:15,638:INFO:Total runtime is 0.09848510424296063 minutes
2025-03-05 15:33:15,641:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:15,641:INFO:Initializing create_model()
2025-03-05 15:33:15,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:15,642:INFO:Checking exceptions
2025-03-05 15:33:15,642:INFO:Importing libraries
2025-03-05 15:33:15,642:INFO:Copying training dataset
2025-03-05 15:33:15,646:INFO:Defining folds
2025-03-05 15:33:15,646:INFO:Declaring metric variables
2025-03-05 15:33:15,649:INFO:Importing untrained model
2025-03-05 15:33:15,652:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:33:15,658:INFO:Starting cross validation
2025-03-05 15:33:15,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:18,286:INFO:Calculating mean and std
2025-03-05 15:33:18,287:INFO:Creating metrics dataframe
2025-03-05 15:33:18,289:INFO:Uploading results into container
2025-03-05 15:33:18,290:INFO:Uploading model into container now
2025-03-05 15:33:18,290:INFO:_master_model_container: 13
2025-03-05 15:33:18,290:INFO:_display_container: 2
2025-03-05 15:33:18,291:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:33:18,291:INFO:create_model() successfully completed......................................
2025-03-05 15:33:18,409:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:18,409:INFO:Creating metrics dataframe
2025-03-05 15:33:18,418:INFO:Initializing Extra Trees Regressor
2025-03-05 15:33:18,418:INFO:Total runtime is 0.1448286294937134 minutes
2025-03-05 15:33:18,422:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:18,422:INFO:Initializing create_model()
2025-03-05 15:33:18,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:18,422:INFO:Checking exceptions
2025-03-05 15:33:18,422:INFO:Importing libraries
2025-03-05 15:33:18,422:INFO:Copying training dataset
2025-03-05 15:33:18,427:INFO:Defining folds
2025-03-05 15:33:18,427:INFO:Declaring metric variables
2025-03-05 15:33:18,430:INFO:Importing untrained model
2025-03-05 15:33:18,433:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:33:18,439:INFO:Starting cross validation
2025-03-05 15:33:18,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:20,198:INFO:Calculating mean and std
2025-03-05 15:33:20,200:INFO:Creating metrics dataframe
2025-03-05 15:33:20,202:INFO:Uploading results into container
2025-03-05 15:33:20,202:INFO:Uploading model into container now
2025-03-05 15:33:20,202:INFO:_master_model_container: 14
2025-03-05 15:33:20,203:INFO:_display_container: 2
2025-03-05 15:33:20,203:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:33:20,203:INFO:create_model() successfully completed......................................
2025-03-05 15:33:20,320:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:20,321:INFO:Creating metrics dataframe
2025-03-05 15:33:20,331:INFO:Initializing AdaBoost Regressor
2025-03-05 15:33:20,331:INFO:Total runtime is 0.1767099698384603 minutes
2025-03-05 15:33:20,335:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:20,335:INFO:Initializing create_model()
2025-03-05 15:33:20,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:20,335:INFO:Checking exceptions
2025-03-05 15:33:20,335:INFO:Importing libraries
2025-03-05 15:33:20,335:INFO:Copying training dataset
2025-03-05 15:33:20,340:INFO:Defining folds
2025-03-05 15:33:20,340:INFO:Declaring metric variables
2025-03-05 15:33:20,343:INFO:Importing untrained model
2025-03-05 15:33:20,347:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:33:20,353:INFO:Starting cross validation
2025-03-05 15:33:20,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:21,779:INFO:Calculating mean and std
2025-03-05 15:33:21,780:INFO:Creating metrics dataframe
2025-03-05 15:33:21,782:INFO:Uploading results into container
2025-03-05 15:33:21,783:INFO:Uploading model into container now
2025-03-05 15:33:21,783:INFO:_master_model_container: 15
2025-03-05 15:33:21,783:INFO:_display_container: 2
2025-03-05 15:33:21,783:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:33:21,783:INFO:create_model() successfully completed......................................
2025-03-05 15:33:21,899:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:21,899:INFO:Creating metrics dataframe
2025-03-05 15:33:21,909:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:33:21,909:INFO:Total runtime is 0.2030020594596863 minutes
2025-03-05 15:33:21,912:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:21,912:INFO:Initializing create_model()
2025-03-05 15:33:21,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:21,912:INFO:Checking exceptions
2025-03-05 15:33:21,912:INFO:Importing libraries
2025-03-05 15:33:21,912:INFO:Copying training dataset
2025-03-05 15:33:21,917:INFO:Defining folds
2025-03-05 15:33:21,917:INFO:Declaring metric variables
2025-03-05 15:33:21,920:INFO:Importing untrained model
2025-03-05 15:33:21,923:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:33:21,929:INFO:Starting cross validation
2025-03-05 15:33:21,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:28,792:INFO:Calculating mean and std
2025-03-05 15:33:28,793:INFO:Creating metrics dataframe
2025-03-05 15:33:28,795:INFO:Uploading results into container
2025-03-05 15:33:28,795:INFO:Uploading model into container now
2025-03-05 15:33:28,796:INFO:_master_model_container: 16
2025-03-05 15:33:28,796:INFO:_display_container: 2
2025-03-05 15:33:28,796:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:33:28,796:INFO:create_model() successfully completed......................................
2025-03-05 15:33:28,915:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:28,915:INFO:Creating metrics dataframe
2025-03-05 15:33:28,924:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:33:28,925:INFO:Total runtime is 0.319931173324585 minutes
2025-03-05 15:33:28,928:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:28,928:INFO:Initializing create_model()
2025-03-05 15:33:28,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:28,928:INFO:Checking exceptions
2025-03-05 15:33:28,928:INFO:Importing libraries
2025-03-05 15:33:28,928:INFO:Copying training dataset
2025-03-05 15:33:28,932:INFO:Defining folds
2025-03-05 15:33:28,933:INFO:Declaring metric variables
2025-03-05 15:33:28,936:INFO:Importing untrained model
2025-03-05 15:33:28,939:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:33:28,945:INFO:Starting cross validation
2025-03-05 15:33:28,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:29,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037401 seconds.
2025-03-05 15:33:29,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:29,027:INFO:[LightGBM] [Info] Total Bins 393
2025-03-05 15:33:29,033:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 2
2025-03-05 15:33:29,048:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:33:30,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2025-03-05 15:33:30,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:30,619:INFO:[LightGBM] [Info] Total Bins 389
2025-03-05 15:33:30,619:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:30,620:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:33:31,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2025-03-05 15:33:31,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:31,022:INFO:[LightGBM] [Info] Total Bins 390
2025-03-05 15:33:31,022:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:31,022:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:33:31,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030603 seconds.
2025-03-05 15:33:31,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:31,391:INFO:[LightGBM] [Info] Total Bins 389
2025-03-05 15:33:31,398:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:31,419:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:33:31,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2025-03-05 15:33:31,959:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:31,960:INFO:[LightGBM] [Info] Total Bins 387
2025-03-05 15:33:31,960:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:31,960:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:33:32,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005522 seconds.
2025-03-05 15:33:32,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 15:33:32,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 15:33:32,302:INFO:[LightGBM] [Info] Total Bins 388
2025-03-05 15:33:32,302:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:32,302:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:33:32,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031670 seconds.
2025-03-05 15:33:32,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:32,733:INFO:[LightGBM] [Info] Total Bins 386
2025-03-05 15:33:32,739:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:32,759:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:33:33,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035070 seconds.
2025-03-05 15:33:33,105:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:33,105:INFO:[LightGBM] [Info] Total Bins 390
2025-03-05 15:33:33,113:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:33,126:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:33:33,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029616 seconds.
2025-03-05 15:33:33,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:33,444:INFO:[LightGBM] [Info] Total Bins 394
2025-03-05 15:33:33,453:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:33,468:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:33:35,270:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038435 seconds.
2025-03-05 15:33:35,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:33:35,271:INFO:[LightGBM] [Info] Total Bins 387
2025-03-05 15:33:35,281:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:33:35,301:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:33:36,506:INFO:Calculating mean and std
2025-03-05 15:33:36,507:INFO:Creating metrics dataframe
2025-03-05 15:33:36,510:INFO:Uploading results into container
2025-03-05 15:33:36,510:INFO:Uploading model into container now
2025-03-05 15:33:36,511:INFO:_master_model_container: 17
2025-03-05 15:33:36,511:INFO:_display_container: 2
2025-03-05 15:33:36,512:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:33:36,512:INFO:create_model() successfully completed......................................
2025-03-05 15:33:36,638:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:36,638:INFO:Creating metrics dataframe
2025-03-05 15:33:36,647:INFO:Initializing Dummy Regressor
2025-03-05 15:33:36,647:INFO:Total runtime is 0.44864533742268886 minutes
2025-03-05 15:33:36,650:INFO:SubProcess create_model() called ==================================
2025-03-05 15:33:36,651:INFO:Initializing create_model()
2025-03-05 15:33:36,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d0e604c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:36,651:INFO:Checking exceptions
2025-03-05 15:33:36,651:INFO:Importing libraries
2025-03-05 15:33:36,651:INFO:Copying training dataset
2025-03-05 15:33:36,655:INFO:Defining folds
2025-03-05 15:33:36,655:INFO:Declaring metric variables
2025-03-05 15:33:36,658:INFO:Importing untrained model
2025-03-05 15:33:36,662:INFO:Dummy Regressor Imported successfully
2025-03-05 15:33:36,668:INFO:Starting cross validation
2025-03-05 15:33:36,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:33:36,871:INFO:Calculating mean and std
2025-03-05 15:33:36,872:INFO:Creating metrics dataframe
2025-03-05 15:33:36,874:INFO:Uploading results into container
2025-03-05 15:33:36,875:INFO:Uploading model into container now
2025-03-05 15:33:36,875:INFO:_master_model_container: 18
2025-03-05 15:33:36,875:INFO:_display_container: 2
2025-03-05 15:33:36,876:INFO:DummyRegressor()
2025-03-05 15:33:36,876:INFO:create_model() successfully completed......................................
2025-03-05 15:33:37,000:INFO:SubProcess create_model() end ==================================
2025-03-05 15:33:37,000:INFO:Creating metrics dataframe
2025-03-05 15:33:37,011:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:33:37,019:INFO:Initializing create_model()
2025-03-05 15:33:37,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:33:37,019:INFO:Checking exceptions
2025-03-05 15:33:37,021:INFO:Importing libraries
2025-03-05 15:33:37,021:INFO:Copying training dataset
2025-03-05 15:33:37,024:INFO:Defining folds
2025-03-05 15:33:37,024:INFO:Declaring metric variables
2025-03-05 15:33:37,024:INFO:Importing untrained model
2025-03-05 15:33:37,025:INFO:Declaring custom model
2025-03-05 15:33:37,025:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:33:37,026:INFO:Cross validation set to False
2025-03-05 15:33:37,026:INFO:Fitting Model
2025-03-05 15:33:37,773:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:33:37,774:INFO:create_model() successfully completed......................................
2025-03-05 15:33:37,912:INFO:_master_model_container: 18
2025-03-05 15:33:37,912:INFO:_display_container: 2
2025-03-05 15:33:37,913:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:33:37,913:INFO:compare_models() successfully completed......................................
2025-03-05 15:33:37,990:INFO:Initializing evaluate_model()
2025-03-05 15:33:37,990:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 15:33:38,000:INFO:Initializing plot_model()
2025-03-05 15:33:38,000:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, system=True)
2025-03-05 15:33:38,000:INFO:Checking exceptions
2025-03-05 15:33:38,002:INFO:Preloading libraries
2025-03-05 15:33:38,008:INFO:Copying training dataset
2025-03-05 15:33:38,008:INFO:Plot type: pipeline
2025-03-05 15:33:38,120:INFO:Visual Rendered Successfully
2025-03-05 15:33:38,247:INFO:plot_model() successfully completed......................................
2025-03-05 15:33:38,292:INFO:Initializing plot_model()
2025-03-05 15:33:38,292:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, system=True)
2025-03-05 15:33:38,292:INFO:Checking exceptions
2025-03-05 15:33:38,298:INFO:Preloading libraries
2025-03-05 15:33:38,304:INFO:Copying training dataset
2025-03-05 15:33:38,304:INFO:Plot type: residuals
2025-03-05 15:33:38,405:INFO:Fitting Model
2025-03-05 15:33:38,405:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 15:33:38,497:INFO:Scoring test/hold-out set
2025-03-05 15:33:38,979:INFO:Visual Rendered Successfully
2025-03-05 15:33:39,103:INFO:plot_model() successfully completed......................................
2025-03-05 15:33:39,117:INFO:Initializing plot_model()
2025-03-05 15:33:39,117:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, system=True)
2025-03-05 15:33:39,118:INFO:Checking exceptions
2025-03-05 15:33:39,122:INFO:Preloading libraries
2025-03-05 15:33:39,128:INFO:Copying training dataset
2025-03-05 15:33:39,129:INFO:Plot type: feature
2025-03-05 15:33:39,130:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:33:39,264:INFO:Visual Rendered Successfully
2025-03-05 15:33:39,383:INFO:plot_model() successfully completed......................................
2025-03-05 15:33:39,396:INFO:Initializing predict_model()
2025-03-05 15:33:39,396:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445df1d9430>)
2025-03-05 15:33:39,396:INFO:Checking exceptions
2025-03-05 15:33:39,396:INFO:Preloading libraries
2025-03-05 15:33:39,457:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:33:39,603:INFO:Initializing predict_model()
2025-03-05 15:33:39,604:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b41d5400>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445df1d9430>)
2025-03-05 15:33:39,604:INFO:Checking exceptions
2025-03-05 15:33:39,604:INFO:Preloading libraries
2025-03-05 15:33:39,606:INFO:Set up data.
2025-03-05 15:33:39,609:INFO:Set up index.
2025-03-05 15:33:39,646:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:34:43,343:INFO:PyCaret RegressionExperiment
2025-03-05 15:34:43,344:INFO:Logging name: reg-default-name
2025-03-05 15:34:43,344:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:34:43,344:INFO:version 3.3.1
2025-03-05 15:34:43,344:INFO:Initializing setup()
2025-03-05 15:34:43,344:INFO:self.USI: 01e0
2025-03-05 15:34:43,344:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:34:43,344:INFO:Checking environment
2025-03-05 15:34:43,344:INFO:python_version: 3.9.21
2025-03-05 15:34:43,344:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:34:43,344:INFO:machine: x86_64
2025-03-05 15:34:43,344:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:34:43,344:INFO:Memory: svmem(total=33374507008, available=21296902144, percent=36.2, used=9505173504, free=3750666240, active=13584904192, inactive=11843489792, buffers=679596032, cached=19439071232, shared=2043334656, slab=1828515840)
2025-03-05 15:34:43,346:INFO:Physical Core: 24
2025-03-05 15:34:43,346:INFO:Logical Core: 32
2025-03-05 15:34:43,346:INFO:Checking libraries
2025-03-05 15:34:43,346:INFO:System:
2025-03-05 15:34:43,346:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:34:43,346:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:34:43,346:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:34:43,346:INFO:PyCaret required dependencies:
2025-03-05 15:34:43,346:INFO:                 pip: 25.0
2025-03-05 15:34:43,346:INFO:          setuptools: 75.8.0
2025-03-05 15:34:43,347:INFO:             pycaret: 3.3.1
2025-03-05 15:34:43,347:INFO:             IPython: 8.18.1
2025-03-05 15:34:43,347:INFO:          ipywidgets: 8.1.5
2025-03-05 15:34:43,347:INFO:                tqdm: 4.67.1
2025-03-05 15:34:43,347:INFO:               numpy: 1.26.4
2025-03-05 15:34:43,347:INFO:              pandas: 2.1.4
2025-03-05 15:34:43,347:INFO:              jinja2: 3.1.5
2025-03-05 15:34:43,347:INFO:               scipy: 1.11.4
2025-03-05 15:34:43,347:INFO:              joblib: 1.3.2
2025-03-05 15:34:43,347:INFO:             sklearn: 1.4.2
2025-03-05 15:34:43,347:INFO:                pyod: 2.0.3
2025-03-05 15:34:43,347:INFO:            imblearn: 0.12.4
2025-03-05 15:34:43,347:INFO:   category_encoders: 2.6.4
2025-03-05 15:34:43,347:INFO:            lightgbm: 4.6.0
2025-03-05 15:34:43,347:INFO:               numba: 0.60.0
2025-03-05 15:34:43,347:INFO:            requests: 2.32.3
2025-03-05 15:34:43,347:INFO:          matplotlib: 3.7.5
2025-03-05 15:34:43,347:INFO:          scikitplot: 0.3.7
2025-03-05 15:34:43,347:INFO:         yellowbrick: 1.5
2025-03-05 15:34:43,347:INFO:              plotly: 5.24.1
2025-03-05 15:34:43,347:INFO:    plotly-resampler: Not installed
2025-03-05 15:34:43,347:INFO:             kaleido: 0.2.1
2025-03-05 15:34:43,347:INFO:           schemdraw: 0.15
2025-03-05 15:34:43,347:INFO:         statsmodels: 0.14.4
2025-03-05 15:34:43,347:INFO:              sktime: 0.26.0
2025-03-05 15:34:43,347:INFO:               tbats: 1.1.3
2025-03-05 15:34:43,347:INFO:            pmdarima: 2.0.4
2025-03-05 15:34:43,347:INFO:              psutil: 7.0.0
2025-03-05 15:34:43,347:INFO:          markupsafe: 3.0.2
2025-03-05 15:34:43,347:INFO:             pickle5: Not installed
2025-03-05 15:34:43,347:INFO:         cloudpickle: 3.1.1
2025-03-05 15:34:43,347:INFO:         deprecation: 2.1.0
2025-03-05 15:34:43,347:INFO:              xxhash: 3.5.0
2025-03-05 15:34:43,347:INFO:           wurlitzer: 3.1.1
2025-03-05 15:34:43,347:INFO:PyCaret optional dependencies:
2025-03-05 15:34:43,347:INFO:                shap: Not installed
2025-03-05 15:34:43,347:INFO:           interpret: Not installed
2025-03-05 15:34:43,347:INFO:                umap: Not installed
2025-03-05 15:34:43,347:INFO:     ydata_profiling: Not installed
2025-03-05 15:34:43,347:INFO:  explainerdashboard: Not installed
2025-03-05 15:34:43,347:INFO:             autoviz: Not installed
2025-03-05 15:34:43,347:INFO:           fairlearn: Not installed
2025-03-05 15:34:43,347:INFO:          deepchecks: Not installed
2025-03-05 15:34:43,347:INFO:             xgboost: Not installed
2025-03-05 15:34:43,347:INFO:            catboost: Not installed
2025-03-05 15:34:43,347:INFO:              kmodes: Not installed
2025-03-05 15:34:43,347:INFO:             mlxtend: Not installed
2025-03-05 15:34:43,347:INFO:       statsforecast: Not installed
2025-03-05 15:34:43,347:INFO:        tune_sklearn: Not installed
2025-03-05 15:34:43,347:INFO:                 ray: Not installed
2025-03-05 15:34:43,347:INFO:            hyperopt: Not installed
2025-03-05 15:34:43,347:INFO:              optuna: Not installed
2025-03-05 15:34:43,347:INFO:               skopt: Not installed
2025-03-05 15:34:43,347:INFO:              mlflow: Not installed
2025-03-05 15:34:43,347:INFO:              gradio: Not installed
2025-03-05 15:34:43,348:INFO:             fastapi: Not installed
2025-03-05 15:34:43,348:INFO:             uvicorn: Not installed
2025-03-05 15:34:43,348:INFO:              m2cgen: Not installed
2025-03-05 15:34:43,348:INFO:           evidently: Not installed
2025-03-05 15:34:43,348:INFO:               fugue: Not installed
2025-03-05 15:34:43,348:INFO:           streamlit: Not installed
2025-03-05 15:34:43,348:INFO:             prophet: Not installed
2025-03-05 15:34:43,348:INFO:None
2025-03-05 15:34:43,348:INFO:Set up GPU usage.
2025-03-05 15:34:43,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,348:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:34:43,348:INFO:Set up data.
2025-03-05 15:34:43,351:INFO:Set up folding strategy.
2025-03-05 15:34:43,351:INFO:Set up train/test split.
2025-03-05 15:34:43,354:INFO:Set up index.
2025-03-05 15:34:43,355:INFO:Assigning column types.
2025-03-05 15:34:43,357:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:34:43,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,357:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,361:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,460:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,472:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,484:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,577:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:34:43,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,584:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,705:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,761:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,805:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:34:43,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:43,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:43,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:43,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,028:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:34:44,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,088:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,232:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:34:44,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,301:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:34:44,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,447:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:34:44,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,695:INFO:Preparing preprocessing pipeline...
2025-03-05 15:34:44,695:INFO:Set up simple imputation.
2025-03-05 15:34:44,695:INFO:Set up polynomial features.
2025-03-05 15:34:44,695:INFO:Set up feature normalization.
2025-03-05 15:34:44,736:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:34:44,746:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-03-05 15:34:44,746:INFO:Creating final display dataframe.
2025-03-05 15:34:44,838:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 4)
5   Transformed train set shape        (14061, 4)
6    Transformed test set shape         (6027, 4)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 3
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU              True
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              01e0
2025-03-05 15:34:44,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:44,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:44,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:45,030:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:45,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:45,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:34:45,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:45,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:34:45,073:INFO:setup() successfully completed in 1.73s...............
2025-03-05 15:34:45,133:INFO:Initializing compare_models()
2025-03-05 15:34:45,133:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:34:45,133:INFO:Checking exceptions
2025-03-05 15:34:45,136:INFO:Preparing display monitor
2025-03-05 15:34:45,157:INFO:Initializing Linear Regression
2025-03-05 15:34:45,157:INFO:Total runtime is 2.8332074483235676e-06 minutes
2025-03-05 15:34:45,160:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:45,161:INFO:Initializing create_model()
2025-03-05 15:34:45,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:45,161:INFO:Checking exceptions
2025-03-05 15:34:45,161:INFO:Importing libraries
2025-03-05 15:34:45,161:INFO:Copying training dataset
2025-03-05 15:34:45,165:INFO:Defining folds
2025-03-05 15:34:45,165:INFO:Declaring metric variables
2025-03-05 15:34:45,168:INFO:Importing untrained model
2025-03-05 15:34:45,171:INFO:Linear Regression Imported successfully
2025-03-05 15:34:45,177:INFO:Starting cross validation
2025-03-05 15:34:45,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:45,409:INFO:Calculating mean and std
2025-03-05 15:34:45,409:INFO:Creating metrics dataframe
2025-03-05 15:34:45,411:INFO:Uploading results into container
2025-03-05 15:34:45,411:INFO:Uploading model into container now
2025-03-05 15:34:45,411:INFO:_master_model_container: 1
2025-03-05 15:34:45,411:INFO:_display_container: 2
2025-03-05 15:34:45,412:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:34:45,412:INFO:create_model() successfully completed......................................
2025-03-05 15:34:45,530:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:45,530:INFO:Creating metrics dataframe
2025-03-05 15:34:45,537:INFO:Initializing Lasso Regression
2025-03-05 15:34:45,537:INFO:Total runtime is 0.006323643525441488 minutes
2025-03-05 15:34:45,540:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:45,540:INFO:Initializing create_model()
2025-03-05 15:34:45,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:45,540:INFO:Checking exceptions
2025-03-05 15:34:45,540:INFO:Importing libraries
2025-03-05 15:34:45,540:INFO:Copying training dataset
2025-03-05 15:34:45,544:INFO:Defining folds
2025-03-05 15:34:45,544:INFO:Declaring metric variables
2025-03-05 15:34:45,547:INFO:Importing untrained model
2025-03-05 15:34:45,551:INFO:Lasso Regression Imported successfully
2025-03-05 15:34:45,558:INFO:Starting cross validation
2025-03-05 15:34:45,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:45,851:INFO:Calculating mean and std
2025-03-05 15:34:45,851:INFO:Creating metrics dataframe
2025-03-05 15:34:45,853:INFO:Uploading results into container
2025-03-05 15:34:45,854:INFO:Uploading model into container now
2025-03-05 15:34:45,854:INFO:_master_model_container: 2
2025-03-05 15:34:45,854:INFO:_display_container: 2
2025-03-05 15:34:45,854:INFO:Lasso(random_state=123)
2025-03-05 15:34:45,854:INFO:create_model() successfully completed......................................
2025-03-05 15:34:45,987:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:45,988:INFO:Creating metrics dataframe
2025-03-05 15:34:45,995:INFO:Initializing Ridge Regression
2025-03-05 15:34:45,995:INFO:Total runtime is 0.013961072762807211 minutes
2025-03-05 15:34:45,998:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:45,999:INFO:Initializing create_model()
2025-03-05 15:34:45,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:45,999:INFO:Checking exceptions
2025-03-05 15:34:45,999:INFO:Importing libraries
2025-03-05 15:34:45,999:INFO:Copying training dataset
2025-03-05 15:34:46,002:INFO:Defining folds
2025-03-05 15:34:46,003:INFO:Declaring metric variables
2025-03-05 15:34:46,005:INFO:Importing untrained model
2025-03-05 15:34:46,008:INFO:Ridge Regression Imported successfully
2025-03-05 15:34:46,014:INFO:Starting cross validation
2025-03-05 15:34:46,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:46,243:INFO:Calculating mean and std
2025-03-05 15:34:46,245:INFO:Creating metrics dataframe
2025-03-05 15:34:46,247:INFO:Uploading results into container
2025-03-05 15:34:46,247:INFO:Uploading model into container now
2025-03-05 15:34:46,247:INFO:_master_model_container: 3
2025-03-05 15:34:46,247:INFO:_display_container: 2
2025-03-05 15:34:46,248:INFO:Ridge(random_state=123)
2025-03-05 15:34:46,248:INFO:create_model() successfully completed......................................
2025-03-05 15:34:46,368:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:46,368:INFO:Creating metrics dataframe
2025-03-05 15:34:46,376:INFO:Initializing Elastic Net
2025-03-05 15:34:46,376:INFO:Total runtime is 0.020311331748962404 minutes
2025-03-05 15:34:46,379:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:46,380:INFO:Initializing create_model()
2025-03-05 15:34:46,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:46,380:INFO:Checking exceptions
2025-03-05 15:34:46,380:INFO:Importing libraries
2025-03-05 15:34:46,380:INFO:Copying training dataset
2025-03-05 15:34:46,384:INFO:Defining folds
2025-03-05 15:34:46,385:INFO:Declaring metric variables
2025-03-05 15:34:46,388:INFO:Importing untrained model
2025-03-05 15:34:46,391:INFO:Elastic Net Imported successfully
2025-03-05 15:34:46,396:INFO:Starting cross validation
2025-03-05 15:34:46,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:46,703:INFO:Calculating mean and std
2025-03-05 15:34:46,704:INFO:Creating metrics dataframe
2025-03-05 15:34:46,706:INFO:Uploading results into container
2025-03-05 15:34:46,709:INFO:Uploading model into container now
2025-03-05 15:34:46,709:INFO:_master_model_container: 4
2025-03-05 15:34:46,709:INFO:_display_container: 2
2025-03-05 15:34:46,709:INFO:ElasticNet(random_state=123)
2025-03-05 15:34:46,709:INFO:create_model() successfully completed......................................
2025-03-05 15:34:46,860:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:46,860:INFO:Creating metrics dataframe
2025-03-05 15:34:46,867:INFO:Initializing Least Angle Regression
2025-03-05 15:34:46,867:INFO:Total runtime is 0.028495824337005617 minutes
2025-03-05 15:34:46,870:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:46,870:INFO:Initializing create_model()
2025-03-05 15:34:46,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:46,870:INFO:Checking exceptions
2025-03-05 15:34:46,870:INFO:Importing libraries
2025-03-05 15:34:46,870:INFO:Copying training dataset
2025-03-05 15:34:46,875:INFO:Defining folds
2025-03-05 15:34:46,875:INFO:Declaring metric variables
2025-03-05 15:34:46,878:INFO:Importing untrained model
2025-03-05 15:34:46,882:INFO:Least Angle Regression Imported successfully
2025-03-05 15:34:46,891:INFO:Starting cross validation
2025-03-05 15:34:46,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:47,121:INFO:Calculating mean and std
2025-03-05 15:34:47,122:INFO:Creating metrics dataframe
2025-03-05 15:34:47,124:INFO:Uploading results into container
2025-03-05 15:34:47,125:INFO:Uploading model into container now
2025-03-05 15:34:47,125:INFO:_master_model_container: 5
2025-03-05 15:34:47,125:INFO:_display_container: 2
2025-03-05 15:34:47,125:INFO:Lars(random_state=123)
2025-03-05 15:34:47,125:INFO:create_model() successfully completed......................................
2025-03-05 15:34:47,259:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:47,259:INFO:Creating metrics dataframe
2025-03-05 15:34:47,266:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:34:47,266:INFO:Total runtime is 0.03515358368555705 minutes
2025-03-05 15:34:47,270:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:47,270:INFO:Initializing create_model()
2025-03-05 15:34:47,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:47,270:INFO:Checking exceptions
2025-03-05 15:34:47,270:INFO:Importing libraries
2025-03-05 15:34:47,270:INFO:Copying training dataset
2025-03-05 15:34:47,275:INFO:Defining folds
2025-03-05 15:34:47,275:INFO:Declaring metric variables
2025-03-05 15:34:47,278:INFO:Importing untrained model
2025-03-05 15:34:47,281:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:34:47,287:INFO:Starting cross validation
2025-03-05 15:34:47,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:47,515:INFO:Calculating mean and std
2025-03-05 15:34:47,516:INFO:Creating metrics dataframe
2025-03-05 15:34:47,518:INFO:Uploading results into container
2025-03-05 15:34:47,518:INFO:Uploading model into container now
2025-03-05 15:34:47,519:INFO:_master_model_container: 6
2025-03-05 15:34:47,519:INFO:_display_container: 2
2025-03-05 15:34:47,519:INFO:LassoLars(random_state=123)
2025-03-05 15:34:47,519:INFO:create_model() successfully completed......................................
2025-03-05 15:34:47,639:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:47,639:INFO:Creating metrics dataframe
2025-03-05 15:34:47,647:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:34:47,647:INFO:Total runtime is 0.04150191545486451 minutes
2025-03-05 15:34:47,651:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:47,651:INFO:Initializing create_model()
2025-03-05 15:34:47,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:47,651:INFO:Checking exceptions
2025-03-05 15:34:47,651:INFO:Importing libraries
2025-03-05 15:34:47,651:INFO:Copying training dataset
2025-03-05 15:34:47,655:INFO:Defining folds
2025-03-05 15:34:47,656:INFO:Declaring metric variables
2025-03-05 15:34:47,659:INFO:Importing untrained model
2025-03-05 15:34:47,661:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:34:47,667:INFO:Starting cross validation
2025-03-05 15:34:47,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:47,887:INFO:Calculating mean and std
2025-03-05 15:34:47,888:INFO:Creating metrics dataframe
2025-03-05 15:34:47,890:INFO:Uploading results into container
2025-03-05 15:34:47,891:INFO:Uploading model into container now
2025-03-05 15:34:47,891:INFO:_master_model_container: 7
2025-03-05 15:34:47,891:INFO:_display_container: 2
2025-03-05 15:34:47,891:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:34:47,891:INFO:create_model() successfully completed......................................
2025-03-05 15:34:48,010:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:48,011:INFO:Creating metrics dataframe
2025-03-05 15:34:48,018:INFO:Initializing Bayesian Ridge
2025-03-05 15:34:48,018:INFO:Total runtime is 0.04768635431925456 minutes
2025-03-05 15:34:48,022:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:48,022:INFO:Initializing create_model()
2025-03-05 15:34:48,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:48,022:INFO:Checking exceptions
2025-03-05 15:34:48,022:INFO:Importing libraries
2025-03-05 15:34:48,022:INFO:Copying training dataset
2025-03-05 15:34:48,026:INFO:Defining folds
2025-03-05 15:34:48,027:INFO:Declaring metric variables
2025-03-05 15:34:48,030:INFO:Importing untrained model
2025-03-05 15:34:48,036:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:34:48,048:INFO:Starting cross validation
2025-03-05 15:34:48,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:48,375:INFO:Calculating mean and std
2025-03-05 15:34:48,376:INFO:Creating metrics dataframe
2025-03-05 15:34:48,380:INFO:Uploading results into container
2025-03-05 15:34:48,380:INFO:Uploading model into container now
2025-03-05 15:34:48,381:INFO:_master_model_container: 8
2025-03-05 15:34:48,381:INFO:_display_container: 2
2025-03-05 15:34:48,381:INFO:BayesianRidge()
2025-03-05 15:34:48,381:INFO:create_model() successfully completed......................................
2025-03-05 15:34:48,541:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:48,541:INFO:Creating metrics dataframe
2025-03-05 15:34:48,549:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:34:48,550:INFO:Total runtime is 0.05653817653656006 minutes
2025-03-05 15:34:48,553:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:48,553:INFO:Initializing create_model()
2025-03-05 15:34:48,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:48,554:INFO:Checking exceptions
2025-03-05 15:34:48,554:INFO:Importing libraries
2025-03-05 15:34:48,554:INFO:Copying training dataset
2025-03-05 15:34:48,558:INFO:Defining folds
2025-03-05 15:34:48,558:INFO:Declaring metric variables
2025-03-05 15:34:48,561:INFO:Importing untrained model
2025-03-05 15:34:48,565:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:34:48,571:INFO:Starting cross validation
2025-03-05 15:34:48,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:48,864:INFO:Calculating mean and std
2025-03-05 15:34:48,865:INFO:Creating metrics dataframe
2025-03-05 15:34:48,867:INFO:Uploading results into container
2025-03-05 15:34:48,867:INFO:Uploading model into container now
2025-03-05 15:34:48,868:INFO:_master_model_container: 9
2025-03-05 15:34:48,868:INFO:_display_container: 2
2025-03-05 15:34:48,868:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:34:48,868:INFO:create_model() successfully completed......................................
2025-03-05 15:34:48,989:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:48,989:INFO:Creating metrics dataframe
2025-03-05 15:34:48,997:INFO:Initializing Huber Regressor
2025-03-05 15:34:48,997:INFO:Total runtime is 0.06400135755538941 minutes
2025-03-05 15:34:49,000:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:49,001:INFO:Initializing create_model()
2025-03-05 15:34:49,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:49,001:INFO:Checking exceptions
2025-03-05 15:34:49,001:INFO:Importing libraries
2025-03-05 15:34:49,001:INFO:Copying training dataset
2025-03-05 15:34:49,007:INFO:Defining folds
2025-03-05 15:34:49,008:INFO:Declaring metric variables
2025-03-05 15:34:49,013:INFO:Importing untrained model
2025-03-05 15:34:49,017:INFO:Huber Regressor Imported successfully
2025-03-05 15:34:49,024:INFO:Starting cross validation
2025-03-05 15:34:49,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:49,963:INFO:Calculating mean and std
2025-03-05 15:34:49,965:INFO:Creating metrics dataframe
2025-03-05 15:34:49,967:INFO:Uploading results into container
2025-03-05 15:34:49,968:INFO:Uploading model into container now
2025-03-05 15:34:49,968:INFO:_master_model_container: 10
2025-03-05 15:34:49,968:INFO:_display_container: 2
2025-03-05 15:34:49,969:INFO:HuberRegressor()
2025-03-05 15:34:49,969:INFO:create_model() successfully completed......................................
2025-03-05 15:34:50,103:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:50,103:INFO:Creating metrics dataframe
2025-03-05 15:34:50,112:INFO:Initializing K Neighbors Regressor
2025-03-05 15:34:50,112:INFO:Total runtime is 0.08257586956024171 minutes
2025-03-05 15:34:50,115:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:50,115:INFO:Initializing create_model()
2025-03-05 15:34:50,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:50,115:INFO:Checking exceptions
2025-03-05 15:34:50,115:INFO:Importing libraries
2025-03-05 15:34:50,115:INFO:Copying training dataset
2025-03-05 15:34:50,120:INFO:Defining folds
2025-03-05 15:34:50,120:INFO:Declaring metric variables
2025-03-05 15:34:50,123:INFO:Importing untrained model
2025-03-05 15:34:50,126:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:34:50,132:INFO:Starting cross validation
2025-03-05 15:34:50,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:50,702:INFO:Calculating mean and std
2025-03-05 15:34:50,704:INFO:Creating metrics dataframe
2025-03-05 15:34:50,706:INFO:Uploading results into container
2025-03-05 15:34:50,706:INFO:Uploading model into container now
2025-03-05 15:34:50,707:INFO:_master_model_container: 11
2025-03-05 15:34:50,707:INFO:_display_container: 2
2025-03-05 15:34:50,707:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:34:50,707:INFO:create_model() successfully completed......................................
2025-03-05 15:34:50,832:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:50,832:INFO:Creating metrics dataframe
2025-03-05 15:34:50,842:INFO:Initializing Decision Tree Regressor
2025-03-05 15:34:50,843:INFO:Total runtime is 0.0947540839513143 minutes
2025-03-05 15:34:50,846:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:50,846:INFO:Initializing create_model()
2025-03-05 15:34:50,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:50,846:INFO:Checking exceptions
2025-03-05 15:34:50,846:INFO:Importing libraries
2025-03-05 15:34:50,847:INFO:Copying training dataset
2025-03-05 15:34:50,851:INFO:Defining folds
2025-03-05 15:34:50,851:INFO:Declaring metric variables
2025-03-05 15:34:50,854:INFO:Importing untrained model
2025-03-05 15:34:50,857:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:34:50,863:INFO:Starting cross validation
2025-03-05 15:34:50,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:51,192:INFO:Calculating mean and std
2025-03-05 15:34:51,193:INFO:Creating metrics dataframe
2025-03-05 15:34:51,194:INFO:Uploading results into container
2025-03-05 15:34:51,195:INFO:Uploading model into container now
2025-03-05 15:34:51,195:INFO:_master_model_container: 12
2025-03-05 15:34:51,195:INFO:_display_container: 2
2025-03-05 15:34:51,195:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:34:51,195:INFO:create_model() successfully completed......................................
2025-03-05 15:34:51,313:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:51,313:INFO:Creating metrics dataframe
2025-03-05 15:34:51,322:INFO:Initializing Random Forest Regressor
2025-03-05 15:34:51,322:INFO:Total runtime is 0.10275110006332398 minutes
2025-03-05 15:34:51,327:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:51,328:INFO:Initializing create_model()
2025-03-05 15:34:51,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:51,328:INFO:Checking exceptions
2025-03-05 15:34:51,328:INFO:Importing libraries
2025-03-05 15:34:51,328:INFO:Copying training dataset
2025-03-05 15:34:51,332:INFO:Defining folds
2025-03-05 15:34:51,332:INFO:Declaring metric variables
2025-03-05 15:34:51,335:INFO:Importing untrained model
2025-03-05 15:34:51,339:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:34:51,345:INFO:Starting cross validation
2025-03-05 15:34:51,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:54,079:INFO:Calculating mean and std
2025-03-05 15:34:54,080:INFO:Creating metrics dataframe
2025-03-05 15:34:54,082:INFO:Uploading results into container
2025-03-05 15:34:54,083:INFO:Uploading model into container now
2025-03-05 15:34:54,084:INFO:_master_model_container: 13
2025-03-05 15:34:54,084:INFO:_display_container: 2
2025-03-05 15:34:54,084:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:34:54,084:INFO:create_model() successfully completed......................................
2025-03-05 15:34:54,221:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:54,221:INFO:Creating metrics dataframe
2025-03-05 15:34:54,231:INFO:Initializing Extra Trees Regressor
2025-03-05 15:34:54,231:INFO:Total runtime is 0.1512271483739217 minutes
2025-03-05 15:34:54,234:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:54,234:INFO:Initializing create_model()
2025-03-05 15:34:54,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:54,235:INFO:Checking exceptions
2025-03-05 15:34:54,235:INFO:Importing libraries
2025-03-05 15:34:54,235:INFO:Copying training dataset
2025-03-05 15:34:54,239:INFO:Defining folds
2025-03-05 15:34:54,239:INFO:Declaring metric variables
2025-03-05 15:34:54,242:INFO:Importing untrained model
2025-03-05 15:34:54,246:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:34:54,251:INFO:Starting cross validation
2025-03-05 15:34:54,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:55,966:INFO:Calculating mean and std
2025-03-05 15:34:55,968:INFO:Creating metrics dataframe
2025-03-05 15:34:55,970:INFO:Uploading results into container
2025-03-05 15:34:55,970:INFO:Uploading model into container now
2025-03-05 15:34:55,970:INFO:_master_model_container: 14
2025-03-05 15:34:55,971:INFO:_display_container: 2
2025-03-05 15:34:55,971:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:34:55,971:INFO:create_model() successfully completed......................................
2025-03-05 15:34:56,091:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:56,091:INFO:Creating metrics dataframe
2025-03-05 15:34:56,101:INFO:Initializing AdaBoost Regressor
2025-03-05 15:34:56,101:INFO:Total runtime is 0.18238970438639324 minutes
2025-03-05 15:34:56,104:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:56,104:INFO:Initializing create_model()
2025-03-05 15:34:56,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:56,104:INFO:Checking exceptions
2025-03-05 15:34:56,104:INFO:Importing libraries
2025-03-05 15:34:56,104:INFO:Copying training dataset
2025-03-05 15:34:56,108:INFO:Defining folds
2025-03-05 15:34:56,108:INFO:Declaring metric variables
2025-03-05 15:34:56,111:INFO:Importing untrained model
2025-03-05 15:34:56,115:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:34:56,120:INFO:Starting cross validation
2025-03-05 15:34:56,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:34:57,789:INFO:Calculating mean and std
2025-03-05 15:34:57,790:INFO:Creating metrics dataframe
2025-03-05 15:34:57,792:INFO:Uploading results into container
2025-03-05 15:34:57,792:INFO:Uploading model into container now
2025-03-05 15:34:57,793:INFO:_master_model_container: 15
2025-03-05 15:34:57,793:INFO:_display_container: 2
2025-03-05 15:34:57,793:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:34:57,793:INFO:create_model() successfully completed......................................
2025-03-05 15:34:57,906:INFO:SubProcess create_model() end ==================================
2025-03-05 15:34:57,906:INFO:Creating metrics dataframe
2025-03-05 15:34:57,916:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:34:57,916:INFO:Total runtime is 0.21264287233352663 minutes
2025-03-05 15:34:57,919:INFO:SubProcess create_model() called ==================================
2025-03-05 15:34:57,920:INFO:Initializing create_model()
2025-03-05 15:34:57,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:34:57,920:INFO:Checking exceptions
2025-03-05 15:34:57,920:INFO:Importing libraries
2025-03-05 15:34:57,920:INFO:Copying training dataset
2025-03-05 15:34:57,924:INFO:Defining folds
2025-03-05 15:34:57,925:INFO:Declaring metric variables
2025-03-05 15:34:57,928:INFO:Importing untrained model
2025-03-05 15:34:57,932:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:34:57,939:INFO:Starting cross validation
2025-03-05 15:34:57,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:35:07,230:INFO:Calculating mean and std
2025-03-05 15:35:07,231:INFO:Creating metrics dataframe
2025-03-05 15:35:07,233:INFO:Uploading results into container
2025-03-05 15:35:07,233:INFO:Uploading model into container now
2025-03-05 15:35:07,234:INFO:_master_model_container: 16
2025-03-05 15:35:07,234:INFO:_display_container: 2
2025-03-05 15:35:07,234:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:35:07,234:INFO:create_model() successfully completed......................................
2025-03-05 15:35:07,354:INFO:SubProcess create_model() end ==================================
2025-03-05 15:35:07,354:INFO:Creating metrics dataframe
2025-03-05 15:35:07,363:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:35:07,364:INFO:Total runtime is 0.3701058586438497 minutes
2025-03-05 15:35:07,367:INFO:SubProcess create_model() called ==================================
2025-03-05 15:35:07,367:INFO:Initializing create_model()
2025-03-05 15:35:07,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:35:07,367:INFO:Checking exceptions
2025-03-05 15:35:07,367:INFO:Importing libraries
2025-03-05 15:35:07,368:INFO:Copying training dataset
2025-03-05 15:35:07,372:INFO:Defining folds
2025-03-05 15:35:07,372:INFO:Declaring metric variables
2025-03-05 15:35:07,375:INFO:Importing untrained model
2025-03-05 15:35:07,380:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:35:07,393:INFO:Starting cross validation
2025-03-05 15:35:07,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:35:07,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032198 seconds.
2025-03-05 15:35:07,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:07,464:INFO:[LightGBM] [Info] Total Bins 587
2025-03-05 15:35:07,471:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 3
2025-03-05 15:35:07,485:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:35:08,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
2025-03-05 15:35:08,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:08,070:INFO:[LightGBM] [Info] Total Bins 582
2025-03-05 15:35:08,071:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:08,071:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:35:08,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-03-05 15:35:08,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:08,787:INFO:[LightGBM] [Info] Total Bins 584
2025-03-05 15:35:08,788:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:08,790:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:35:09,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032595 seconds.
2025-03-05 15:35:09,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:09,700:INFO:[LightGBM] [Info] Total Bins 583
2025-03-05 15:35:09,706:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:09,725:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:35:10,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2025-03-05 15:35:10,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:10,498:INFO:[LightGBM] [Info] Total Bins 580
2025-03-05 15:35:10,498:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:10,498:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:35:10,965:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039597 seconds.
2025-03-05 15:35:10,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:10,966:INFO:[LightGBM] [Info] Total Bins 580
2025-03-05 15:35:10,976:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:10,995:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:35:12,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2025-03-05 15:35:12,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:12,986:INFO:[LightGBM] [Info] Total Bins 578
2025-03-05 15:35:12,986:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:12,986:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:35:13,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2025-03-05 15:35:13,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:13,317:INFO:[LightGBM] [Info] Total Bins 583
2025-03-05 15:35:13,318:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:13,318:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:35:14,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-03-05 15:35:14,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 15:35:14,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 15:35:14,559:INFO:[LightGBM] [Info] Total Bins 588
2025-03-05 15:35:14,562:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:14,583:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:35:15,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2025-03-05 15:35:15,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:35:15,225:INFO:[LightGBM] [Info] Total Bins 580
2025-03-05 15:35:15,225:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 3
2025-03-05 15:35:15,226:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:35:15,568:INFO:Calculating mean and std
2025-03-05 15:35:15,569:INFO:Creating metrics dataframe
2025-03-05 15:35:15,571:INFO:Uploading results into container
2025-03-05 15:35:15,572:INFO:Uploading model into container now
2025-03-05 15:35:15,572:INFO:_master_model_container: 17
2025-03-05 15:35:15,572:INFO:_display_container: 2
2025-03-05 15:35:15,573:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:35:15,573:INFO:create_model() successfully completed......................................
2025-03-05 15:35:15,696:INFO:SubProcess create_model() end ==================================
2025-03-05 15:35:15,696:INFO:Creating metrics dataframe
2025-03-05 15:35:15,705:INFO:Initializing Dummy Regressor
2025-03-05 15:35:15,706:INFO:Total runtime is 0.5091408530871073 minutes
2025-03-05 15:35:15,709:INFO:SubProcess create_model() called ==================================
2025-03-05 15:35:15,709:INFO:Initializing create_model()
2025-03-05 15:35:15,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445ceb5c1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:35:15,709:INFO:Checking exceptions
2025-03-05 15:35:15,709:INFO:Importing libraries
2025-03-05 15:35:15,709:INFO:Copying training dataset
2025-03-05 15:35:15,714:INFO:Defining folds
2025-03-05 15:35:15,714:INFO:Declaring metric variables
2025-03-05 15:35:15,717:INFO:Importing untrained model
2025-03-05 15:35:15,720:INFO:Dummy Regressor Imported successfully
2025-03-05 15:35:15,727:INFO:Starting cross validation
2025-03-05 15:35:15,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:35:15,929:INFO:Calculating mean and std
2025-03-05 15:35:15,930:INFO:Creating metrics dataframe
2025-03-05 15:35:15,932:INFO:Uploading results into container
2025-03-05 15:35:15,933:INFO:Uploading model into container now
2025-03-05 15:35:15,933:INFO:_master_model_container: 18
2025-03-05 15:35:15,933:INFO:_display_container: 2
2025-03-05 15:35:15,933:INFO:DummyRegressor()
2025-03-05 15:35:15,933:INFO:create_model() successfully completed......................................
2025-03-05 15:35:16,058:INFO:SubProcess create_model() end ==================================
2025-03-05 15:35:16,058:INFO:Creating metrics dataframe
2025-03-05 15:35:16,069:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:35:16,076:INFO:Initializing create_model()
2025-03-05 15:35:16,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:35:16,077:INFO:Checking exceptions
2025-03-05 15:35:16,078:INFO:Importing libraries
2025-03-05 15:35:16,078:INFO:Copying training dataset
2025-03-05 15:35:16,082:INFO:Defining folds
2025-03-05 15:35:16,082:INFO:Declaring metric variables
2025-03-05 15:35:16,082:INFO:Importing untrained model
2025-03-05 15:35:16,082:INFO:Declaring custom model
2025-03-05 15:35:16,083:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:35:16,083:INFO:Cross validation set to False
2025-03-05 15:35:16,083:INFO:Fitting Model
2025-03-05 15:35:17,101:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:35:17,101:INFO:create_model() successfully completed......................................
2025-03-05 15:35:17,251:INFO:_master_model_container: 18
2025-03-05 15:35:17,251:INFO:_display_container: 2
2025-03-05 15:35:17,251:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:35:17,251:INFO:compare_models() successfully completed......................................
2025-03-05 15:35:17,281:INFO:Initializing evaluate_model()
2025-03-05 15:35:17,282:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 15:35:17,291:INFO:Initializing plot_model()
2025-03-05 15:35:17,291:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, system=True)
2025-03-05 15:35:17,291:INFO:Checking exceptions
2025-03-05 15:35:17,293:INFO:Preloading libraries
2025-03-05 15:35:17,301:INFO:Copying training dataset
2025-03-05 15:35:17,301:INFO:Plot type: pipeline
2025-03-05 15:35:17,424:INFO:Visual Rendered Successfully
2025-03-05 15:35:17,542:INFO:plot_model() successfully completed......................................
2025-03-05 15:35:20,556:INFO:Initializing plot_model()
2025-03-05 15:35:20,556:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, system=True)
2025-03-05 15:35:20,557:INFO:Checking exceptions
2025-03-05 15:35:20,565:INFO:Preloading libraries
2025-03-05 15:35:20,579:INFO:Copying training dataset
2025-03-05 15:35:20,579:INFO:Plot type: residuals
2025-03-05 15:35:20,680:INFO:Fitting Model
2025-03-05 15:35:20,680:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 15:35:20,772:INFO:Scoring test/hold-out set
2025-03-05 15:35:21,251:INFO:Visual Rendered Successfully
2025-03-05 15:35:21,372:INFO:plot_model() successfully completed......................................
2025-03-05 15:35:21,384:INFO:Initializing plot_model()
2025-03-05 15:35:21,384:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, system=True)
2025-03-05 15:35:21,384:INFO:Checking exceptions
2025-03-05 15:35:21,389:INFO:Preloading libraries
2025-03-05 15:35:21,396:INFO:Copying training dataset
2025-03-05 15:35:21,396:INFO:Plot type: feature
2025-03-05 15:35:21,397:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:35:21,511:INFO:Visual Rendered Successfully
2025-03-05 15:35:21,630:INFO:plot_model() successfully completed......................................
2025-03-05 15:35:21,649:INFO:Initializing predict_model()
2025-03-05 15:35:21,649:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445ceaabb80>)
2025-03-05 15:35:21,649:INFO:Checking exceptions
2025-03-05 15:35:21,650:INFO:Preloading libraries
2025-03-05 15:35:21,709:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:35:22,114:INFO:Initializing predict_model()
2025-03-05 15:35:22,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebd9460>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445ceaabe50>)
2025-03-05 15:35:22,114:INFO:Checking exceptions
2025-03-05 15:35:22,114:INFO:Preloading libraries
2025-03-05 15:35:22,116:INFO:Set up data.
2025-03-05 15:35:22,119:INFO:Set up index.
2025-03-05 15:35:22,156:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:36:35,371:INFO:PyCaret RegressionExperiment
2025-03-05 15:36:35,371:INFO:Logging name: reg-default-name
2025-03-05 15:36:35,371:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:36:35,371:INFO:version 3.3.1
2025-03-05 15:36:35,371:INFO:Initializing setup()
2025-03-05 15:36:35,371:INFO:self.USI: f717
2025-03-05 15:36:35,371:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:36:35,371:INFO:Checking environment
2025-03-05 15:36:35,371:INFO:python_version: 3.9.21
2025-03-05 15:36:35,372:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:36:35,372:INFO:machine: x86_64
2025-03-05 15:36:35,372:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:36:35,372:INFO:Memory: svmem(total=33374507008, available=21285605376, percent=36.2, used=9516986368, free=3734446080, active=13611028480, inactive=11845419008, buffers=680398848, cached=19442675712, shared=2042798080, slab=1828556800)
2025-03-05 15:36:35,373:INFO:Physical Core: 24
2025-03-05 15:36:35,373:INFO:Logical Core: 32
2025-03-05 15:36:35,373:INFO:Checking libraries
2025-03-05 15:36:35,373:INFO:System:
2025-03-05 15:36:35,373:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:36:35,373:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:36:35,373:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:36:35,373:INFO:PyCaret required dependencies:
2025-03-05 15:36:35,373:INFO:                 pip: 25.0
2025-03-05 15:36:35,373:INFO:          setuptools: 75.8.0
2025-03-05 15:36:35,373:INFO:             pycaret: 3.3.1
2025-03-05 15:36:35,373:INFO:             IPython: 8.18.1
2025-03-05 15:36:35,373:INFO:          ipywidgets: 8.1.5
2025-03-05 15:36:35,373:INFO:                tqdm: 4.67.1
2025-03-05 15:36:35,373:INFO:               numpy: 1.26.4
2025-03-05 15:36:35,373:INFO:              pandas: 2.1.4
2025-03-05 15:36:35,373:INFO:              jinja2: 3.1.5
2025-03-05 15:36:35,373:INFO:               scipy: 1.11.4
2025-03-05 15:36:35,373:INFO:              joblib: 1.3.2
2025-03-05 15:36:35,373:INFO:             sklearn: 1.4.2
2025-03-05 15:36:35,373:INFO:                pyod: 2.0.3
2025-03-05 15:36:35,373:INFO:            imblearn: 0.12.4
2025-03-05 15:36:35,373:INFO:   category_encoders: 2.6.4
2025-03-05 15:36:35,373:INFO:            lightgbm: 4.6.0
2025-03-05 15:36:35,373:INFO:               numba: 0.60.0
2025-03-05 15:36:35,373:INFO:            requests: 2.32.3
2025-03-05 15:36:35,373:INFO:          matplotlib: 3.7.5
2025-03-05 15:36:35,373:INFO:          scikitplot: 0.3.7
2025-03-05 15:36:35,373:INFO:         yellowbrick: 1.5
2025-03-05 15:36:35,373:INFO:              plotly: 5.24.1
2025-03-05 15:36:35,373:INFO:    plotly-resampler: Not installed
2025-03-05 15:36:35,373:INFO:             kaleido: 0.2.1
2025-03-05 15:36:35,373:INFO:           schemdraw: 0.15
2025-03-05 15:36:35,373:INFO:         statsmodels: 0.14.4
2025-03-05 15:36:35,373:INFO:              sktime: 0.26.0
2025-03-05 15:36:35,373:INFO:               tbats: 1.1.3
2025-03-05 15:36:35,373:INFO:            pmdarima: 2.0.4
2025-03-05 15:36:35,373:INFO:              psutil: 7.0.0
2025-03-05 15:36:35,373:INFO:          markupsafe: 3.0.2
2025-03-05 15:36:35,373:INFO:             pickle5: Not installed
2025-03-05 15:36:35,373:INFO:         cloudpickle: 3.1.1
2025-03-05 15:36:35,373:INFO:         deprecation: 2.1.0
2025-03-05 15:36:35,373:INFO:              xxhash: 3.5.0
2025-03-05 15:36:35,373:INFO:           wurlitzer: 3.1.1
2025-03-05 15:36:35,373:INFO:PyCaret optional dependencies:
2025-03-05 15:36:35,373:INFO:                shap: Not installed
2025-03-05 15:36:35,373:INFO:           interpret: Not installed
2025-03-05 15:36:35,373:INFO:                umap: Not installed
2025-03-05 15:36:35,374:INFO:     ydata_profiling: Not installed
2025-03-05 15:36:35,374:INFO:  explainerdashboard: Not installed
2025-03-05 15:36:35,374:INFO:             autoviz: Not installed
2025-03-05 15:36:35,374:INFO:           fairlearn: Not installed
2025-03-05 15:36:35,374:INFO:          deepchecks: Not installed
2025-03-05 15:36:35,374:INFO:             xgboost: Not installed
2025-03-05 15:36:35,374:INFO:            catboost: Not installed
2025-03-05 15:36:35,374:INFO:              kmodes: Not installed
2025-03-05 15:36:35,374:INFO:             mlxtend: Not installed
2025-03-05 15:36:35,374:INFO:       statsforecast: Not installed
2025-03-05 15:36:35,374:INFO:        tune_sklearn: Not installed
2025-03-05 15:36:35,374:INFO:                 ray: Not installed
2025-03-05 15:36:35,374:INFO:            hyperopt: Not installed
2025-03-05 15:36:35,374:INFO:              optuna: Not installed
2025-03-05 15:36:35,374:INFO:               skopt: Not installed
2025-03-05 15:36:35,374:INFO:              mlflow: Not installed
2025-03-05 15:36:35,374:INFO:              gradio: Not installed
2025-03-05 15:36:35,374:INFO:             fastapi: Not installed
2025-03-05 15:36:35,374:INFO:             uvicorn: Not installed
2025-03-05 15:36:35,374:INFO:              m2cgen: Not installed
2025-03-05 15:36:35,374:INFO:           evidently: Not installed
2025-03-05 15:36:35,374:INFO:               fugue: Not installed
2025-03-05 15:36:35,374:INFO:           streamlit: Not installed
2025-03-05 15:36:35,374:INFO:             prophet: Not installed
2025-03-05 15:36:35,374:INFO:None
2025-03-05 15:36:35,374:INFO:Set up GPU usage.
2025-03-05 15:36:35,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,374:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:36:35,374:INFO:Set up data.
2025-03-05 15:36:35,377:INFO:Set up folding strategy.
2025-03-05 15:36:35,377:INFO:Set up train/test split.
2025-03-05 15:36:35,381:INFO:Set up index.
2025-03-05 15:36:35,381:INFO:Assigning column types.
2025-03-05 15:36:35,384:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:36:35,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,384:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,388:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,392:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,484:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,496:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,600:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:36:35,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,607:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,614:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,828:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:36:35,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,839:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:35,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:35,956:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:36:35,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,015:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,057:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:36:36,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,264:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:36:36,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:36:36,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,472:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:36:36,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,678:INFO:Preparing preprocessing pipeline...
2025-03-05 15:36:36,679:INFO:Set up simple imputation.
2025-03-05 15:36:36,679:INFO:Set up polynomial features.
2025-03-05 15:36:36,679:INFO:Set up feature normalization.
2025-03-05 15:36:36,679:INFO:Set up column name cleaning.
2025-03-05 15:36:36,720:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:36:36,726:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 15:36:36,726:INFO:Creating final display dataframe.
2025-03-05 15:36:36,827:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape       (20088, 10)
5   Transformed train set shape       (14061, 10)
6    Transformed test set shape        (6027, 10)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 3
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU              True
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f717
2025-03-05 15:36:36,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:36,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:36,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:37,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:37,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:37,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:36:37,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:37,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:36:37,050:INFO:setup() successfully completed in 1.68s...............
2025-03-05 15:36:37,092:INFO:Initializing compare_models()
2025-03-05 15:36:37,092:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:36:37,093:INFO:Checking exceptions
2025-03-05 15:36:37,096:INFO:Preparing display monitor
2025-03-05 15:36:37,115:INFO:Initializing Linear Regression
2025-03-05 15:36:37,115:INFO:Total runtime is 2.6464462280273437e-06 minutes
2025-03-05 15:36:37,118:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:37,118:INFO:Initializing create_model()
2025-03-05 15:36:37,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:37,118:INFO:Checking exceptions
2025-03-05 15:36:37,118:INFO:Importing libraries
2025-03-05 15:36:37,118:INFO:Copying training dataset
2025-03-05 15:36:37,123:INFO:Defining folds
2025-03-05 15:36:37,123:INFO:Declaring metric variables
2025-03-05 15:36:37,126:INFO:Importing untrained model
2025-03-05 15:36:37,129:INFO:Linear Regression Imported successfully
2025-03-05 15:36:37,135:INFO:Starting cross validation
2025-03-05 15:36:37,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:37,496:INFO:Calculating mean and std
2025-03-05 15:36:37,496:INFO:Creating metrics dataframe
2025-03-05 15:36:37,498:INFO:Uploading results into container
2025-03-05 15:36:37,505:INFO:Uploading model into container now
2025-03-05 15:36:37,506:INFO:_master_model_container: 1
2025-03-05 15:36:37,506:INFO:_display_container: 2
2025-03-05 15:36:37,507:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:36:37,508:INFO:create_model() successfully completed......................................
2025-03-05 15:36:37,674:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:37,674:INFO:Creating metrics dataframe
2025-03-05 15:36:37,680:INFO:Initializing Lasso Regression
2025-03-05 15:36:37,680:INFO:Total runtime is 0.009428179264068604 minutes
2025-03-05 15:36:37,683:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:37,684:INFO:Initializing create_model()
2025-03-05 15:36:37,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:37,684:INFO:Checking exceptions
2025-03-05 15:36:37,684:INFO:Importing libraries
2025-03-05 15:36:37,684:INFO:Copying training dataset
2025-03-05 15:36:37,688:INFO:Defining folds
2025-03-05 15:36:37,688:INFO:Declaring metric variables
2025-03-05 15:36:37,691:INFO:Importing untrained model
2025-03-05 15:36:37,694:INFO:Lasso Regression Imported successfully
2025-03-05 15:36:37,699:INFO:Starting cross validation
2025-03-05 15:36:37,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:38,106:INFO:Calculating mean and std
2025-03-05 15:36:38,107:INFO:Creating metrics dataframe
2025-03-05 15:36:38,111:INFO:Uploading results into container
2025-03-05 15:36:38,112:INFO:Uploading model into container now
2025-03-05 15:36:38,113:INFO:_master_model_container: 2
2025-03-05 15:36:38,113:INFO:_display_container: 2
2025-03-05 15:36:38,114:INFO:Lasso(random_state=123)
2025-03-05 15:36:38,114:INFO:create_model() successfully completed......................................
2025-03-05 15:36:38,269:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:38,270:INFO:Creating metrics dataframe
2025-03-05 15:36:38,276:INFO:Initializing Ridge Regression
2025-03-05 15:36:38,276:INFO:Total runtime is 0.01935875415802002 minutes
2025-03-05 15:36:38,279:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:38,279:INFO:Initializing create_model()
2025-03-05 15:36:38,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:38,279:INFO:Checking exceptions
2025-03-05 15:36:38,280:INFO:Importing libraries
2025-03-05 15:36:38,280:INFO:Copying training dataset
2025-03-05 15:36:38,284:INFO:Defining folds
2025-03-05 15:36:38,284:INFO:Declaring metric variables
2025-03-05 15:36:38,287:INFO:Importing untrained model
2025-03-05 15:36:38,290:INFO:Ridge Regression Imported successfully
2025-03-05 15:36:38,297:INFO:Starting cross validation
2025-03-05 15:36:38,298:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:38,652:INFO:Calculating mean and std
2025-03-05 15:36:38,653:INFO:Creating metrics dataframe
2025-03-05 15:36:38,655:INFO:Uploading results into container
2025-03-05 15:36:38,656:INFO:Uploading model into container now
2025-03-05 15:36:38,656:INFO:_master_model_container: 3
2025-03-05 15:36:38,657:INFO:_display_container: 2
2025-03-05 15:36:38,658:INFO:Ridge(random_state=123)
2025-03-05 15:36:38,658:INFO:create_model() successfully completed......................................
2025-03-05 15:36:38,844:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:38,845:INFO:Creating metrics dataframe
2025-03-05 15:36:38,852:INFO:Initializing Elastic Net
2025-03-05 15:36:38,852:INFO:Total runtime is 0.028955849011739095 minutes
2025-03-05 15:36:38,855:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:38,855:INFO:Initializing create_model()
2025-03-05 15:36:38,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:38,856:INFO:Checking exceptions
2025-03-05 15:36:38,856:INFO:Importing libraries
2025-03-05 15:36:38,856:INFO:Copying training dataset
2025-03-05 15:36:38,860:INFO:Defining folds
2025-03-05 15:36:38,861:INFO:Declaring metric variables
2025-03-05 15:36:38,864:INFO:Importing untrained model
2025-03-05 15:36:38,867:INFO:Elastic Net Imported successfully
2025-03-05 15:36:38,873:INFO:Starting cross validation
2025-03-05 15:36:38,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:39,854:INFO:Calculating mean and std
2025-03-05 15:36:39,857:INFO:Creating metrics dataframe
2025-03-05 15:36:39,861:INFO:Uploading results into container
2025-03-05 15:36:39,864:INFO:Uploading model into container now
2025-03-05 15:36:39,865:INFO:_master_model_container: 4
2025-03-05 15:36:39,865:INFO:_display_container: 2
2025-03-05 15:36:39,865:INFO:ElasticNet(random_state=123)
2025-03-05 15:36:39,865:INFO:create_model() successfully completed......................................
2025-03-05 15:36:40,035:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:40,035:INFO:Creating metrics dataframe
2025-03-05 15:36:40,042:INFO:Initializing Least Angle Regression
2025-03-05 15:36:40,042:INFO:Total runtime is 0.048790649573008216 minutes
2025-03-05 15:36:40,045:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:40,046:INFO:Initializing create_model()
2025-03-05 15:36:40,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:40,046:INFO:Checking exceptions
2025-03-05 15:36:40,046:INFO:Importing libraries
2025-03-05 15:36:40,046:INFO:Copying training dataset
2025-03-05 15:36:40,050:INFO:Defining folds
2025-03-05 15:36:40,051:INFO:Declaring metric variables
2025-03-05 15:36:40,054:INFO:Importing untrained model
2025-03-05 15:36:40,057:INFO:Least Angle Regression Imported successfully
2025-03-05 15:36:40,063:INFO:Starting cross validation
2025-03-05 15:36:40,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:40,432:INFO:Calculating mean and std
2025-03-05 15:36:40,433:INFO:Creating metrics dataframe
2025-03-05 15:36:40,438:INFO:Uploading results into container
2025-03-05 15:36:40,438:INFO:Uploading model into container now
2025-03-05 15:36:40,439:INFO:_master_model_container: 5
2025-03-05 15:36:40,439:INFO:_display_container: 2
2025-03-05 15:36:40,440:INFO:Lars(random_state=123)
2025-03-05 15:36:40,440:INFO:create_model() successfully completed......................................
2025-03-05 15:36:40,600:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:40,600:INFO:Creating metrics dataframe
2025-03-05 15:36:40,607:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:36:40,607:INFO:Total runtime is 0.05821349620819091 minutes
2025-03-05 15:36:40,611:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:40,611:INFO:Initializing create_model()
2025-03-05 15:36:40,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:40,611:INFO:Checking exceptions
2025-03-05 15:36:40,611:INFO:Importing libraries
2025-03-05 15:36:40,611:INFO:Copying training dataset
2025-03-05 15:36:40,616:INFO:Defining folds
2025-03-05 15:36:40,616:INFO:Declaring metric variables
2025-03-05 15:36:40,619:INFO:Importing untrained model
2025-03-05 15:36:40,622:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:36:40,628:INFO:Starting cross validation
2025-03-05 15:36:40,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:41,150:INFO:Calculating mean and std
2025-03-05 15:36:41,152:INFO:Creating metrics dataframe
2025-03-05 15:36:41,156:INFO:Uploading results into container
2025-03-05 15:36:41,156:INFO:Uploading model into container now
2025-03-05 15:36:41,157:INFO:_master_model_container: 6
2025-03-05 15:36:41,157:INFO:_display_container: 2
2025-03-05 15:36:41,157:INFO:LassoLars(random_state=123)
2025-03-05 15:36:41,158:INFO:create_model() successfully completed......................................
2025-03-05 15:36:41,321:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:41,321:INFO:Creating metrics dataframe
2025-03-05 15:36:41,329:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:36:41,329:INFO:Total runtime is 0.07023365100224813 minutes
2025-03-05 15:36:41,332:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:41,333:INFO:Initializing create_model()
2025-03-05 15:36:41,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:41,333:INFO:Checking exceptions
2025-03-05 15:36:41,333:INFO:Importing libraries
2025-03-05 15:36:41,333:INFO:Copying training dataset
2025-03-05 15:36:41,338:INFO:Defining folds
2025-03-05 15:36:41,338:INFO:Declaring metric variables
2025-03-05 15:36:41,342:INFO:Importing untrained model
2025-03-05 15:36:41,345:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:36:41,352:INFO:Starting cross validation
2025-03-05 15:36:41,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:41,753:INFO:Calculating mean and std
2025-03-05 15:36:41,754:INFO:Creating metrics dataframe
2025-03-05 15:36:41,758:INFO:Uploading results into container
2025-03-05 15:36:41,759:INFO:Uploading model into container now
2025-03-05 15:36:41,760:INFO:_master_model_container: 7
2025-03-05 15:36:41,760:INFO:_display_container: 2
2025-03-05 15:36:41,760:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:36:41,760:INFO:create_model() successfully completed......................................
2025-03-05 15:36:41,909:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:41,909:INFO:Creating metrics dataframe
2025-03-05 15:36:41,917:INFO:Initializing Bayesian Ridge
2025-03-05 15:36:41,917:INFO:Total runtime is 0.08004692395528157 minutes
2025-03-05 15:36:41,921:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:41,921:INFO:Initializing create_model()
2025-03-05 15:36:41,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:41,921:INFO:Checking exceptions
2025-03-05 15:36:41,921:INFO:Importing libraries
2025-03-05 15:36:41,921:INFO:Copying training dataset
2025-03-05 15:36:41,926:INFO:Defining folds
2025-03-05 15:36:41,926:INFO:Declaring metric variables
2025-03-05 15:36:41,929:INFO:Importing untrained model
2025-03-05 15:36:41,933:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:36:41,938:INFO:Starting cross validation
2025-03-05 15:36:41,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:43,277:INFO:Calculating mean and std
2025-03-05 15:36:43,278:INFO:Creating metrics dataframe
2025-03-05 15:36:43,281:INFO:Uploading results into container
2025-03-05 15:36:43,282:INFO:Uploading model into container now
2025-03-05 15:36:43,283:INFO:_master_model_container: 8
2025-03-05 15:36:43,283:INFO:_display_container: 2
2025-03-05 15:36:43,283:INFO:BayesianRidge()
2025-03-05 15:36:43,283:INFO:create_model() successfully completed......................................
2025-03-05 15:36:43,419:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:43,419:INFO:Creating metrics dataframe
2025-03-05 15:36:43,427:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:36:43,427:INFO:Total runtime is 0.105210808912913 minutes
2025-03-05 15:36:43,430:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:43,431:INFO:Initializing create_model()
2025-03-05 15:36:43,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:43,431:INFO:Checking exceptions
2025-03-05 15:36:43,431:INFO:Importing libraries
2025-03-05 15:36:43,431:INFO:Copying training dataset
2025-03-05 15:36:43,436:INFO:Defining folds
2025-03-05 15:36:43,436:INFO:Declaring metric variables
2025-03-05 15:36:43,439:INFO:Importing untrained model
2025-03-05 15:36:43,443:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:36:43,449:INFO:Starting cross validation
2025-03-05 15:36:43,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:43,918:INFO:Calculating mean and std
2025-03-05 15:36:43,919:INFO:Creating metrics dataframe
2025-03-05 15:36:43,921:INFO:Uploading results into container
2025-03-05 15:36:43,923:INFO:Uploading model into container now
2025-03-05 15:36:43,924:INFO:_master_model_container: 9
2025-03-05 15:36:43,924:INFO:_display_container: 2
2025-03-05 15:36:43,925:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:36:43,925:INFO:create_model() successfully completed......................................
2025-03-05 15:36:44,078:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:44,078:INFO:Creating metrics dataframe
2025-03-05 15:36:44,086:INFO:Initializing Huber Regressor
2025-03-05 15:36:44,087:INFO:Total runtime is 0.11619886954625447 minutes
2025-03-05 15:36:44,090:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:44,090:INFO:Initializing create_model()
2025-03-05 15:36:44,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:44,090:INFO:Checking exceptions
2025-03-05 15:36:44,090:INFO:Importing libraries
2025-03-05 15:36:44,090:INFO:Copying training dataset
2025-03-05 15:36:44,095:INFO:Defining folds
2025-03-05 15:36:44,095:INFO:Declaring metric variables
2025-03-05 15:36:44,098:INFO:Importing untrained model
2025-03-05 15:36:44,102:INFO:Huber Regressor Imported successfully
2025-03-05 15:36:44,108:INFO:Starting cross validation
2025-03-05 15:36:44,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:44,539:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:44,985:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:45,567:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:46,080:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:46,483:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:47,124:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:47,484:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:47,759:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:48,084:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:48,418:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:36:48,439:INFO:Calculating mean and std
2025-03-05 15:36:48,441:INFO:Creating metrics dataframe
2025-03-05 15:36:48,444:INFO:Uploading results into container
2025-03-05 15:36:48,447:INFO:Uploading model into container now
2025-03-05 15:36:48,449:INFO:_master_model_container: 10
2025-03-05 15:36:48,449:INFO:_display_container: 2
2025-03-05 15:36:48,449:INFO:HuberRegressor()
2025-03-05 15:36:48,449:INFO:create_model() successfully completed......................................
2025-03-05 15:36:48,612:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:48,612:INFO:Creating metrics dataframe
2025-03-05 15:36:48,621:INFO:Initializing K Neighbors Regressor
2025-03-05 15:36:48,621:INFO:Total runtime is 0.19176912705103555 minutes
2025-03-05 15:36:48,624:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:48,624:INFO:Initializing create_model()
2025-03-05 15:36:48,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:48,624:INFO:Checking exceptions
2025-03-05 15:36:48,625:INFO:Importing libraries
2025-03-05 15:36:48,625:INFO:Copying training dataset
2025-03-05 15:36:48,630:INFO:Defining folds
2025-03-05 15:36:48,630:INFO:Declaring metric variables
2025-03-05 15:36:48,633:INFO:Importing untrained model
2025-03-05 15:36:48,637:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:36:48,643:INFO:Starting cross validation
2025-03-05 15:36:48,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:49,438:INFO:Calculating mean and std
2025-03-05 15:36:49,441:INFO:Creating metrics dataframe
2025-03-05 15:36:49,443:INFO:Uploading results into container
2025-03-05 15:36:49,443:INFO:Uploading model into container now
2025-03-05 15:36:49,444:INFO:_master_model_container: 11
2025-03-05 15:36:49,444:INFO:_display_container: 2
2025-03-05 15:36:49,444:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:36:49,444:INFO:create_model() successfully completed......................................
2025-03-05 15:36:49,563:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:49,563:INFO:Creating metrics dataframe
2025-03-05 15:36:49,573:INFO:Initializing Decision Tree Regressor
2025-03-05 15:36:49,573:INFO:Total runtime is 0.20764206647872924 minutes
2025-03-05 15:36:49,577:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:49,577:INFO:Initializing create_model()
2025-03-05 15:36:49,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:49,577:INFO:Checking exceptions
2025-03-05 15:36:49,577:INFO:Importing libraries
2025-03-05 15:36:49,577:INFO:Copying training dataset
2025-03-05 15:36:49,582:INFO:Defining folds
2025-03-05 15:36:49,582:INFO:Declaring metric variables
2025-03-05 15:36:49,585:INFO:Importing untrained model
2025-03-05 15:36:49,588:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:36:49,594:INFO:Starting cross validation
2025-03-05 15:36:49,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:50,058:INFO:Calculating mean and std
2025-03-05 15:36:50,059:INFO:Creating metrics dataframe
2025-03-05 15:36:50,061:INFO:Uploading results into container
2025-03-05 15:36:50,061:INFO:Uploading model into container now
2025-03-05 15:36:50,062:INFO:_master_model_container: 12
2025-03-05 15:36:50,062:INFO:_display_container: 2
2025-03-05 15:36:50,062:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:36:50,062:INFO:create_model() successfully completed......................................
2025-03-05 15:36:50,181:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:50,182:INFO:Creating metrics dataframe
2025-03-05 15:36:50,191:INFO:Initializing Random Forest Regressor
2025-03-05 15:36:50,191:INFO:Total runtime is 0.21793503363927205 minutes
2025-03-05 15:36:50,195:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:50,195:INFO:Initializing create_model()
2025-03-05 15:36:50,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:50,195:INFO:Checking exceptions
2025-03-05 15:36:50,195:INFO:Importing libraries
2025-03-05 15:36:50,195:INFO:Copying training dataset
2025-03-05 15:36:50,200:INFO:Defining folds
2025-03-05 15:36:50,200:INFO:Declaring metric variables
2025-03-05 15:36:50,203:INFO:Importing untrained model
2025-03-05 15:36:50,206:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:36:50,212:INFO:Starting cross validation
2025-03-05 15:36:50,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:53,194:INFO:Calculating mean and std
2025-03-05 15:36:53,196:INFO:Creating metrics dataframe
2025-03-05 15:36:53,199:INFO:Uploading results into container
2025-03-05 15:36:53,200:INFO:Uploading model into container now
2025-03-05 15:36:53,201:INFO:_master_model_container: 13
2025-03-05 15:36:53,201:INFO:_display_container: 2
2025-03-05 15:36:53,201:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:36:53,201:INFO:create_model() successfully completed......................................
2025-03-05 15:36:53,326:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:53,326:INFO:Creating metrics dataframe
2025-03-05 15:36:53,335:INFO:Initializing Extra Trees Regressor
2025-03-05 15:36:53,335:INFO:Total runtime is 0.27034087975819904 minutes
2025-03-05 15:36:53,338:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:53,339:INFO:Initializing create_model()
2025-03-05 15:36:53,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:53,339:INFO:Checking exceptions
2025-03-05 15:36:53,339:INFO:Importing libraries
2025-03-05 15:36:53,339:INFO:Copying training dataset
2025-03-05 15:36:53,346:INFO:Defining folds
2025-03-05 15:36:53,346:INFO:Declaring metric variables
2025-03-05 15:36:53,349:INFO:Importing untrained model
2025-03-05 15:36:53,353:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:36:53,359:INFO:Starting cross validation
2025-03-05 15:36:53,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:55,274:INFO:Calculating mean and std
2025-03-05 15:36:55,275:INFO:Creating metrics dataframe
2025-03-05 15:36:55,278:INFO:Uploading results into container
2025-03-05 15:36:55,278:INFO:Uploading model into container now
2025-03-05 15:36:55,279:INFO:_master_model_container: 14
2025-03-05 15:36:55,279:INFO:_display_container: 2
2025-03-05 15:36:55,279:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:36:55,279:INFO:create_model() successfully completed......................................
2025-03-05 15:36:55,400:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:55,401:INFO:Creating metrics dataframe
2025-03-05 15:36:55,411:INFO:Initializing AdaBoost Regressor
2025-03-05 15:36:55,411:INFO:Total runtime is 0.30494022369384766 minutes
2025-03-05 15:36:55,415:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:55,415:INFO:Initializing create_model()
2025-03-05 15:36:55,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:55,415:INFO:Checking exceptions
2025-03-05 15:36:55,415:INFO:Importing libraries
2025-03-05 15:36:55,415:INFO:Copying training dataset
2025-03-05 15:36:55,420:INFO:Defining folds
2025-03-05 15:36:55,420:INFO:Declaring metric variables
2025-03-05 15:36:55,424:INFO:Importing untrained model
2025-03-05 15:36:55,427:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:36:55,433:INFO:Starting cross validation
2025-03-05 15:36:55,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:36:59,321:INFO:Calculating mean and std
2025-03-05 15:36:59,323:INFO:Creating metrics dataframe
2025-03-05 15:36:59,324:INFO:Uploading results into container
2025-03-05 15:36:59,325:INFO:Uploading model into container now
2025-03-05 15:36:59,326:INFO:_master_model_container: 15
2025-03-05 15:36:59,326:INFO:_display_container: 2
2025-03-05 15:36:59,326:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:36:59,326:INFO:create_model() successfully completed......................................
2025-03-05 15:36:59,451:INFO:SubProcess create_model() end ==================================
2025-03-05 15:36:59,451:INFO:Creating metrics dataframe
2025-03-05 15:36:59,460:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:36:59,460:INFO:Total runtime is 0.3724243919054667 minutes
2025-03-05 15:36:59,463:INFO:SubProcess create_model() called ==================================
2025-03-05 15:36:59,464:INFO:Initializing create_model()
2025-03-05 15:36:59,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:36:59,464:INFO:Checking exceptions
2025-03-05 15:36:59,464:INFO:Importing libraries
2025-03-05 15:36:59,464:INFO:Copying training dataset
2025-03-05 15:36:59,468:INFO:Defining folds
2025-03-05 15:36:59,468:INFO:Declaring metric variables
2025-03-05 15:36:59,472:INFO:Importing untrained model
2025-03-05 15:36:59,475:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:36:59,480:INFO:Starting cross validation
2025-03-05 15:36:59,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:11,003:INFO:Calculating mean and std
2025-03-05 15:37:11,004:INFO:Creating metrics dataframe
2025-03-05 15:37:11,006:INFO:Uploading results into container
2025-03-05 15:37:11,006:INFO:Uploading model into container now
2025-03-05 15:37:11,007:INFO:_master_model_container: 16
2025-03-05 15:37:11,007:INFO:_display_container: 2
2025-03-05 15:37:11,007:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:37:11,007:INFO:create_model() successfully completed......................................
2025-03-05 15:37:11,128:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:11,128:INFO:Creating metrics dataframe
2025-03-05 15:37:11,137:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:37:11,137:INFO:Total runtime is 0.5670430739720662 minutes
2025-03-05 15:37:11,141:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:11,141:INFO:Initializing create_model()
2025-03-05 15:37:11,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:11,141:INFO:Checking exceptions
2025-03-05 15:37:11,141:INFO:Importing libraries
2025-03-05 15:37:11,141:INFO:Copying training dataset
2025-03-05 15:37:11,146:INFO:Defining folds
2025-03-05 15:37:11,146:INFO:Declaring metric variables
2025-03-05 15:37:11,149:INFO:Importing untrained model
2025-03-05 15:37:11,153:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:37:11,159:INFO:Starting cross validation
2025-03-05 15:37:11,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:11,207:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:11,242:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035134 seconds.
2025-03-05 15:37:11,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:11,243:INFO:[LightGBM] [Info] Total Bins 1394
2025-03-05 15:37:11,255:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 9
2025-03-05 15:37:11,272:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:37:12,549:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:12,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028407 seconds.
2025-03-05 15:37:12,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:12,578:INFO:[LightGBM] [Info] Total Bins 1391
2025-03-05 15:37:12,585:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:12,601:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:37:13,840:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:13,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031412 seconds.
2025-03-05 15:37:13,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:13,872:INFO:[LightGBM] [Info] Total Bins 1391
2025-03-05 15:37:13,878:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:13,893:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:37:15,783:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:15,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033349 seconds.
2025-03-05 15:37:15,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:15,817:INFO:[LightGBM] [Info] Total Bins 1390
2025-03-05 15:37:15,825:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:15,841:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:37:17,361:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:17,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-03-05 15:37:17,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:17,363:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:37:17,366:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:17,366:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:37:17,975:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:17,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000277 seconds.
2025-03-05 15:37:17,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 15:37:17,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 15:37:17,977:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:37:17,977:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:17,977:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:37:18,636:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:18,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2025-03-05 15:37:18,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:18,637:INFO:[LightGBM] [Info] Total Bins 1387
2025-03-05 15:37:18,639:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:18,640:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:37:19,227:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:19,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.
2025-03-05 15:37:19,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:19,229:INFO:[LightGBM] [Info] Total Bins 1390
2025-03-05 15:37:19,229:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:19,229:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:37:19,782:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:19,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2025-03-05 15:37:19,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:37:19,783:INFO:[LightGBM] [Info] Total Bins 1397
2025-03-05 15:37:19,783:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:19,786:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:37:20,491:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:37:20,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003099 seconds.
2025-03-05 15:37:20,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 15:37:20,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 15:37:20,495:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:37:20,495:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:37:20,495:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:37:22,249:INFO:Calculating mean and std
2025-03-05 15:37:22,250:INFO:Creating metrics dataframe
2025-03-05 15:37:22,252:INFO:Uploading results into container
2025-03-05 15:37:22,253:INFO:Uploading model into container now
2025-03-05 15:37:22,254:INFO:_master_model_container: 17
2025-03-05 15:37:22,254:INFO:_display_container: 2
2025-03-05 15:37:22,254:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:37:22,254:INFO:create_model() successfully completed......................................
2025-03-05 15:37:22,385:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:22,385:INFO:Creating metrics dataframe
2025-03-05 15:37:22,394:INFO:Initializing Dummy Regressor
2025-03-05 15:37:22,394:INFO:Total runtime is 0.7546638131141662 minutes
2025-03-05 15:37:22,398:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:22,398:INFO:Initializing create_model()
2025-03-05 15:37:22,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d28634c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:22,398:INFO:Checking exceptions
2025-03-05 15:37:22,398:INFO:Importing libraries
2025-03-05 15:37:22,398:INFO:Copying training dataset
2025-03-05 15:37:22,403:INFO:Defining folds
2025-03-05 15:37:22,403:INFO:Declaring metric variables
2025-03-05 15:37:22,406:INFO:Importing untrained model
2025-03-05 15:37:22,409:INFO:Dummy Regressor Imported successfully
2025-03-05 15:37:22,414:INFO:Starting cross validation
2025-03-05 15:37:22,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:22,671:INFO:Calculating mean and std
2025-03-05 15:37:22,672:INFO:Creating metrics dataframe
2025-03-05 15:37:22,674:INFO:Uploading results into container
2025-03-05 15:37:22,675:INFO:Uploading model into container now
2025-03-05 15:37:22,675:INFO:_master_model_container: 18
2025-03-05 15:37:22,676:INFO:_display_container: 2
2025-03-05 15:37:22,676:INFO:DummyRegressor()
2025-03-05 15:37:22,676:INFO:create_model() successfully completed......................................
2025-03-05 15:37:22,797:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:22,797:INFO:Creating metrics dataframe
2025-03-05 15:37:22,807:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:37:22,816:INFO:Initializing create_model()
2025-03-05 15:37:22,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:22,816:INFO:Checking exceptions
2025-03-05 15:37:22,818:INFO:Importing libraries
2025-03-05 15:37:22,818:INFO:Copying training dataset
2025-03-05 15:37:22,822:INFO:Defining folds
2025-03-05 15:37:22,822:INFO:Declaring metric variables
2025-03-05 15:37:22,822:INFO:Importing untrained model
2025-03-05 15:37:22,822:INFO:Declaring custom model
2025-03-05 15:37:22,823:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:37:22,824:INFO:Cross validation set to False
2025-03-05 15:37:22,825:INFO:Fitting Model
2025-03-05 15:37:24,070:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:37:24,070:INFO:create_model() successfully completed......................................
2025-03-05 15:37:24,219:INFO:_master_model_container: 18
2025-03-05 15:37:24,219:INFO:_display_container: 2
2025-03-05 15:37:24,220:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:37:24,220:INFO:compare_models() successfully completed......................................
2025-03-05 15:37:24,258:INFO:Initializing evaluate_model()
2025-03-05 15:37:24,259:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 15:37:24,267:INFO:Initializing plot_model()
2025-03-05 15:37:24,267:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, system=True)
2025-03-05 15:37:24,267:INFO:Checking exceptions
2025-03-05 15:37:24,269:INFO:Preloading libraries
2025-03-05 15:37:24,275:INFO:Copying training dataset
2025-03-05 15:37:24,275:INFO:Plot type: pipeline
2025-03-05 15:37:24,389:INFO:Visual Rendered Successfully
2025-03-05 15:37:24,507:INFO:plot_model() successfully completed......................................
2025-03-05 15:37:24,542:INFO:Initializing plot_model()
2025-03-05 15:37:24,542:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, system=True)
2025-03-05 15:37:24,542:INFO:Checking exceptions
2025-03-05 15:37:24,547:INFO:Preloading libraries
2025-03-05 15:37:24,554:INFO:Copying training dataset
2025-03-05 15:37:24,554:INFO:Plot type: residuals
2025-03-05 15:37:24,698:INFO:Fitting Model
2025-03-05 15:37:24,698:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 15:37:24,782:INFO:Scoring test/hold-out set
2025-03-05 15:37:25,275:INFO:Visual Rendered Successfully
2025-03-05 15:37:25,402:INFO:plot_model() successfully completed......................................
2025-03-05 15:37:25,456:INFO:Initializing plot_model()
2025-03-05 15:37:25,456:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, system=True)
2025-03-05 15:37:25,456:INFO:Checking exceptions
2025-03-05 15:37:25,462:INFO:Preloading libraries
2025-03-05 15:37:25,467:INFO:Copying training dataset
2025-03-05 15:37:25,467:INFO:Plot type: feature
2025-03-05 15:37:25,468:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:37:25,628:INFO:Visual Rendered Successfully
2025-03-05 15:37:25,750:INFO:plot_model() successfully completed......................................
2025-03-05 15:37:25,767:INFO:Initializing predict_model()
2025-03-05 15:37:25,767:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445d0d79e50>)
2025-03-05 15:37:25,767:INFO:Checking exceptions
2025-03-05 15:37:25,768:INFO:Preloading libraries
2025-03-05 15:37:25,835:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:37:26,055:INFO:Initializing predict_model()
2025-03-05 15:37:26,055:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445cebfeb80>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445d0d791f0>)
2025-03-05 15:37:26,055:INFO:Checking exceptions
2025-03-05 15:37:26,055:INFO:Preloading libraries
2025-03-05 15:37:26,057:INFO:Set up data.
2025-03-05 15:37:26,061:INFO:Set up index.
2025-03-05 15:37:26,106:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:37:47,145:INFO:PyCaret RegressionExperiment
2025-03-05 15:37:47,145:INFO:Logging name: reg-default-name
2025-03-05 15:37:47,145:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:37:47,146:INFO:version 3.3.1
2025-03-05 15:37:47,146:INFO:Initializing setup()
2025-03-05 15:37:47,146:INFO:self.USI: 0fb0
2025-03-05 15:37:47,146:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:37:47,146:INFO:Checking environment
2025-03-05 15:37:47,146:INFO:python_version: 3.9.21
2025-03-05 15:37:47,146:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:37:47,146:INFO:machine: x86_64
2025-03-05 15:37:47,146:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:37:47,146:INFO:Memory: svmem(total=33374507008, available=21332750336, percent=36.1, used=9462173696, free=3775004672, active=13555912704, inactive=11849629696, buffers=680988672, cached=19456339968, shared=2050494464, slab=1828667392)
2025-03-05 15:37:47,148:INFO:Physical Core: 24
2025-03-05 15:37:47,148:INFO:Logical Core: 32
2025-03-05 15:37:47,148:INFO:Checking libraries
2025-03-05 15:37:47,148:INFO:System:
2025-03-05 15:37:47,148:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:37:47,148:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:37:47,149:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:37:47,149:INFO:PyCaret required dependencies:
2025-03-05 15:37:47,149:INFO:                 pip: 25.0
2025-03-05 15:37:47,149:INFO:          setuptools: 75.8.0
2025-03-05 15:37:47,149:INFO:             pycaret: 3.3.1
2025-03-05 15:37:47,149:INFO:             IPython: 8.18.1
2025-03-05 15:37:47,149:INFO:          ipywidgets: 8.1.5
2025-03-05 15:37:47,149:INFO:                tqdm: 4.67.1
2025-03-05 15:37:47,149:INFO:               numpy: 1.26.4
2025-03-05 15:37:47,149:INFO:              pandas: 2.1.4
2025-03-05 15:37:47,149:INFO:              jinja2: 3.1.5
2025-03-05 15:37:47,149:INFO:               scipy: 1.11.4
2025-03-05 15:37:47,149:INFO:              joblib: 1.3.2
2025-03-05 15:37:47,149:INFO:             sklearn: 1.4.2
2025-03-05 15:37:47,149:INFO:                pyod: 2.0.3
2025-03-05 15:37:47,149:INFO:            imblearn: 0.12.4
2025-03-05 15:37:47,149:INFO:   category_encoders: 2.6.4
2025-03-05 15:37:47,149:INFO:            lightgbm: 4.6.0
2025-03-05 15:37:47,150:INFO:               numba: 0.60.0
2025-03-05 15:37:47,150:INFO:            requests: 2.32.3
2025-03-05 15:37:47,150:INFO:          matplotlib: 3.7.5
2025-03-05 15:37:47,150:INFO:          scikitplot: 0.3.7
2025-03-05 15:37:47,150:INFO:         yellowbrick: 1.5
2025-03-05 15:37:47,150:INFO:              plotly: 5.24.1
2025-03-05 15:37:47,150:INFO:    plotly-resampler: Not installed
2025-03-05 15:37:47,150:INFO:             kaleido: 0.2.1
2025-03-05 15:37:47,150:INFO:           schemdraw: 0.15
2025-03-05 15:37:47,150:INFO:         statsmodels: 0.14.4
2025-03-05 15:37:47,150:INFO:              sktime: 0.26.0
2025-03-05 15:37:47,150:INFO:               tbats: 1.1.3
2025-03-05 15:37:47,150:INFO:            pmdarima: 2.0.4
2025-03-05 15:37:47,150:INFO:              psutil: 7.0.0
2025-03-05 15:37:47,150:INFO:          markupsafe: 3.0.2
2025-03-05 15:37:47,150:INFO:             pickle5: Not installed
2025-03-05 15:37:47,150:INFO:         cloudpickle: 3.1.1
2025-03-05 15:37:47,150:INFO:         deprecation: 2.1.0
2025-03-05 15:37:47,150:INFO:              xxhash: 3.5.0
2025-03-05 15:37:47,150:INFO:           wurlitzer: 3.1.1
2025-03-05 15:37:47,150:INFO:PyCaret optional dependencies:
2025-03-05 15:37:47,151:INFO:                shap: Not installed
2025-03-05 15:37:47,151:INFO:           interpret: Not installed
2025-03-05 15:37:47,151:INFO:                umap: Not installed
2025-03-05 15:37:47,151:INFO:     ydata_profiling: Not installed
2025-03-05 15:37:47,151:INFO:  explainerdashboard: Not installed
2025-03-05 15:37:47,151:INFO:             autoviz: Not installed
2025-03-05 15:37:47,151:INFO:           fairlearn: Not installed
2025-03-05 15:37:47,151:INFO:          deepchecks: Not installed
2025-03-05 15:37:47,151:INFO:             xgboost: Not installed
2025-03-05 15:37:47,151:INFO:            catboost: Not installed
2025-03-05 15:37:47,151:INFO:              kmodes: Not installed
2025-03-05 15:37:47,151:INFO:             mlxtend: Not installed
2025-03-05 15:37:47,151:INFO:       statsforecast: Not installed
2025-03-05 15:37:47,151:INFO:        tune_sklearn: Not installed
2025-03-05 15:37:47,151:INFO:                 ray: Not installed
2025-03-05 15:37:47,151:INFO:            hyperopt: Not installed
2025-03-05 15:37:47,151:INFO:              optuna: Not installed
2025-03-05 15:37:47,151:INFO:               skopt: Not installed
2025-03-05 15:37:47,151:INFO:              mlflow: Not installed
2025-03-05 15:37:47,151:INFO:              gradio: Not installed
2025-03-05 15:37:47,151:INFO:             fastapi: Not installed
2025-03-05 15:37:47,151:INFO:             uvicorn: Not installed
2025-03-05 15:37:47,151:INFO:              m2cgen: Not installed
2025-03-05 15:37:47,151:INFO:           evidently: Not installed
2025-03-05 15:37:47,151:INFO:               fugue: Not installed
2025-03-05 15:37:47,151:INFO:           streamlit: Not installed
2025-03-05 15:37:47,152:INFO:             prophet: Not installed
2025-03-05 15:37:47,152:INFO:None
2025-03-05 15:37:47,152:INFO:Set up GPU usage.
2025-03-05 15:37:47,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,152:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:37:47,152:INFO:Set up data.
2025-03-05 15:37:47,155:INFO:Set up folding strategy.
2025-03-05 15:37:47,155:INFO:Set up train/test split.
2025-03-05 15:37:47,159:INFO:Set up index.
2025-03-05 15:37:47,159:INFO:Assigning column types.
2025-03-05 15:37:47,162:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:37:47,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,163:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,167:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,266:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,278:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,384:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:37:47,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,392:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,401:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,507:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,519:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,570:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,612:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:37:47,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,635:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,850:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:37:47,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:47,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:47,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:47,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:48,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:37:48,060:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,060:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,064:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:37:48,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:48,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:37:48,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,302:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:37:48,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,533:INFO:Preparing preprocessing pipeline...
2025-03-05 15:37:48,533:INFO:Set up simple imputation.
2025-03-05 15:37:48,533:INFO:Set up polynomial features.
2025-03-05 15:37:48,533:INFO:Set up feature normalization.
2025-03-05 15:37:48,534:INFO:Set up column name cleaning.
2025-03-05 15:37:48,570:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:37:48,576:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth', 'accel_data.x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-03-05 15:37:48,576:INFO:Creating final display dataframe.
2025-03-05 15:37:48,674:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 3)
4        Transformed data shape       (20088, 10)
5   Transformed train set shape       (14061, 10)
6    Transformed test set shape        (6027, 10)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 3
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU              True
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              0fb0
2025-03-05 15:37:48,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:37:48,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:37:48,883:INFO:setup() successfully completed in 1.74s...............
2025-03-05 15:37:48,901:INFO:Initializing compare_models()
2025-03-05 15:37:48,901:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:37:48,901:INFO:Checking exceptions
2025-03-05 15:37:48,904:INFO:Preparing display monitor
2025-03-05 15:37:48,925:INFO:Initializing Linear Regression
2025-03-05 15:37:48,925:INFO:Total runtime is 2.868970235188802e-06 minutes
2025-03-05 15:37:48,928:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:48,929:INFO:Initializing create_model()
2025-03-05 15:37:48,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:48,929:INFO:Checking exceptions
2025-03-05 15:37:48,929:INFO:Importing libraries
2025-03-05 15:37:48,929:INFO:Copying training dataset
2025-03-05 15:37:48,933:INFO:Defining folds
2025-03-05 15:37:48,933:INFO:Declaring metric variables
2025-03-05 15:37:48,936:INFO:Importing untrained model
2025-03-05 15:37:48,939:INFO:Linear Regression Imported successfully
2025-03-05 15:37:48,946:INFO:Starting cross validation
2025-03-05 15:37:48,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:49,319:INFO:Calculating mean and std
2025-03-05 15:37:49,319:INFO:Creating metrics dataframe
2025-03-05 15:37:49,321:INFO:Uploading results into container
2025-03-05 15:37:49,322:INFO:Uploading model into container now
2025-03-05 15:37:49,323:INFO:_master_model_container: 1
2025-03-05 15:37:49,323:INFO:_display_container: 2
2025-03-05 15:37:49,323:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:37:49,323:INFO:create_model() successfully completed......................................
2025-03-05 15:37:49,462:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:49,462:INFO:Creating metrics dataframe
2025-03-05 15:37:49,468:INFO:Initializing Lasso Regression
2025-03-05 15:37:49,469:INFO:Total runtime is 0.00905529260635376 minutes
2025-03-05 15:37:49,472:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:49,472:INFO:Initializing create_model()
2025-03-05 15:37:49,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:49,472:INFO:Checking exceptions
2025-03-05 15:37:49,472:INFO:Importing libraries
2025-03-05 15:37:49,472:INFO:Copying training dataset
2025-03-05 15:37:49,476:INFO:Defining folds
2025-03-05 15:37:49,476:INFO:Declaring metric variables
2025-03-05 15:37:49,479:INFO:Importing untrained model
2025-03-05 15:37:49,482:INFO:Lasso Regression Imported successfully
2025-03-05 15:37:49,488:INFO:Starting cross validation
2025-03-05 15:37:49,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:50,168:INFO:Calculating mean and std
2025-03-05 15:37:50,169:INFO:Creating metrics dataframe
2025-03-05 15:37:50,171:INFO:Uploading results into container
2025-03-05 15:37:50,172:INFO:Uploading model into container now
2025-03-05 15:37:50,172:INFO:_master_model_container: 2
2025-03-05 15:37:50,172:INFO:_display_container: 2
2025-03-05 15:37:50,172:INFO:Lasso(random_state=123)
2025-03-05 15:37:50,172:INFO:create_model() successfully completed......................................
2025-03-05 15:37:50,346:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:50,346:INFO:Creating metrics dataframe
2025-03-05 15:37:50,353:INFO:Initializing Ridge Regression
2025-03-05 15:37:50,354:INFO:Total runtime is 0.023805816968282066 minutes
2025-03-05 15:37:50,357:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:50,357:INFO:Initializing create_model()
2025-03-05 15:37:50,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:50,357:INFO:Checking exceptions
2025-03-05 15:37:50,357:INFO:Importing libraries
2025-03-05 15:37:50,357:INFO:Copying training dataset
2025-03-05 15:37:50,362:INFO:Defining folds
2025-03-05 15:37:50,362:INFO:Declaring metric variables
2025-03-05 15:37:50,365:INFO:Importing untrained model
2025-03-05 15:37:50,368:INFO:Ridge Regression Imported successfully
2025-03-05 15:37:50,374:INFO:Starting cross validation
2025-03-05 15:37:50,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:50,729:INFO:Calculating mean and std
2025-03-05 15:37:50,734:INFO:Creating metrics dataframe
2025-03-05 15:37:50,739:INFO:Uploading results into container
2025-03-05 15:37:50,739:INFO:Uploading model into container now
2025-03-05 15:37:50,740:INFO:_master_model_container: 3
2025-03-05 15:37:50,740:INFO:_display_container: 2
2025-03-05 15:37:50,740:INFO:Ridge(random_state=123)
2025-03-05 15:37:50,744:INFO:create_model() successfully completed......................................
2025-03-05 15:37:50,935:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:50,935:INFO:Creating metrics dataframe
2025-03-05 15:37:50,942:INFO:Initializing Elastic Net
2025-03-05 15:37:50,943:INFO:Total runtime is 0.03362356026967367 minutes
2025-03-05 15:37:50,946:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:50,946:INFO:Initializing create_model()
2025-03-05 15:37:50,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:50,946:INFO:Checking exceptions
2025-03-05 15:37:50,947:INFO:Importing libraries
2025-03-05 15:37:50,947:INFO:Copying training dataset
2025-03-05 15:37:50,951:INFO:Defining folds
2025-03-05 15:37:50,951:INFO:Declaring metric variables
2025-03-05 15:37:50,954:INFO:Importing untrained model
2025-03-05 15:37:50,957:INFO:Elastic Net Imported successfully
2025-03-05 15:37:50,963:INFO:Starting cross validation
2025-03-05 15:37:50,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:51,914:INFO:Calculating mean and std
2025-03-05 15:37:51,916:INFO:Creating metrics dataframe
2025-03-05 15:37:51,918:INFO:Uploading results into container
2025-03-05 15:37:51,919:INFO:Uploading model into container now
2025-03-05 15:37:51,919:INFO:_master_model_container: 4
2025-03-05 15:37:51,919:INFO:_display_container: 2
2025-03-05 15:37:51,920:INFO:ElasticNet(random_state=123)
2025-03-05 15:37:51,920:INFO:create_model() successfully completed......................................
2025-03-05 15:37:52,059:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:52,059:INFO:Creating metrics dataframe
2025-03-05 15:37:52,066:INFO:Initializing Least Angle Regression
2025-03-05 15:37:52,066:INFO:Total runtime is 0.052353191375732425 minutes
2025-03-05 15:37:52,070:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:52,070:INFO:Initializing create_model()
2025-03-05 15:37:52,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:52,070:INFO:Checking exceptions
2025-03-05 15:37:52,070:INFO:Importing libraries
2025-03-05 15:37:52,070:INFO:Copying training dataset
2025-03-05 15:37:52,075:INFO:Defining folds
2025-03-05 15:37:52,075:INFO:Declaring metric variables
2025-03-05 15:37:52,079:INFO:Importing untrained model
2025-03-05 15:37:52,082:INFO:Least Angle Regression Imported successfully
2025-03-05 15:37:52,089:INFO:Starting cross validation
2025-03-05 15:37:52,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:52,502:INFO:Calculating mean and std
2025-03-05 15:37:52,505:INFO:Creating metrics dataframe
2025-03-05 15:37:52,513:INFO:Uploading results into container
2025-03-05 15:37:52,513:INFO:Uploading model into container now
2025-03-05 15:37:52,514:INFO:_master_model_container: 5
2025-03-05 15:37:52,514:INFO:_display_container: 2
2025-03-05 15:37:52,515:INFO:Lars(random_state=123)
2025-03-05 15:37:52,515:INFO:create_model() successfully completed......................................
2025-03-05 15:37:52,665:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:52,665:INFO:Creating metrics dataframe
2025-03-05 15:37:52,672:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:37:52,673:INFO:Total runtime is 0.06245582103729248 minutes
2025-03-05 15:37:52,676:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:52,676:INFO:Initializing create_model()
2025-03-05 15:37:52,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:52,676:INFO:Checking exceptions
2025-03-05 15:37:52,676:INFO:Importing libraries
2025-03-05 15:37:52,676:INFO:Copying training dataset
2025-03-05 15:37:52,681:INFO:Defining folds
2025-03-05 15:37:52,681:INFO:Declaring metric variables
2025-03-05 15:37:52,685:INFO:Importing untrained model
2025-03-05 15:37:52,688:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:37:52,694:INFO:Starting cross validation
2025-03-05 15:37:52,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:53,059:INFO:Calculating mean and std
2025-03-05 15:37:53,060:INFO:Creating metrics dataframe
2025-03-05 15:37:53,062:INFO:Uploading results into container
2025-03-05 15:37:53,064:INFO:Uploading model into container now
2025-03-05 15:37:53,065:INFO:_master_model_container: 6
2025-03-05 15:37:53,066:INFO:_display_container: 2
2025-03-05 15:37:53,066:INFO:LassoLars(random_state=123)
2025-03-05 15:37:53,066:INFO:create_model() successfully completed......................................
2025-03-05 15:37:53,221:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:53,221:INFO:Creating metrics dataframe
2025-03-05 15:37:53,229:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:37:53,229:INFO:Total runtime is 0.0717238704363505 minutes
2025-03-05 15:37:53,232:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:53,232:INFO:Initializing create_model()
2025-03-05 15:37:53,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:53,232:INFO:Checking exceptions
2025-03-05 15:37:53,232:INFO:Importing libraries
2025-03-05 15:37:53,232:INFO:Copying training dataset
2025-03-05 15:37:53,237:INFO:Defining folds
2025-03-05 15:37:53,238:INFO:Declaring metric variables
2025-03-05 15:37:53,241:INFO:Importing untrained model
2025-03-05 15:37:53,244:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:37:53,250:INFO:Starting cross validation
2025-03-05 15:37:53,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:53,736:INFO:Calculating mean and std
2025-03-05 15:37:53,738:INFO:Creating metrics dataframe
2025-03-05 15:37:53,742:INFO:Uploading results into container
2025-03-05 15:37:53,742:INFO:Uploading model into container now
2025-03-05 15:37:53,743:INFO:_master_model_container: 7
2025-03-05 15:37:53,743:INFO:_display_container: 2
2025-03-05 15:37:53,744:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:37:53,744:INFO:create_model() successfully completed......................................
2025-03-05 15:37:53,906:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:53,907:INFO:Creating metrics dataframe
2025-03-05 15:37:53,914:INFO:Initializing Bayesian Ridge
2025-03-05 15:37:53,914:INFO:Total runtime is 0.08315054972966512 minutes
2025-03-05 15:37:53,918:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:53,918:INFO:Initializing create_model()
2025-03-05 15:37:53,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:53,918:INFO:Checking exceptions
2025-03-05 15:37:53,918:INFO:Importing libraries
2025-03-05 15:37:53,918:INFO:Copying training dataset
2025-03-05 15:37:53,923:INFO:Defining folds
2025-03-05 15:37:53,923:INFO:Declaring metric variables
2025-03-05 15:37:53,926:INFO:Importing untrained model
2025-03-05 15:37:53,930:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:37:53,935:INFO:Starting cross validation
2025-03-05 15:37:53,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:54,958:INFO:Calculating mean and std
2025-03-05 15:37:54,960:INFO:Creating metrics dataframe
2025-03-05 15:37:54,962:INFO:Uploading results into container
2025-03-05 15:37:54,962:INFO:Uploading model into container now
2025-03-05 15:37:54,963:INFO:_master_model_container: 8
2025-03-05 15:37:54,963:INFO:_display_container: 2
2025-03-05 15:37:54,963:INFO:BayesianRidge()
2025-03-05 15:37:54,963:INFO:create_model() successfully completed......................................
2025-03-05 15:37:55,103:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:55,103:INFO:Creating metrics dataframe
2025-03-05 15:37:55,111:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:37:55,112:INFO:Total runtime is 0.10310672124226888 minutes
2025-03-05 15:37:55,115:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:55,116:INFO:Initializing create_model()
2025-03-05 15:37:55,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:55,116:INFO:Checking exceptions
2025-03-05 15:37:55,116:INFO:Importing libraries
2025-03-05 15:37:55,116:INFO:Copying training dataset
2025-03-05 15:37:55,121:INFO:Defining folds
2025-03-05 15:37:55,121:INFO:Declaring metric variables
2025-03-05 15:37:55,124:INFO:Importing untrained model
2025-03-05 15:37:55,128:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:37:55,134:INFO:Starting cross validation
2025-03-05 15:37:55,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:55,616:INFO:Calculating mean and std
2025-03-05 15:37:55,618:INFO:Creating metrics dataframe
2025-03-05 15:37:55,620:INFO:Uploading results into container
2025-03-05 15:37:55,621:INFO:Uploading model into container now
2025-03-05 15:37:55,621:INFO:_master_model_container: 9
2025-03-05 15:37:55,621:INFO:_display_container: 2
2025-03-05 15:37:55,622:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:37:55,622:INFO:create_model() successfully completed......................................
2025-03-05 15:37:55,759:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:55,759:INFO:Creating metrics dataframe
2025-03-05 15:37:55,767:INFO:Initializing Huber Regressor
2025-03-05 15:37:55,768:INFO:Total runtime is 0.11403923034667969 minutes
2025-03-05 15:37:55,771:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:55,771:INFO:Initializing create_model()
2025-03-05 15:37:55,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:55,771:INFO:Checking exceptions
2025-03-05 15:37:55,771:INFO:Importing libraries
2025-03-05 15:37:55,771:INFO:Copying training dataset
2025-03-05 15:37:55,776:INFO:Defining folds
2025-03-05 15:37:55,776:INFO:Declaring metric variables
2025-03-05 15:37:55,780:INFO:Importing untrained model
2025-03-05 15:37:55,783:INFO:Huber Regressor Imported successfully
2025-03-05 15:37:55,790:INFO:Starting cross validation
2025-03-05 15:37:55,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:37:56,059:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:56,343:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:56,656:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:56,996:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:57,322:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:57,793:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:58,436:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:58,812:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:59,260:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:59,734:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-05 15:37:59,750:INFO:Calculating mean and std
2025-03-05 15:37:59,751:INFO:Creating metrics dataframe
2025-03-05 15:37:59,754:INFO:Uploading results into container
2025-03-05 15:37:59,754:INFO:Uploading model into container now
2025-03-05 15:37:59,755:INFO:_master_model_container: 10
2025-03-05 15:37:59,755:INFO:_display_container: 2
2025-03-05 15:37:59,755:INFO:HuberRegressor()
2025-03-05 15:37:59,755:INFO:create_model() successfully completed......................................
2025-03-05 15:37:59,897:INFO:SubProcess create_model() end ==================================
2025-03-05 15:37:59,897:INFO:Creating metrics dataframe
2025-03-05 15:37:59,905:INFO:Initializing K Neighbors Regressor
2025-03-05 15:37:59,905:INFO:Total runtime is 0.18299744923909506 minutes
2025-03-05 15:37:59,910:INFO:SubProcess create_model() called ==================================
2025-03-05 15:37:59,911:INFO:Initializing create_model()
2025-03-05 15:37:59,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:37:59,911:INFO:Checking exceptions
2025-03-05 15:37:59,911:INFO:Importing libraries
2025-03-05 15:37:59,911:INFO:Copying training dataset
2025-03-05 15:37:59,919:INFO:Defining folds
2025-03-05 15:37:59,919:INFO:Declaring metric variables
2025-03-05 15:37:59,923:INFO:Importing untrained model
2025-03-05 15:37:59,926:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:37:59,934:INFO:Starting cross validation
2025-03-05 15:37:59,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:00,708:INFO:Calculating mean and std
2025-03-05 15:38:00,710:INFO:Creating metrics dataframe
2025-03-05 15:38:00,712:INFO:Uploading results into container
2025-03-05 15:38:00,712:INFO:Uploading model into container now
2025-03-05 15:38:00,713:INFO:_master_model_container: 11
2025-03-05 15:38:00,713:INFO:_display_container: 2
2025-03-05 15:38:00,713:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:38:00,713:INFO:create_model() successfully completed......................................
2025-03-05 15:38:00,839:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:00,839:INFO:Creating metrics dataframe
2025-03-05 15:38:00,848:INFO:Initializing Decision Tree Regressor
2025-03-05 15:38:00,848:INFO:Total runtime is 0.19871180454889933 minutes
2025-03-05 15:38:00,851:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:00,852:INFO:Initializing create_model()
2025-03-05 15:38:00,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:00,852:INFO:Checking exceptions
2025-03-05 15:38:00,852:INFO:Importing libraries
2025-03-05 15:38:00,852:INFO:Copying training dataset
2025-03-05 15:38:00,856:INFO:Defining folds
2025-03-05 15:38:00,857:INFO:Declaring metric variables
2025-03-05 15:38:00,860:INFO:Importing untrained model
2025-03-05 15:38:00,863:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:38:00,869:INFO:Starting cross validation
2025-03-05 15:38:00,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:01,337:INFO:Calculating mean and std
2025-03-05 15:38:01,338:INFO:Creating metrics dataframe
2025-03-05 15:38:01,340:INFO:Uploading results into container
2025-03-05 15:38:01,341:INFO:Uploading model into container now
2025-03-05 15:38:01,341:INFO:_master_model_container: 12
2025-03-05 15:38:01,341:INFO:_display_container: 2
2025-03-05 15:38:01,341:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:38:01,341:INFO:create_model() successfully completed......................................
2025-03-05 15:38:01,461:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:01,461:INFO:Creating metrics dataframe
2025-03-05 15:38:01,470:INFO:Initializing Random Forest Regressor
2025-03-05 15:38:01,470:INFO:Total runtime is 0.2090837319691976 minutes
2025-03-05 15:38:01,473:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:01,473:INFO:Initializing create_model()
2025-03-05 15:38:01,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:01,474:INFO:Checking exceptions
2025-03-05 15:38:01,474:INFO:Importing libraries
2025-03-05 15:38:01,474:INFO:Copying training dataset
2025-03-05 15:38:01,478:INFO:Defining folds
2025-03-05 15:38:01,479:INFO:Declaring metric variables
2025-03-05 15:38:01,482:INFO:Importing untrained model
2025-03-05 15:38:01,485:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:38:01,492:INFO:Starting cross validation
2025-03-05 15:38:01,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:04,488:INFO:Calculating mean and std
2025-03-05 15:38:04,489:INFO:Creating metrics dataframe
2025-03-05 15:38:04,491:INFO:Uploading results into container
2025-03-05 15:38:04,492:INFO:Uploading model into container now
2025-03-05 15:38:04,492:INFO:_master_model_container: 13
2025-03-05 15:38:04,492:INFO:_display_container: 2
2025-03-05 15:38:04,493:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:38:04,493:INFO:create_model() successfully completed......................................
2025-03-05 15:38:04,611:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:04,611:INFO:Creating metrics dataframe
2025-03-05 15:38:04,621:INFO:Initializing Extra Trees Regressor
2025-03-05 15:38:04,622:INFO:Total runtime is 0.26160720189412434 minutes
2025-03-05 15:38:04,626:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:04,626:INFO:Initializing create_model()
2025-03-05 15:38:04,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:04,627:INFO:Checking exceptions
2025-03-05 15:38:04,627:INFO:Importing libraries
2025-03-05 15:38:04,627:INFO:Copying training dataset
2025-03-05 15:38:04,631:INFO:Defining folds
2025-03-05 15:38:04,631:INFO:Declaring metric variables
2025-03-05 15:38:04,634:INFO:Importing untrained model
2025-03-05 15:38:04,637:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:38:04,643:INFO:Starting cross validation
2025-03-05 15:38:04,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:06,561:INFO:Calculating mean and std
2025-03-05 15:38:06,562:INFO:Creating metrics dataframe
2025-03-05 15:38:06,564:INFO:Uploading results into container
2025-03-05 15:38:06,565:INFO:Uploading model into container now
2025-03-05 15:38:06,565:INFO:_master_model_container: 14
2025-03-05 15:38:06,566:INFO:_display_container: 2
2025-03-05 15:38:06,566:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:38:06,566:INFO:create_model() successfully completed......................................
2025-03-05 15:38:06,693:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:06,693:INFO:Creating metrics dataframe
2025-03-05 15:38:06,703:INFO:Initializing AdaBoost Regressor
2025-03-05 15:38:06,703:INFO:Total runtime is 0.29629273017247515 minutes
2025-03-05 15:38:06,706:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:06,707:INFO:Initializing create_model()
2025-03-05 15:38:06,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:06,707:INFO:Checking exceptions
2025-03-05 15:38:06,707:INFO:Importing libraries
2025-03-05 15:38:06,707:INFO:Copying training dataset
2025-03-05 15:38:06,712:INFO:Defining folds
2025-03-05 15:38:06,712:INFO:Declaring metric variables
2025-03-05 15:38:06,715:INFO:Importing untrained model
2025-03-05 15:38:06,718:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:38:06,724:INFO:Starting cross validation
2025-03-05 15:38:06,725:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:10,654:INFO:Calculating mean and std
2025-03-05 15:38:10,655:INFO:Creating metrics dataframe
2025-03-05 15:38:10,657:INFO:Uploading results into container
2025-03-05 15:38:10,658:INFO:Uploading model into container now
2025-03-05 15:38:10,658:INFO:_master_model_container: 15
2025-03-05 15:38:10,658:INFO:_display_container: 2
2025-03-05 15:38:10,658:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:38:10,659:INFO:create_model() successfully completed......................................
2025-03-05 15:38:10,783:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:10,784:INFO:Creating metrics dataframe
2025-03-05 15:38:10,793:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:38:10,793:INFO:Total runtime is 0.3644633611043294 minutes
2025-03-05 15:38:10,796:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:10,796:INFO:Initializing create_model()
2025-03-05 15:38:10,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:10,797:INFO:Checking exceptions
2025-03-05 15:38:10,797:INFO:Importing libraries
2025-03-05 15:38:10,797:INFO:Copying training dataset
2025-03-05 15:38:10,801:INFO:Defining folds
2025-03-05 15:38:10,802:INFO:Declaring metric variables
2025-03-05 15:38:10,805:INFO:Importing untrained model
2025-03-05 15:38:10,808:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:38:10,814:INFO:Starting cross validation
2025-03-05 15:38:10,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:22,518:INFO:Calculating mean and std
2025-03-05 15:38:22,519:INFO:Creating metrics dataframe
2025-03-05 15:38:22,521:INFO:Uploading results into container
2025-03-05 15:38:22,521:INFO:Uploading model into container now
2025-03-05 15:38:22,522:INFO:_master_model_container: 16
2025-03-05 15:38:22,522:INFO:_display_container: 2
2025-03-05 15:38:22,522:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:38:22,522:INFO:create_model() successfully completed......................................
2025-03-05 15:38:22,646:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:22,646:INFO:Creating metrics dataframe
2025-03-05 15:38:22,655:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:38:22,656:INFO:Total runtime is 0.562171733379364 minutes
2025-03-05 15:38:22,659:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:22,659:INFO:Initializing create_model()
2025-03-05 15:38:22,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:22,659:INFO:Checking exceptions
2025-03-05 15:38:22,659:INFO:Importing libraries
2025-03-05 15:38:22,659:INFO:Copying training dataset
2025-03-05 15:38:22,664:INFO:Defining folds
2025-03-05 15:38:22,664:INFO:Declaring metric variables
2025-03-05 15:38:22,667:INFO:Importing untrained model
2025-03-05 15:38:22,671:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:38:22,677:INFO:Starting cross validation
2025-03-05 15:38:22,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:22,717:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:22,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031405 seconds.
2025-03-05 15:38:22,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:22,749:INFO:[LightGBM] [Info] Total Bins 1394
2025-03-05 15:38:22,757:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 9
2025-03-05 15:38:22,769:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:38:23,464:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:23,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-03-05 15:38:23,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:23,465:INFO:[LightGBM] [Info] Total Bins 1391
2025-03-05 15:38:23,465:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:23,465:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:38:25,207:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:25,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029652 seconds.
2025-03-05 15:38:25,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:25,237:INFO:[LightGBM] [Info] Total Bins 1391
2025-03-05 15:38:25,243:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:25,257:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:38:28,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:28,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-05 15:38:28,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:28,423:INFO:[LightGBM] [Info] Total Bins 1390
2025-03-05 15:38:28,423:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:28,425:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:38:29,155:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:29,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
2025-03-05 15:38:29,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:29,156:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:38:29,156:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:29,158:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:38:29,627:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:29,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003082 seconds.
2025-03-05 15:38:29,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:29,630:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:38:29,630:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:29,631:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:38:30,050:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:30,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.
2025-03-05 15:38:30,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:30,052:INFO:[LightGBM] [Info] Total Bins 1387
2025-03-05 15:38:30,053:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:30,054:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:38:30,712:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:30,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
2025-03-05 15:38:30,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:30,714:INFO:[LightGBM] [Info] Total Bins 1390
2025-03-05 15:38:30,714:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:30,714:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:38:31,314:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:31,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-03-05 15:38:31,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:31,315:INFO:[LightGBM] [Info] Total Bins 1397
2025-03-05 15:38:31,315:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:31,316:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:38:31,757:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-03-05 15:38:31,758:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-03-05 15:38:31,767:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:38:31,767:INFO:[LightGBM] [Info] Total Bins 1386
2025-03-05 15:38:31,768:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 9
2025-03-05 15:38:31,768:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:38:32,297:INFO:Calculating mean and std
2025-03-05 15:38:32,303:INFO:Creating metrics dataframe
2025-03-05 15:38:32,306:INFO:Uploading results into container
2025-03-05 15:38:32,307:INFO:Uploading model into container now
2025-03-05 15:38:32,307:INFO:_master_model_container: 17
2025-03-05 15:38:32,308:INFO:_display_container: 2
2025-03-05 15:38:32,308:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:38:32,308:INFO:create_model() successfully completed......................................
2025-03-05 15:38:32,438:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:32,438:INFO:Creating metrics dataframe
2025-03-05 15:38:32,448:INFO:Initializing Dummy Regressor
2025-03-05 15:38:32,448:INFO:Total runtime is 0.7253762642542521 minutes
2025-03-05 15:38:32,451:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:32,451:INFO:Initializing create_model()
2025-03-05 15:38:32,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445d1235cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:32,451:INFO:Checking exceptions
2025-03-05 15:38:32,451:INFO:Importing libraries
2025-03-05 15:38:32,451:INFO:Copying training dataset
2025-03-05 15:38:32,456:INFO:Defining folds
2025-03-05 15:38:32,456:INFO:Declaring metric variables
2025-03-05 15:38:32,459:INFO:Importing untrained model
2025-03-05 15:38:32,462:INFO:Dummy Regressor Imported successfully
2025-03-05 15:38:32,467:INFO:Starting cross validation
2025-03-05 15:38:32,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:32,722:INFO:Calculating mean and std
2025-03-05 15:38:32,723:INFO:Creating metrics dataframe
2025-03-05 15:38:32,725:INFO:Uploading results into container
2025-03-05 15:38:32,726:INFO:Uploading model into container now
2025-03-05 15:38:32,726:INFO:_master_model_container: 18
2025-03-05 15:38:32,726:INFO:_display_container: 2
2025-03-05 15:38:32,726:INFO:DummyRegressor()
2025-03-05 15:38:32,726:INFO:create_model() successfully completed......................................
2025-03-05 15:38:32,850:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:32,850:INFO:Creating metrics dataframe
2025-03-05 15:38:32,860:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:38:32,868:INFO:Initializing create_model()
2025-03-05 15:38:32,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:32,868:INFO:Checking exceptions
2025-03-05 15:38:32,870:INFO:Importing libraries
2025-03-05 15:38:32,870:INFO:Copying training dataset
2025-03-05 15:38:32,874:INFO:Defining folds
2025-03-05 15:38:32,874:INFO:Declaring metric variables
2025-03-05 15:38:32,874:INFO:Importing untrained model
2025-03-05 15:38:32,874:INFO:Declaring custom model
2025-03-05 15:38:32,875:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:38:32,875:INFO:Cross validation set to False
2025-03-05 15:38:32,875:INFO:Fitting Model
2025-03-05 15:38:34,129:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:38:34,129:INFO:create_model() successfully completed......................................
2025-03-05 15:38:34,281:INFO:_master_model_container: 18
2025-03-05 15:38:34,281:INFO:_display_container: 2
2025-03-05 15:38:34,281:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:38:34,281:INFO:compare_models() successfully completed......................................
2025-03-05 15:38:34,361:INFO:Initializing evaluate_model()
2025-03-05 15:38:34,362:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 15:38:34,373:INFO:Initializing plot_model()
2025-03-05 15:38:34,373:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d0de1400>, system=True)
2025-03-05 15:38:34,373:INFO:Checking exceptions
2025-03-05 15:38:34,375:INFO:Preloading libraries
2025-03-05 15:38:34,381:INFO:Copying training dataset
2025-03-05 15:38:34,381:INFO:Plot type: pipeline
2025-03-05 15:38:34,500:INFO:Visual Rendered Successfully
2025-03-05 15:38:34,627:INFO:plot_model() successfully completed......................................
2025-03-05 15:38:39,308:INFO:PyCaret RegressionExperiment
2025-03-05 15:38:39,309:INFO:Logging name: reg-default-name
2025-03-05 15:38:39,309:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:38:39,309:INFO:version 3.3.1
2025-03-05 15:38:39,309:INFO:Initializing setup()
2025-03-05 15:38:39,309:INFO:self.USI: ee64
2025-03-05 15:38:39,309:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:38:39,309:INFO:Checking environment
2025-03-05 15:38:39,309:INFO:python_version: 3.9.21
2025-03-05 15:38:39,309:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:38:39,309:INFO:machine: x86_64
2025-03-05 15:38:39,309:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:38:39,309:INFO:Memory: svmem(total=33374507008, available=21238382592, percent=36.4, used=9521643520, free=3678040064, active=13620854784, inactive=11850698752, buffers=681631744, cached=19493191680, shared=2085384192, slab=1828970496)
2025-03-05 15:38:39,310:INFO:Physical Core: 24
2025-03-05 15:38:39,310:INFO:Logical Core: 32
2025-03-05 15:38:39,310:INFO:Checking libraries
2025-03-05 15:38:39,310:INFO:System:
2025-03-05 15:38:39,310:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:38:39,310:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:38:39,310:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:38:39,310:INFO:PyCaret required dependencies:
2025-03-05 15:38:39,310:INFO:                 pip: 25.0
2025-03-05 15:38:39,310:INFO:          setuptools: 75.8.0
2025-03-05 15:38:39,310:INFO:             pycaret: 3.3.1
2025-03-05 15:38:39,310:INFO:             IPython: 8.18.1
2025-03-05 15:38:39,310:INFO:          ipywidgets: 8.1.5
2025-03-05 15:38:39,310:INFO:                tqdm: 4.67.1
2025-03-05 15:38:39,310:INFO:               numpy: 1.26.4
2025-03-05 15:38:39,310:INFO:              pandas: 2.1.4
2025-03-05 15:38:39,310:INFO:              jinja2: 3.1.5
2025-03-05 15:38:39,310:INFO:               scipy: 1.11.4
2025-03-05 15:38:39,310:INFO:              joblib: 1.3.2
2025-03-05 15:38:39,310:INFO:             sklearn: 1.4.2
2025-03-05 15:38:39,310:INFO:                pyod: 2.0.3
2025-03-05 15:38:39,310:INFO:            imblearn: 0.12.4
2025-03-05 15:38:39,310:INFO:   category_encoders: 2.6.4
2025-03-05 15:38:39,310:INFO:            lightgbm: 4.6.0
2025-03-05 15:38:39,310:INFO:               numba: 0.60.0
2025-03-05 15:38:39,310:INFO:            requests: 2.32.3
2025-03-05 15:38:39,310:INFO:          matplotlib: 3.7.5
2025-03-05 15:38:39,310:INFO:          scikitplot: 0.3.7
2025-03-05 15:38:39,310:INFO:         yellowbrick: 1.5
2025-03-05 15:38:39,310:INFO:              plotly: 5.24.1
2025-03-05 15:38:39,310:INFO:    plotly-resampler: Not installed
2025-03-05 15:38:39,310:INFO:             kaleido: 0.2.1
2025-03-05 15:38:39,310:INFO:           schemdraw: 0.15
2025-03-05 15:38:39,310:INFO:         statsmodels: 0.14.4
2025-03-05 15:38:39,310:INFO:              sktime: 0.26.0
2025-03-05 15:38:39,310:INFO:               tbats: 1.1.3
2025-03-05 15:38:39,310:INFO:            pmdarima: 2.0.4
2025-03-05 15:38:39,310:INFO:              psutil: 7.0.0
2025-03-05 15:38:39,310:INFO:          markupsafe: 3.0.2
2025-03-05 15:38:39,310:INFO:             pickle5: Not installed
2025-03-05 15:38:39,310:INFO:         cloudpickle: 3.1.1
2025-03-05 15:38:39,311:INFO:         deprecation: 2.1.0
2025-03-05 15:38:39,311:INFO:              xxhash: 3.5.0
2025-03-05 15:38:39,311:INFO:           wurlitzer: 3.1.1
2025-03-05 15:38:39,311:INFO:PyCaret optional dependencies:
2025-03-05 15:38:39,311:INFO:                shap: Not installed
2025-03-05 15:38:39,311:INFO:           interpret: Not installed
2025-03-05 15:38:39,311:INFO:                umap: Not installed
2025-03-05 15:38:39,311:INFO:     ydata_profiling: Not installed
2025-03-05 15:38:39,311:INFO:  explainerdashboard: Not installed
2025-03-05 15:38:39,311:INFO:             autoviz: Not installed
2025-03-05 15:38:39,311:INFO:           fairlearn: Not installed
2025-03-05 15:38:39,311:INFO:          deepchecks: Not installed
2025-03-05 15:38:39,311:INFO:             xgboost: Not installed
2025-03-05 15:38:39,311:INFO:            catboost: Not installed
2025-03-05 15:38:39,311:INFO:              kmodes: Not installed
2025-03-05 15:38:39,311:INFO:             mlxtend: Not installed
2025-03-05 15:38:39,311:INFO:       statsforecast: Not installed
2025-03-05 15:38:39,311:INFO:        tune_sklearn: Not installed
2025-03-05 15:38:39,311:INFO:                 ray: Not installed
2025-03-05 15:38:39,311:INFO:            hyperopt: Not installed
2025-03-05 15:38:39,311:INFO:              optuna: Not installed
2025-03-05 15:38:39,311:INFO:               skopt: Not installed
2025-03-05 15:38:39,311:INFO:              mlflow: Not installed
2025-03-05 15:38:39,311:INFO:              gradio: Not installed
2025-03-05 15:38:39,311:INFO:             fastapi: Not installed
2025-03-05 15:38:39,311:INFO:             uvicorn: Not installed
2025-03-05 15:38:39,311:INFO:              m2cgen: Not installed
2025-03-05 15:38:39,311:INFO:           evidently: Not installed
2025-03-05 15:38:39,311:INFO:               fugue: Not installed
2025-03-05 15:38:39,311:INFO:           streamlit: Not installed
2025-03-05 15:38:39,311:INFO:             prophet: Not installed
2025-03-05 15:38:39,311:INFO:None
2025-03-05 15:38:39,311:INFO:Set up GPU usage.
2025-03-05 15:38:39,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,311:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:38:39,311:INFO:Set up data.
2025-03-05 15:38:39,316:INFO:Set up folding strategy.
2025-03-05 15:38:39,317:INFO:Set up train/test split.
2025-03-05 15:38:39,322:INFO:Set up index.
2025-03-05 15:38:39,323:INFO:Assigning column types.
2025-03-05 15:38:39,326:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:38:39,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,326:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,330:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,334:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,428:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,532:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:38:39,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,536:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,734:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:38:39,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,754:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:39,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:39,949:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:38:39,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:39,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,153:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:38:40,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:38:40,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,372:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:38:40,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,598:INFO:Preparing preprocessing pipeline...
2025-03-05 15:38:40,598:INFO:Set up simple imputation.
2025-03-05 15:38:40,598:INFO:Set up polynomial features.
2025-03-05 15:38:40,599:INFO:Set up feature normalization.
2025-03-05 15:38:40,636:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:38:40,642:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-03-05 15:38:40,642:INFO:Creating final display dataframe.
2025-03-05 15:38:40,722:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 4)
5   Transformed train set shape        (14061, 4)
6    Transformed test set shape         (6027, 4)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 3
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU              True
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              ee64
2025-03-05 15:38:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:38:40,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:38:40,944:INFO:setup() successfully completed in 1.64s...............
2025-03-05 15:38:42,705:INFO:Initializing compare_models()
2025-03-05 15:38:42,706:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:38:42,707:INFO:Checking exceptions
2025-03-05 15:38:42,708:INFO:Preparing display monitor
2025-03-05 15:38:42,729:INFO:Initializing Linear Regression
2025-03-05 15:38:42,730:INFO:Total runtime is 3.043810526529948e-06 minutes
2025-03-05 15:38:42,732:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:42,733:INFO:Initializing create_model()
2025-03-05 15:38:42,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:42,733:INFO:Checking exceptions
2025-03-05 15:38:42,733:INFO:Importing libraries
2025-03-05 15:38:42,733:INFO:Copying training dataset
2025-03-05 15:38:42,737:INFO:Defining folds
2025-03-05 15:38:42,737:INFO:Declaring metric variables
2025-03-05 15:38:42,740:INFO:Importing untrained model
2025-03-05 15:38:42,743:INFO:Linear Regression Imported successfully
2025-03-05 15:38:42,749:INFO:Starting cross validation
2025-03-05 15:38:42,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:42,993:INFO:Calculating mean and std
2025-03-05 15:38:42,994:INFO:Creating metrics dataframe
2025-03-05 15:38:42,995:INFO:Uploading results into container
2025-03-05 15:38:42,996:INFO:Uploading model into container now
2025-03-05 15:38:42,996:INFO:_master_model_container: 1
2025-03-05 15:38:42,996:INFO:_display_container: 2
2025-03-05 15:38:42,996:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:38:42,996:INFO:create_model() successfully completed......................................
2025-03-05 15:38:43,120:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:43,120:INFO:Creating metrics dataframe
2025-03-05 15:38:43,126:INFO:Initializing Lasso Regression
2025-03-05 15:38:43,127:INFO:Total runtime is 0.0066209991772969564 minutes
2025-03-05 15:38:43,130:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:43,130:INFO:Initializing create_model()
2025-03-05 15:38:43,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:43,130:INFO:Checking exceptions
2025-03-05 15:38:43,130:INFO:Importing libraries
2025-03-05 15:38:43,130:INFO:Copying training dataset
2025-03-05 15:38:43,134:INFO:Defining folds
2025-03-05 15:38:43,134:INFO:Declaring metric variables
2025-03-05 15:38:43,137:INFO:Importing untrained model
2025-03-05 15:38:43,140:INFO:Lasso Regression Imported successfully
2025-03-05 15:38:43,148:INFO:Starting cross validation
2025-03-05 15:38:43,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:43,468:INFO:Calculating mean and std
2025-03-05 15:38:43,468:INFO:Creating metrics dataframe
2025-03-05 15:38:43,470:INFO:Uploading results into container
2025-03-05 15:38:43,471:INFO:Uploading model into container now
2025-03-05 15:38:43,471:INFO:_master_model_container: 2
2025-03-05 15:38:43,471:INFO:_display_container: 2
2025-03-05 15:38:43,472:INFO:Lasso(random_state=123)
2025-03-05 15:38:43,472:INFO:create_model() successfully completed......................................
2025-03-05 15:38:43,623:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:43,624:INFO:Creating metrics dataframe
2025-03-05 15:38:43,631:INFO:Initializing Ridge Regression
2025-03-05 15:38:43,631:INFO:Total runtime is 0.015027940273284912 minutes
2025-03-05 15:38:43,635:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:43,635:INFO:Initializing create_model()
2025-03-05 15:38:43,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:43,635:INFO:Checking exceptions
2025-03-05 15:38:43,635:INFO:Importing libraries
2025-03-05 15:38:43,635:INFO:Copying training dataset
2025-03-05 15:38:43,639:INFO:Defining folds
2025-03-05 15:38:43,639:INFO:Declaring metric variables
2025-03-05 15:38:43,642:INFO:Importing untrained model
2025-03-05 15:38:43,646:INFO:Ridge Regression Imported successfully
2025-03-05 15:38:43,652:INFO:Starting cross validation
2025-03-05 15:38:43,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:43,874:INFO:Calculating mean and std
2025-03-05 15:38:43,875:INFO:Creating metrics dataframe
2025-03-05 15:38:43,877:INFO:Uploading results into container
2025-03-05 15:38:43,877:INFO:Uploading model into container now
2025-03-05 15:38:43,877:INFO:_master_model_container: 3
2025-03-05 15:38:43,878:INFO:_display_container: 2
2025-03-05 15:38:43,878:INFO:Ridge(random_state=123)
2025-03-05 15:38:43,878:INFO:create_model() successfully completed......................................
2025-03-05 15:38:43,999:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:43,999:INFO:Creating metrics dataframe
2025-03-05 15:38:44,006:INFO:Initializing Elastic Net
2025-03-05 15:38:44,006:INFO:Total runtime is 0.021280105908711752 minutes
2025-03-05 15:38:44,009:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:44,010:INFO:Initializing create_model()
2025-03-05 15:38:44,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:44,010:INFO:Checking exceptions
2025-03-05 15:38:44,010:INFO:Importing libraries
2025-03-05 15:38:44,010:INFO:Copying training dataset
2025-03-05 15:38:44,014:INFO:Defining folds
2025-03-05 15:38:44,014:INFO:Declaring metric variables
2025-03-05 15:38:44,018:INFO:Importing untrained model
2025-03-05 15:38:44,021:INFO:Elastic Net Imported successfully
2025-03-05 15:38:44,027:INFO:Starting cross validation
2025-03-05 15:38:44,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:44,339:INFO:Calculating mean and std
2025-03-05 15:38:44,340:INFO:Creating metrics dataframe
2025-03-05 15:38:44,342:INFO:Uploading results into container
2025-03-05 15:38:44,345:INFO:Uploading model into container now
2025-03-05 15:38:44,346:INFO:_master_model_container: 4
2025-03-05 15:38:44,346:INFO:_display_container: 2
2025-03-05 15:38:44,346:INFO:ElasticNet(random_state=123)
2025-03-05 15:38:44,346:INFO:create_model() successfully completed......................................
2025-03-05 15:38:44,511:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:44,511:INFO:Creating metrics dataframe
2025-03-05 15:38:44,518:INFO:Initializing Least Angle Regression
2025-03-05 15:38:44,518:INFO:Total runtime is 0.029806979497273765 minutes
2025-03-05 15:38:44,521:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:44,521:INFO:Initializing create_model()
2025-03-05 15:38:44,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:44,521:INFO:Checking exceptions
2025-03-05 15:38:44,521:INFO:Importing libraries
2025-03-05 15:38:44,521:INFO:Copying training dataset
2025-03-05 15:38:44,526:INFO:Defining folds
2025-03-05 15:38:44,526:INFO:Declaring metric variables
2025-03-05 15:38:44,529:INFO:Importing untrained model
2025-03-05 15:38:44,532:INFO:Least Angle Regression Imported successfully
2025-03-05 15:38:44,538:INFO:Starting cross validation
2025-03-05 15:38:44,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:44,763:INFO:Calculating mean and std
2025-03-05 15:38:44,764:INFO:Creating metrics dataframe
2025-03-05 15:38:44,766:INFO:Uploading results into container
2025-03-05 15:38:44,767:INFO:Uploading model into container now
2025-03-05 15:38:44,767:INFO:_master_model_container: 5
2025-03-05 15:38:44,767:INFO:_display_container: 2
2025-03-05 15:38:44,767:INFO:Lars(random_state=123)
2025-03-05 15:38:44,767:INFO:create_model() successfully completed......................................
2025-03-05 15:38:44,888:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:44,888:INFO:Creating metrics dataframe
2025-03-05 15:38:44,895:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:38:44,896:INFO:Total runtime is 0.036101484298706056 minutes
2025-03-05 15:38:44,899:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:44,899:INFO:Initializing create_model()
2025-03-05 15:38:44,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:44,899:INFO:Checking exceptions
2025-03-05 15:38:44,899:INFO:Importing libraries
2025-03-05 15:38:44,899:INFO:Copying training dataset
2025-03-05 15:38:44,904:INFO:Defining folds
2025-03-05 15:38:44,904:INFO:Declaring metric variables
2025-03-05 15:38:44,907:INFO:Importing untrained model
2025-03-05 15:38:44,910:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:38:44,915:INFO:Starting cross validation
2025-03-05 15:38:44,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:45,137:INFO:Calculating mean and std
2025-03-05 15:38:45,138:INFO:Creating metrics dataframe
2025-03-05 15:38:45,140:INFO:Uploading results into container
2025-03-05 15:38:45,141:INFO:Uploading model into container now
2025-03-05 15:38:45,141:INFO:_master_model_container: 6
2025-03-05 15:38:45,141:INFO:_display_container: 2
2025-03-05 15:38:45,141:INFO:LassoLars(random_state=123)
2025-03-05 15:38:45,141:INFO:create_model() successfully completed......................................
2025-03-05 15:38:45,264:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:45,264:INFO:Creating metrics dataframe
2025-03-05 15:38:45,272:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:38:45,272:INFO:Total runtime is 0.04237494071324666 minutes
2025-03-05 15:38:45,275:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:45,275:INFO:Initializing create_model()
2025-03-05 15:38:45,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:45,275:INFO:Checking exceptions
2025-03-05 15:38:45,275:INFO:Importing libraries
2025-03-05 15:38:45,275:INFO:Copying training dataset
2025-03-05 15:38:45,280:INFO:Defining folds
2025-03-05 15:38:45,280:INFO:Declaring metric variables
2025-03-05 15:38:45,283:INFO:Importing untrained model
2025-03-05 15:38:45,286:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:38:45,291:INFO:Starting cross validation
2025-03-05 15:38:45,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:45,539:INFO:Calculating mean and std
2025-03-05 15:38:45,540:INFO:Creating metrics dataframe
2025-03-05 15:38:45,542:INFO:Uploading results into container
2025-03-05 15:38:45,543:INFO:Uploading model into container now
2025-03-05 15:38:45,543:INFO:_master_model_container: 7
2025-03-05 15:38:45,543:INFO:_display_container: 2
2025-03-05 15:38:45,543:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:38:45,544:INFO:create_model() successfully completed......................................
2025-03-05 15:38:45,664:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:45,664:INFO:Creating metrics dataframe
2025-03-05 15:38:45,672:INFO:Initializing Bayesian Ridge
2025-03-05 15:38:45,672:INFO:Total runtime is 0.04904344876607259 minutes
2025-03-05 15:38:45,675:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:45,676:INFO:Initializing create_model()
2025-03-05 15:38:45,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:45,676:INFO:Checking exceptions
2025-03-05 15:38:45,676:INFO:Importing libraries
2025-03-05 15:38:45,676:INFO:Copying training dataset
2025-03-05 15:38:45,680:INFO:Defining folds
2025-03-05 15:38:45,680:INFO:Declaring metric variables
2025-03-05 15:38:45,683:INFO:Importing untrained model
2025-03-05 15:38:45,686:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:38:45,692:INFO:Starting cross validation
2025-03-05 15:38:45,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:45,986:INFO:Calculating mean and std
2025-03-05 15:38:45,987:INFO:Creating metrics dataframe
2025-03-05 15:38:45,989:INFO:Uploading results into container
2025-03-05 15:38:45,991:INFO:Uploading model into container now
2025-03-05 15:38:45,992:INFO:_master_model_container: 8
2025-03-05 15:38:45,992:INFO:_display_container: 2
2025-03-05 15:38:45,993:INFO:BayesianRidge()
2025-03-05 15:38:45,993:INFO:create_model() successfully completed......................................
2025-03-05 15:38:46,144:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:46,144:INFO:Creating metrics dataframe
2025-03-05 15:38:46,152:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:38:46,152:INFO:Total runtime is 0.05704301595687866 minutes
2025-03-05 15:38:46,155:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:46,156:INFO:Initializing create_model()
2025-03-05 15:38:46,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:46,156:INFO:Checking exceptions
2025-03-05 15:38:46,156:INFO:Importing libraries
2025-03-05 15:38:46,156:INFO:Copying training dataset
2025-03-05 15:38:46,160:INFO:Defining folds
2025-03-05 15:38:46,160:INFO:Declaring metric variables
2025-03-05 15:38:46,163:INFO:Importing untrained model
2025-03-05 15:38:46,166:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:38:46,173:INFO:Starting cross validation
2025-03-05 15:38:46,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:46,457:INFO:Calculating mean and std
2025-03-05 15:38:46,458:INFO:Creating metrics dataframe
2025-03-05 15:38:46,460:INFO:Uploading results into container
2025-03-05 15:38:46,460:INFO:Uploading model into container now
2025-03-05 15:38:46,461:INFO:_master_model_container: 9
2025-03-05 15:38:46,461:INFO:_display_container: 2
2025-03-05 15:38:46,461:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:38:46,461:INFO:create_model() successfully completed......................................
2025-03-05 15:38:46,585:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:46,585:INFO:Creating metrics dataframe
2025-03-05 15:38:46,593:INFO:Initializing Huber Regressor
2025-03-05 15:38:46,593:INFO:Total runtime is 0.0643884023030599 minutes
2025-03-05 15:38:46,596:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:46,596:INFO:Initializing create_model()
2025-03-05 15:38:46,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:46,596:INFO:Checking exceptions
2025-03-05 15:38:46,596:INFO:Importing libraries
2025-03-05 15:38:46,597:INFO:Copying training dataset
2025-03-05 15:38:46,601:INFO:Defining folds
2025-03-05 15:38:46,601:INFO:Declaring metric variables
2025-03-05 15:38:46,604:INFO:Importing untrained model
2025-03-05 15:38:46,607:INFO:Huber Regressor Imported successfully
2025-03-05 15:38:46,613:INFO:Starting cross validation
2025-03-05 15:38:46,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:48,113:INFO:Calculating mean and std
2025-03-05 15:38:48,115:INFO:Creating metrics dataframe
2025-03-05 15:38:48,118:INFO:Uploading results into container
2025-03-05 15:38:48,118:INFO:Uploading model into container now
2025-03-05 15:38:48,119:INFO:_master_model_container: 10
2025-03-05 15:38:48,119:INFO:_display_container: 2
2025-03-05 15:38:48,119:INFO:HuberRegressor()
2025-03-05 15:38:48,119:INFO:create_model() successfully completed......................................
2025-03-05 15:38:48,279:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:48,280:INFO:Creating metrics dataframe
2025-03-05 15:38:48,289:INFO:Initializing K Neighbors Regressor
2025-03-05 15:38:48,289:INFO:Total runtime is 0.09265486796696981 minutes
2025-03-05 15:38:48,292:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:48,292:INFO:Initializing create_model()
2025-03-05 15:38:48,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:48,292:INFO:Checking exceptions
2025-03-05 15:38:48,292:INFO:Importing libraries
2025-03-05 15:38:48,292:INFO:Copying training dataset
2025-03-05 15:38:48,297:INFO:Defining folds
2025-03-05 15:38:48,297:INFO:Declaring metric variables
2025-03-05 15:38:48,300:INFO:Importing untrained model
2025-03-05 15:38:48,304:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:38:48,309:INFO:Starting cross validation
2025-03-05 15:38:48,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:48,876:INFO:Calculating mean and std
2025-03-05 15:38:48,877:INFO:Creating metrics dataframe
2025-03-05 15:38:48,879:INFO:Uploading results into container
2025-03-05 15:38:48,879:INFO:Uploading model into container now
2025-03-05 15:38:48,880:INFO:_master_model_container: 11
2025-03-05 15:38:48,880:INFO:_display_container: 2
2025-03-05 15:38:48,880:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:38:48,881:INFO:create_model() successfully completed......................................
2025-03-05 15:38:49,002:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:49,002:INFO:Creating metrics dataframe
2025-03-05 15:38:49,011:INFO:Initializing Decision Tree Regressor
2025-03-05 15:38:49,011:INFO:Total runtime is 0.10469959179560344 minutes
2025-03-05 15:38:49,015:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:49,015:INFO:Initializing create_model()
2025-03-05 15:38:49,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:49,015:INFO:Checking exceptions
2025-03-05 15:38:49,015:INFO:Importing libraries
2025-03-05 15:38:49,015:INFO:Copying training dataset
2025-03-05 15:38:49,019:INFO:Defining folds
2025-03-05 15:38:49,020:INFO:Declaring metric variables
2025-03-05 15:38:49,023:INFO:Importing untrained model
2025-03-05 15:38:49,025:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:38:49,031:INFO:Starting cross validation
2025-03-05 15:38:49,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:49,372:INFO:Calculating mean and std
2025-03-05 15:38:49,373:INFO:Creating metrics dataframe
2025-03-05 15:38:49,375:INFO:Uploading results into container
2025-03-05 15:38:49,375:INFO:Uploading model into container now
2025-03-05 15:38:49,376:INFO:_master_model_container: 12
2025-03-05 15:38:49,376:INFO:_display_container: 2
2025-03-05 15:38:49,376:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:38:49,376:INFO:create_model() successfully completed......................................
2025-03-05 15:38:49,503:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:49,503:INFO:Creating metrics dataframe
2025-03-05 15:38:49,519:INFO:Initializing Random Forest Regressor
2025-03-05 15:38:49,520:INFO:Total runtime is 0.11316950321197511 minutes
2025-03-05 15:38:49,525:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:49,525:INFO:Initializing create_model()
2025-03-05 15:38:49,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:49,525:INFO:Checking exceptions
2025-03-05 15:38:49,525:INFO:Importing libraries
2025-03-05 15:38:49,525:INFO:Copying training dataset
2025-03-05 15:38:49,530:INFO:Defining folds
2025-03-05 15:38:49,530:INFO:Declaring metric variables
2025-03-05 15:38:49,533:INFO:Importing untrained model
2025-03-05 15:38:49,536:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:38:49,541:INFO:Starting cross validation
2025-03-05 15:38:49,542:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:52,283:INFO:Calculating mean and std
2025-03-05 15:38:52,284:INFO:Creating metrics dataframe
2025-03-05 15:38:52,286:INFO:Uploading results into container
2025-03-05 15:38:52,286:INFO:Uploading model into container now
2025-03-05 15:38:52,287:INFO:_master_model_container: 13
2025-03-05 15:38:52,287:INFO:_display_container: 2
2025-03-05 15:38:52,287:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:38:52,287:INFO:create_model() successfully completed......................................
2025-03-05 15:38:52,417:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:52,417:INFO:Creating metrics dataframe
2025-03-05 15:38:52,428:INFO:Initializing Extra Trees Regressor
2025-03-05 15:38:52,428:INFO:Total runtime is 0.16163849830627441 minutes
2025-03-05 15:38:52,432:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:52,432:INFO:Initializing create_model()
2025-03-05 15:38:52,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:52,432:INFO:Checking exceptions
2025-03-05 15:38:52,432:INFO:Importing libraries
2025-03-05 15:38:52,432:INFO:Copying training dataset
2025-03-05 15:38:52,436:INFO:Defining folds
2025-03-05 15:38:52,437:INFO:Declaring metric variables
2025-03-05 15:38:52,440:INFO:Importing untrained model
2025-03-05 15:38:52,443:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:38:52,450:INFO:Starting cross validation
2025-03-05 15:38:52,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:54,260:INFO:Calculating mean and std
2025-03-05 15:38:54,261:INFO:Creating metrics dataframe
2025-03-05 15:38:54,264:INFO:Uploading results into container
2025-03-05 15:38:54,264:INFO:Uploading model into container now
2025-03-05 15:38:54,264:INFO:_master_model_container: 14
2025-03-05 15:38:54,265:INFO:_display_container: 2
2025-03-05 15:38:54,265:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:38:54,265:INFO:create_model() successfully completed......................................
2025-03-05 15:38:54,393:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:54,393:INFO:Creating metrics dataframe
2025-03-05 15:38:54,404:INFO:Initializing AdaBoost Regressor
2025-03-05 15:38:54,404:INFO:Total runtime is 0.19458144108454387 minutes
2025-03-05 15:38:54,407:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:54,408:INFO:Initializing create_model()
2025-03-05 15:38:54,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:54,408:INFO:Checking exceptions
2025-03-05 15:38:54,408:INFO:Importing libraries
2025-03-05 15:38:54,408:INFO:Copying training dataset
2025-03-05 15:38:54,412:INFO:Defining folds
2025-03-05 15:38:54,413:INFO:Declaring metric variables
2025-03-05 15:38:54,416:INFO:Importing untrained model
2025-03-05 15:38:54,419:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:38:54,427:INFO:Starting cross validation
2025-03-05 15:38:54,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:38:56,096:INFO:Calculating mean and std
2025-03-05 15:38:56,097:INFO:Creating metrics dataframe
2025-03-05 15:38:56,099:INFO:Uploading results into container
2025-03-05 15:38:56,100:INFO:Uploading model into container now
2025-03-05 15:38:56,100:INFO:_master_model_container: 15
2025-03-05 15:38:56,100:INFO:_display_container: 2
2025-03-05 15:38:56,100:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:38:56,100:INFO:create_model() successfully completed......................................
2025-03-05 15:38:56,222:INFO:SubProcess create_model() end ==================================
2025-03-05 15:38:56,222:INFO:Creating metrics dataframe
2025-03-05 15:38:56,231:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:38:56,231:INFO:Total runtime is 0.22503180106480916 minutes
2025-03-05 15:38:56,234:INFO:SubProcess create_model() called ==================================
2025-03-05 15:38:56,234:INFO:Initializing create_model()
2025-03-05 15:38:56,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:38:56,235:INFO:Checking exceptions
2025-03-05 15:38:56,235:INFO:Importing libraries
2025-03-05 15:38:56,235:INFO:Copying training dataset
2025-03-05 15:38:56,239:INFO:Defining folds
2025-03-05 15:38:56,239:INFO:Declaring metric variables
2025-03-05 15:38:56,242:INFO:Importing untrained model
2025-03-05 15:38:56,245:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:38:56,251:INFO:Starting cross validation
2025-03-05 15:38:56,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:05,464:INFO:Calculating mean and std
2025-03-05 15:39:05,465:INFO:Creating metrics dataframe
2025-03-05 15:39:05,467:INFO:Uploading results into container
2025-03-05 15:39:05,467:INFO:Uploading model into container now
2025-03-05 15:39:05,468:INFO:_master_model_container: 16
2025-03-05 15:39:05,468:INFO:_display_container: 2
2025-03-05 15:39:05,468:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:39:05,468:INFO:create_model() successfully completed......................................
2025-03-05 15:39:05,590:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:05,590:INFO:Creating metrics dataframe
2025-03-05 15:39:05,600:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:39:05,600:INFO:Total runtime is 0.38117276827494306 minutes
2025-03-05 15:39:05,603:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:05,603:INFO:Initializing create_model()
2025-03-05 15:39:05,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445d116bb20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445cebfefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:05,604:INFO:Checking exceptions
2025-03-05 15:39:05,604:INFO:Importing libraries
2025-03-05 15:39:05,604:INFO:Copying training dataset
2025-03-05 15:39:05,608:INFO:Defining folds
2025-03-05 15:39:05,608:INFO:Declaring metric variables
2025-03-05 15:39:05,611:INFO:Importing untrained model
2025-03-05 15:39:05,615:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:39:05,621:INFO:Starting cross validation
2025-03-05 15:39:05,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:05,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031443 seconds.
2025-03-05 15:39:05,690:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:05,690:INFO:[LightGBM] [Info] Total Bins 587
2025-03-05 15:39:05,700:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 3
2025-03-05 15:39:05,717:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:39:13,378:INFO:PyCaret RegressionExperiment
2025-03-05 15:39:13,378:INFO:Logging name: reg-default-name
2025-03-05 15:39:13,378:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 15:39:13,378:INFO:version 3.3.1
2025-03-05 15:39:13,379:INFO:Initializing setup()
2025-03-05 15:39:13,379:INFO:self.USI: 57c1
2025-03-05 15:39:13,379:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 15:39:13,379:INFO:Checking environment
2025-03-05 15:39:13,379:INFO:python_version: 3.9.21
2025-03-05 15:39:13,379:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 15:39:13,379:INFO:machine: x86_64
2025-03-05 15:39:13,379:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:39:13,379:INFO:Memory: svmem(total=33374507008, available=21283229696, percent=36.2, used=9501700096, free=3720462336, active=13583331328, inactive=11851325440, buffers=682004480, cached=19470340096, shared=2060488704, slab=1829064704)
2025-03-05 15:39:13,380:INFO:Physical Core: 24
2025-03-05 15:39:13,380:INFO:Logical Core: 32
2025-03-05 15:39:13,380:INFO:Checking libraries
2025-03-05 15:39:13,380:INFO:System:
2025-03-05 15:39:13,380:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 15:39:13,380:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 15:39:13,380:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 15:39:13,380:INFO:PyCaret required dependencies:
2025-03-05 15:39:13,380:INFO:                 pip: 25.0
2025-03-05 15:39:13,380:INFO:          setuptools: 75.8.0
2025-03-05 15:39:13,380:INFO:             pycaret: 3.3.1
2025-03-05 15:39:13,380:INFO:             IPython: 8.18.1
2025-03-05 15:39:13,380:INFO:          ipywidgets: 8.1.5
2025-03-05 15:39:13,380:INFO:                tqdm: 4.67.1
2025-03-05 15:39:13,380:INFO:               numpy: 1.26.4
2025-03-05 15:39:13,380:INFO:              pandas: 2.1.4
2025-03-05 15:39:13,380:INFO:              jinja2: 3.1.5
2025-03-05 15:39:13,380:INFO:               scipy: 1.11.4
2025-03-05 15:39:13,380:INFO:              joblib: 1.3.2
2025-03-05 15:39:13,380:INFO:             sklearn: 1.4.2
2025-03-05 15:39:13,380:INFO:                pyod: 2.0.3
2025-03-05 15:39:13,380:INFO:            imblearn: 0.12.4
2025-03-05 15:39:13,380:INFO:   category_encoders: 2.6.4
2025-03-05 15:39:13,380:INFO:            lightgbm: 4.6.0
2025-03-05 15:39:13,380:INFO:               numba: 0.60.0
2025-03-05 15:39:13,380:INFO:            requests: 2.32.3
2025-03-05 15:39:13,380:INFO:          matplotlib: 3.7.5
2025-03-05 15:39:13,380:INFO:          scikitplot: 0.3.7
2025-03-05 15:39:13,380:INFO:         yellowbrick: 1.5
2025-03-05 15:39:13,380:INFO:              plotly: 5.24.1
2025-03-05 15:39:13,380:INFO:    plotly-resampler: Not installed
2025-03-05 15:39:13,380:INFO:             kaleido: 0.2.1
2025-03-05 15:39:13,380:INFO:           schemdraw: 0.15
2025-03-05 15:39:13,380:INFO:         statsmodels: 0.14.4
2025-03-05 15:39:13,380:INFO:              sktime: 0.26.0
2025-03-05 15:39:13,380:INFO:               tbats: 1.1.3
2025-03-05 15:39:13,380:INFO:            pmdarima: 2.0.4
2025-03-05 15:39:13,380:INFO:              psutil: 7.0.0
2025-03-05 15:39:13,380:INFO:          markupsafe: 3.0.2
2025-03-05 15:39:13,380:INFO:             pickle5: Not installed
2025-03-05 15:39:13,380:INFO:         cloudpickle: 3.1.1
2025-03-05 15:39:13,380:INFO:         deprecation: 2.1.0
2025-03-05 15:39:13,380:INFO:              xxhash: 3.5.0
2025-03-05 15:39:13,381:INFO:           wurlitzer: 3.1.1
2025-03-05 15:39:13,381:INFO:PyCaret optional dependencies:
2025-03-05 15:39:13,381:INFO:                shap: Not installed
2025-03-05 15:39:13,381:INFO:           interpret: Not installed
2025-03-05 15:39:13,381:INFO:                umap: Not installed
2025-03-05 15:39:13,381:INFO:     ydata_profiling: Not installed
2025-03-05 15:39:13,381:INFO:  explainerdashboard: Not installed
2025-03-05 15:39:13,381:INFO:             autoviz: Not installed
2025-03-05 15:39:13,381:INFO:           fairlearn: Not installed
2025-03-05 15:39:13,381:INFO:          deepchecks: Not installed
2025-03-05 15:39:13,381:INFO:             xgboost: Not installed
2025-03-05 15:39:13,381:INFO:            catboost: Not installed
2025-03-05 15:39:13,381:INFO:              kmodes: Not installed
2025-03-05 15:39:13,381:INFO:             mlxtend: Not installed
2025-03-05 15:39:13,381:INFO:       statsforecast: Not installed
2025-03-05 15:39:13,381:INFO:        tune_sklearn: Not installed
2025-03-05 15:39:13,381:INFO:                 ray: Not installed
2025-03-05 15:39:13,381:INFO:            hyperopt: Not installed
2025-03-05 15:39:13,381:INFO:              optuna: Not installed
2025-03-05 15:39:13,381:INFO:               skopt: Not installed
2025-03-05 15:39:13,381:INFO:              mlflow: Not installed
2025-03-05 15:39:13,381:INFO:              gradio: Not installed
2025-03-05 15:39:13,381:INFO:             fastapi: Not installed
2025-03-05 15:39:13,381:INFO:             uvicorn: Not installed
2025-03-05 15:39:13,381:INFO:              m2cgen: Not installed
2025-03-05 15:39:13,381:INFO:           evidently: Not installed
2025-03-05 15:39:13,381:INFO:               fugue: Not installed
2025-03-05 15:39:13,381:INFO:           streamlit: Not installed
2025-03-05 15:39:13,381:INFO:             prophet: Not installed
2025-03-05 15:39:13,381:INFO:None
2025-03-05 15:39:13,381:INFO:Set up GPU usage.
2025-03-05 15:39:13,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,381:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 15:39:13,381:INFO:Set up data.
2025-03-05 15:39:13,384:INFO:Set up folding strategy.
2025-03-05 15:39:13,384:INFO:Set up train/test split.
2025-03-05 15:39:13,387:INFO:Set up index.
2025-03-05 15:39:13,388:INFO:Assigning column types.
2025-03-05 15:39:13,390:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 15:39:13,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,391:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,492:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,516:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,618:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 15:39:13,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,744:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,850:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 15:39:13,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:13,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:13,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 15:39:13,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,026:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,072:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 15:39:14,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,141:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,301:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 15:39:14,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,314:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,363:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 15:39:14,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,513:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 15:39:14,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,740:INFO:Preparing preprocessing pipeline...
2025-03-05 15:39:14,740:INFO:Set up simple imputation.
2025-03-05 15:39:14,740:INFO:Set up polynomial features.
2025-03-05 15:39:14,767:INFO:Finished creating preprocessing pipeline.
2025-03-05 15:39:14,771:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-03-05 15:39:14,771:INFO:Creating final display dataframe.
2025-03-05 15:39:14,833:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (20088, 2)
4        Transformed data shape        (20088, 3)
5   Transformed train set shape        (14061, 3)
6    Transformed test set shape         (6027, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              57c1
2025-03-05 15:39:14,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:14,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:14,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:15,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:15,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:15,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 15:39:15,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:15,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 15:39:15,051:INFO:setup() successfully completed in 1.67s...............
2025-03-05 15:39:15,070:INFO:Initializing compare_models()
2025-03-05 15:39:15,070:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 15:39:15,070:INFO:Checking exceptions
2025-03-05 15:39:15,073:INFO:Preparing display monitor
2025-03-05 15:39:15,097:INFO:Initializing Linear Regression
2025-03-05 15:39:15,097:INFO:Total runtime is 2.022584279378255e-06 minutes
2025-03-05 15:39:15,100:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:15,100:INFO:Initializing create_model()
2025-03-05 15:39:15,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:15,101:INFO:Checking exceptions
2025-03-05 15:39:15,101:INFO:Importing libraries
2025-03-05 15:39:15,101:INFO:Copying training dataset
2025-03-05 15:39:15,104:INFO:Defining folds
2025-03-05 15:39:15,104:INFO:Declaring metric variables
2025-03-05 15:39:15,108:INFO:Importing untrained model
2025-03-05 15:39:15,111:INFO:Linear Regression Imported successfully
2025-03-05 15:39:15,123:INFO:Starting cross validation
2025-03-05 15:39:15,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:15,304:INFO:Calculating mean and std
2025-03-05 15:39:15,304:INFO:Creating metrics dataframe
2025-03-05 15:39:15,306:INFO:Uploading results into container
2025-03-05 15:39:15,306:INFO:Uploading model into container now
2025-03-05 15:39:15,307:INFO:_master_model_container: 1
2025-03-05 15:39:15,307:INFO:_display_container: 2
2025-03-05 15:39:15,307:INFO:LinearRegression(n_jobs=-1)
2025-03-05 15:39:15,307:INFO:create_model() successfully completed......................................
2025-03-05 15:39:15,450:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:15,450:INFO:Creating metrics dataframe
2025-03-05 15:39:15,457:INFO:Initializing Lasso Regression
2025-03-05 15:39:15,457:INFO:Total runtime is 0.006000705560048421 minutes
2025-03-05 15:39:15,460:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:15,460:INFO:Initializing create_model()
2025-03-05 15:39:15,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:15,460:INFO:Checking exceptions
2025-03-05 15:39:15,460:INFO:Importing libraries
2025-03-05 15:39:15,461:INFO:Copying training dataset
2025-03-05 15:39:15,464:INFO:Defining folds
2025-03-05 15:39:15,464:INFO:Declaring metric variables
2025-03-05 15:39:15,468:INFO:Importing untrained model
2025-03-05 15:39:15,471:INFO:Lasso Regression Imported successfully
2025-03-05 15:39:15,477:INFO:Starting cross validation
2025-03-05 15:39:15,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:15,710:INFO:Calculating mean and std
2025-03-05 15:39:15,711:INFO:Creating metrics dataframe
2025-03-05 15:39:15,713:INFO:Uploading results into container
2025-03-05 15:39:15,713:INFO:Uploading model into container now
2025-03-05 15:39:15,714:INFO:_master_model_container: 2
2025-03-05 15:39:15,714:INFO:_display_container: 2
2025-03-05 15:39:15,714:INFO:Lasso(random_state=123)
2025-03-05 15:39:15,714:INFO:create_model() successfully completed......................................
2025-03-05 15:39:15,867:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:15,867:INFO:Creating metrics dataframe
2025-03-05 15:39:15,874:INFO:Initializing Ridge Regression
2025-03-05 15:39:15,874:INFO:Total runtime is 0.012961411476135254 minutes
2025-03-05 15:39:15,877:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:15,878:INFO:Initializing create_model()
2025-03-05 15:39:15,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:15,878:INFO:Checking exceptions
2025-03-05 15:39:15,878:INFO:Importing libraries
2025-03-05 15:39:15,878:INFO:Copying training dataset
2025-03-05 15:39:15,882:INFO:Defining folds
2025-03-05 15:39:15,882:INFO:Declaring metric variables
2025-03-05 15:39:15,885:INFO:Importing untrained model
2025-03-05 15:39:15,888:INFO:Ridge Regression Imported successfully
2025-03-05 15:39:15,894:INFO:Starting cross validation
2025-03-05 15:39:15,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:16,066:INFO:Calculating mean and std
2025-03-05 15:39:16,066:INFO:Creating metrics dataframe
2025-03-05 15:39:16,068:INFO:Uploading results into container
2025-03-05 15:39:16,068:INFO:Uploading model into container now
2025-03-05 15:39:16,069:INFO:_master_model_container: 3
2025-03-05 15:39:16,069:INFO:_display_container: 2
2025-03-05 15:39:16,069:INFO:Ridge(random_state=123)
2025-03-05 15:39:16,069:INFO:create_model() successfully completed......................................
2025-03-05 15:39:16,205:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:16,205:INFO:Creating metrics dataframe
2025-03-05 15:39:16,212:INFO:Initializing Elastic Net
2025-03-05 15:39:16,213:INFO:Total runtime is 0.018600491682688396 minutes
2025-03-05 15:39:16,216:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:16,216:INFO:Initializing create_model()
2025-03-05 15:39:16,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:16,217:INFO:Checking exceptions
2025-03-05 15:39:16,217:INFO:Importing libraries
2025-03-05 15:39:16,217:INFO:Copying training dataset
2025-03-05 15:39:16,221:INFO:Defining folds
2025-03-05 15:39:16,221:INFO:Declaring metric variables
2025-03-05 15:39:16,224:INFO:Importing untrained model
2025-03-05 15:39:16,227:INFO:Elastic Net Imported successfully
2025-03-05 15:39:16,233:INFO:Starting cross validation
2025-03-05 15:39:16,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:16,514:INFO:Calculating mean and std
2025-03-05 15:39:16,515:INFO:Creating metrics dataframe
2025-03-05 15:39:16,517:INFO:Uploading results into container
2025-03-05 15:39:16,518:INFO:Uploading model into container now
2025-03-05 15:39:16,519:INFO:_master_model_container: 4
2025-03-05 15:39:16,519:INFO:_display_container: 2
2025-03-05 15:39:16,519:INFO:ElasticNet(random_state=123)
2025-03-05 15:39:16,519:INFO:create_model() successfully completed......................................
2025-03-05 15:39:16,675:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:16,675:INFO:Creating metrics dataframe
2025-03-05 15:39:16,683:INFO:Initializing Least Angle Regression
2025-03-05 15:39:16,683:INFO:Total runtime is 0.026432394981384277 minutes
2025-03-05 15:39:16,686:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:16,686:INFO:Initializing create_model()
2025-03-05 15:39:16,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:16,686:INFO:Checking exceptions
2025-03-05 15:39:16,686:INFO:Importing libraries
2025-03-05 15:39:16,686:INFO:Copying training dataset
2025-03-05 15:39:16,691:INFO:Defining folds
2025-03-05 15:39:16,691:INFO:Declaring metric variables
2025-03-05 15:39:16,694:INFO:Importing untrained model
2025-03-05 15:39:16,697:INFO:Least Angle Regression Imported successfully
2025-03-05 15:39:16,703:INFO:Starting cross validation
2025-03-05 15:39:16,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:16,873:INFO:Calculating mean and std
2025-03-05 15:39:16,874:INFO:Creating metrics dataframe
2025-03-05 15:39:16,876:INFO:Uploading results into container
2025-03-05 15:39:16,876:INFO:Uploading model into container now
2025-03-05 15:39:16,877:INFO:_master_model_container: 5
2025-03-05 15:39:16,877:INFO:_display_container: 2
2025-03-05 15:39:16,877:INFO:Lars(random_state=123)
2025-03-05 15:39:16,877:INFO:create_model() successfully completed......................................
2025-03-05 15:39:17,012:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:17,012:INFO:Creating metrics dataframe
2025-03-05 15:39:17,020:INFO:Initializing Lasso Least Angle Regression
2025-03-05 15:39:17,020:INFO:Total runtime is 0.03205307722091675 minutes
2025-03-05 15:39:17,023:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:17,023:INFO:Initializing create_model()
2025-03-05 15:39:17,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:17,024:INFO:Checking exceptions
2025-03-05 15:39:17,024:INFO:Importing libraries
2025-03-05 15:39:17,024:INFO:Copying training dataset
2025-03-05 15:39:17,028:INFO:Defining folds
2025-03-05 15:39:17,028:INFO:Declaring metric variables
2025-03-05 15:39:17,031:INFO:Importing untrained model
2025-03-05 15:39:17,034:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 15:39:17,040:INFO:Starting cross validation
2025-03-05 15:39:17,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:17,210:INFO:Calculating mean and std
2025-03-05 15:39:17,211:INFO:Creating metrics dataframe
2025-03-05 15:39:17,213:INFO:Uploading results into container
2025-03-05 15:39:17,213:INFO:Uploading model into container now
2025-03-05 15:39:17,214:INFO:_master_model_container: 6
2025-03-05 15:39:17,214:INFO:_display_container: 2
2025-03-05 15:39:17,214:INFO:LassoLars(random_state=123)
2025-03-05 15:39:17,214:INFO:create_model() successfully completed......................................
2025-03-05 15:39:17,349:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:17,349:INFO:Creating metrics dataframe
2025-03-05 15:39:17,356:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 15:39:17,357:INFO:Total runtime is 0.0376646876335144 minutes
2025-03-05 15:39:17,360:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:17,360:INFO:Initializing create_model()
2025-03-05 15:39:17,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:17,360:INFO:Checking exceptions
2025-03-05 15:39:17,360:INFO:Importing libraries
2025-03-05 15:39:17,360:INFO:Copying training dataset
2025-03-05 15:39:17,365:INFO:Defining folds
2025-03-05 15:39:17,365:INFO:Declaring metric variables
2025-03-05 15:39:17,368:INFO:Importing untrained model
2025-03-05 15:39:17,373:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 15:39:17,380:INFO:Starting cross validation
2025-03-05 15:39:17,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:17,566:INFO:Calculating mean and std
2025-03-05 15:39:17,567:INFO:Creating metrics dataframe
2025-03-05 15:39:17,569:INFO:Uploading results into container
2025-03-05 15:39:17,569:INFO:Uploading model into container now
2025-03-05 15:39:17,569:INFO:_master_model_container: 7
2025-03-05 15:39:17,570:INFO:_display_container: 2
2025-03-05 15:39:17,570:INFO:OrthogonalMatchingPursuit()
2025-03-05 15:39:17,570:INFO:create_model() successfully completed......................................
2025-03-05 15:39:17,705:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:17,705:INFO:Creating metrics dataframe
2025-03-05 15:39:17,713:INFO:Initializing Bayesian Ridge
2025-03-05 15:39:17,713:INFO:Total runtime is 0.04360546668370564 minutes
2025-03-05 15:39:17,716:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:17,717:INFO:Initializing create_model()
2025-03-05 15:39:17,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:17,717:INFO:Checking exceptions
2025-03-05 15:39:17,717:INFO:Importing libraries
2025-03-05 15:39:17,717:INFO:Copying training dataset
2025-03-05 15:39:17,721:INFO:Defining folds
2025-03-05 15:39:17,721:INFO:Declaring metric variables
2025-03-05 15:39:17,724:INFO:Importing untrained model
2025-03-05 15:39:17,728:INFO:Bayesian Ridge Imported successfully
2025-03-05 15:39:17,733:INFO:Starting cross validation
2025-03-05 15:39:17,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:17,978:INFO:Calculating mean and std
2025-03-05 15:39:17,980:INFO:Creating metrics dataframe
2025-03-05 15:39:17,982:INFO:Uploading results into container
2025-03-05 15:39:17,983:INFO:Uploading model into container now
2025-03-05 15:39:17,983:INFO:_master_model_container: 8
2025-03-05 15:39:17,983:INFO:_display_container: 2
2025-03-05 15:39:17,984:INFO:BayesianRidge()
2025-03-05 15:39:17,984:INFO:create_model() successfully completed......................................
2025-03-05 15:39:18,140:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:18,140:INFO:Creating metrics dataframe
2025-03-05 15:39:18,148:INFO:Initializing Passive Aggressive Regressor
2025-03-05 15:39:18,148:INFO:Total runtime is 0.05084971984227498 minutes
2025-03-05 15:39:18,151:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:18,151:INFO:Initializing create_model()
2025-03-05 15:39:18,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:18,151:INFO:Checking exceptions
2025-03-05 15:39:18,151:INFO:Importing libraries
2025-03-05 15:39:18,151:INFO:Copying training dataset
2025-03-05 15:39:18,156:INFO:Defining folds
2025-03-05 15:39:18,156:INFO:Declaring metric variables
2025-03-05 15:39:18,159:INFO:Importing untrained model
2025-03-05 15:39:18,162:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 15:39:18,167:INFO:Starting cross validation
2025-03-05 15:39:18,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:18,436:INFO:Calculating mean and std
2025-03-05 15:39:18,437:INFO:Creating metrics dataframe
2025-03-05 15:39:18,439:INFO:Uploading results into container
2025-03-05 15:39:18,439:INFO:Uploading model into container now
2025-03-05 15:39:18,439:INFO:_master_model_container: 9
2025-03-05 15:39:18,440:INFO:_display_container: 2
2025-03-05 15:39:18,440:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 15:39:18,440:INFO:create_model() successfully completed......................................
2025-03-05 15:39:18,575:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:18,575:INFO:Creating metrics dataframe
2025-03-05 15:39:18,583:INFO:Initializing Huber Regressor
2025-03-05 15:39:18,583:INFO:Total runtime is 0.05810651381810506 minutes
2025-03-05 15:39:18,586:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:18,586:INFO:Initializing create_model()
2025-03-05 15:39:18,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:18,587:INFO:Checking exceptions
2025-03-05 15:39:18,587:INFO:Importing libraries
2025-03-05 15:39:18,587:INFO:Copying training dataset
2025-03-05 15:39:18,591:INFO:Defining folds
2025-03-05 15:39:18,591:INFO:Declaring metric variables
2025-03-05 15:39:18,594:INFO:Importing untrained model
2025-03-05 15:39:18,597:INFO:Huber Regressor Imported successfully
2025-03-05 15:39:18,602:INFO:Starting cross validation
2025-03-05 15:39:18,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:19,945:INFO:Calculating mean and std
2025-03-05 15:39:19,948:INFO:Creating metrics dataframe
2025-03-05 15:39:19,951:INFO:Uploading results into container
2025-03-05 15:39:19,952:INFO:Uploading model into container now
2025-03-05 15:39:19,953:INFO:_master_model_container: 10
2025-03-05 15:39:19,953:INFO:_display_container: 2
2025-03-05 15:39:19,953:INFO:HuberRegressor()
2025-03-05 15:39:19,953:INFO:create_model() successfully completed......................................
2025-03-05 15:39:20,137:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:20,137:INFO:Creating metrics dataframe
2025-03-05 15:39:20,146:INFO:Initializing K Neighbors Regressor
2025-03-05 15:39:20,146:INFO:Total runtime is 0.08415315945943197 minutes
2025-03-05 15:39:20,149:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:20,149:INFO:Initializing create_model()
2025-03-05 15:39:20,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:20,149:INFO:Checking exceptions
2025-03-05 15:39:20,149:INFO:Importing libraries
2025-03-05 15:39:20,149:INFO:Copying training dataset
2025-03-05 15:39:20,154:INFO:Defining folds
2025-03-05 15:39:20,154:INFO:Declaring metric variables
2025-03-05 15:39:20,157:INFO:Importing untrained model
2025-03-05 15:39:20,160:INFO:K Neighbors Regressor Imported successfully
2025-03-05 15:39:20,166:INFO:Starting cross validation
2025-03-05 15:39:20,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:20,668:INFO:Calculating mean and std
2025-03-05 15:39:20,670:INFO:Creating metrics dataframe
2025-03-05 15:39:20,672:INFO:Uploading results into container
2025-03-05 15:39:20,672:INFO:Uploading model into container now
2025-03-05 15:39:20,672:INFO:_master_model_container: 11
2025-03-05 15:39:20,673:INFO:_display_container: 2
2025-03-05 15:39:20,673:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 15:39:20,673:INFO:create_model() successfully completed......................................
2025-03-05 15:39:20,811:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:20,812:INFO:Creating metrics dataframe
2025-03-05 15:39:20,821:INFO:Initializing Decision Tree Regressor
2025-03-05 15:39:20,821:INFO:Total runtime is 0.09539876381556193 minutes
2025-03-05 15:39:20,824:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:20,824:INFO:Initializing create_model()
2025-03-05 15:39:20,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:20,824:INFO:Checking exceptions
2025-03-05 15:39:20,824:INFO:Importing libraries
2025-03-05 15:39:20,825:INFO:Copying training dataset
2025-03-05 15:39:20,829:INFO:Defining folds
2025-03-05 15:39:20,829:INFO:Declaring metric variables
2025-03-05 15:39:20,832:INFO:Importing untrained model
2025-03-05 15:39:20,835:INFO:Decision Tree Regressor Imported successfully
2025-03-05 15:39:20,841:INFO:Starting cross validation
2025-03-05 15:39:20,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:21,088:INFO:Calculating mean and std
2025-03-05 15:39:21,089:INFO:Creating metrics dataframe
2025-03-05 15:39:21,090:INFO:Uploading results into container
2025-03-05 15:39:21,091:INFO:Uploading model into container now
2025-03-05 15:39:21,091:INFO:_master_model_container: 12
2025-03-05 15:39:21,092:INFO:_display_container: 2
2025-03-05 15:39:21,092:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 15:39:21,092:INFO:create_model() successfully completed......................................
2025-03-05 15:39:21,227:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:21,227:INFO:Creating metrics dataframe
2025-03-05 15:39:21,236:INFO:Initializing Random Forest Regressor
2025-03-05 15:39:21,236:INFO:Total runtime is 0.10232309500376384 minutes
2025-03-05 15:39:21,239:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:21,240:INFO:Initializing create_model()
2025-03-05 15:39:21,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:21,240:INFO:Checking exceptions
2025-03-05 15:39:21,240:INFO:Importing libraries
2025-03-05 15:39:21,240:INFO:Copying training dataset
2025-03-05 15:39:21,245:INFO:Defining folds
2025-03-05 15:39:21,245:INFO:Declaring metric variables
2025-03-05 15:39:21,248:INFO:Importing untrained model
2025-03-05 15:39:21,251:INFO:Random Forest Regressor Imported successfully
2025-03-05 15:39:21,257:INFO:Starting cross validation
2025-03-05 15:39:21,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:23,861:INFO:Calculating mean and std
2025-03-05 15:39:23,862:INFO:Creating metrics dataframe
2025-03-05 15:39:23,864:INFO:Uploading results into container
2025-03-05 15:39:23,865:INFO:Uploading model into container now
2025-03-05 15:39:23,866:INFO:_master_model_container: 13
2025-03-05 15:39:23,866:INFO:_display_container: 2
2025-03-05 15:39:23,866:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:39:23,866:INFO:create_model() successfully completed......................................
2025-03-05 15:39:24,002:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:24,002:INFO:Creating metrics dataframe
2025-03-05 15:39:24,013:INFO:Initializing Extra Trees Regressor
2025-03-05 15:39:24,013:INFO:Total runtime is 0.148599382241567 minutes
2025-03-05 15:39:24,016:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:24,016:INFO:Initializing create_model()
2025-03-05 15:39:24,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:24,016:INFO:Checking exceptions
2025-03-05 15:39:24,016:INFO:Importing libraries
2025-03-05 15:39:24,016:INFO:Copying training dataset
2025-03-05 15:39:24,021:INFO:Defining folds
2025-03-05 15:39:24,021:INFO:Declaring metric variables
2025-03-05 15:39:24,024:INFO:Importing untrained model
2025-03-05 15:39:24,027:INFO:Extra Trees Regressor Imported successfully
2025-03-05 15:39:24,033:INFO:Starting cross validation
2025-03-05 15:39:24,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:25,704:INFO:Calculating mean and std
2025-03-05 15:39:25,705:INFO:Creating metrics dataframe
2025-03-05 15:39:25,707:INFO:Uploading results into container
2025-03-05 15:39:25,707:INFO:Uploading model into container now
2025-03-05 15:39:25,708:INFO:_master_model_container: 14
2025-03-05 15:39:25,708:INFO:_display_container: 2
2025-03-05 15:39:25,708:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:39:25,708:INFO:create_model() successfully completed......................................
2025-03-05 15:39:25,843:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:25,844:INFO:Creating metrics dataframe
2025-03-05 15:39:25,853:INFO:Initializing AdaBoost Regressor
2025-03-05 15:39:25,853:INFO:Total runtime is 0.1792737921079 minutes
2025-03-05 15:39:25,856:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:25,857:INFO:Initializing create_model()
2025-03-05 15:39:25,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:25,857:INFO:Checking exceptions
2025-03-05 15:39:25,857:INFO:Importing libraries
2025-03-05 15:39:25,857:INFO:Copying training dataset
2025-03-05 15:39:25,861:INFO:Defining folds
2025-03-05 15:39:25,861:INFO:Declaring metric variables
2025-03-05 15:39:25,864:INFO:Importing untrained model
2025-03-05 15:39:25,867:INFO:AdaBoost Regressor Imported successfully
2025-03-05 15:39:25,873:INFO:Starting cross validation
2025-03-05 15:39:25,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:27,230:INFO:Calculating mean and std
2025-03-05 15:39:27,232:INFO:Creating metrics dataframe
2025-03-05 15:39:27,233:INFO:Uploading results into container
2025-03-05 15:39:27,234:INFO:Uploading model into container now
2025-03-05 15:39:27,234:INFO:_master_model_container: 15
2025-03-05 15:39:27,234:INFO:_display_container: 2
2025-03-05 15:39:27,234:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 15:39:27,234:INFO:create_model() successfully completed......................................
2025-03-05 15:39:27,371:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:27,371:INFO:Creating metrics dataframe
2025-03-05 15:39:27,380:INFO:Initializing Gradient Boosting Regressor
2025-03-05 15:39:27,381:INFO:Total runtime is 0.20473332405090333 minutes
2025-03-05 15:39:27,384:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:27,384:INFO:Initializing create_model()
2025-03-05 15:39:27,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:27,384:INFO:Checking exceptions
2025-03-05 15:39:27,384:INFO:Importing libraries
2025-03-05 15:39:27,384:INFO:Copying training dataset
2025-03-05 15:39:27,389:INFO:Defining folds
2025-03-05 15:39:27,389:INFO:Declaring metric variables
2025-03-05 15:39:27,392:INFO:Importing untrained model
2025-03-05 15:39:27,395:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:39:27,402:INFO:Starting cross validation
2025-03-05 15:39:27,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:34,190:INFO:Calculating mean and std
2025-03-05 15:39:34,191:INFO:Creating metrics dataframe
2025-03-05 15:39:34,202:INFO:Uploading results into container
2025-03-05 15:39:34,202:INFO:Uploading model into container now
2025-03-05 15:39:34,203:INFO:_master_model_container: 16
2025-03-05 15:39:34,203:INFO:_display_container: 2
2025-03-05 15:39:34,203:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:39:34,203:INFO:create_model() successfully completed......................................
2025-03-05 15:39:34,344:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:34,344:INFO:Creating metrics dataframe
2025-03-05 15:39:34,355:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 15:39:34,355:INFO:Total runtime is 0.3209694306055705 minutes
2025-03-05 15:39:34,361:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:34,362:INFO:Initializing create_model()
2025-03-05 15:39:34,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:34,362:INFO:Checking exceptions
2025-03-05 15:39:34,362:INFO:Importing libraries
2025-03-05 15:39:34,362:INFO:Copying training dataset
2025-03-05 15:39:34,371:INFO:Defining folds
2025-03-05 15:39:34,371:INFO:Declaring metric variables
2025-03-05 15:39:34,377:INFO:Importing untrained model
2025-03-05 15:39:34,384:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 15:39:34,395:INFO:Starting cross validation
2025-03-05 15:39:34,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:34,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031036 seconds.
2025-03-05 15:39:34,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:34,466:INFO:[LightGBM] [Info] Total Bins 438
2025-03-05 15:39:34,472:INFO:[LightGBM] [Info] Number of data points in the train set: 12654, number of used features: 2
2025-03-05 15:39:34,490:INFO:[LightGBM] [Info] Start training from score 5.451083
2025-03-05 15:39:34,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2025-03-05 15:39:34,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:34,872:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:39:34,875:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:34,876:INFO:[LightGBM] [Info] Start training from score 5.448874
2025-03-05 15:39:35,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042635 seconds.
2025-03-05 15:39:35,588:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:35,588:INFO:[LightGBM] [Info] Total Bins 432
2025-03-05 15:39:35,597:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:35,617:INFO:[LightGBM] [Info] Start training from score 5.445476
2025-03-05 15:39:36,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030608 seconds.
2025-03-05 15:39:36,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:36,902:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:39:36,908:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:36,923:INFO:[LightGBM] [Info] Start training from score 5.444923
2025-03-05 15:39:37,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028683 seconds.
2025-03-05 15:39:37,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:37,375:INFO:[LightGBM] [Info] Total Bins 432
2025-03-05 15:39:37,383:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:37,401:INFO:[LightGBM] [Info] Start training from score 5.454642
2025-03-05 15:39:39,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037624 seconds.
2025-03-05 15:39:39,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:39,194:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:39:39,204:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:39,219:INFO:[LightGBM] [Info] Start training from score 5.456381
2025-03-05 15:39:41,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031600 seconds.
2025-03-05 15:39:41,002:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:41,002:INFO:[LightGBM] [Info] Total Bins 430
2025-03-05 15:39:41,010:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:41,021:INFO:[LightGBM] [Info] Start training from score 5.445555
2025-03-05 15:39:41,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035114 seconds.
2025-03-05 15:39:41,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:41,447:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:39:41,447:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:41,447:INFO:[LightGBM] [Info] Start training from score 5.456104
2025-03-05 15:39:41,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009177 seconds.
2025-03-05 15:39:41,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-05 15:39:41,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-05 15:39:41,806:INFO:[LightGBM] [Info] Total Bins 436
2025-03-05 15:39:41,808:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:41,809:INFO:[LightGBM] [Info] Start training from score 5.460253
2025-03-05 15:39:42,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028570 seconds.
2025-03-05 15:39:42,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 15:39:42,352:INFO:[LightGBM] [Info] Total Bins 434
2025-03-05 15:39:42,362:INFO:[LightGBM] [Info] Number of data points in the train set: 12655, number of used features: 2
2025-03-05 15:39:42,376:INFO:[LightGBM] [Info] Start training from score 5.452390
2025-03-05 15:39:42,858:INFO:Calculating mean and std
2025-03-05 15:39:42,860:INFO:Creating metrics dataframe
2025-03-05 15:39:42,862:INFO:Uploading results into container
2025-03-05 15:39:42,863:INFO:Uploading model into container now
2025-03-05 15:39:42,863:INFO:_master_model_container: 17
2025-03-05 15:39:42,863:INFO:_display_container: 2
2025-03-05 15:39:42,864:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 15:39:42,864:INFO:create_model() successfully completed......................................
2025-03-05 15:39:43,012:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:43,012:INFO:Creating metrics dataframe
2025-03-05 15:39:43,022:INFO:Initializing Dummy Regressor
2025-03-05 15:39:43,022:INFO:Total runtime is 0.4654175798098246 minutes
2025-03-05 15:39:43,025:INFO:SubProcess create_model() called ==================================
2025-03-05 15:39:43,026:INFO:Initializing create_model()
2025-03-05 15:39:43,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445eb1472b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:43,026:INFO:Checking exceptions
2025-03-05 15:39:43,026:INFO:Importing libraries
2025-03-05 15:39:43,026:INFO:Copying training dataset
2025-03-05 15:39:43,030:INFO:Defining folds
2025-03-05 15:39:43,030:INFO:Declaring metric variables
2025-03-05 15:39:43,034:INFO:Importing untrained model
2025-03-05 15:39:43,037:INFO:Dummy Regressor Imported successfully
2025-03-05 15:39:43,043:INFO:Starting cross validation
2025-03-05 15:39:43,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 15:39:43,201:INFO:Calculating mean and std
2025-03-05 15:39:43,202:INFO:Creating metrics dataframe
2025-03-05 15:39:43,203:INFO:Uploading results into container
2025-03-05 15:39:43,204:INFO:Uploading model into container now
2025-03-05 15:39:43,204:INFO:_master_model_container: 18
2025-03-05 15:39:43,204:INFO:_display_container: 2
2025-03-05 15:39:43,205:INFO:DummyRegressor()
2025-03-05 15:39:43,205:INFO:create_model() successfully completed......................................
2025-03-05 15:39:43,343:INFO:SubProcess create_model() end ==================================
2025-03-05 15:39:43,343:INFO:Creating metrics dataframe
2025-03-05 15:39:43,353:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-05 15:39:43,361:INFO:Initializing create_model()
2025-03-05 15:39:43,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 15:39:43,361:INFO:Checking exceptions
2025-03-05 15:39:43,363:INFO:Importing libraries
2025-03-05 15:39:43,363:INFO:Copying training dataset
2025-03-05 15:39:43,366:INFO:Defining folds
2025-03-05 15:39:43,366:INFO:Declaring metric variables
2025-03-05 15:39:43,367:INFO:Importing untrained model
2025-03-05 15:39:43,367:INFO:Declaring custom model
2025-03-05 15:39:43,367:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 15:39:43,368:INFO:Cross validation set to False
2025-03-05 15:39:43,368:INFO:Fitting Model
2025-03-05 15:39:44,110:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:39:44,110:INFO:create_model() successfully completed......................................
2025-03-05 15:39:44,272:INFO:_master_model_container: 18
2025-03-05 15:39:44,272:INFO:_display_container: 2
2025-03-05 15:39:44,272:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 15:39:44,272:INFO:compare_models() successfully completed......................................
2025-03-05 15:39:44,336:INFO:Initializing evaluate_model()
2025-03-05 15:39:44,337:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 15:39:44,345:INFO:Initializing plot_model()
2025-03-05 15:39:44,345:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:39:44,345:INFO:Checking exceptions
2025-03-05 15:39:44,348:INFO:Preloading libraries
2025-03-05 15:39:44,354:INFO:Copying training dataset
2025-03-05 15:39:44,354:INFO:Plot type: pipeline
2025-03-05 15:39:44,436:INFO:Visual Rendered Successfully
2025-03-05 15:39:44,573:INFO:plot_model() successfully completed......................................
2025-03-05 15:39:44,596:INFO:Initializing plot_model()
2025-03-05 15:39:44,596:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:39:44,596:INFO:Checking exceptions
2025-03-05 15:39:44,601:INFO:Preloading libraries
2025-03-05 15:39:44,607:INFO:Copying training dataset
2025-03-05 15:39:44,607:INFO:Plot type: residuals
2025-03-05 15:39:44,694:INFO:Fitting Model
2025-03-05 15:39:44,694:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-05 15:39:44,785:INFO:Scoring test/hold-out set
2025-03-05 15:39:45,263:INFO:Visual Rendered Successfully
2025-03-05 15:39:45,405:INFO:plot_model() successfully completed......................................
2025-03-05 15:39:45,425:INFO:Initializing plot_model()
2025-03-05 15:39:45,425:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:39:45,425:INFO:Checking exceptions
2025-03-05 15:39:45,430:INFO:Preloading libraries
2025-03-05 15:39:45,436:INFO:Copying training dataset
2025-03-05 15:39:45,436:INFO:Plot type: feature
2025-03-05 15:39:45,437:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:39:45,544:INFO:Visual Rendered Successfully
2025-03-05 15:39:45,685:INFO:plot_model() successfully completed......................................
2025-03-05 15:39:45,707:INFO:Initializing predict_model()
2025-03-05 15:39:45,708:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445b0dcd430>)
2025-03-05 15:39:45,708:INFO:Checking exceptions
2025-03-05 15:39:45,708:INFO:Preloading libraries
2025-03-05 15:39:45,772:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:39:46,613:INFO:Initializing predict_model()
2025-03-05 15:39:46,613:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445b0dcdf70>)
2025-03-05 15:39:46,614:INFO:Checking exceptions
2025-03-05 15:39:46,615:INFO:Preloading libraries
2025-03-05 15:39:46,618:INFO:Set up data.
2025-03-05 15:39:46,623:INFO:Set up index.
2025-03-05 15:39:46,657:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-05 15:40:57,549:INFO:Initializing plot_model()
2025-03-05 15:40:57,549:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:40:57,549:INFO:Checking exceptions
2025-03-05 15:40:57,552:INFO:Preloading libraries
2025-03-05 15:40:57,557:INFO:Copying training dataset
2025-03-05 15:40:57,558:INFO:Plot type: feature
2025-03-05 15:40:57,559:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:40:57,669:INFO:Visual Rendered Successfully
2025-03-05 15:40:57,822:INFO:plot_model() successfully completed......................................
2025-03-05 15:40:58,565:INFO:Initializing plot_model()
2025-03-05 15:40:58,565:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:40:58,565:INFO:Checking exceptions
2025-03-05 15:40:59,314:INFO:Initializing plot_model()
2025-03-05 15:40:59,314:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:40:59,314:INFO:Checking exceptions
2025-03-05 15:40:59,317:INFO:Preloading libraries
2025-03-05 15:40:59,322:INFO:Copying training dataset
2025-03-05 15:40:59,322:INFO:Plot type: feature_all
2025-03-05 15:40:59,339:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:40:59,414:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/matplotlib/_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-03-05 15:40:59,414:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/matplotlib/_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-03-05 15:40:59,415:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/matplotlib/patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-03-05 15:40:59,415:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/matplotlib/transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-03-05 15:40:59,437:INFO:Visual Rendered Successfully
2025-03-05 15:40:59,588:INFO:plot_model() successfully completed......................................
2025-03-05 15:41:00,687:INFO:Initializing plot_model()
2025-03-05 15:41:00,687:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:41:00,687:INFO:Checking exceptions
2025-03-05 15:41:00,689:INFO:Preloading libraries
2025-03-05 15:41:00,696:INFO:Copying training dataset
2025-03-05 15:41:00,696:INFO:Plot type: feature
2025-03-05 15:41:00,697:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 15:41:00,803:INFO:Visual Rendered Successfully
2025-03-05 15:41:00,938:INFO:plot_model() successfully completed......................................
2025-03-05 15:41:01,647:INFO:Initializing plot_model()
2025-03-05 15:41:01,648:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:41:01,648:INFO:Checking exceptions
2025-03-05 15:41:01,650:INFO:Preloading libraries
2025-03-05 15:41:01,656:INFO:Copying training dataset
2025-03-05 15:41:01,656:INFO:Plot type: residuals_interactive
2025-03-05 15:41:01,772:INFO:Calculated model residuals
2025-03-05 15:41:02,195:INFO:Calculated Tunkey-Anscombe Plot
2025-03-05 15:41:03,786:INFO:Calculated Normal QQ Plot
2025-03-05 15:41:03,933:INFO:Calculated Scale-Location Plot
2025-03-05 15:41:04,821:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2025-03-05 15:41:04,887:INFO:Visual Rendered Successfully
2025-03-05 15:41:05,040:INFO:plot_model() successfully completed......................................
2025-03-05 15:41:05,243:INFO:Initializing plot_model()
2025-03-05 15:41:05,243:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445b0dc0910>, system=True)
2025-03-05 15:41:05,243:INFO:Checking exceptions
2025-03-05 15:41:05,246:INFO:Preloading libraries
2025-03-05 15:41:05,252:INFO:Copying training dataset
2025-03-05 15:41:05,253:INFO:Plot type: rfe
2025-03-05 15:41:05,315:INFO:Fitting Model
2025-03-05 15:41:24,203:INFO:Visual Rendered Successfully
2025-03-05 15:41:24,365:INFO:plot_model() successfully completed......................................
2025-03-05 16:06:37,397:INFO:PyCaret RegressionExperiment
2025-03-05 16:06:37,397:INFO:Logging name: reg-default-name
2025-03-05 16:06:37,397:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-05 16:06:37,397:INFO:version 3.3.1
2025-03-05 16:06:37,397:INFO:Initializing setup()
2025-03-05 16:06:37,397:INFO:self.USI: feda
2025-03-05 16:06:37,397:INFO:self._variable_keys: {'fold_shuffle_param', 'X', 'data', 'y', 'exp_name_log', 'gpu_param', 'exp_id', 'seed', 'idx', 'transform_target_param', '_ml_usecase', 'y_test', '_available_plots', 'fold_generator', 'target_param', 'log_plots_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'n_jobs_param', 'memory'}
2025-03-05 16:06:37,397:INFO:Checking environment
2025-03-05 16:06:37,397:INFO:python_version: 3.9.21
2025-03-05 16:06:37,397:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-05 16:06:37,397:INFO:machine: x86_64
2025-03-05 16:06:37,397:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 16:06:37,397:INFO:Memory: svmem(total=33374507008, available=20679536640, percent=38.0, used=10023084032, free=3278573568, active=14287613952, inactive=11503915008, buffers=674603008, cached=19398246400, shared=2142785536, slab=1825562624)
2025-03-05 16:06:37,398:INFO:Physical Core: 24
2025-03-05 16:06:37,398:INFO:Logical Core: 32
2025-03-05 16:06:37,398:INFO:Checking libraries
2025-03-05 16:06:37,398:INFO:System:
2025-03-05 16:06:37,398:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-05 16:06:37,398:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-05 16:06:37,398:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-05 16:06:37,398:INFO:PyCaret required dependencies:
2025-03-05 16:06:37,398:INFO:                 pip: 25.0
2025-03-05 16:06:37,398:INFO:          setuptools: 75.8.0
2025-03-05 16:06:37,399:INFO:             pycaret: 3.3.1
2025-03-05 16:06:37,399:INFO:             IPython: 8.18.1
2025-03-05 16:06:37,399:INFO:          ipywidgets: 8.1.5
2025-03-05 16:06:37,399:INFO:                tqdm: 4.67.1
2025-03-05 16:06:37,399:INFO:               numpy: 1.26.4
2025-03-05 16:06:37,399:INFO:              pandas: 2.1.4
2025-03-05 16:06:37,399:INFO:              jinja2: 3.1.5
2025-03-05 16:06:37,399:INFO:               scipy: 1.11.4
2025-03-05 16:06:37,399:INFO:              joblib: 1.3.2
2025-03-05 16:06:37,399:INFO:             sklearn: 1.4.2
2025-03-05 16:06:37,399:INFO:                pyod: 2.0.3
2025-03-05 16:06:37,399:INFO:            imblearn: 0.12.4
2025-03-05 16:06:37,399:INFO:   category_encoders: 2.6.4
2025-03-05 16:06:37,399:INFO:            lightgbm: 4.6.0
2025-03-05 16:06:37,399:INFO:               numba: 0.60.0
2025-03-05 16:06:37,399:INFO:            requests: 2.32.3
2025-03-05 16:06:37,399:INFO:          matplotlib: 3.7.5
2025-03-05 16:06:37,399:INFO:          scikitplot: 0.3.7
2025-03-05 16:06:37,399:INFO:         yellowbrick: 1.5
2025-03-05 16:06:37,399:INFO:              plotly: 5.24.1
2025-03-05 16:06:37,399:INFO:    plotly-resampler: Not installed
2025-03-05 16:06:37,399:INFO:             kaleido: 0.2.1
2025-03-05 16:06:37,399:INFO:           schemdraw: 0.15
2025-03-05 16:06:37,399:INFO:         statsmodels: 0.14.4
2025-03-05 16:06:37,399:INFO:              sktime: 0.26.0
2025-03-05 16:06:37,399:INFO:               tbats: 1.1.3
2025-03-05 16:06:37,399:INFO:            pmdarima: 2.0.4
2025-03-05 16:06:37,399:INFO:              psutil: 7.0.0
2025-03-05 16:06:37,399:INFO:          markupsafe: 3.0.2
2025-03-05 16:06:37,399:INFO:             pickle5: Not installed
2025-03-05 16:06:37,399:INFO:         cloudpickle: 3.1.1
2025-03-05 16:06:37,399:INFO:         deprecation: 2.1.0
2025-03-05 16:06:37,399:INFO:              xxhash: 3.5.0
2025-03-05 16:06:37,399:INFO:           wurlitzer: 3.1.1
2025-03-05 16:06:37,399:INFO:PyCaret optional dependencies:
2025-03-05 16:06:37,399:INFO:                shap: Not installed
2025-03-05 16:06:37,399:INFO:           interpret: Not installed
2025-03-05 16:06:37,399:INFO:                umap: Not installed
2025-03-05 16:06:37,399:INFO:     ydata_profiling: Not installed
2025-03-05 16:06:37,399:INFO:  explainerdashboard: Not installed
2025-03-05 16:06:37,399:INFO:             autoviz: Not installed
2025-03-05 16:06:37,399:INFO:           fairlearn: Not installed
2025-03-05 16:06:37,399:INFO:          deepchecks: Not installed
2025-03-05 16:06:37,399:INFO:             xgboost: Not installed
2025-03-05 16:06:37,399:INFO:            catboost: Not installed
2025-03-05 16:06:37,399:INFO:              kmodes: Not installed
2025-03-05 16:06:37,399:INFO:             mlxtend: Not installed
2025-03-05 16:06:37,399:INFO:       statsforecast: Not installed
2025-03-05 16:06:37,399:INFO:        tune_sklearn: Not installed
2025-03-05 16:06:37,399:INFO:                 ray: Not installed
2025-03-05 16:06:37,399:INFO:            hyperopt: Not installed
2025-03-05 16:06:37,399:INFO:              optuna: Not installed
2025-03-05 16:06:37,399:INFO:               skopt: Not installed
2025-03-05 16:06:37,399:INFO:              mlflow: Not installed
2025-03-05 16:06:37,399:INFO:              gradio: Not installed
2025-03-05 16:06:37,399:INFO:             fastapi: Not installed
2025-03-05 16:06:37,400:INFO:             uvicorn: Not installed
2025-03-05 16:06:37,400:INFO:              m2cgen: Not installed
2025-03-05 16:06:37,400:INFO:           evidently: Not installed
2025-03-05 16:06:37,400:INFO:               fugue: Not installed
2025-03-05 16:06:37,400:INFO:           streamlit: Not installed
2025-03-05 16:06:37,400:INFO:             prophet: Not installed
2025-03-05 16:06:37,400:INFO:None
2025-03-05 16:06:37,400:INFO:Set up GPU usage.
2025-03-05 16:06:37,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,400:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-05 16:06:37,400:INFO:Set up data.
2025-03-05 16:06:37,403:INFO:Set up folding strategy.
2025-03-05 16:06:37,403:INFO:Set up train/test split.
2025-03-05 16:06:37,406:INFO:Set up index.
2025-03-05 16:06:37,406:INFO:Assigning column types.
2025-03-05 16:06:37,409:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-05 16:06:37,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,409:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,413:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,513:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,525:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,629:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-05 16:06:37,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,638:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,754:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:37,886:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-05 16:06:37,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:37,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:37,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,119:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-05 16:06:38,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,232:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,347:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-05 16:06:38,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-05 16:06:38,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,562:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-05 16:06:38,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,793:INFO:Preparing preprocessing pipeline...
2025-03-05 16:06:38,793:INFO:Set up simple imputation.
2025-03-05 16:06:38,793:INFO:Set up polynomial features.
2025-03-05 16:06:38,818:INFO:Finished creating preprocessing pipeline.
2025-03-05 16:06:38,823:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-03-05 16:06:38,823:INFO:Creating final display dataframe.
2025-03-05 16:06:38,885:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (22160, 2)
4        Transformed data shape        (22160, 3)
5   Transformed train set shape        (15511, 3)
6    Transformed test set shape         (6649, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              feda
2025-03-05 16:06:38,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:38,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:38,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-05 16:06:39,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:39,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-05 16:06:39,107:INFO:setup() successfully completed in 1.71s...............
2025-03-05 16:06:39,138:INFO:Initializing compare_models()
2025-03-05 16:06:39,138:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-05 16:06:39,138:INFO:Checking exceptions
2025-03-05 16:06:39,141:INFO:Preparing display monitor
2025-03-05 16:06:39,161:INFO:Initializing Linear Regression
2025-03-05 16:06:39,161:INFO:Total runtime is 2.8967857360839845e-06 minutes
2025-03-05 16:06:39,164:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:39,164:INFO:Initializing create_model()
2025-03-05 16:06:39,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:39,165:INFO:Checking exceptions
2025-03-05 16:06:39,165:INFO:Importing libraries
2025-03-05 16:06:39,165:INFO:Copying training dataset
2025-03-05 16:06:39,169:INFO:Defining folds
2025-03-05 16:06:39,169:INFO:Declaring metric variables
2025-03-05 16:06:39,175:INFO:Importing untrained model
2025-03-05 16:06:39,181:INFO:Linear Regression Imported successfully
2025-03-05 16:06:39,192:INFO:Starting cross validation
2025-03-05 16:06:39,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:39,389:INFO:Calculating mean and std
2025-03-05 16:06:39,390:INFO:Creating metrics dataframe
2025-03-05 16:06:39,391:INFO:Uploading results into container
2025-03-05 16:06:39,391:INFO:Uploading model into container now
2025-03-05 16:06:39,392:INFO:_master_model_container: 1
2025-03-05 16:06:39,392:INFO:_display_container: 2
2025-03-05 16:06:39,392:INFO:LinearRegression(n_jobs=-1)
2025-03-05 16:06:39,392:INFO:create_model() successfully completed......................................
2025-03-05 16:06:39,540:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:39,540:INFO:Creating metrics dataframe
2025-03-05 16:06:39,547:INFO:Initializing Lasso Regression
2025-03-05 16:06:39,547:INFO:Total runtime is 0.006430602073669434 minutes
2025-03-05 16:06:39,551:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:39,551:INFO:Initializing create_model()
2025-03-05 16:06:39,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:39,551:INFO:Checking exceptions
2025-03-05 16:06:39,551:INFO:Importing libraries
2025-03-05 16:06:39,551:INFO:Copying training dataset
2025-03-05 16:06:39,555:INFO:Defining folds
2025-03-05 16:06:39,555:INFO:Declaring metric variables
2025-03-05 16:06:39,559:INFO:Importing untrained model
2025-03-05 16:06:39,562:INFO:Lasso Regression Imported successfully
2025-03-05 16:06:39,568:INFO:Starting cross validation
2025-03-05 16:06:39,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:39,866:INFO:Calculating mean and std
2025-03-05 16:06:39,866:INFO:Creating metrics dataframe
2025-03-05 16:06:39,868:INFO:Uploading results into container
2025-03-05 16:06:39,869:INFO:Uploading model into container now
2025-03-05 16:06:39,869:INFO:_master_model_container: 2
2025-03-05 16:06:39,869:INFO:_display_container: 2
2025-03-05 16:06:39,869:INFO:Lasso(random_state=123)
2025-03-05 16:06:39,869:INFO:create_model() successfully completed......................................
2025-03-05 16:06:40,038:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:40,038:INFO:Creating metrics dataframe
2025-03-05 16:06:40,045:INFO:Initializing Ridge Regression
2025-03-05 16:06:40,046:INFO:Total runtime is 0.014743165175120036 minutes
2025-03-05 16:06:40,049:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:40,049:INFO:Initializing create_model()
2025-03-05 16:06:40,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:40,050:INFO:Checking exceptions
2025-03-05 16:06:40,050:INFO:Importing libraries
2025-03-05 16:06:40,050:INFO:Copying training dataset
2025-03-05 16:06:40,053:INFO:Defining folds
2025-03-05 16:06:40,053:INFO:Declaring metric variables
2025-03-05 16:06:40,056:INFO:Importing untrained model
2025-03-05 16:06:40,060:INFO:Ridge Regression Imported successfully
2025-03-05 16:06:40,066:INFO:Starting cross validation
2025-03-05 16:06:40,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:40,238:INFO:Calculating mean and std
2025-03-05 16:06:40,240:INFO:Creating metrics dataframe
2025-03-05 16:06:40,241:INFO:Uploading results into container
2025-03-05 16:06:40,242:INFO:Uploading model into container now
2025-03-05 16:06:40,242:INFO:_master_model_container: 3
2025-03-05 16:06:40,243:INFO:_display_container: 2
2025-03-05 16:06:40,243:INFO:Ridge(random_state=123)
2025-03-05 16:06:40,243:INFO:create_model() successfully completed......................................
2025-03-05 16:06:40,389:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:40,389:INFO:Creating metrics dataframe
2025-03-05 16:06:40,396:INFO:Initializing Elastic Net
2025-03-05 16:06:40,396:INFO:Total runtime is 0.020581976572672526 minutes
2025-03-05 16:06:40,399:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:40,399:INFO:Initializing create_model()
2025-03-05 16:06:40,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:40,399:INFO:Checking exceptions
2025-03-05 16:06:40,399:INFO:Importing libraries
2025-03-05 16:06:40,399:INFO:Copying training dataset
2025-03-05 16:06:40,404:INFO:Defining folds
2025-03-05 16:06:40,404:INFO:Declaring metric variables
2025-03-05 16:06:40,407:INFO:Importing untrained model
2025-03-05 16:06:40,410:INFO:Elastic Net Imported successfully
2025-03-05 16:06:40,416:INFO:Starting cross validation
2025-03-05 16:06:40,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:40,718:INFO:Calculating mean and std
2025-03-05 16:06:40,719:INFO:Creating metrics dataframe
2025-03-05 16:06:40,721:INFO:Uploading results into container
2025-03-05 16:06:40,723:INFO:Uploading model into container now
2025-03-05 16:06:40,724:INFO:_master_model_container: 4
2025-03-05 16:06:40,724:INFO:_display_container: 2
2025-03-05 16:06:40,724:INFO:ElasticNet(random_state=123)
2025-03-05 16:06:40,724:INFO:create_model() successfully completed......................................
2025-03-05 16:06:40,890:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:40,890:INFO:Creating metrics dataframe
2025-03-05 16:06:40,898:INFO:Initializing Least Angle Regression
2025-03-05 16:06:40,898:INFO:Total runtime is 0.028941698869069415 minutes
2025-03-05 16:06:40,901:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:40,901:INFO:Initializing create_model()
2025-03-05 16:06:40,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:40,901:INFO:Checking exceptions
2025-03-05 16:06:40,901:INFO:Importing libraries
2025-03-05 16:06:40,901:INFO:Copying training dataset
2025-03-05 16:06:40,906:INFO:Defining folds
2025-03-05 16:06:40,906:INFO:Declaring metric variables
2025-03-05 16:06:40,909:INFO:Importing untrained model
2025-03-05 16:06:40,912:INFO:Least Angle Regression Imported successfully
2025-03-05 16:06:40,918:INFO:Starting cross validation
2025-03-05 16:06:40,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:41,089:INFO:Calculating mean and std
2025-03-05 16:06:41,090:INFO:Creating metrics dataframe
2025-03-05 16:06:41,092:INFO:Uploading results into container
2025-03-05 16:06:41,093:INFO:Uploading model into container now
2025-03-05 16:06:41,093:INFO:_master_model_container: 5
2025-03-05 16:06:41,093:INFO:_display_container: 2
2025-03-05 16:06:41,093:INFO:Lars(random_state=123)
2025-03-05 16:06:41,093:INFO:create_model() successfully completed......................................
2025-03-05 16:06:41,240:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:41,240:INFO:Creating metrics dataframe
2025-03-05 16:06:41,247:INFO:Initializing Lasso Least Angle Regression
2025-03-05 16:06:41,248:INFO:Total runtime is 0.03477457761764526 minutes
2025-03-05 16:06:41,250:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:41,251:INFO:Initializing create_model()
2025-03-05 16:06:41,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:41,251:INFO:Checking exceptions
2025-03-05 16:06:41,251:INFO:Importing libraries
2025-03-05 16:06:41,251:INFO:Copying training dataset
2025-03-05 16:06:41,255:INFO:Defining folds
2025-03-05 16:06:41,255:INFO:Declaring metric variables
2025-03-05 16:06:41,258:INFO:Importing untrained model
2025-03-05 16:06:41,261:INFO:Lasso Least Angle Regression Imported successfully
2025-03-05 16:06:41,267:INFO:Starting cross validation
2025-03-05 16:06:41,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:41,439:INFO:Calculating mean and std
2025-03-05 16:06:41,440:INFO:Creating metrics dataframe
2025-03-05 16:06:41,442:INFO:Uploading results into container
2025-03-05 16:06:41,442:INFO:Uploading model into container now
2025-03-05 16:06:41,443:INFO:_master_model_container: 6
2025-03-05 16:06:41,443:INFO:_display_container: 2
2025-03-05 16:06:41,443:INFO:LassoLars(random_state=123)
2025-03-05 16:06:41,443:INFO:create_model() successfully completed......................................
2025-03-05 16:06:41,592:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:41,593:INFO:Creating metrics dataframe
2025-03-05 16:06:41,600:INFO:Initializing Orthogonal Matching Pursuit
2025-03-05 16:06:41,600:INFO:Total runtime is 0.04065362215042114 minutes
2025-03-05 16:06:41,603:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:41,604:INFO:Initializing create_model()
2025-03-05 16:06:41,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:41,604:INFO:Checking exceptions
2025-03-05 16:06:41,604:INFO:Importing libraries
2025-03-05 16:06:41,604:INFO:Copying training dataset
2025-03-05 16:06:41,608:INFO:Defining folds
2025-03-05 16:06:41,609:INFO:Declaring metric variables
2025-03-05 16:06:41,612:INFO:Importing untrained model
2025-03-05 16:06:41,615:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-05 16:06:41,621:INFO:Starting cross validation
2025-03-05 16:06:41,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:41,789:INFO:Calculating mean and std
2025-03-05 16:06:41,790:INFO:Creating metrics dataframe
2025-03-05 16:06:41,792:INFO:Uploading results into container
2025-03-05 16:06:41,793:INFO:Uploading model into container now
2025-03-05 16:06:41,793:INFO:_master_model_container: 7
2025-03-05 16:06:41,793:INFO:_display_container: 2
2025-03-05 16:06:41,793:INFO:OrthogonalMatchingPursuit()
2025-03-05 16:06:41,793:INFO:create_model() successfully completed......................................
2025-03-05 16:06:41,941:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:41,941:INFO:Creating metrics dataframe
2025-03-05 16:06:41,949:INFO:Initializing Bayesian Ridge
2025-03-05 16:06:41,949:INFO:Total runtime is 0.04647175073623657 minutes
2025-03-05 16:06:41,952:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:41,953:INFO:Initializing create_model()
2025-03-05 16:06:41,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:41,953:INFO:Checking exceptions
2025-03-05 16:06:41,953:INFO:Importing libraries
2025-03-05 16:06:41,953:INFO:Copying training dataset
2025-03-05 16:06:41,957:INFO:Defining folds
2025-03-05 16:06:41,957:INFO:Declaring metric variables
2025-03-05 16:06:41,960:INFO:Importing untrained model
2025-03-05 16:06:41,963:INFO:Bayesian Ridge Imported successfully
2025-03-05 16:06:41,969:INFO:Starting cross validation
2025-03-05 16:06:41,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:42,364:INFO:Calculating mean and std
2025-03-05 16:06:42,366:INFO:Creating metrics dataframe
2025-03-05 16:06:42,369:INFO:Uploading results into container
2025-03-05 16:06:42,370:INFO:Uploading model into container now
2025-03-05 16:06:42,371:INFO:_master_model_container: 8
2025-03-05 16:06:42,371:INFO:_display_container: 2
2025-03-05 16:06:42,371:INFO:BayesianRidge()
2025-03-05 16:06:42,371:INFO:create_model() successfully completed......................................
2025-03-05 16:06:42,587:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:42,587:INFO:Creating metrics dataframe
2025-03-05 16:06:42,595:INFO:Initializing Passive Aggressive Regressor
2025-03-05 16:06:42,595:INFO:Total runtime is 0.057225235303243 minutes
2025-03-05 16:06:42,598:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:42,598:INFO:Initializing create_model()
2025-03-05 16:06:42,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:42,598:INFO:Checking exceptions
2025-03-05 16:06:42,598:INFO:Importing libraries
2025-03-05 16:06:42,599:INFO:Copying training dataset
2025-03-05 16:06:42,603:INFO:Defining folds
2025-03-05 16:06:42,603:INFO:Declaring metric variables
2025-03-05 16:06:42,606:INFO:Importing untrained model
2025-03-05 16:06:42,610:INFO:Passive Aggressive Regressor Imported successfully
2025-03-05 16:06:42,615:INFO:Starting cross validation
2025-03-05 16:06:42,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:42,881:INFO:Calculating mean and std
2025-03-05 16:06:42,882:INFO:Creating metrics dataframe
2025-03-05 16:06:42,884:INFO:Uploading results into container
2025-03-05 16:06:42,884:INFO:Uploading model into container now
2025-03-05 16:06:42,884:INFO:_master_model_container: 9
2025-03-05 16:06:42,884:INFO:_display_container: 2
2025-03-05 16:06:42,885:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-05 16:06:42,885:INFO:create_model() successfully completed......................................
2025-03-05 16:06:43,033:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:43,033:INFO:Creating metrics dataframe
2025-03-05 16:06:43,042:INFO:Initializing Huber Regressor
2025-03-05 16:06:43,042:INFO:Total runtime is 0.06468393802642822 minutes
2025-03-05 16:06:43,045:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:43,045:INFO:Initializing create_model()
2025-03-05 16:06:43,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:43,046:INFO:Checking exceptions
2025-03-05 16:06:43,046:INFO:Importing libraries
2025-03-05 16:06:43,046:INFO:Copying training dataset
2025-03-05 16:06:43,050:INFO:Defining folds
2025-03-05 16:06:43,050:INFO:Declaring metric variables
2025-03-05 16:06:43,053:INFO:Importing untrained model
2025-03-05 16:06:43,056:INFO:Huber Regressor Imported successfully
2025-03-05 16:06:43,062:INFO:Starting cross validation
2025-03-05 16:06:43,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:44,522:INFO:Calculating mean and std
2025-03-05 16:06:44,524:INFO:Creating metrics dataframe
2025-03-05 16:06:44,528:INFO:Uploading results into container
2025-03-05 16:06:44,529:INFO:Uploading model into container now
2025-03-05 16:06:44,531:INFO:_master_model_container: 10
2025-03-05 16:06:44,531:INFO:_display_container: 2
2025-03-05 16:06:44,532:INFO:HuberRegressor()
2025-03-05 16:06:44,532:INFO:create_model() successfully completed......................................
2025-03-05 16:06:44,718:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:44,718:INFO:Creating metrics dataframe
2025-03-05 16:06:44,727:INFO:Initializing K Neighbors Regressor
2025-03-05 16:06:44,727:INFO:Total runtime is 0.09276192982991535 minutes
2025-03-05 16:06:44,730:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:44,730:INFO:Initializing create_model()
2025-03-05 16:06:44,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:44,730:INFO:Checking exceptions
2025-03-05 16:06:44,730:INFO:Importing libraries
2025-03-05 16:06:44,730:INFO:Copying training dataset
2025-03-05 16:06:44,735:INFO:Defining folds
2025-03-05 16:06:44,735:INFO:Declaring metric variables
2025-03-05 16:06:44,738:INFO:Importing untrained model
2025-03-05 16:06:44,742:INFO:K Neighbors Regressor Imported successfully
2025-03-05 16:06:44,747:INFO:Starting cross validation
2025-03-05 16:06:44,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:45,234:INFO:Calculating mean and std
2025-03-05 16:06:45,235:INFO:Creating metrics dataframe
2025-03-05 16:06:45,237:INFO:Uploading results into container
2025-03-05 16:06:45,238:INFO:Uploading model into container now
2025-03-05 16:06:45,238:INFO:_master_model_container: 11
2025-03-05 16:06:45,238:INFO:_display_container: 2
2025-03-05 16:06:45,239:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-05 16:06:45,239:INFO:create_model() successfully completed......................................
2025-03-05 16:06:45,386:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:45,386:INFO:Creating metrics dataframe
2025-03-05 16:06:45,395:INFO:Initializing Decision Tree Regressor
2025-03-05 16:06:45,395:INFO:Total runtime is 0.10390216906865436 minutes
2025-03-05 16:06:45,399:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:45,399:INFO:Initializing create_model()
2025-03-05 16:06:45,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:45,400:INFO:Checking exceptions
2025-03-05 16:06:45,400:INFO:Importing libraries
2025-03-05 16:06:45,400:INFO:Copying training dataset
2025-03-05 16:06:45,406:INFO:Defining folds
2025-03-05 16:06:45,407:INFO:Declaring metric variables
2025-03-05 16:06:45,410:INFO:Importing untrained model
2025-03-05 16:06:45,413:INFO:Decision Tree Regressor Imported successfully
2025-03-05 16:06:45,419:INFO:Starting cross validation
2025-03-05 16:06:45,420:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:45,680:INFO:Calculating mean and std
2025-03-05 16:06:45,681:INFO:Creating metrics dataframe
2025-03-05 16:06:45,683:INFO:Uploading results into container
2025-03-05 16:06:45,684:INFO:Uploading model into container now
2025-03-05 16:06:45,684:INFO:_master_model_container: 12
2025-03-05 16:06:45,684:INFO:_display_container: 2
2025-03-05 16:06:45,684:INFO:DecisionTreeRegressor(random_state=123)
2025-03-05 16:06:45,684:INFO:create_model() successfully completed......................................
2025-03-05 16:06:45,834:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:45,834:INFO:Creating metrics dataframe
2025-03-05 16:06:45,843:INFO:Initializing Random Forest Regressor
2025-03-05 16:06:45,843:INFO:Total runtime is 0.11136855284372964 minutes
2025-03-05 16:06:45,846:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:45,847:INFO:Initializing create_model()
2025-03-05 16:06:45,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:45,847:INFO:Checking exceptions
2025-03-05 16:06:45,847:INFO:Importing libraries
2025-03-05 16:06:45,847:INFO:Copying training dataset
2025-03-05 16:06:45,851:INFO:Defining folds
2025-03-05 16:06:45,851:INFO:Declaring metric variables
2025-03-05 16:06:45,854:INFO:Importing untrained model
2025-03-05 16:06:45,858:INFO:Random Forest Regressor Imported successfully
2025-03-05 16:06:45,863:INFO:Starting cross validation
2025-03-05 16:06:45,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:48,586:INFO:Calculating mean and std
2025-03-05 16:06:48,587:INFO:Creating metrics dataframe
2025-03-05 16:06:48,589:INFO:Uploading results into container
2025-03-05 16:06:48,589:INFO:Uploading model into container now
2025-03-05 16:06:48,590:INFO:_master_model_container: 13
2025-03-05 16:06:48,590:INFO:_display_container: 2
2025-03-05 16:06:48,590:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-05 16:06:48,590:INFO:create_model() successfully completed......................................
2025-03-05 16:06:48,741:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:48,742:INFO:Creating metrics dataframe
2025-03-05 16:06:48,752:INFO:Initializing Extra Trees Regressor
2025-03-05 16:06:48,752:INFO:Total runtime is 0.15985132455825804 minutes
2025-03-05 16:06:48,755:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:48,755:INFO:Initializing create_model()
2025-03-05 16:06:48,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:48,756:INFO:Checking exceptions
2025-03-05 16:06:48,756:INFO:Importing libraries
2025-03-05 16:06:48,756:INFO:Copying training dataset
2025-03-05 16:06:48,760:INFO:Defining folds
2025-03-05 16:06:48,760:INFO:Declaring metric variables
2025-03-05 16:06:48,764:INFO:Importing untrained model
2025-03-05 16:06:48,767:INFO:Extra Trees Regressor Imported successfully
2025-03-05 16:06:48,773:INFO:Starting cross validation
2025-03-05 16:06:48,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:50,452:INFO:Calculating mean and std
2025-03-05 16:06:50,453:INFO:Creating metrics dataframe
2025-03-05 16:06:50,455:INFO:Uploading results into container
2025-03-05 16:06:50,455:INFO:Uploading model into container now
2025-03-05 16:06:50,456:INFO:_master_model_container: 14
2025-03-05 16:06:50,456:INFO:_display_container: 2
2025-03-05 16:06:50,457:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-05 16:06:50,457:INFO:create_model() successfully completed......................................
2025-03-05 16:06:50,604:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:50,604:INFO:Creating metrics dataframe
2025-03-05 16:06:50,614:INFO:Initializing AdaBoost Regressor
2025-03-05 16:06:50,614:INFO:Total runtime is 0.19087827603022256 minutes
2025-03-05 16:06:50,617:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:50,618:INFO:Initializing create_model()
2025-03-05 16:06:50,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:50,618:INFO:Checking exceptions
2025-03-05 16:06:50,618:INFO:Importing libraries
2025-03-05 16:06:50,618:INFO:Copying training dataset
2025-03-05 16:06:50,622:INFO:Defining folds
2025-03-05 16:06:50,622:INFO:Declaring metric variables
2025-03-05 16:06:50,625:INFO:Importing untrained model
2025-03-05 16:06:50,628:INFO:AdaBoost Regressor Imported successfully
2025-03-05 16:06:50,634:INFO:Starting cross validation
2025-03-05 16:06:50,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:52,006:INFO:Calculating mean and std
2025-03-05 16:06:52,007:INFO:Creating metrics dataframe
2025-03-05 16:06:52,009:INFO:Uploading results into container
2025-03-05 16:06:52,010:INFO:Uploading model into container now
2025-03-05 16:06:52,010:INFO:_master_model_container: 15
2025-03-05 16:06:52,010:INFO:_display_container: 2
2025-03-05 16:06:52,010:INFO:AdaBoostRegressor(random_state=123)
2025-03-05 16:06:52,010:INFO:create_model() successfully completed......................................
2025-03-05 16:06:52,156:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:52,156:INFO:Creating metrics dataframe
2025-03-05 16:06:52,165:INFO:Initializing Gradient Boosting Regressor
2025-03-05 16:06:52,165:INFO:Total runtime is 0.2167383790016174 minutes
2025-03-05 16:06:52,168:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:52,169:INFO:Initializing create_model()
2025-03-05 16:06:52,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:52,169:INFO:Checking exceptions
2025-03-05 16:06:52,169:INFO:Importing libraries
2025-03-05 16:06:52,169:INFO:Copying training dataset
2025-03-05 16:06:52,173:INFO:Defining folds
2025-03-05 16:06:52,174:INFO:Declaring metric variables
2025-03-05 16:06:52,177:INFO:Importing untrained model
2025-03-05 16:06:52,181:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 16:06:52,186:INFO:Starting cross validation
2025-03-05 16:06:52,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:06:59,776:INFO:Calculating mean and std
2025-03-05 16:06:59,777:INFO:Creating metrics dataframe
2025-03-05 16:06:59,779:INFO:Uploading results into container
2025-03-05 16:06:59,779:INFO:Uploading model into container now
2025-03-05 16:06:59,780:INFO:_master_model_container: 16
2025-03-05 16:06:59,780:INFO:_display_container: 2
2025-03-05 16:06:59,780:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 16:06:59,780:INFO:create_model() successfully completed......................................
2025-03-05 16:06:59,928:INFO:SubProcess create_model() end ==================================
2025-03-05 16:06:59,929:INFO:Creating metrics dataframe
2025-03-05 16:06:59,939:INFO:Initializing Light Gradient Boosting Machine
2025-03-05 16:06:59,939:INFO:Total runtime is 0.3462950428326924 minutes
2025-03-05 16:06:59,942:INFO:SubProcess create_model() called ==================================
2025-03-05 16:06:59,943:INFO:Initializing create_model()
2025-03-05 16:06:59,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:06:59,943:INFO:Checking exceptions
2025-03-05 16:06:59,943:INFO:Importing libraries
2025-03-05 16:06:59,943:INFO:Copying training dataset
2025-03-05 16:06:59,947:INFO:Defining folds
2025-03-05 16:06:59,948:INFO:Declaring metric variables
2025-03-05 16:06:59,951:INFO:Importing untrained model
2025-03-05 16:06:59,954:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-05 16:06:59,960:INFO:Starting cross validation
2025-03-05 16:06:59,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:07:00,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035542 seconds.
2025-03-05 16:07:00,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:00,029:INFO:[LightGBM] [Info] Total Bins 428
2025-03-05 16:07:00,036:INFO:[LightGBM] [Info] Number of data points in the train set: 13959, number of used features: 2
2025-03-05 16:07:00,050:INFO:[LightGBM] [Info] Start training from score 5.505194
2025-03-05 16:07:01,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033557 seconds.
2025-03-05 16:07:01,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:01,383:INFO:[LightGBM] [Info] Total Bins 430
2025-03-05 16:07:01,390:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:01,407:INFO:[LightGBM] [Info] Start training from score 5.508560
2025-03-05 16:07:02,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031656 seconds.
2025-03-05 16:07:02,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:02,916:INFO:[LightGBM] [Info] Total Bins 428
2025-03-05 16:07:02,922:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:02,936:INFO:[LightGBM] [Info] Start training from score 5.504191
2025-03-05 16:07:04,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034737 seconds.
2025-03-05 16:07:04,439:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:04,439:INFO:[LightGBM] [Info] Total Bins 428
2025-03-05 16:07:04,445:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:04,467:INFO:[LightGBM] [Info] Start training from score 5.508883
2025-03-05 16:07:05,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030716 seconds.
2025-03-05 16:07:05,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:05,981:INFO:[LightGBM] [Info] Total Bins 428
2025-03-05 16:07:05,987:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:06,004:INFO:[LightGBM] [Info] Start training from score 5.501648
2025-03-05 16:07:07,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031704 seconds.
2025-03-05 16:07:07,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:07,273:INFO:[LightGBM] [Info] Total Bins 426
2025-03-05 16:07:07,280:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:07,302:INFO:[LightGBM] [Info] Start training from score 5.511390
2025-03-05 16:07:08,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027698 seconds.
2025-03-05 16:07:08,854:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:08,854:INFO:[LightGBM] [Info] Total Bins 428
2025-03-05 16:07:08,859:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:08,875:INFO:[LightGBM] [Info] Start training from score 5.511605
2025-03-05 16:07:09,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027672 seconds.
2025-03-05 16:07:09,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:09,550:INFO:[LightGBM] [Info] Total Bins 426
2025-03-05 16:07:09,559:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:09,576:INFO:[LightGBM] [Info] Start training from score 5.519019
2025-03-05 16:07:10,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036673 seconds.
2025-03-05 16:07:10,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:10,161:INFO:[LightGBM] [Info] Total Bins 430
2025-03-05 16:07:10,168:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:10,192:INFO:[LightGBM] [Info] Start training from score 5.515294
2025-03-05 16:07:10,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031686 seconds.
2025-03-05 16:07:10,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-05 16:07:10,872:INFO:[LightGBM] [Info] Total Bins 430
2025-03-05 16:07:10,878:INFO:[LightGBM] [Info] Number of data points in the train set: 13960, number of used features: 2
2025-03-05 16:07:10,892:INFO:[LightGBM] [Info] Start training from score 5.515759
2025-03-05 16:07:11,671:INFO:Calculating mean and std
2025-03-05 16:07:11,673:INFO:Creating metrics dataframe
2025-03-05 16:07:11,675:INFO:Uploading results into container
2025-03-05 16:07:11,675:INFO:Uploading model into container now
2025-03-05 16:07:11,676:INFO:_master_model_container: 17
2025-03-05 16:07:11,676:INFO:_display_container: 2
2025-03-05 16:07:11,677:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-05 16:07:11,677:INFO:create_model() successfully completed......................................
2025-03-05 16:07:11,835:INFO:SubProcess create_model() end ==================================
2025-03-05 16:07:11,836:INFO:Creating metrics dataframe
2025-03-05 16:07:11,845:INFO:Initializing Dummy Regressor
2025-03-05 16:07:11,846:INFO:Total runtime is 0.5447420199712116 minutes
2025-03-05 16:07:11,849:INFO:SubProcess create_model() called ==================================
2025-03-05 16:07:11,849:INFO:Initializing create_model()
2025-03-05 16:07:11,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7445a8aff370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:07:11,849:INFO:Checking exceptions
2025-03-05 16:07:11,849:INFO:Importing libraries
2025-03-05 16:07:11,849:INFO:Copying training dataset
2025-03-05 16:07:11,854:INFO:Defining folds
2025-03-05 16:07:11,854:INFO:Declaring metric variables
2025-03-05 16:07:11,857:INFO:Importing untrained model
2025-03-05 16:07:11,860:INFO:Dummy Regressor Imported successfully
2025-03-05 16:07:11,866:INFO:Starting cross validation
2025-03-05 16:07:11,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-05 16:07:12,028:INFO:Calculating mean and std
2025-03-05 16:07:12,029:INFO:Creating metrics dataframe
2025-03-05 16:07:12,031:INFO:Uploading results into container
2025-03-05 16:07:12,031:INFO:Uploading model into container now
2025-03-05 16:07:12,032:INFO:_master_model_container: 18
2025-03-05 16:07:12,032:INFO:_display_container: 2
2025-03-05 16:07:12,032:INFO:DummyRegressor()
2025-03-05 16:07:12,032:INFO:create_model() successfully completed......................................
2025-03-05 16:07:12,184:INFO:SubProcess create_model() end ==================================
2025-03-05 16:07:12,184:INFO:Creating metrics dataframe
2025-03-05 16:07:12,194:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-03-05 16:07:12,203:INFO:Initializing create_model()
2025-03-05 16:07:12,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-05 16:07:12,203:INFO:Checking exceptions
2025-03-05 16:07:12,206:INFO:Importing libraries
2025-03-05 16:07:12,206:INFO:Copying training dataset
2025-03-05 16:07:12,210:INFO:Defining folds
2025-03-05 16:07:12,210:INFO:Declaring metric variables
2025-03-05 16:07:12,210:INFO:Importing untrained model
2025-03-05 16:07:12,210:INFO:Declaring custom model
2025-03-05 16:07:12,211:INFO:Gradient Boosting Regressor Imported successfully
2025-03-05 16:07:12,211:INFO:Cross validation set to False
2025-03-05 16:07:12,211:INFO:Fitting Model
2025-03-05 16:07:13,051:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 16:07:13,051:INFO:create_model() successfully completed......................................
2025-03-05 16:07:13,225:INFO:_master_model_container: 18
2025-03-05 16:07:13,225:INFO:_display_container: 2
2025-03-05 16:07:13,226:INFO:GradientBoostingRegressor(random_state=123)
2025-03-05 16:07:13,226:INFO:compare_models() successfully completed......................................
2025-03-05 16:07:13,259:INFO:Initializing evaluate_model()
2025-03-05 16:07:13,260:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 16:07:13,268:INFO:Initializing plot_model()
2025-03-05 16:07:13,269:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, system=True)
2025-03-05 16:07:13,269:INFO:Checking exceptions
2025-03-05 16:07:13,273:INFO:Preloading libraries
2025-03-05 16:07:13,279:INFO:Copying training dataset
2025-03-05 16:07:13,279:INFO:Plot type: pipeline
2025-03-05 16:07:13,362:INFO:Visual Rendered Successfully
2025-03-05 16:07:13,508:INFO:plot_model() successfully completed......................................
2025-03-05 16:07:13,550:INFO:Initializing plot_model()
2025-03-05 16:07:13,550:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, system=True)
2025-03-05 16:07:13,550:INFO:Checking exceptions
2025-03-05 16:07:13,555:INFO:Preloading libraries
2025-03-05 16:07:13,562:INFO:Copying training dataset
2025-03-05 16:07:13,562:INFO:Plot type: residuals
2025-03-05 16:07:13,647:INFO:Fitting Model
2025-03-05 16:07:13,647:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning:

X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names


2025-03-05 16:07:13,744:INFO:Scoring test/hold-out set
2025-03-05 16:07:14,338:INFO:Visual Rendered Successfully
2025-03-05 16:07:14,493:INFO:plot_model() successfully completed......................................
2025-03-05 16:07:15,959:INFO:Initializing evaluate_model()
2025-03-05 16:07:15,959:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-05 16:07:15,969:INFO:Initializing plot_model()
2025-03-05 16:07:15,970:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, system=True)
2025-03-05 16:07:15,970:INFO:Checking exceptions
2025-03-05 16:07:15,973:INFO:Preloading libraries
2025-03-05 16:07:15,979:INFO:Copying training dataset
2025-03-05 16:07:15,979:INFO:Plot type: pipeline
2025-03-05 16:07:16,068:INFO:Visual Rendered Successfully
2025-03-05 16:07:16,228:INFO:plot_model() successfully completed......................................
2025-03-05 16:07:16,254:INFO:Initializing plot_model()
2025-03-05 16:07:16,255:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, system=True)
2025-03-05 16:07:16,255:INFO:Checking exceptions
2025-03-05 16:07:16,260:INFO:Preloading libraries
2025-03-05 16:07:16,266:INFO:Copying training dataset
2025-03-05 16:07:16,266:INFO:Plot type: residuals
2025-03-05 16:07:16,351:INFO:Fitting Model
2025-03-05 16:07:16,351:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning:

X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names


2025-03-05 16:07:16,447:INFO:Scoring test/hold-out set
2025-03-05 16:07:17,052:INFO:Visual Rendered Successfully
2025-03-05 16:07:17,228:INFO:plot_model() successfully completed......................................
2025-03-05 16:07:17,349:INFO:Initializing plot_model()
2025-03-05 16:07:17,349:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, system=True)
2025-03-05 16:07:17,350:INFO:Checking exceptions
2025-03-05 16:07:17,355:INFO:Preloading libraries
2025-03-05 16:07:17,361:INFO:Copying training dataset
2025-03-05 16:07:17,361:INFO:Plot type: feature
2025-03-05 16:07:17,362:WARNING:No coef_ found. Trying feature_importances_
2025-03-05 16:07:17,468:INFO:Visual Rendered Successfully
2025-03-05 16:07:17,620:INFO:plot_model() successfully completed......................................
2025-03-05 16:07:17,636:INFO:Initializing predict_model()
2025-03-05 16:07:17,636:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445a90e11f0>)
2025-03-05 16:07:17,637:INFO:Checking exceptions
2025-03-05 16:07:17,637:INFO:Preloading libraries
2025-03-05 16:07:17,690:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning:

'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.


2025-03-05 16:07:17,882:INFO:Initializing predict_model()
2025-03-05 16:07:17,883:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7445abc994f0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7445a90e1280>)
2025-03-05 16:07:17,883:INFO:Checking exceptions
2025-03-05 16:07:17,883:INFO:Preloading libraries
2025-03-05 16:07:17,885:INFO:Set up data.
2025-03-05 16:07:17,888:INFO:Set up index.
2025-03-05 16:07:17,921:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning:

'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.


2025-03-07 13:46:00,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:00,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:00,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:00,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:00,969:INFO:PyCaret RegressionExperiment
2025-03-07 13:46:00,969:INFO:Logging name: reg-default-name
2025-03-07 13:46:00,969:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-07 13:46:00,969:INFO:version 3.3.1
2025-03-07 13:46:00,969:INFO:Initializing setup()
2025-03-07 13:46:00,969:INFO:self.USI: 55ad
2025-03-07 13:46:00,969:INFO:self._variable_keys: {'X', 'target_param', 'fold_groups_param', 'gpu_param', 'idx', 'gpu_n_jobs_param', 'html_param', 'log_plots_param', 'exp_name_log', 'X_train', 'exp_id', '_ml_usecase', 'transform_target_param', 'n_jobs_param', 'data', 'fold_generator', 'USI', 'seed', 'memory', 'y', 'fold_shuffle_param', '_available_plots', 'logging_param', 'pipeline', 'y_test', 'X_test', 'y_train'}
2025-03-07 13:46:00,969:INFO:Checking environment
2025-03-07 13:46:00,969:INFO:python_version: 3.9.21
2025-03-07 13:46:00,969:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-07 13:46:00,969:INFO:machine: x86_64
2025-03-07 13:46:00,969:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-07 13:46:00,969:INFO:Memory: svmem(total=33374502912, available=27145240576, percent=18.7, used=4552613888, free=21603020800, active=6241779712, inactive=3231830016, buffers=332156928, cached=6886711296, shared=1193676800, slab=826347520)
2025-03-07 13:46:00,971:INFO:Physical Core: 24
2025-03-07 13:46:00,971:INFO:Logical Core: 32
2025-03-07 13:46:00,971:INFO:Checking libraries
2025-03-07 13:46:00,971:INFO:System:
2025-03-07 13:46:00,971:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-07 13:46:00,971:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-07 13:46:00,971:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-07 13:46:00,971:INFO:PyCaret required dependencies:
2025-03-07 13:46:00,999:INFO:                 pip: 25.0
2025-03-07 13:46:00,999:INFO:          setuptools: 75.8.0
2025-03-07 13:46:00,999:INFO:             pycaret: 3.3.1
2025-03-07 13:46:00,999:INFO:             IPython: 8.18.1
2025-03-07 13:46:00,999:INFO:          ipywidgets: 8.1.5
2025-03-07 13:46:00,999:INFO:                tqdm: 4.67.1
2025-03-07 13:46:00,999:INFO:               numpy: 1.26.4
2025-03-07 13:46:00,999:INFO:              pandas: 2.1.4
2025-03-07 13:46:00,999:INFO:              jinja2: 3.1.5
2025-03-07 13:46:00,999:INFO:               scipy: 1.11.4
2025-03-07 13:46:00,999:INFO:              joblib: 1.3.2
2025-03-07 13:46:00,999:INFO:             sklearn: 1.4.2
2025-03-07 13:46:00,999:INFO:                pyod: 2.0.3
2025-03-07 13:46:00,999:INFO:            imblearn: 0.12.4
2025-03-07 13:46:00,999:INFO:   category_encoders: 2.6.4
2025-03-07 13:46:00,999:INFO:            lightgbm: 4.6.0
2025-03-07 13:46:00,999:INFO:               numba: 0.60.0
2025-03-07 13:46:00,999:INFO:            requests: 2.32.3
2025-03-07 13:46:00,999:INFO:          matplotlib: 3.7.5
2025-03-07 13:46:00,999:INFO:          scikitplot: 0.3.7
2025-03-07 13:46:00,999:INFO:         yellowbrick: 1.5
2025-03-07 13:46:00,999:INFO:              plotly: 5.24.1
2025-03-07 13:46:00,999:INFO:    plotly-resampler: Not installed
2025-03-07 13:46:00,999:INFO:             kaleido: 0.2.1
2025-03-07 13:46:00,999:INFO:           schemdraw: 0.15
2025-03-07 13:46:00,999:INFO:         statsmodels: 0.14.4
2025-03-07 13:46:00,999:INFO:              sktime: 0.26.0
2025-03-07 13:46:00,999:INFO:               tbats: 1.1.3
2025-03-07 13:46:00,999:INFO:            pmdarima: 2.0.4
2025-03-07 13:46:00,999:INFO:              psutil: 7.0.0
2025-03-07 13:46:00,999:INFO:          markupsafe: 3.0.2
2025-03-07 13:46:00,999:INFO:             pickle5: Not installed
2025-03-07 13:46:00,999:INFO:         cloudpickle: 3.1.1
2025-03-07 13:46:00,999:INFO:         deprecation: 2.1.0
2025-03-07 13:46:00,999:INFO:              xxhash: 3.5.0
2025-03-07 13:46:00,999:INFO:           wurlitzer: 3.1.1
2025-03-07 13:46:00,999:INFO:PyCaret optional dependencies:
2025-03-07 13:46:01,019:INFO:                shap: Not installed
2025-03-07 13:46:01,019:INFO:           interpret: Not installed
2025-03-07 13:46:01,019:INFO:                umap: Not installed
2025-03-07 13:46:01,019:INFO:     ydata_profiling: Not installed
2025-03-07 13:46:01,019:INFO:  explainerdashboard: Not installed
2025-03-07 13:46:01,019:INFO:             autoviz: Not installed
2025-03-07 13:46:01,019:INFO:           fairlearn: Not installed
2025-03-07 13:46:01,019:INFO:          deepchecks: Not installed
2025-03-07 13:46:01,019:INFO:             xgboost: Not installed
2025-03-07 13:46:01,019:INFO:            catboost: Not installed
2025-03-07 13:46:01,019:INFO:              kmodes: Not installed
2025-03-07 13:46:01,019:INFO:             mlxtend: Not installed
2025-03-07 13:46:01,019:INFO:       statsforecast: Not installed
2025-03-07 13:46:01,019:INFO:        tune_sklearn: Not installed
2025-03-07 13:46:01,019:INFO:                 ray: Not installed
2025-03-07 13:46:01,019:INFO:            hyperopt: Not installed
2025-03-07 13:46:01,019:INFO:              optuna: Not installed
2025-03-07 13:46:01,019:INFO:               skopt: Not installed
2025-03-07 13:46:01,020:INFO:              mlflow: Not installed
2025-03-07 13:46:01,020:INFO:              gradio: Not installed
2025-03-07 13:46:01,020:INFO:             fastapi: Not installed
2025-03-07 13:46:01,020:INFO:             uvicorn: Not installed
2025-03-07 13:46:01,020:INFO:              m2cgen: Not installed
2025-03-07 13:46:01,020:INFO:           evidently: Not installed
2025-03-07 13:46:01,020:INFO:               fugue: Not installed
2025-03-07 13:46:01,020:INFO:           streamlit: Not installed
2025-03-07 13:46:01,020:INFO:             prophet: Not installed
2025-03-07 13:46:01,020:INFO:None
2025-03-07 13:46:01,020:INFO:Set up GPU usage.
2025-03-07 13:46:01,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,020:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-07 13:46:01,020:INFO:Set up data.
2025-03-07 13:46:01,027:INFO:Set up folding strategy.
2025-03-07 13:46:01,027:INFO:Set up train/test split.
2025-03-07 13:46:01,032:INFO:Set up index.
2025-03-07 13:46:01,033:INFO:Assigning column types.
2025-03-07 13:46:01,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-07 13:46:01,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,037:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-07 13:46:01,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,042:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-07 13:46:01,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,047:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:01,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:01,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:01,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:01,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,360:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,366:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,374:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,525:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-07 13:46:15,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,537:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,556:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,658:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,722:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,734:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:15,937:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-07 13:46:15,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:15,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:15,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,360:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-07 13:46:16,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,494:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,642:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-07 13:46:16,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:16,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:16,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-07 13:46:16,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,038:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-07 13:46:17,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,376:INFO:Preparing preprocessing pipeline...
2025-03-07 13:46:17,376:INFO:Set up simple imputation.
2025-03-07 13:46:17,376:INFO:Set up polynomial features.
2025-03-07 13:46:17,402:INFO:Finished creating preprocessing pipeline.
2025-03-07 13:46:17,423:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-03-07 13:46:17,424:INFO:Creating final display dataframe.
2025-03-07 13:46:17,508:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (25445, 2)
4        Transformed data shape        (25445, 3)
5   Transformed train set shape        (17811, 3)
6    Transformed test set shape         (7634, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              55ad
2025-03-07 13:46:17,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-07 13:46:17,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-07 13:46:17,827:INFO:setup() successfully completed in 16.86s...............
2025-03-07 13:46:17,836:INFO:Initializing compare_models()
2025-03-07 13:46:17,836:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-07 13:46:17,836:INFO:Checking exceptions
2025-03-07 13:46:17,838:INFO:Preparing display monitor
2025-03-07 13:46:17,861:INFO:Initializing Linear Regression
2025-03-07 13:46:17,861:INFO:Total runtime is 2.9365221659342447e-06 minutes
2025-03-07 13:46:17,864:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:17,864:INFO:Initializing create_model()
2025-03-07 13:46:17,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:17,865:INFO:Checking exceptions
2025-03-07 13:46:17,865:INFO:Importing libraries
2025-03-07 13:46:17,865:INFO:Copying training dataset
2025-03-07 13:46:17,869:INFO:Defining folds
2025-03-07 13:46:17,869:INFO:Declaring metric variables
2025-03-07 13:46:17,873:INFO:Importing untrained model
2025-03-07 13:46:17,879:INFO:Linear Regression Imported successfully
2025-03-07 13:46:17,889:INFO:Starting cross validation
2025-03-07 13:46:17,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:18,148:INFO:Calculating mean and std
2025-03-07 13:46:18,148:INFO:Creating metrics dataframe
2025-03-07 13:46:18,150:INFO:Uploading results into container
2025-03-07 13:46:18,150:INFO:Uploading model into container now
2025-03-07 13:46:18,151:INFO:_master_model_container: 1
2025-03-07 13:46:18,151:INFO:_display_container: 2
2025-03-07 13:46:18,151:INFO:LinearRegression(n_jobs=-1)
2025-03-07 13:46:18,151:INFO:create_model() successfully completed......................................
2025-03-07 13:46:18,212:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:18,212:INFO:Creating metrics dataframe
2025-03-07 13:46:18,218:INFO:Initializing Lasso Regression
2025-03-07 13:46:18,218:INFO:Total runtime is 0.005964752038319906 minutes
2025-03-07 13:46:18,222:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:18,222:INFO:Initializing create_model()
2025-03-07 13:46:18,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:18,222:INFO:Checking exceptions
2025-03-07 13:46:18,222:INFO:Importing libraries
2025-03-07 13:46:18,222:INFO:Copying training dataset
2025-03-07 13:46:18,227:INFO:Defining folds
2025-03-07 13:46:18,227:INFO:Declaring metric variables
2025-03-07 13:46:18,230:INFO:Importing untrained model
2025-03-07 13:46:18,233:INFO:Lasso Regression Imported successfully
2025-03-07 13:46:18,239:INFO:Starting cross validation
2025-03-07 13:46:18,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:18,507:INFO:Calculating mean and std
2025-03-07 13:46:18,507:INFO:Creating metrics dataframe
2025-03-07 13:46:18,509:INFO:Uploading results into container
2025-03-07 13:46:18,510:INFO:Uploading model into container now
2025-03-07 13:46:18,511:INFO:_master_model_container: 2
2025-03-07 13:46:18,511:INFO:_display_container: 2
2025-03-07 13:46:18,511:INFO:Lasso(random_state=123)
2025-03-07 13:46:18,511:INFO:create_model() successfully completed......................................
2025-03-07 13:46:18,581:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:18,581:INFO:Creating metrics dataframe
2025-03-07 13:46:18,591:INFO:Initializing Ridge Regression
2025-03-07 13:46:18,591:INFO:Total runtime is 0.012173899014790853 minutes
2025-03-07 13:46:18,595:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:18,596:INFO:Initializing create_model()
2025-03-07 13:46:18,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:18,596:INFO:Checking exceptions
2025-03-07 13:46:18,596:INFO:Importing libraries
2025-03-07 13:46:18,596:INFO:Copying training dataset
2025-03-07 13:46:18,603:INFO:Defining folds
2025-03-07 13:46:18,603:INFO:Declaring metric variables
2025-03-07 13:46:18,607:INFO:Importing untrained model
2025-03-07 13:46:18,611:INFO:Ridge Regression Imported successfully
2025-03-07 13:46:18,617:INFO:Starting cross validation
2025-03-07 13:46:18,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:18,866:INFO:Calculating mean and std
2025-03-07 13:46:18,867:INFO:Creating metrics dataframe
2025-03-07 13:46:18,868:INFO:Uploading results into container
2025-03-07 13:46:18,869:INFO:Uploading model into container now
2025-03-07 13:46:18,869:INFO:_master_model_container: 3
2025-03-07 13:46:18,869:INFO:_display_container: 2
2025-03-07 13:46:18,869:INFO:Ridge(random_state=123)
2025-03-07 13:46:18,870:INFO:create_model() successfully completed......................................
2025-03-07 13:46:18,929:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:18,929:INFO:Creating metrics dataframe
2025-03-07 13:46:18,936:INFO:Initializing Elastic Net
2025-03-07 13:46:18,936:INFO:Total runtime is 0.017928044001261394 minutes
2025-03-07 13:46:18,939:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:18,940:INFO:Initializing create_model()
2025-03-07 13:46:18,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:18,940:INFO:Checking exceptions
2025-03-07 13:46:18,940:INFO:Importing libraries
2025-03-07 13:46:18,940:INFO:Copying training dataset
2025-03-07 13:46:18,946:INFO:Defining folds
2025-03-07 13:46:18,946:INFO:Declaring metric variables
2025-03-07 13:46:18,954:INFO:Importing untrained model
2025-03-07 13:46:18,961:INFO:Elastic Net Imported successfully
2025-03-07 13:46:18,975:INFO:Starting cross validation
2025-03-07 13:46:18,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:19,276:INFO:Calculating mean and std
2025-03-07 13:46:19,277:INFO:Creating metrics dataframe
2025-03-07 13:46:19,280:INFO:Uploading results into container
2025-03-07 13:46:19,281:INFO:Uploading model into container now
2025-03-07 13:46:19,281:INFO:_master_model_container: 4
2025-03-07 13:46:19,281:INFO:_display_container: 2
2025-03-07 13:46:19,282:INFO:ElasticNet(random_state=123)
2025-03-07 13:46:19,282:INFO:create_model() successfully completed......................................
2025-03-07 13:46:19,349:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:19,349:INFO:Creating metrics dataframe
2025-03-07 13:46:19,359:INFO:Initializing Least Angle Regression
2025-03-07 13:46:19,359:INFO:Total runtime is 0.024977517127990723 minutes
2025-03-07 13:46:19,363:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:19,364:INFO:Initializing create_model()
2025-03-07 13:46:19,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:19,364:INFO:Checking exceptions
2025-03-07 13:46:19,364:INFO:Importing libraries
2025-03-07 13:46:19,364:INFO:Copying training dataset
2025-03-07 13:46:19,370:INFO:Defining folds
2025-03-07 13:46:19,370:INFO:Declaring metric variables
2025-03-07 13:46:19,375:INFO:Importing untrained model
2025-03-07 13:46:19,379:INFO:Least Angle Regression Imported successfully
2025-03-07 13:46:19,386:INFO:Starting cross validation
2025-03-07 13:46:19,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:19,573:INFO:Calculating mean and std
2025-03-07 13:46:19,573:INFO:Creating metrics dataframe
2025-03-07 13:46:19,575:INFO:Uploading results into container
2025-03-07 13:46:19,576:INFO:Uploading model into container now
2025-03-07 13:46:19,576:INFO:_master_model_container: 5
2025-03-07 13:46:19,577:INFO:_display_container: 2
2025-03-07 13:46:19,577:INFO:Lars(random_state=123)
2025-03-07 13:46:19,577:INFO:create_model() successfully completed......................................
2025-03-07 13:46:19,635:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:19,635:INFO:Creating metrics dataframe
2025-03-07 13:46:19,642:INFO:Initializing Lasso Least Angle Regression
2025-03-07 13:46:19,642:INFO:Total runtime is 0.02969800631205241 minutes
2025-03-07 13:46:19,646:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:19,646:INFO:Initializing create_model()
2025-03-07 13:46:19,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:19,646:INFO:Checking exceptions
2025-03-07 13:46:19,646:INFO:Importing libraries
2025-03-07 13:46:19,646:INFO:Copying training dataset
2025-03-07 13:46:19,653:INFO:Defining folds
2025-03-07 13:46:19,654:INFO:Declaring metric variables
2025-03-07 13:46:19,657:INFO:Importing untrained model
2025-03-07 13:46:19,662:INFO:Lasso Least Angle Regression Imported successfully
2025-03-07 13:46:19,674:INFO:Starting cross validation
2025-03-07 13:46:19,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:19,905:INFO:Calculating mean and std
2025-03-07 13:46:19,906:INFO:Creating metrics dataframe
2025-03-07 13:46:19,908:INFO:Uploading results into container
2025-03-07 13:46:19,909:INFO:Uploading model into container now
2025-03-07 13:46:19,909:INFO:_master_model_container: 6
2025-03-07 13:46:19,909:INFO:_display_container: 2
2025-03-07 13:46:19,909:INFO:LassoLars(random_state=123)
2025-03-07 13:46:19,909:INFO:create_model() successfully completed......................................
2025-03-07 13:46:20,001:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:20,001:INFO:Creating metrics dataframe
2025-03-07 13:46:20,019:INFO:Initializing Orthogonal Matching Pursuit
2025-03-07 13:46:20,019:INFO:Total runtime is 0.035976938406626385 minutes
2025-03-07 13:46:20,027:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:20,028:INFO:Initializing create_model()
2025-03-07 13:46:20,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:20,028:INFO:Checking exceptions
2025-03-07 13:46:20,028:INFO:Importing libraries
2025-03-07 13:46:20,028:INFO:Copying training dataset
2025-03-07 13:46:20,039:INFO:Defining folds
2025-03-07 13:46:20,039:INFO:Declaring metric variables
2025-03-07 13:46:20,046:INFO:Importing untrained model
2025-03-07 13:46:20,053:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-07 13:46:20,066:INFO:Starting cross validation
2025-03-07 13:46:20,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:20,359:INFO:Calculating mean and std
2025-03-07 13:46:20,360:INFO:Creating metrics dataframe
2025-03-07 13:46:20,363:INFO:Uploading results into container
2025-03-07 13:46:20,363:INFO:Uploading model into container now
2025-03-07 13:46:20,364:INFO:_master_model_container: 7
2025-03-07 13:46:20,364:INFO:_display_container: 2
2025-03-07 13:46:20,364:INFO:OrthogonalMatchingPursuit()
2025-03-07 13:46:20,364:INFO:create_model() successfully completed......................................
2025-03-07 13:46:20,424:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:20,425:INFO:Creating metrics dataframe
2025-03-07 13:46:20,432:INFO:Initializing Bayesian Ridge
2025-03-07 13:46:20,432:INFO:Total runtime is 0.04286048809687297 minutes
2025-03-07 13:46:20,435:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:20,436:INFO:Initializing create_model()
2025-03-07 13:46:20,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:20,436:INFO:Checking exceptions
2025-03-07 13:46:20,436:INFO:Importing libraries
2025-03-07 13:46:20,436:INFO:Copying training dataset
2025-03-07 13:46:20,440:INFO:Defining folds
2025-03-07 13:46:20,440:INFO:Declaring metric variables
2025-03-07 13:46:20,443:INFO:Importing untrained model
2025-03-07 13:46:20,446:INFO:Bayesian Ridge Imported successfully
2025-03-07 13:46:20,452:INFO:Starting cross validation
2025-03-07 13:46:20,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:20,696:INFO:Calculating mean and std
2025-03-07 13:46:20,697:INFO:Creating metrics dataframe
2025-03-07 13:46:20,700:INFO:Uploading results into container
2025-03-07 13:46:20,701:INFO:Uploading model into container now
2025-03-07 13:46:20,701:INFO:_master_model_container: 8
2025-03-07 13:46:20,701:INFO:_display_container: 2
2025-03-07 13:46:20,702:INFO:BayesianRidge()
2025-03-07 13:46:20,702:INFO:create_model() successfully completed......................................
2025-03-07 13:46:20,769:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:20,770:INFO:Creating metrics dataframe
2025-03-07 13:46:20,781:INFO:Initializing Passive Aggressive Regressor
2025-03-07 13:46:20,781:INFO:Total runtime is 0.04867066144943238 minutes
2025-03-07 13:46:20,785:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:20,785:INFO:Initializing create_model()
2025-03-07 13:46:20,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:20,786:INFO:Checking exceptions
2025-03-07 13:46:20,786:INFO:Importing libraries
2025-03-07 13:46:20,786:INFO:Copying training dataset
2025-03-07 13:46:20,792:INFO:Defining folds
2025-03-07 13:46:20,792:INFO:Declaring metric variables
2025-03-07 13:46:20,796:INFO:Importing untrained model
2025-03-07 13:46:20,801:INFO:Passive Aggressive Regressor Imported successfully
2025-03-07 13:46:20,809:INFO:Starting cross validation
2025-03-07 13:46:20,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:21,089:INFO:Calculating mean and std
2025-03-07 13:46:21,089:INFO:Creating metrics dataframe
2025-03-07 13:46:21,092:INFO:Uploading results into container
2025-03-07 13:46:21,092:INFO:Uploading model into container now
2025-03-07 13:46:21,093:INFO:_master_model_container: 9
2025-03-07 13:46:21,093:INFO:_display_container: 2
2025-03-07 13:46:21,093:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-07 13:46:21,093:INFO:create_model() successfully completed......................................
2025-03-07 13:46:21,149:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:21,149:INFO:Creating metrics dataframe
2025-03-07 13:46:21,158:INFO:Initializing Huber Regressor
2025-03-07 13:46:21,158:INFO:Total runtime is 0.054951588312784835 minutes
2025-03-07 13:46:21,161:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:21,162:INFO:Initializing create_model()
2025-03-07 13:46:21,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:21,162:INFO:Checking exceptions
2025-03-07 13:46:21,162:INFO:Importing libraries
2025-03-07 13:46:21,162:INFO:Copying training dataset
2025-03-07 13:46:21,166:INFO:Defining folds
2025-03-07 13:46:21,166:INFO:Declaring metric variables
2025-03-07 13:46:21,169:INFO:Importing untrained model
2025-03-07 13:46:21,172:INFO:Huber Regressor Imported successfully
2025-03-07 13:46:21,178:INFO:Starting cross validation
2025-03-07 13:46:21,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:22,990:INFO:Calculating mean and std
2025-03-07 13:46:22,992:INFO:Creating metrics dataframe
2025-03-07 13:46:22,996:INFO:Uploading results into container
2025-03-07 13:46:22,996:INFO:Uploading model into container now
2025-03-07 13:46:22,997:INFO:_master_model_container: 10
2025-03-07 13:46:22,997:INFO:_display_container: 2
2025-03-07 13:46:22,998:INFO:HuberRegressor()
2025-03-07 13:46:22,998:INFO:create_model() successfully completed......................................
2025-03-07 13:46:23,097:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:23,097:INFO:Creating metrics dataframe
2025-03-07 13:46:23,105:INFO:Initializing K Neighbors Regressor
2025-03-07 13:46:23,106:INFO:Total runtime is 0.08741960525512696 minutes
2025-03-07 13:46:23,109:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:23,110:INFO:Initializing create_model()
2025-03-07 13:46:23,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:23,110:INFO:Checking exceptions
2025-03-07 13:46:23,110:INFO:Importing libraries
2025-03-07 13:46:23,110:INFO:Copying training dataset
2025-03-07 13:46:23,115:INFO:Defining folds
2025-03-07 13:46:23,115:INFO:Declaring metric variables
2025-03-07 13:46:23,118:INFO:Importing untrained model
2025-03-07 13:46:23,122:INFO:K Neighbors Regressor Imported successfully
2025-03-07 13:46:23,127:INFO:Starting cross validation
2025-03-07 13:46:23,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:24,000:INFO:Calculating mean and std
2025-03-07 13:46:24,002:INFO:Creating metrics dataframe
2025-03-07 13:46:24,006:INFO:Uploading results into container
2025-03-07 13:46:24,007:INFO:Uploading model into container now
2025-03-07 13:46:24,008:INFO:_master_model_container: 11
2025-03-07 13:46:24,008:INFO:_display_container: 2
2025-03-07 13:46:24,008:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-07 13:46:24,008:INFO:create_model() successfully completed......................................
2025-03-07 13:46:24,098:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:24,098:INFO:Creating metrics dataframe
2025-03-07 13:46:24,114:INFO:Initializing Decision Tree Regressor
2025-03-07 13:46:24,114:INFO:Total runtime is 0.10422799587249756 minutes
2025-03-07 13:46:24,120:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:24,120:INFO:Initializing create_model()
2025-03-07 13:46:24,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:24,120:INFO:Checking exceptions
2025-03-07 13:46:24,120:INFO:Importing libraries
2025-03-07 13:46:24,121:INFO:Copying training dataset
2025-03-07 13:46:24,129:INFO:Defining folds
2025-03-07 13:46:24,129:INFO:Declaring metric variables
2025-03-07 13:46:24,135:INFO:Importing untrained model
2025-03-07 13:46:24,141:INFO:Decision Tree Regressor Imported successfully
2025-03-07 13:46:24,153:INFO:Starting cross validation
2025-03-07 13:46:24,154:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:24,738:INFO:Calculating mean and std
2025-03-07 13:46:24,739:INFO:Creating metrics dataframe
2025-03-07 13:46:24,741:INFO:Uploading results into container
2025-03-07 13:46:24,741:INFO:Uploading model into container now
2025-03-07 13:46:24,741:INFO:_master_model_container: 12
2025-03-07 13:46:24,742:INFO:_display_container: 2
2025-03-07 13:46:24,742:INFO:DecisionTreeRegressor(random_state=123)
2025-03-07 13:46:24,742:INFO:create_model() successfully completed......................................
2025-03-07 13:46:24,800:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:24,800:INFO:Creating metrics dataframe
2025-03-07 13:46:24,809:INFO:Initializing Random Forest Regressor
2025-03-07 13:46:24,809:INFO:Total runtime is 0.11580687363942464 minutes
2025-03-07 13:46:24,812:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:24,812:INFO:Initializing create_model()
2025-03-07 13:46:24,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:24,812:INFO:Checking exceptions
2025-03-07 13:46:24,812:INFO:Importing libraries
2025-03-07 13:46:24,812:INFO:Copying training dataset
2025-03-07 13:46:24,817:INFO:Defining folds
2025-03-07 13:46:24,817:INFO:Declaring metric variables
2025-03-07 13:46:24,820:INFO:Importing untrained model
2025-03-07 13:46:24,823:INFO:Random Forest Regressor Imported successfully
2025-03-07 13:46:24,828:INFO:Starting cross validation
2025-03-07 13:46:24,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:28,695:INFO:Calculating mean and std
2025-03-07 13:46:28,697:INFO:Creating metrics dataframe
2025-03-07 13:46:28,700:INFO:Uploading results into container
2025-03-07 13:46:28,701:INFO:Uploading model into container now
2025-03-07 13:46:28,702:INFO:_master_model_container: 13
2025-03-07 13:46:28,702:INFO:_display_container: 2
2025-03-07 13:46:28,703:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-07 13:46:28,703:INFO:create_model() successfully completed......................................
2025-03-07 13:46:28,777:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:28,777:INFO:Creating metrics dataframe
2025-03-07 13:46:28,791:INFO:Initializing Extra Trees Regressor
2025-03-07 13:46:28,791:INFO:Total runtime is 0.1821702837944031 minutes
2025-03-07 13:46:28,795:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:28,795:INFO:Initializing create_model()
2025-03-07 13:46:28,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:28,795:INFO:Checking exceptions
2025-03-07 13:46:28,795:INFO:Importing libraries
2025-03-07 13:46:28,795:INFO:Copying training dataset
2025-03-07 13:46:28,802:INFO:Defining folds
2025-03-07 13:46:28,802:INFO:Declaring metric variables
2025-03-07 13:46:28,806:INFO:Importing untrained model
2025-03-07 13:46:28,811:INFO:Extra Trees Regressor Imported successfully
2025-03-07 13:46:28,818:INFO:Starting cross validation
2025-03-07 13:46:28,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:31,358:INFO:Calculating mean and std
2025-03-07 13:46:31,359:INFO:Creating metrics dataframe
2025-03-07 13:46:31,362:INFO:Uploading results into container
2025-03-07 13:46:31,362:INFO:Uploading model into container now
2025-03-07 13:46:31,363:INFO:_master_model_container: 14
2025-03-07 13:46:31,363:INFO:_display_container: 2
2025-03-07 13:46:31,363:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-07 13:46:31,363:INFO:create_model() successfully completed......................................
2025-03-07 13:46:31,439:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:31,439:INFO:Creating metrics dataframe
2025-03-07 13:46:31,458:INFO:Initializing AdaBoost Regressor
2025-03-07 13:46:31,458:INFO:Total runtime is 0.22662311792373657 minutes
2025-03-07 13:46:31,463:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:31,464:INFO:Initializing create_model()
2025-03-07 13:46:31,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:31,464:INFO:Checking exceptions
2025-03-07 13:46:31,464:INFO:Importing libraries
2025-03-07 13:46:31,464:INFO:Copying training dataset
2025-03-07 13:46:31,471:INFO:Defining folds
2025-03-07 13:46:31,471:INFO:Declaring metric variables
2025-03-07 13:46:31,476:INFO:Importing untrained model
2025-03-07 13:46:31,480:INFO:AdaBoost Regressor Imported successfully
2025-03-07 13:46:31,489:INFO:Starting cross validation
2025-03-07 13:46:31,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:34,553:INFO:Calculating mean and std
2025-03-07 13:46:34,554:INFO:Creating metrics dataframe
2025-03-07 13:46:34,556:INFO:Uploading results into container
2025-03-07 13:46:34,557:INFO:Uploading model into container now
2025-03-07 13:46:34,557:INFO:_master_model_container: 15
2025-03-07 13:46:34,557:INFO:_display_container: 2
2025-03-07 13:46:34,558:INFO:AdaBoostRegressor(random_state=123)
2025-03-07 13:46:34,558:INFO:create_model() successfully completed......................................
2025-03-07 13:46:34,618:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:34,618:INFO:Creating metrics dataframe
2025-03-07 13:46:34,628:INFO:Initializing Gradient Boosting Regressor
2025-03-07 13:46:34,628:INFO:Total runtime is 0.2794548948605855 minutes
2025-03-07 13:46:34,631:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:34,631:INFO:Initializing create_model()
2025-03-07 13:46:34,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:34,631:INFO:Checking exceptions
2025-03-07 13:46:34,631:INFO:Importing libraries
2025-03-07 13:46:34,631:INFO:Copying training dataset
2025-03-07 13:46:34,636:INFO:Defining folds
2025-03-07 13:46:34,636:INFO:Declaring metric variables
2025-03-07 13:46:34,639:INFO:Importing untrained model
2025-03-07 13:46:34,643:INFO:Gradient Boosting Regressor Imported successfully
2025-03-07 13:46:34,650:INFO:Starting cross validation
2025-03-07 13:46:34,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:55,106:INFO:Calculating mean and std
2025-03-07 13:46:55,107:INFO:Creating metrics dataframe
2025-03-07 13:46:55,109:INFO:Uploading results into container
2025-03-07 13:46:55,109:INFO:Uploading model into container now
2025-03-07 13:46:55,110:INFO:_master_model_container: 16
2025-03-07 13:46:55,110:INFO:_display_container: 2
2025-03-07 13:46:55,110:INFO:GradientBoostingRegressor(random_state=123)
2025-03-07 13:46:55,110:INFO:create_model() successfully completed......................................
2025-03-07 13:46:55,178:INFO:SubProcess create_model() end ==================================
2025-03-07 13:46:55,178:INFO:Creating metrics dataframe
2025-03-07 13:46:55,187:INFO:Initializing Light Gradient Boosting Machine
2025-03-07 13:46:55,188:INFO:Total runtime is 0.622118349870046 minutes
2025-03-07 13:46:55,191:INFO:SubProcess create_model() called ==================================
2025-03-07 13:46:55,191:INFO:Initializing create_model()
2025-03-07 13:46:55,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:46:55,192:INFO:Checking exceptions
2025-03-07 13:46:55,192:INFO:Importing libraries
2025-03-07 13:46:55,192:INFO:Copying training dataset
2025-03-07 13:46:55,196:INFO:Defining folds
2025-03-07 13:46:55,196:INFO:Declaring metric variables
2025-03-07 13:46:55,199:INFO:Importing untrained model
2025-03-07 13:46:55,204:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-07 13:46:55,213:INFO:Starting cross validation
2025-03-07 13:46:55,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:46:55,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031140 seconds.
2025-03-07 13:46:55,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:46:55,297:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:46:55,311:INFO:[LightGBM] [Info] Number of data points in the train set: 16029, number of used features: 2
2025-03-07 13:46:55,329:INFO:[LightGBM] [Info] Start training from score 6.880591
2025-03-07 13:46:57,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026482 seconds.
2025-03-07 13:46:57,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:46:57,177:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:46:57,184:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:46:57,202:INFO:[LightGBM] [Info] Start training from score 6.875686
2025-03-07 13:46:58,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026745 seconds.
2025-03-07 13:46:58,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:46:58,476:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:46:58,489:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:46:58,512:INFO:[LightGBM] [Info] Start training from score 6.876981
2025-03-07 13:47:04,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003623 seconds.
2025-03-07 13:47:04,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:04,822:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:04,822:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:04,823:INFO:[LightGBM] [Info] Start training from score 6.877885
2025-03-07 13:47:05,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056625 seconds.
2025-03-07 13:47:05,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:05,757:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:05,765:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:05,786:INFO:[LightGBM] [Info] Start training from score 6.877402
2025-03-07 13:47:06,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032626 seconds.
2025-03-07 13:47:06,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:06,747:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:06,753:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:06,767:INFO:[LightGBM] [Info] Start training from score 6.867280
2025-03-07 13:47:10,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037613 seconds.
2025-03-07 13:47:10,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:10,867:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:10,873:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:10,891:INFO:[LightGBM] [Info] Start training from score 6.877480
2025-03-07 13:47:12,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2025-03-07 13:47:12,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:12,735:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:12,735:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:12,735:INFO:[LightGBM] [Info] Start training from score 6.886494
2025-03-07 13:47:13,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2025-03-07 13:47:13,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:13,038:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:13,039:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:13,039:INFO:[LightGBM] [Info] Start training from score 6.883016
2025-03-07 13:47:13,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2025-03-07 13:47:13,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-07 13:47:13,291:INFO:[LightGBM] [Info] Total Bins 510
2025-03-07 13:47:13,291:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-07 13:47:13,292:INFO:[LightGBM] [Info] Start training from score 6.879117
2025-03-07 13:47:13,668:INFO:Calculating mean and std
2025-03-07 13:47:13,671:INFO:Creating metrics dataframe
2025-03-07 13:47:13,674:INFO:Uploading results into container
2025-03-07 13:47:13,674:INFO:Uploading model into container now
2025-03-07 13:47:13,675:INFO:_master_model_container: 17
2025-03-07 13:47:13,675:INFO:_display_container: 2
2025-03-07 13:47:13,676:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-07 13:47:13,676:INFO:create_model() successfully completed......................................
2025-03-07 13:47:13,769:INFO:SubProcess create_model() end ==================================
2025-03-07 13:47:13,769:INFO:Creating metrics dataframe
2025-03-07 13:47:13,783:INFO:Initializing Dummy Regressor
2025-03-07 13:47:13,783:INFO:Total runtime is 0.9320459365844727 minutes
2025-03-07 13:47:13,788:INFO:SubProcess create_model() called ==================================
2025-03-07 13:47:13,788:INFO:Initializing create_model()
2025-03-07 13:47:13,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b1d9ede50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:47:13,788:INFO:Checking exceptions
2025-03-07 13:47:13,788:INFO:Importing libraries
2025-03-07 13:47:13,788:INFO:Copying training dataset
2025-03-07 13:47:13,795:INFO:Defining folds
2025-03-07 13:47:13,795:INFO:Declaring metric variables
2025-03-07 13:47:13,800:INFO:Importing untrained model
2025-03-07 13:47:13,805:INFO:Dummy Regressor Imported successfully
2025-03-07 13:47:13,813:INFO:Starting cross validation
2025-03-07 13:47:13,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-07 13:47:14,009:INFO:Calculating mean and std
2025-03-07 13:47:14,010:INFO:Creating metrics dataframe
2025-03-07 13:47:14,012:INFO:Uploading results into container
2025-03-07 13:47:14,012:INFO:Uploading model into container now
2025-03-07 13:47:14,013:INFO:_master_model_container: 18
2025-03-07 13:47:14,013:INFO:_display_container: 2
2025-03-07 13:47:14,013:INFO:DummyRegressor()
2025-03-07 13:47:14,013:INFO:create_model() successfully completed......................................
2025-03-07 13:47:14,072:INFO:SubProcess create_model() end ==================================
2025-03-07 13:47:14,072:INFO:Creating metrics dataframe
2025-03-07 13:47:14,083:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-07 13:47:14,090:INFO:Initializing create_model()
2025-03-07 13:47:14,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-07 13:47:14,090:INFO:Checking exceptions
2025-03-07 13:47:14,092:INFO:Importing libraries
2025-03-07 13:47:14,092:INFO:Copying training dataset
2025-03-07 13:47:14,096:INFO:Defining folds
2025-03-07 13:47:14,096:INFO:Declaring metric variables
2025-03-07 13:47:14,096:INFO:Importing untrained model
2025-03-07 13:47:14,096:INFO:Declaring custom model
2025-03-07 13:47:14,097:INFO:Gradient Boosting Regressor Imported successfully
2025-03-07 13:47:14,097:INFO:Cross validation set to False
2025-03-07 13:47:14,097:INFO:Fitting Model
2025-03-07 13:47:16,280:INFO:GradientBoostingRegressor(random_state=123)
2025-03-07 13:47:16,280:INFO:create_model() successfully completed......................................
2025-03-07 13:47:16,369:INFO:_master_model_container: 18
2025-03-07 13:47:16,369:INFO:_display_container: 2
2025-03-07 13:47:16,370:INFO:GradientBoostingRegressor(random_state=123)
2025-03-07 13:47:16,370:INFO:compare_models() successfully completed......................................
2025-03-07 13:47:16,402:INFO:Initializing evaluate_model()
2025-03-07 13:47:16,403:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-07 13:47:16,422:INFO:Initializing plot_model()
2025-03-07 13:47:16,422:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, system=True)
2025-03-07 13:47:16,422:INFO:Checking exceptions
2025-03-07 13:47:16,428:INFO:Preloading libraries
2025-03-07 13:47:16,443:INFO:Copying training dataset
2025-03-07 13:47:16,443:INFO:Plot type: pipeline
2025-03-07 13:47:16,602:INFO:Visual Rendered Successfully
2025-03-07 13:47:16,662:INFO:plot_model() successfully completed......................................
2025-03-07 13:47:38,321:INFO:Initializing evaluate_model()
2025-03-07 13:47:38,321:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-07 13:47:38,339:INFO:Initializing plot_model()
2025-03-07 13:47:38,339:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, system=True)
2025-03-07 13:47:38,339:INFO:Checking exceptions
2025-03-07 13:47:38,344:INFO:Preloading libraries
2025-03-07 13:47:38,354:INFO:Copying training dataset
2025-03-07 13:47:38,354:INFO:Plot type: pipeline
2025-03-07 13:47:38,490:INFO:Visual Rendered Successfully
2025-03-07 13:47:38,556:INFO:plot_model() successfully completed......................................
2025-03-07 13:47:38,604:INFO:Initializing plot_model()
2025-03-07 13:47:38,604:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, system=True)
2025-03-07 13:47:38,605:INFO:Checking exceptions
2025-03-07 13:47:38,614:INFO:Preloading libraries
2025-03-07 13:47:38,621:INFO:Copying training dataset
2025-03-07 13:47:38,621:INFO:Plot type: residuals
2025-03-07 13:47:38,727:INFO:Fitting Model
2025-03-07 13:47:38,728:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-07 13:47:38,830:INFO:Scoring test/hold-out set
2025-03-07 13:47:39,588:INFO:Visual Rendered Successfully
2025-03-07 13:47:39,653:INFO:plot_model() successfully completed......................................
2025-03-07 13:47:39,666:INFO:Initializing plot_model()
2025-03-07 13:47:39,667:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, system=True)
2025-03-07 13:47:39,667:INFO:Checking exceptions
2025-03-07 13:47:39,672:INFO:Preloading libraries
2025-03-07 13:47:39,679:INFO:Copying training dataset
2025-03-07 13:47:39,679:INFO:Plot type: feature
2025-03-07 13:47:39,681:WARNING:No coef_ found. Trying feature_importances_
2025-03-07 13:47:39,805:INFO:Visual Rendered Successfully
2025-03-07 13:47:39,892:INFO:plot_model() successfully completed......................................
2025-03-07 13:47:39,919:INFO:Initializing predict_model()
2025-03-07 13:47:39,919:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f1b388453a0>)
2025-03-07 13:47:39,919:INFO:Checking exceptions
2025-03-07 13:47:39,919:INFO:Preloading libraries
2025-03-07 13:47:40,002:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-07 13:47:40,468:INFO:Initializing predict_model()
2025-03-07 13:47:40,469:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1b1ec799d0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f1b1cff99d0>)
2025-03-07 13:47:40,470:INFO:Checking exceptions
2025-03-07 13:47:40,470:INFO:Preloading libraries
2025-03-07 13:47:40,473:INFO:Set up data.
2025-03-07 13:47:40,480:INFO:Set up index.
2025-03-07 13:47:40,548:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-31 13:47:26,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,835:INFO:PyCaret RegressionExperiment
2025-03-31 13:47:26,835:INFO:Logging name: reg-default-name
2025-03-31 13:47:26,835:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-31 13:47:26,835:INFO:version 3.3.1
2025-03-31 13:47:26,835:INFO:Initializing setup()
2025-03-31 13:47:26,835:INFO:self.USI: dfd3
2025-03-31 13:47:26,835:INFO:self._variable_keys: {'transform_target_param', 'y_train', 'pipeline', 'USI', 'log_plots_param', 'exp_id', 'fold_generator', 'gpu_n_jobs_param', '_available_plots', 'logging_param', 'seed', 'n_jobs_param', 'X_train', 'idx', 'html_param', 'y', '_ml_usecase', 'X_test', 'data', 'y_test', 'fold_groups_param', 'fold_shuffle_param', 'target_param', 'gpu_param', 'exp_name_log', 'memory', 'X'}
2025-03-31 13:47:26,835:INFO:Checking environment
2025-03-31 13:47:26,835:INFO:python_version: 3.9.21
2025-03-31 13:47:26,835:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-03-31 13:47:26,835:INFO:machine: x86_64
2025-03-31 13:47:26,835:INFO:platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-31 13:47:26,835:INFO:Memory: svmem(total=33374515200, available=27009556480, percent=19.1, used=4986187776, free=24286588928, active=5782573056, inactive=1293983744, buffers=319143936, cached=3782594560, shared=895819776, slab=791764992)
2025-03-31 13:47:26,836:INFO:Physical Core: 24
2025-03-31 13:47:26,836:INFO:Logical Core: 32
2025-03-31 13:47:26,836:INFO:Checking libraries
2025-03-31 13:47:26,836:INFO:System:
2025-03-31 13:47:26,836:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-03-31 13:47:26,836:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-03-31 13:47:26,836:INFO:   machine: Linux-6.8.0-52-generic-x86_64-with-glibc2.35
2025-03-31 13:47:26,836:INFO:PyCaret required dependencies:
2025-03-31 13:47:26,855:INFO:                 pip: 25.0
2025-03-31 13:47:26,855:INFO:          setuptools: 75.8.0
2025-03-31 13:47:26,855:INFO:             pycaret: 3.3.1
2025-03-31 13:47:26,855:INFO:             IPython: 8.18.1
2025-03-31 13:47:26,855:INFO:          ipywidgets: 8.1.5
2025-03-31 13:47:26,855:INFO:                tqdm: 4.67.1
2025-03-31 13:47:26,855:INFO:               numpy: 1.26.4
2025-03-31 13:47:26,855:INFO:              pandas: 2.1.4
2025-03-31 13:47:26,855:INFO:              jinja2: 3.1.5
2025-03-31 13:47:26,855:INFO:               scipy: 1.11.4
2025-03-31 13:47:26,855:INFO:              joblib: 1.3.2
2025-03-31 13:47:26,855:INFO:             sklearn: 1.4.2
2025-03-31 13:47:26,855:INFO:                pyod: 2.0.3
2025-03-31 13:47:26,855:INFO:            imblearn: 0.12.4
2025-03-31 13:47:26,855:INFO:   category_encoders: 2.6.4
2025-03-31 13:47:26,855:INFO:            lightgbm: 4.6.0
2025-03-31 13:47:26,855:INFO:               numba: 0.60.0
2025-03-31 13:47:26,855:INFO:            requests: 2.32.3
2025-03-31 13:47:26,855:INFO:          matplotlib: 3.7.5
2025-03-31 13:47:26,856:INFO:          scikitplot: 0.3.7
2025-03-31 13:47:26,856:INFO:         yellowbrick: 1.5
2025-03-31 13:47:26,856:INFO:              plotly: 5.24.1
2025-03-31 13:47:26,856:INFO:    plotly-resampler: Not installed
2025-03-31 13:47:26,856:INFO:             kaleido: 0.2.1
2025-03-31 13:47:26,856:INFO:           schemdraw: 0.15
2025-03-31 13:47:26,856:INFO:         statsmodels: 0.14.4
2025-03-31 13:47:26,856:INFO:              sktime: 0.26.0
2025-03-31 13:47:26,856:INFO:               tbats: 1.1.3
2025-03-31 13:47:26,856:INFO:            pmdarima: 2.0.4
2025-03-31 13:47:26,856:INFO:              psutil: 7.0.0
2025-03-31 13:47:26,856:INFO:          markupsafe: 3.0.2
2025-03-31 13:47:26,856:INFO:             pickle5: Not installed
2025-03-31 13:47:26,856:INFO:         cloudpickle: 3.1.1
2025-03-31 13:47:26,856:INFO:         deprecation: 2.1.0
2025-03-31 13:47:26,856:INFO:              xxhash: 3.5.0
2025-03-31 13:47:26,856:INFO:           wurlitzer: 3.1.1
2025-03-31 13:47:26,856:INFO:PyCaret optional dependencies:
2025-03-31 13:47:26,876:INFO:                shap: Not installed
2025-03-31 13:47:26,876:INFO:           interpret: Not installed
2025-03-31 13:47:26,876:INFO:                umap: Not installed
2025-03-31 13:47:26,876:INFO:     ydata_profiling: Not installed
2025-03-31 13:47:26,876:INFO:  explainerdashboard: Not installed
2025-03-31 13:47:26,876:INFO:             autoviz: Not installed
2025-03-31 13:47:26,876:INFO:           fairlearn: Not installed
2025-03-31 13:47:26,876:INFO:          deepchecks: Not installed
2025-03-31 13:47:26,876:INFO:             xgboost: Not installed
2025-03-31 13:47:26,876:INFO:            catboost: Not installed
2025-03-31 13:47:26,876:INFO:              kmodes: Not installed
2025-03-31 13:47:26,876:INFO:             mlxtend: Not installed
2025-03-31 13:47:26,876:INFO:       statsforecast: Not installed
2025-03-31 13:47:26,876:INFO:        tune_sklearn: Not installed
2025-03-31 13:47:26,877:INFO:                 ray: Not installed
2025-03-31 13:47:26,877:INFO:            hyperopt: Not installed
2025-03-31 13:47:26,877:INFO:              optuna: Not installed
2025-03-31 13:47:26,877:INFO:               skopt: Not installed
2025-03-31 13:47:26,877:INFO:              mlflow: Not installed
2025-03-31 13:47:26,877:INFO:              gradio: Not installed
2025-03-31 13:47:26,877:INFO:             fastapi: Not installed
2025-03-31 13:47:26,877:INFO:             uvicorn: Not installed
2025-03-31 13:47:26,877:INFO:              m2cgen: Not installed
2025-03-31 13:47:26,877:INFO:           evidently: Not installed
2025-03-31 13:47:26,877:INFO:               fugue: Not installed
2025-03-31 13:47:26,877:INFO:           streamlit: Not installed
2025-03-31 13:47:26,877:INFO:             prophet: Not installed
2025-03-31 13:47:26,877:INFO:None
2025-03-31 13:47:26,877:INFO:Set up GPU usage.
2025-03-31 13:47:26,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,877:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-03-31 13:47:26,877:INFO:Set up data.
2025-03-31 13:47:26,886:INFO:Set up folding strategy.
2025-03-31 13:47:26,886:INFO:Set up train/test split.
2025-03-31 13:47:26,892:INFO:Set up index.
2025-03-31 13:47:26,894:INFO:Assigning column types.
2025-03-31 13:47:26,899:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-31 13:47:26,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,899:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-31 13:47:26,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,906:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-31 13:47:26,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:26,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:26,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:26,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:27,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:27,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:27,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:27,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,608:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,618:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,782:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-31 13:47:39,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,785:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,845:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,849:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:39,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:39,994:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-31 13:47:39,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:39,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,396:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-31 13:47:40,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,840:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-31 13:47:40,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-31 13:47:40,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:40,954:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-31 13:47:40,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:40,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,096:INFO:Preparing preprocessing pipeline...
2025-03-31 13:47:41,097:INFO:Set up simple imputation.
2025-03-31 13:47:41,097:INFO:Set up polynomial features.
2025-03-31 13:47:41,108:INFO:Finished creating preprocessing pipeline.
2025-03-31 13:47:41,110:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-03-31 13:47:41,110:INFO:Creating final display dataframe.
2025-03-31 13:47:41,142:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape        (25445, 2)
4        Transformed data shape        (25445, 3)
5   Transformed train set shape        (17811, 3)
6    Transformed test set shape         (7634, 3)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              dfd3
2025-03-31 13:47:41,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 13:47:41,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 13:47:41,395:INFO:setup() successfully completed in 14.56s...............
2025-03-31 13:47:41,405:INFO:Initializing compare_models()
2025-03-31 13:47:41,405:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-31 13:47:41,406:INFO:Checking exceptions
2025-03-31 13:47:41,408:INFO:Preparing display monitor
2025-03-31 13:47:41,428:INFO:Initializing Linear Regression
2025-03-31 13:47:41,428:INFO:Total runtime is 2.6623407999674478e-06 minutes
2025-03-31 13:47:41,431:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:41,431:INFO:Initializing create_model()
2025-03-31 13:47:41,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:41,432:INFO:Checking exceptions
2025-03-31 13:47:41,432:INFO:Importing libraries
2025-03-31 13:47:41,432:INFO:Copying training dataset
2025-03-31 13:47:41,435:INFO:Defining folds
2025-03-31 13:47:41,435:INFO:Declaring metric variables
2025-03-31 13:47:41,439:INFO:Importing untrained model
2025-03-31 13:47:41,446:INFO:Linear Regression Imported successfully
2025-03-31 13:47:41,457:INFO:Starting cross validation
2025-03-31 13:47:41,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:41,647:INFO:Calculating mean and std
2025-03-31 13:47:41,647:INFO:Creating metrics dataframe
2025-03-31 13:47:41,649:INFO:Uploading results into container
2025-03-31 13:47:41,649:INFO:Uploading model into container now
2025-03-31 13:47:41,650:INFO:_master_model_container: 1
2025-03-31 13:47:41,650:INFO:_display_container: 2
2025-03-31 13:47:41,650:INFO:LinearRegression(n_jobs=-1)
2025-03-31 13:47:41,650:INFO:create_model() successfully completed......................................
2025-03-31 13:47:41,740:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:41,740:INFO:Creating metrics dataframe
2025-03-31 13:47:41,754:INFO:Initializing Lasso Regression
2025-03-31 13:47:41,755:INFO:Total runtime is 0.0054472287495930995 minutes
2025-03-31 13:47:41,761:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:41,762:INFO:Initializing create_model()
2025-03-31 13:47:41,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:41,762:INFO:Checking exceptions
2025-03-31 13:47:41,762:INFO:Importing libraries
2025-03-31 13:47:41,762:INFO:Copying training dataset
2025-03-31 13:47:41,771:INFO:Defining folds
2025-03-31 13:47:41,771:INFO:Declaring metric variables
2025-03-31 13:47:41,778:INFO:Importing untrained model
2025-03-31 13:47:41,785:INFO:Lasso Regression Imported successfully
2025-03-31 13:47:41,799:INFO:Starting cross validation
2025-03-31 13:47:41,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:42,201:INFO:Calculating mean and std
2025-03-31 13:47:42,201:INFO:Creating metrics dataframe
2025-03-31 13:47:42,202:INFO:Uploading results into container
2025-03-31 13:47:42,203:INFO:Uploading model into container now
2025-03-31 13:47:42,203:INFO:_master_model_container: 2
2025-03-31 13:47:42,203:INFO:_display_container: 2
2025-03-31 13:47:42,203:INFO:Lasso(random_state=123)
2025-03-31 13:47:42,203:INFO:create_model() successfully completed......................................
2025-03-31 13:47:42,320:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:42,321:INFO:Creating metrics dataframe
2025-03-31 13:47:42,324:INFO:Initializing Ridge Regression
2025-03-31 13:47:42,324:INFO:Total runtime is 0.01494067112604777 minutes
2025-03-31 13:47:42,326:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:42,326:INFO:Initializing create_model()
2025-03-31 13:47:42,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:42,326:INFO:Checking exceptions
2025-03-31 13:47:42,326:INFO:Importing libraries
2025-03-31 13:47:42,326:INFO:Copying training dataset
2025-03-31 13:47:42,328:INFO:Defining folds
2025-03-31 13:47:42,328:INFO:Declaring metric variables
2025-03-31 13:47:42,330:INFO:Importing untrained model
2025-03-31 13:47:42,331:INFO:Ridge Regression Imported successfully
2025-03-31 13:47:42,334:INFO:Starting cross validation
2025-03-31 13:47:42,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:42,514:INFO:Calculating mean and std
2025-03-31 13:47:42,515:INFO:Creating metrics dataframe
2025-03-31 13:47:42,517:INFO:Uploading results into container
2025-03-31 13:47:42,517:INFO:Uploading model into container now
2025-03-31 13:47:42,518:INFO:_master_model_container: 3
2025-03-31 13:47:42,518:INFO:_display_container: 2
2025-03-31 13:47:42,518:INFO:Ridge(random_state=123)
2025-03-31 13:47:42,518:INFO:create_model() successfully completed......................................
2025-03-31 13:47:42,578:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:42,578:INFO:Creating metrics dataframe
2025-03-31 13:47:42,582:INFO:Initializing Elastic Net
2025-03-31 13:47:42,582:INFO:Total runtime is 0.019235547383626303 minutes
2025-03-31 13:47:42,583:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:42,584:INFO:Initializing create_model()
2025-03-31 13:47:42,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:42,584:INFO:Checking exceptions
2025-03-31 13:47:42,584:INFO:Importing libraries
2025-03-31 13:47:42,584:INFO:Copying training dataset
2025-03-31 13:47:42,586:INFO:Defining folds
2025-03-31 13:47:42,586:INFO:Declaring metric variables
2025-03-31 13:47:42,589:INFO:Importing untrained model
2025-03-31 13:47:42,592:INFO:Elastic Net Imported successfully
2025-03-31 13:47:42,601:INFO:Starting cross validation
2025-03-31 13:47:42,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:42,883:INFO:Calculating mean and std
2025-03-31 13:47:42,885:INFO:Creating metrics dataframe
2025-03-31 13:47:42,886:INFO:Uploading results into container
2025-03-31 13:47:42,887:INFO:Uploading model into container now
2025-03-31 13:47:42,887:INFO:_master_model_container: 4
2025-03-31 13:47:42,887:INFO:_display_container: 2
2025-03-31 13:47:42,887:INFO:ElasticNet(random_state=123)
2025-03-31 13:47:42,888:INFO:create_model() successfully completed......................................
2025-03-31 13:47:42,948:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:42,948:INFO:Creating metrics dataframe
2025-03-31 13:47:42,955:INFO:Initializing Least Angle Regression
2025-03-31 13:47:42,955:INFO:Total runtime is 0.02545241912206014 minutes
2025-03-31 13:47:42,958:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:42,958:INFO:Initializing create_model()
2025-03-31 13:47:42,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:42,958:INFO:Checking exceptions
2025-03-31 13:47:42,958:INFO:Importing libraries
2025-03-31 13:47:42,958:INFO:Copying training dataset
2025-03-31 13:47:42,962:INFO:Defining folds
2025-03-31 13:47:42,962:INFO:Declaring metric variables
2025-03-31 13:47:42,964:INFO:Importing untrained model
2025-03-31 13:47:42,967:INFO:Least Angle Regression Imported successfully
2025-03-31 13:47:42,971:INFO:Starting cross validation
2025-03-31 13:47:42,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:43,095:INFO:Calculating mean and std
2025-03-31 13:47:43,096:INFO:Creating metrics dataframe
2025-03-31 13:47:43,098:INFO:Uploading results into container
2025-03-31 13:47:43,099:INFO:Uploading model into container now
2025-03-31 13:47:43,100:INFO:_master_model_container: 5
2025-03-31 13:47:43,100:INFO:_display_container: 2
2025-03-31 13:47:43,100:INFO:Lars(random_state=123)
2025-03-31 13:47:43,100:INFO:create_model() successfully completed......................................
2025-03-31 13:47:43,209:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:43,210:INFO:Creating metrics dataframe
2025-03-31 13:47:43,225:INFO:Initializing Lasso Least Angle Regression
2025-03-31 13:47:43,225:INFO:Total runtime is 0.02995455265045166 minutes
2025-03-31 13:47:43,231:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:43,231:INFO:Initializing create_model()
2025-03-31 13:47:43,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:43,231:INFO:Checking exceptions
2025-03-31 13:47:43,231:INFO:Importing libraries
2025-03-31 13:47:43,232:INFO:Copying training dataset
2025-03-31 13:47:43,239:INFO:Defining folds
2025-03-31 13:47:43,239:INFO:Declaring metric variables
2025-03-31 13:47:43,249:INFO:Importing untrained model
2025-03-31 13:47:43,259:INFO:Lasso Least Angle Regression Imported successfully
2025-03-31 13:47:43,273:INFO:Starting cross validation
2025-03-31 13:47:43,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:43,536:INFO:Calculating mean and std
2025-03-31 13:47:43,537:INFO:Creating metrics dataframe
2025-03-31 13:47:43,538:INFO:Uploading results into container
2025-03-31 13:47:43,538:INFO:Uploading model into container now
2025-03-31 13:47:43,538:INFO:_master_model_container: 6
2025-03-31 13:47:43,538:INFO:_display_container: 2
2025-03-31 13:47:43,538:INFO:LassoLars(random_state=123)
2025-03-31 13:47:43,538:INFO:create_model() successfully completed......................................
2025-03-31 13:47:43,588:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:43,588:INFO:Creating metrics dataframe
2025-03-31 13:47:43,592:INFO:Initializing Orthogonal Matching Pursuit
2025-03-31 13:47:43,592:INFO:Total runtime is 0.03606594403584798 minutes
2025-03-31 13:47:43,593:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:43,593:INFO:Initializing create_model()
2025-03-31 13:47:43,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:43,593:INFO:Checking exceptions
2025-03-31 13:47:43,593:INFO:Importing libraries
2025-03-31 13:47:43,593:INFO:Copying training dataset
2025-03-31 13:47:43,595:INFO:Defining folds
2025-03-31 13:47:43,595:INFO:Declaring metric variables
2025-03-31 13:47:43,597:INFO:Importing untrained model
2025-03-31 13:47:43,598:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-31 13:47:43,600:INFO:Starting cross validation
2025-03-31 13:47:43,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:43,683:INFO:Calculating mean and std
2025-03-31 13:47:43,684:INFO:Creating metrics dataframe
2025-03-31 13:47:43,685:INFO:Uploading results into container
2025-03-31 13:47:43,685:INFO:Uploading model into container now
2025-03-31 13:47:43,685:INFO:_master_model_container: 7
2025-03-31 13:47:43,685:INFO:_display_container: 2
2025-03-31 13:47:43,685:INFO:OrthogonalMatchingPursuit()
2025-03-31 13:47:43,685:INFO:create_model() successfully completed......................................
2025-03-31 13:47:43,730:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:43,730:INFO:Creating metrics dataframe
2025-03-31 13:47:43,739:INFO:Initializing Bayesian Ridge
2025-03-31 13:47:43,739:INFO:Total runtime is 0.038523129622141515 minutes
2025-03-31 13:47:43,741:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:43,742:INFO:Initializing create_model()
2025-03-31 13:47:43,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:43,742:INFO:Checking exceptions
2025-03-31 13:47:43,742:INFO:Importing libraries
2025-03-31 13:47:43,742:INFO:Copying training dataset
2025-03-31 13:47:43,744:INFO:Defining folds
2025-03-31 13:47:43,744:INFO:Declaring metric variables
2025-03-31 13:47:43,746:INFO:Importing untrained model
2025-03-31 13:47:43,748:INFO:Bayesian Ridge Imported successfully
2025-03-31 13:47:43,751:INFO:Starting cross validation
2025-03-31 13:47:43,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:43,919:INFO:Calculating mean and std
2025-03-31 13:47:43,920:INFO:Creating metrics dataframe
2025-03-31 13:47:43,921:INFO:Uploading results into container
2025-03-31 13:47:43,922:INFO:Uploading model into container now
2025-03-31 13:47:43,922:INFO:_master_model_container: 8
2025-03-31 13:47:43,922:INFO:_display_container: 2
2025-03-31 13:47:43,923:INFO:BayesianRidge()
2025-03-31 13:47:43,923:INFO:create_model() successfully completed......................................
2025-03-31 13:47:44,027:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:44,027:INFO:Creating metrics dataframe
2025-03-31 13:47:44,031:INFO:Initializing Passive Aggressive Regressor
2025-03-31 13:47:44,032:INFO:Total runtime is 0.043397847811381014 minutes
2025-03-31 13:47:44,033:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:44,034:INFO:Initializing create_model()
2025-03-31 13:47:44,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:44,034:INFO:Checking exceptions
2025-03-31 13:47:44,034:INFO:Importing libraries
2025-03-31 13:47:44,034:INFO:Copying training dataset
2025-03-31 13:47:44,038:INFO:Defining folds
2025-03-31 13:47:44,038:INFO:Declaring metric variables
2025-03-31 13:47:44,040:INFO:Importing untrained model
2025-03-31 13:47:44,041:INFO:Passive Aggressive Regressor Imported successfully
2025-03-31 13:47:44,044:INFO:Starting cross validation
2025-03-31 13:47:44,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:44,309:INFO:Calculating mean and std
2025-03-31 13:47:44,310:INFO:Creating metrics dataframe
2025-03-31 13:47:44,311:INFO:Uploading results into container
2025-03-31 13:47:44,311:INFO:Uploading model into container now
2025-03-31 13:47:44,311:INFO:_master_model_container: 9
2025-03-31 13:47:44,311:INFO:_display_container: 2
2025-03-31 13:47:44,311:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-31 13:47:44,311:INFO:create_model() successfully completed......................................
2025-03-31 13:47:44,363:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:44,363:INFO:Creating metrics dataframe
2025-03-31 13:47:44,377:INFO:Initializing Huber Regressor
2025-03-31 13:47:44,377:INFO:Total runtime is 0.04915512005488077 minutes
2025-03-31 13:47:44,384:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:44,384:INFO:Initializing create_model()
2025-03-31 13:47:44,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:44,385:INFO:Checking exceptions
2025-03-31 13:47:44,385:INFO:Importing libraries
2025-03-31 13:47:44,385:INFO:Copying training dataset
2025-03-31 13:47:44,393:INFO:Defining folds
2025-03-31 13:47:44,393:INFO:Declaring metric variables
2025-03-31 13:47:44,400:INFO:Importing untrained model
2025-03-31 13:47:44,407:INFO:Huber Regressor Imported successfully
2025-03-31 13:47:44,420:INFO:Starting cross validation
2025-03-31 13:47:44,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:45,710:INFO:Calculating mean and std
2025-03-31 13:47:45,711:INFO:Creating metrics dataframe
2025-03-31 13:47:45,713:INFO:Uploading results into container
2025-03-31 13:47:45,713:INFO:Uploading model into container now
2025-03-31 13:47:45,713:INFO:_master_model_container: 10
2025-03-31 13:47:45,713:INFO:_display_container: 2
2025-03-31 13:47:45,713:INFO:HuberRegressor()
2025-03-31 13:47:45,714:INFO:create_model() successfully completed......................................
2025-03-31 13:47:45,776:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:45,776:INFO:Creating metrics dataframe
2025-03-31 13:47:45,791:INFO:Initializing K Neighbors Regressor
2025-03-31 13:47:45,791:INFO:Total runtime is 0.07272400458653767 minutes
2025-03-31 13:47:45,798:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:45,798:INFO:Initializing create_model()
2025-03-31 13:47:45,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:45,798:INFO:Checking exceptions
2025-03-31 13:47:45,798:INFO:Importing libraries
2025-03-31 13:47:45,798:INFO:Copying training dataset
2025-03-31 13:47:45,806:INFO:Defining folds
2025-03-31 13:47:45,806:INFO:Declaring metric variables
2025-03-31 13:47:45,811:INFO:Importing untrained model
2025-03-31 13:47:45,813:INFO:K Neighbors Regressor Imported successfully
2025-03-31 13:47:45,817:INFO:Starting cross validation
2025-03-31 13:47:45,818:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:46,678:INFO:Calculating mean and std
2025-03-31 13:47:46,680:INFO:Creating metrics dataframe
2025-03-31 13:47:46,685:INFO:Uploading results into container
2025-03-31 13:47:46,690:INFO:Uploading model into container now
2025-03-31 13:47:46,691:INFO:_master_model_container: 11
2025-03-31 13:47:46,691:INFO:_display_container: 2
2025-03-31 13:47:46,691:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-31 13:47:46,692:INFO:create_model() successfully completed......................................
2025-03-31 13:47:46,808:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:46,808:INFO:Creating metrics dataframe
2025-03-31 13:47:46,825:INFO:Initializing Decision Tree Regressor
2025-03-31 13:47:46,825:INFO:Total runtime is 0.08995285828908284 minutes
2025-03-31 13:47:46,833:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:46,834:INFO:Initializing create_model()
2025-03-31 13:47:46,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:46,835:INFO:Checking exceptions
2025-03-31 13:47:46,835:INFO:Importing libraries
2025-03-31 13:47:46,835:INFO:Copying training dataset
2025-03-31 13:47:46,846:INFO:Defining folds
2025-03-31 13:47:46,846:INFO:Declaring metric variables
2025-03-31 13:47:46,852:INFO:Importing untrained model
2025-03-31 13:47:46,860:INFO:Decision Tree Regressor Imported successfully
2025-03-31 13:47:46,877:INFO:Starting cross validation
2025-03-31 13:47:46,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:47,512:INFO:Calculating mean and std
2025-03-31 13:47:47,512:INFO:Creating metrics dataframe
2025-03-31 13:47:47,513:INFO:Uploading results into container
2025-03-31 13:47:47,514:INFO:Uploading model into container now
2025-03-31 13:47:47,514:INFO:_master_model_container: 12
2025-03-31 13:47:47,514:INFO:_display_container: 2
2025-03-31 13:47:47,514:INFO:DecisionTreeRegressor(random_state=123)
2025-03-31 13:47:47,514:INFO:create_model() successfully completed......................................
2025-03-31 13:47:47,558:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:47,558:INFO:Creating metrics dataframe
2025-03-31 13:47:47,564:INFO:Initializing Random Forest Regressor
2025-03-31 13:47:47,564:INFO:Total runtime is 0.10227550665537516 minutes
2025-03-31 13:47:47,567:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:47,567:INFO:Initializing create_model()
2025-03-31 13:47:47,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:47,567:INFO:Checking exceptions
2025-03-31 13:47:47,567:INFO:Importing libraries
2025-03-31 13:47:47,567:INFO:Copying training dataset
2025-03-31 13:47:47,571:INFO:Defining folds
2025-03-31 13:47:47,571:INFO:Declaring metric variables
2025-03-31 13:47:47,573:INFO:Importing untrained model
2025-03-31 13:47:47,574:INFO:Random Forest Regressor Imported successfully
2025-03-31 13:47:47,577:INFO:Starting cross validation
2025-03-31 13:47:47,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:50,859:INFO:Calculating mean and std
2025-03-31 13:47:50,861:INFO:Creating metrics dataframe
2025-03-31 13:47:50,863:INFO:Uploading results into container
2025-03-31 13:47:50,864:INFO:Uploading model into container now
2025-03-31 13:47:50,864:INFO:_master_model_container: 13
2025-03-31 13:47:50,864:INFO:_display_container: 2
2025-03-31 13:47:50,865:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:47:50,865:INFO:create_model() successfully completed......................................
2025-03-31 13:47:50,952:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:50,952:INFO:Creating metrics dataframe
2025-03-31 13:47:50,971:INFO:Initializing Extra Trees Regressor
2025-03-31 13:47:50,972:INFO:Total runtime is 0.1590640107790629 minutes
2025-03-31 13:47:50,978:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:50,978:INFO:Initializing create_model()
2025-03-31 13:47:50,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:50,979:INFO:Checking exceptions
2025-03-31 13:47:50,979:INFO:Importing libraries
2025-03-31 13:47:50,979:INFO:Copying training dataset
2025-03-31 13:47:50,989:INFO:Defining folds
2025-03-31 13:47:50,990:INFO:Declaring metric variables
2025-03-31 13:47:51,002:INFO:Importing untrained model
2025-03-31 13:47:51,009:INFO:Extra Trees Regressor Imported successfully
2025-03-31 13:47:51,024:INFO:Starting cross validation
2025-03-31 13:47:51,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:53,887:INFO:Calculating mean and std
2025-03-31 13:47:53,891:INFO:Creating metrics dataframe
2025-03-31 13:47:53,897:INFO:Uploading results into container
2025-03-31 13:47:53,899:INFO:Uploading model into container now
2025-03-31 13:47:53,900:INFO:_master_model_container: 14
2025-03-31 13:47:53,900:INFO:_display_container: 2
2025-03-31 13:47:53,901:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:47:53,901:INFO:create_model() successfully completed......................................
2025-03-31 13:47:54,006:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:54,006:INFO:Creating metrics dataframe
2025-03-31 13:47:54,022:INFO:Initializing AdaBoost Regressor
2025-03-31 13:47:54,023:INFO:Total runtime is 0.2099165399869283 minutes
2025-03-31 13:47:54,030:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:54,030:INFO:Initializing create_model()
2025-03-31 13:47:54,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:54,031:INFO:Checking exceptions
2025-03-31 13:47:54,031:INFO:Importing libraries
2025-03-31 13:47:54,031:INFO:Copying training dataset
2025-03-31 13:47:54,043:INFO:Defining folds
2025-03-31 13:47:54,043:INFO:Declaring metric variables
2025-03-31 13:47:54,050:INFO:Importing untrained model
2025-03-31 13:47:54,056:INFO:AdaBoost Regressor Imported successfully
2025-03-31 13:47:54,065:INFO:Starting cross validation
2025-03-31 13:47:54,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:47:55,865:INFO:Calculating mean and std
2025-03-31 13:47:55,866:INFO:Creating metrics dataframe
2025-03-31 13:47:55,867:INFO:Uploading results into container
2025-03-31 13:47:55,867:INFO:Uploading model into container now
2025-03-31 13:47:55,867:INFO:_master_model_container: 15
2025-03-31 13:47:55,867:INFO:_display_container: 2
2025-03-31 13:47:55,867:INFO:AdaBoostRegressor(random_state=123)
2025-03-31 13:47:55,867:INFO:create_model() successfully completed......................................
2025-03-31 13:47:55,906:INFO:SubProcess create_model() end ==================================
2025-03-31 13:47:55,906:INFO:Creating metrics dataframe
2025-03-31 13:47:55,910:INFO:Initializing Gradient Boosting Regressor
2025-03-31 13:47:55,911:INFO:Total runtime is 0.24138133923212687 minutes
2025-03-31 13:47:55,912:INFO:SubProcess create_model() called ==================================
2025-03-31 13:47:55,912:INFO:Initializing create_model()
2025-03-31 13:47:55,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:47:55,912:INFO:Checking exceptions
2025-03-31 13:47:55,912:INFO:Importing libraries
2025-03-31 13:47:55,912:INFO:Copying training dataset
2025-03-31 13:47:55,914:INFO:Defining folds
2025-03-31 13:47:55,914:INFO:Declaring metric variables
2025-03-31 13:47:55,915:INFO:Importing untrained model
2025-03-31 13:47:55,917:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:47:55,920:INFO:Starting cross validation
2025-03-31 13:47:55,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:48:12,815:INFO:Calculating mean and std
2025-03-31 13:48:12,816:INFO:Creating metrics dataframe
2025-03-31 13:48:12,816:INFO:Uploading results into container
2025-03-31 13:48:12,817:INFO:Uploading model into container now
2025-03-31 13:48:12,817:INFO:_master_model_container: 16
2025-03-31 13:48:12,817:INFO:_display_container: 2
2025-03-31 13:48:12,817:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:48:12,817:INFO:create_model() successfully completed......................................
2025-03-31 13:48:12,854:INFO:SubProcess create_model() end ==================================
2025-03-31 13:48:12,854:INFO:Creating metrics dataframe
2025-03-31 13:48:12,859:INFO:Initializing Light Gradient Boosting Machine
2025-03-31 13:48:12,859:INFO:Total runtime is 0.5238565762837728 minutes
2025-03-31 13:48:12,861:INFO:SubProcess create_model() called ==================================
2025-03-31 13:48:12,861:INFO:Initializing create_model()
2025-03-31 13:48:12,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:48:12,861:INFO:Checking exceptions
2025-03-31 13:48:12,861:INFO:Importing libraries
2025-03-31 13:48:12,861:INFO:Copying training dataset
2025-03-31 13:48:12,864:INFO:Defining folds
2025-03-31 13:48:12,864:INFO:Declaring metric variables
2025-03-31 13:48:12,865:INFO:Importing untrained model
2025-03-31 13:48:12,866:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-31 13:48:12,869:INFO:Starting cross validation
2025-03-31 13:48:12,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:48:12,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009880 seconds.
2025-03-31 13:48:12,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-31 13:48:12,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-31 13:48:12,916:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:12,917:INFO:[LightGBM] [Info] Number of data points in the train set: 16029, number of used features: 2
2025-03-31 13:48:12,917:INFO:[LightGBM] [Info] Start training from score 6.880591
2025-03-31 13:48:14,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048068 seconds.
2025-03-31 13:48:14,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:14,687:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:14,694:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:14,711:INFO:[LightGBM] [Info] Start training from score 6.875686
2025-03-31 13:48:20,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031263 seconds.
2025-03-31 13:48:20,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:20,949:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:20,957:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:20,974:INFO:[LightGBM] [Info] Start training from score 6.876981
2025-03-31 13:48:29,153:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028607 seconds.
2025-03-31 13:48:29,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:29,154:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:29,154:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:29,155:INFO:[LightGBM] [Info] Start training from score 6.877885
2025-03-31 13:48:35,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030730 seconds.
2025-03-31 13:48:35,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:35,511:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:35,518:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:35,534:INFO:[LightGBM] [Info] Start training from score 6.877402
2025-03-31 13:48:40,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2025-03-31 13:48:40,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:40,004:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:40,004:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:40,004:INFO:[LightGBM] [Info] Start training from score 6.867280
2025-03-31 13:48:42,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028043 seconds.
2025-03-31 13:48:42,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:42,579:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:42,588:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:42,605:INFO:[LightGBM] [Info] Start training from score 6.877480
2025-03-31 13:48:48,767:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031382 seconds.
2025-03-31 13:48:48,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:48,768:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:48,774:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:48,790:INFO:[LightGBM] [Info] Start training from score 6.886494
2025-03-31 13:48:50,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029802 seconds.
2025-03-31 13:48:50,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:50,533:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:50,539:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:50,555:INFO:[LightGBM] [Info] Start training from score 6.883016
2025-03-31 13:48:50,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031774 seconds.
2025-03-31 13:48:50,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:48:50,787:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:48:50,793:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:48:50,810:INFO:[LightGBM] [Info] Start training from score 6.879117
2025-03-31 13:48:55,793:INFO:Calculating mean and std
2025-03-31 13:48:55,794:INFO:Creating metrics dataframe
2025-03-31 13:48:55,795:INFO:Uploading results into container
2025-03-31 13:48:55,795:INFO:Uploading model into container now
2025-03-31 13:48:55,795:INFO:_master_model_container: 17
2025-03-31 13:48:55,795:INFO:_display_container: 2
2025-03-31 13:48:55,795:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:48:55,795:INFO:create_model() successfully completed......................................
2025-03-31 13:48:55,832:INFO:SubProcess create_model() end ==================================
2025-03-31 13:48:55,832:INFO:Creating metrics dataframe
2025-03-31 13:48:55,842:INFO:Initializing Dummy Regressor
2025-03-31 13:48:55,842:INFO:Total runtime is 1.240240188439687 minutes
2025-03-31 13:48:55,844:INFO:SubProcess create_model() called ==================================
2025-03-31 13:48:55,844:INFO:Initializing create_model()
2025-03-31 13:48:55,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53333280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:48:55,844:INFO:Checking exceptions
2025-03-31 13:48:55,844:INFO:Importing libraries
2025-03-31 13:48:55,844:INFO:Copying training dataset
2025-03-31 13:48:55,847:INFO:Defining folds
2025-03-31 13:48:55,847:INFO:Declaring metric variables
2025-03-31 13:48:55,848:INFO:Importing untrained model
2025-03-31 13:48:55,850:INFO:Dummy Regressor Imported successfully
2025-03-31 13:48:55,852:INFO:Starting cross validation
2025-03-31 13:48:55,853:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:48:55,982:INFO:Calculating mean and std
2025-03-31 13:48:55,984:INFO:Creating metrics dataframe
2025-03-31 13:48:55,987:INFO:Uploading results into container
2025-03-31 13:48:55,988:INFO:Uploading model into container now
2025-03-31 13:48:55,989:INFO:_master_model_container: 18
2025-03-31 13:48:55,989:INFO:_display_container: 2
2025-03-31 13:48:55,989:INFO:DummyRegressor()
2025-03-31 13:48:55,989:INFO:create_model() successfully completed......................................
2025-03-31 13:48:56,083:INFO:SubProcess create_model() end ==================================
2025-03-31 13:48:56,083:INFO:Creating metrics dataframe
2025-03-31 13:48:56,101:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-31 13:48:56,113:INFO:Initializing create_model()
2025-03-31 13:48:56,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:48:56,114:INFO:Checking exceptions
2025-03-31 13:48:56,116:INFO:Importing libraries
2025-03-31 13:48:56,116:INFO:Copying training dataset
2025-03-31 13:48:56,122:INFO:Defining folds
2025-03-31 13:48:56,122:INFO:Declaring metric variables
2025-03-31 13:48:56,123:INFO:Importing untrained model
2025-03-31 13:48:56,123:INFO:Declaring custom model
2025-03-31 13:48:56,124:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:48:56,125:INFO:Cross validation set to False
2025-03-31 13:48:56,125:INFO:Fitting Model
2025-03-31 13:48:57,595:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:48:57,595:INFO:create_model() successfully completed......................................
2025-03-31 13:48:57,755:INFO:_master_model_container: 18
2025-03-31 13:48:57,755:INFO:_display_container: 2
2025-03-31 13:48:57,756:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:48:57,756:INFO:compare_models() successfully completed......................................
2025-03-31 13:48:57,777:INFO:Initializing evaluate_model()
2025-03-31 13:48:57,777:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-31 13:48:57,808:INFO:Initializing plot_model()
2025-03-31 13:48:57,808:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, system=True)
2025-03-31 13:48:57,808:INFO:Checking exceptions
2025-03-31 13:48:57,815:INFO:Preloading libraries
2025-03-31 13:48:57,828:INFO:Copying training dataset
2025-03-31 13:48:57,828:INFO:Plot type: pipeline
2025-03-31 13:48:58,005:INFO:Visual Rendered Successfully
2025-03-31 13:48:58,054:INFO:plot_model() successfully completed......................................
2025-03-31 13:48:58,073:INFO:Initializing plot_model()
2025-03-31 13:48:58,074:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, system=True)
2025-03-31 13:48:58,074:INFO:Checking exceptions
2025-03-31 13:48:58,077:INFO:Preloading libraries
2025-03-31 13:48:58,080:INFO:Copying training dataset
2025-03-31 13:48:58,080:INFO:Plot type: residuals
2025-03-31 13:48:58,168:INFO:Fitting Model
2025-03-31 13:48:58,168:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2025-03-31 13:48:58,220:INFO:Scoring test/hold-out set
2025-03-31 13:48:59,215:INFO:Visual Rendered Successfully
2025-03-31 13:48:59,319:INFO:plot_model() successfully completed......................................
2025-03-31 13:48:59,362:INFO:Initializing plot_model()
2025-03-31 13:48:59,363:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, system=True)
2025-03-31 13:48:59,364:INFO:Checking exceptions
2025-03-31 13:48:59,372:INFO:Preloading libraries
2025-03-31 13:48:59,379:INFO:Copying training dataset
2025-03-31 13:48:59,379:INFO:Plot type: feature
2025-03-31 13:48:59,380:WARNING:No coef_ found. Trying feature_importances_
2025-03-31 13:48:59,536:INFO:Visual Rendered Successfully
2025-03-31 13:48:59,598:INFO:plot_model() successfully completed......................................
2025-03-31 13:48:59,642:INFO:Initializing predict_model()
2025-03-31 13:48:59,643:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x701a53190160>)
2025-03-31 13:48:59,643:INFO:Checking exceptions
2025-03-31 13:48:59,643:INFO:Preloading libraries
2025-03-31 13:48:59,722:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-31 13:48:59,869:INFO:Initializing predict_model()
2025-03-31 13:48:59,870:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x701a53190820>)
2025-03-31 13:48:59,870:INFO:Checking exceptions
2025-03-31 13:48:59,870:INFO:Preloading libraries
2025-03-31 13:48:59,875:INFO:Set up data.
2025-03-31 13:48:59,881:INFO:Set up index.
2025-03-31 13:48:59,977:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-03-31 13:51:22,960:INFO:Initializing compare_models()
2025-03-31 13:51:22,960:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-31 13:51:22,960:INFO:Checking exceptions
2025-03-31 13:51:22,965:INFO:Preparing display monitor
2025-03-31 13:51:23,008:INFO:Initializing Linear Regression
2025-03-31 13:51:23,009:INFO:Total runtime is 7.796287536621094e-06 minutes
2025-03-31 13:51:23,017:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:23,018:INFO:Initializing create_model()
2025-03-31 13:51:23,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:23,018:INFO:Checking exceptions
2025-03-31 13:51:23,018:INFO:Importing libraries
2025-03-31 13:51:23,018:INFO:Copying training dataset
2025-03-31 13:51:23,027:INFO:Defining folds
2025-03-31 13:51:23,027:INFO:Declaring metric variables
2025-03-31 13:51:23,034:INFO:Importing untrained model
2025-03-31 13:51:23,040:INFO:Linear Regression Imported successfully
2025-03-31 13:51:23,072:INFO:Starting cross validation
2025-03-31 13:51:23,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:23,185:INFO:Calculating mean and std
2025-03-31 13:51:23,185:INFO:Creating metrics dataframe
2025-03-31 13:51:23,186:INFO:Uploading results into container
2025-03-31 13:51:23,186:INFO:Uploading model into container now
2025-03-31 13:51:23,186:INFO:_master_model_container: 19
2025-03-31 13:51:23,186:INFO:_display_container: 5
2025-03-31 13:51:23,186:INFO:LinearRegression(n_jobs=-1)
2025-03-31 13:51:23,186:INFO:create_model() successfully completed......................................
2025-03-31 13:51:23,269:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:23,270:INFO:Creating metrics dataframe
2025-03-31 13:51:23,285:INFO:Initializing Lasso Regression
2025-03-31 13:51:23,285:INFO:Total runtime is 0.0046213030815124515 minutes
2025-03-31 13:51:23,293:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:23,294:INFO:Initializing create_model()
2025-03-31 13:51:23,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:23,294:INFO:Checking exceptions
2025-03-31 13:51:23,294:INFO:Importing libraries
2025-03-31 13:51:23,294:INFO:Copying training dataset
2025-03-31 13:51:23,303:INFO:Defining folds
2025-03-31 13:51:23,303:INFO:Declaring metric variables
2025-03-31 13:51:23,311:INFO:Importing untrained model
2025-03-31 13:51:23,320:INFO:Lasso Regression Imported successfully
2025-03-31 13:51:23,338:INFO:Starting cross validation
2025-03-31 13:51:23,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:23,639:INFO:Calculating mean and std
2025-03-31 13:51:23,640:INFO:Creating metrics dataframe
2025-03-31 13:51:23,641:INFO:Uploading results into container
2025-03-31 13:51:23,642:INFO:Uploading model into container now
2025-03-31 13:51:23,642:INFO:_master_model_container: 20
2025-03-31 13:51:23,642:INFO:_display_container: 5
2025-03-31 13:51:23,642:INFO:Lasso(random_state=123)
2025-03-31 13:51:23,642:INFO:create_model() successfully completed......................................
2025-03-31 13:51:23,771:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:23,771:INFO:Creating metrics dataframe
2025-03-31 13:51:23,774:INFO:Initializing Ridge Regression
2025-03-31 13:51:23,774:INFO:Total runtime is 0.01277063290278117 minutes
2025-03-31 13:51:23,776:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:23,776:INFO:Initializing create_model()
2025-03-31 13:51:23,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:23,776:INFO:Checking exceptions
2025-03-31 13:51:23,776:INFO:Importing libraries
2025-03-31 13:51:23,776:INFO:Copying training dataset
2025-03-31 13:51:23,779:INFO:Defining folds
2025-03-31 13:51:23,779:INFO:Declaring metric variables
2025-03-31 13:51:23,780:INFO:Importing untrained model
2025-03-31 13:51:23,782:INFO:Ridge Regression Imported successfully
2025-03-31 13:51:23,784:INFO:Starting cross validation
2025-03-31 13:51:23,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:23,954:INFO:Calculating mean and std
2025-03-31 13:51:23,955:INFO:Creating metrics dataframe
2025-03-31 13:51:23,956:INFO:Uploading results into container
2025-03-31 13:51:23,956:INFO:Uploading model into container now
2025-03-31 13:51:23,957:INFO:_master_model_container: 21
2025-03-31 13:51:23,957:INFO:_display_container: 5
2025-03-31 13:51:23,957:INFO:Ridge(random_state=123)
2025-03-31 13:51:23,957:INFO:create_model() successfully completed......................................
2025-03-31 13:51:24,005:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:24,005:INFO:Creating metrics dataframe
2025-03-31 13:51:24,009:INFO:Initializing Elastic Net
2025-03-31 13:51:24,009:INFO:Total runtime is 0.016680383682250978 minutes
2025-03-31 13:51:24,010:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:24,011:INFO:Initializing create_model()
2025-03-31 13:51:24,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:24,011:INFO:Checking exceptions
2025-03-31 13:51:24,011:INFO:Importing libraries
2025-03-31 13:51:24,011:INFO:Copying training dataset
2025-03-31 13:51:24,014:INFO:Defining folds
2025-03-31 13:51:24,014:INFO:Declaring metric variables
2025-03-31 13:51:24,015:INFO:Importing untrained model
2025-03-31 13:51:24,017:INFO:Elastic Net Imported successfully
2025-03-31 13:51:24,020:INFO:Starting cross validation
2025-03-31 13:51:24,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:24,213:INFO:Calculating mean and std
2025-03-31 13:51:24,214:INFO:Creating metrics dataframe
2025-03-31 13:51:24,216:INFO:Uploading results into container
2025-03-31 13:51:24,216:INFO:Uploading model into container now
2025-03-31 13:51:24,216:INFO:_master_model_container: 22
2025-03-31 13:51:24,217:INFO:_display_container: 5
2025-03-31 13:51:24,217:INFO:ElasticNet(random_state=123)
2025-03-31 13:51:24,217:INFO:create_model() successfully completed......................................
2025-03-31 13:51:24,313:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:24,313:INFO:Creating metrics dataframe
2025-03-31 13:51:24,318:INFO:Initializing Least Angle Regression
2025-03-31 13:51:24,318:INFO:Total runtime is 0.021829358736673993 minutes
2025-03-31 13:51:24,320:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:24,320:INFO:Initializing create_model()
2025-03-31 13:51:24,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:24,320:INFO:Checking exceptions
2025-03-31 13:51:24,320:INFO:Importing libraries
2025-03-31 13:51:24,320:INFO:Copying training dataset
2025-03-31 13:51:24,323:INFO:Defining folds
2025-03-31 13:51:24,323:INFO:Declaring metric variables
2025-03-31 13:51:24,325:INFO:Importing untrained model
2025-03-31 13:51:24,326:INFO:Least Angle Regression Imported successfully
2025-03-31 13:51:24,329:INFO:Starting cross validation
2025-03-31 13:51:24,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:24,681:INFO:Calculating mean and std
2025-03-31 13:51:24,684:INFO:Creating metrics dataframe
2025-03-31 13:51:24,691:INFO:Uploading results into container
2025-03-31 13:51:24,692:INFO:Uploading model into container now
2025-03-31 13:51:24,693:INFO:_master_model_container: 23
2025-03-31 13:51:24,693:INFO:_display_container: 5
2025-03-31 13:51:24,694:INFO:Lars(random_state=123)
2025-03-31 13:51:24,695:INFO:create_model() successfully completed......................................
2025-03-31 13:51:24,766:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:24,767:INFO:Creating metrics dataframe
2025-03-31 13:51:24,770:INFO:Initializing Lasso Least Angle Regression
2025-03-31 13:51:24,770:INFO:Total runtime is 0.02937030792236328 minutes
2025-03-31 13:51:24,772:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:24,772:INFO:Initializing create_model()
2025-03-31 13:51:24,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:24,772:INFO:Checking exceptions
2025-03-31 13:51:24,772:INFO:Importing libraries
2025-03-31 13:51:24,772:INFO:Copying training dataset
2025-03-31 13:51:24,774:INFO:Defining folds
2025-03-31 13:51:24,774:INFO:Declaring metric variables
2025-03-31 13:51:24,776:INFO:Importing untrained model
2025-03-31 13:51:24,777:INFO:Lasso Least Angle Regression Imported successfully
2025-03-31 13:51:24,782:INFO:Starting cross validation
2025-03-31 13:51:24,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:25,067:INFO:Calculating mean and std
2025-03-31 13:51:25,068:INFO:Creating metrics dataframe
2025-03-31 13:51:25,070:INFO:Uploading results into container
2025-03-31 13:51:25,070:INFO:Uploading model into container now
2025-03-31 13:51:25,071:INFO:_master_model_container: 24
2025-03-31 13:51:25,071:INFO:_display_container: 5
2025-03-31 13:51:25,071:INFO:LassoLars(random_state=123)
2025-03-31 13:51:25,071:INFO:create_model() successfully completed......................................
2025-03-31 13:51:25,160:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:25,161:INFO:Creating metrics dataframe
2025-03-31 13:51:25,180:INFO:Initializing Orthogonal Matching Pursuit
2025-03-31 13:51:25,181:INFO:Total runtime is 0.03620741764704386 minutes
2025-03-31 13:51:25,188:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:25,189:INFO:Initializing create_model()
2025-03-31 13:51:25,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:25,189:INFO:Checking exceptions
2025-03-31 13:51:25,189:INFO:Importing libraries
2025-03-31 13:51:25,189:INFO:Copying training dataset
2025-03-31 13:51:25,199:INFO:Defining folds
2025-03-31 13:51:25,200:INFO:Declaring metric variables
2025-03-31 13:51:25,207:INFO:Importing untrained model
2025-03-31 13:51:25,214:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-31 13:51:25,232:INFO:Starting cross validation
2025-03-31 13:51:25,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:25,617:INFO:Calculating mean and std
2025-03-31 13:51:25,619:INFO:Creating metrics dataframe
2025-03-31 13:51:25,623:INFO:Uploading results into container
2025-03-31 13:51:25,624:INFO:Uploading model into container now
2025-03-31 13:51:25,625:INFO:_master_model_container: 25
2025-03-31 13:51:25,625:INFO:_display_container: 5
2025-03-31 13:51:25,625:INFO:OrthogonalMatchingPursuit()
2025-03-31 13:51:25,626:INFO:create_model() successfully completed......................................
2025-03-31 13:51:25,727:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:25,727:INFO:Creating metrics dataframe
2025-03-31 13:51:25,744:INFO:Initializing Bayesian Ridge
2025-03-31 13:51:25,744:INFO:Total runtime is 0.04559756517410278 minutes
2025-03-31 13:51:25,750:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:25,750:INFO:Initializing create_model()
2025-03-31 13:51:25,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:25,751:INFO:Checking exceptions
2025-03-31 13:51:25,751:INFO:Importing libraries
2025-03-31 13:51:25,751:INFO:Copying training dataset
2025-03-31 13:51:25,763:INFO:Defining folds
2025-03-31 13:51:25,764:INFO:Declaring metric variables
2025-03-31 13:51:25,771:INFO:Importing untrained model
2025-03-31 13:51:25,779:INFO:Bayesian Ridge Imported successfully
2025-03-31 13:51:25,795:INFO:Starting cross validation
2025-03-31 13:51:25,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:25,973:INFO:Calculating mean and std
2025-03-31 13:51:25,974:INFO:Creating metrics dataframe
2025-03-31 13:51:25,975:INFO:Uploading results into container
2025-03-31 13:51:25,975:INFO:Uploading model into container now
2025-03-31 13:51:25,975:INFO:_master_model_container: 26
2025-03-31 13:51:25,975:INFO:_display_container: 5
2025-03-31 13:51:25,976:INFO:BayesianRidge()
2025-03-31 13:51:25,976:INFO:create_model() successfully completed......................................
2025-03-31 13:51:26,032:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:26,032:INFO:Creating metrics dataframe
2025-03-31 13:51:26,040:INFO:Initializing Passive Aggressive Regressor
2025-03-31 13:51:26,040:INFO:Total runtime is 0.05053009986877441 minutes
2025-03-31 13:51:26,043:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:26,043:INFO:Initializing create_model()
2025-03-31 13:51:26,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:26,043:INFO:Checking exceptions
2025-03-31 13:51:26,043:INFO:Importing libraries
2025-03-31 13:51:26,044:INFO:Copying training dataset
2025-03-31 13:51:26,048:INFO:Defining folds
2025-03-31 13:51:26,048:INFO:Declaring metric variables
2025-03-31 13:51:26,052:INFO:Importing untrained model
2025-03-31 13:51:26,054:INFO:Passive Aggressive Regressor Imported successfully
2025-03-31 13:51:26,063:INFO:Starting cross validation
2025-03-31 13:51:26,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:26,345:INFO:Calculating mean and std
2025-03-31 13:51:26,346:INFO:Creating metrics dataframe
2025-03-31 13:51:26,348:INFO:Uploading results into container
2025-03-31 13:51:26,348:INFO:Uploading model into container now
2025-03-31 13:51:26,348:INFO:_master_model_container: 27
2025-03-31 13:51:26,348:INFO:_display_container: 5
2025-03-31 13:51:26,349:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-31 13:51:26,349:INFO:create_model() successfully completed......................................
2025-03-31 13:51:26,414:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:26,414:INFO:Creating metrics dataframe
2025-03-31 13:51:26,424:INFO:Initializing Huber Regressor
2025-03-31 13:51:26,424:INFO:Total runtime is 0.0569385011990865 minutes
2025-03-31 13:51:26,429:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:26,429:INFO:Initializing create_model()
2025-03-31 13:51:26,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:26,429:INFO:Checking exceptions
2025-03-31 13:51:26,429:INFO:Importing libraries
2025-03-31 13:51:26,429:INFO:Copying training dataset
2025-03-31 13:51:26,437:INFO:Defining folds
2025-03-31 13:51:26,437:INFO:Declaring metric variables
2025-03-31 13:51:26,444:INFO:Importing untrained model
2025-03-31 13:51:26,452:INFO:Huber Regressor Imported successfully
2025-03-31 13:51:26,468:INFO:Starting cross validation
2025-03-31 13:51:26,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:27,756:INFO:Calculating mean and std
2025-03-31 13:51:27,756:INFO:Creating metrics dataframe
2025-03-31 13:51:27,758:INFO:Uploading results into container
2025-03-31 13:51:27,758:INFO:Uploading model into container now
2025-03-31 13:51:27,759:INFO:_master_model_container: 28
2025-03-31 13:51:27,759:INFO:_display_container: 5
2025-03-31 13:51:27,759:INFO:HuberRegressor()
2025-03-31 13:51:27,759:INFO:create_model() successfully completed......................................
2025-03-31 13:51:27,825:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:27,825:INFO:Creating metrics dataframe
2025-03-31 13:51:27,832:INFO:Initializing K Neighbors Regressor
2025-03-31 13:51:27,833:INFO:Total runtime is 0.0804079532623291 minutes
2025-03-31 13:51:27,835:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:27,835:INFO:Initializing create_model()
2025-03-31 13:51:27,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:27,836:INFO:Checking exceptions
2025-03-31 13:51:27,836:INFO:Importing libraries
2025-03-31 13:51:27,836:INFO:Copying training dataset
2025-03-31 13:51:27,840:INFO:Defining folds
2025-03-31 13:51:27,840:INFO:Declaring metric variables
2025-03-31 13:51:27,843:INFO:Importing untrained model
2025-03-31 13:51:27,846:INFO:K Neighbors Regressor Imported successfully
2025-03-31 13:51:27,852:INFO:Starting cross validation
2025-03-31 13:51:27,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:28,620:INFO:Calculating mean and std
2025-03-31 13:51:28,623:INFO:Creating metrics dataframe
2025-03-31 13:51:28,626:INFO:Uploading results into container
2025-03-31 13:51:28,628:INFO:Uploading model into container now
2025-03-31 13:51:28,629:INFO:_master_model_container: 29
2025-03-31 13:51:28,629:INFO:_display_container: 5
2025-03-31 13:51:28,630:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-31 13:51:28,630:INFO:create_model() successfully completed......................................
2025-03-31 13:51:28,736:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:28,737:INFO:Creating metrics dataframe
2025-03-31 13:51:28,751:INFO:Initializing Decision Tree Regressor
2025-03-31 13:51:28,751:INFO:Total runtime is 0.09571397304534911 minutes
2025-03-31 13:51:28,756:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:28,756:INFO:Initializing create_model()
2025-03-31 13:51:28,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:28,756:INFO:Checking exceptions
2025-03-31 13:51:28,756:INFO:Importing libraries
2025-03-31 13:51:28,756:INFO:Copying training dataset
2025-03-31 13:51:28,762:INFO:Defining folds
2025-03-31 13:51:28,762:INFO:Declaring metric variables
2025-03-31 13:51:28,765:INFO:Importing untrained model
2025-03-31 13:51:28,768:INFO:Decision Tree Regressor Imported successfully
2025-03-31 13:51:28,772:INFO:Starting cross validation
2025-03-31 13:51:28,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:29,435:INFO:Calculating mean and std
2025-03-31 13:51:29,436:INFO:Creating metrics dataframe
2025-03-31 13:51:29,437:INFO:Uploading results into container
2025-03-31 13:51:29,437:INFO:Uploading model into container now
2025-03-31 13:51:29,437:INFO:_master_model_container: 30
2025-03-31 13:51:29,437:INFO:_display_container: 5
2025-03-31 13:51:29,437:INFO:DecisionTreeRegressor(random_state=123)
2025-03-31 13:51:29,437:INFO:create_model() successfully completed......................................
2025-03-31 13:51:29,485:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:29,485:INFO:Creating metrics dataframe
2025-03-31 13:51:29,489:INFO:Initializing Random Forest Regressor
2025-03-31 13:51:29,489:INFO:Total runtime is 0.10801539023717244 minutes
2025-03-31 13:51:29,491:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:29,491:INFO:Initializing create_model()
2025-03-31 13:51:29,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:29,491:INFO:Checking exceptions
2025-03-31 13:51:29,491:INFO:Importing libraries
2025-03-31 13:51:29,491:INFO:Copying training dataset
2025-03-31 13:51:29,493:INFO:Defining folds
2025-03-31 13:51:29,493:INFO:Declaring metric variables
2025-03-31 13:51:29,494:INFO:Importing untrained model
2025-03-31 13:51:29,496:INFO:Random Forest Regressor Imported successfully
2025-03-31 13:51:29,498:INFO:Starting cross validation
2025-03-31 13:51:29,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:32,816:INFO:Calculating mean and std
2025-03-31 13:51:32,818:INFO:Creating metrics dataframe
2025-03-31 13:51:32,822:INFO:Uploading results into container
2025-03-31 13:51:32,823:INFO:Uploading model into container now
2025-03-31 13:51:32,824:INFO:_master_model_container: 31
2025-03-31 13:51:32,824:INFO:_display_container: 5
2025-03-31 13:51:32,824:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:51:32,825:INFO:create_model() successfully completed......................................
2025-03-31 13:51:32,943:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:32,943:INFO:Creating metrics dataframe
2025-03-31 13:51:32,969:INFO:Initializing Extra Trees Regressor
2025-03-31 13:51:32,970:INFO:Total runtime is 0.16602547566095988 minutes
2025-03-31 13:51:32,981:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:32,982:INFO:Initializing create_model()
2025-03-31 13:51:32,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:32,983:INFO:Checking exceptions
2025-03-31 13:51:32,983:INFO:Importing libraries
2025-03-31 13:51:32,983:INFO:Copying training dataset
2025-03-31 13:51:32,996:INFO:Defining folds
2025-03-31 13:51:32,997:INFO:Declaring metric variables
2025-03-31 13:51:33,005:INFO:Importing untrained model
2025-03-31 13:51:33,014:INFO:Extra Trees Regressor Imported successfully
2025-03-31 13:51:33,029:INFO:Starting cross validation
2025-03-31 13:51:33,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:35,806:INFO:Calculating mean and std
2025-03-31 13:51:35,808:INFO:Creating metrics dataframe
2025-03-31 13:51:35,812:INFO:Uploading results into container
2025-03-31 13:51:35,813:INFO:Uploading model into container now
2025-03-31 13:51:35,814:INFO:_master_model_container: 32
2025-03-31 13:51:35,814:INFO:_display_container: 5
2025-03-31 13:51:35,814:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:51:35,815:INFO:create_model() successfully completed......................................
2025-03-31 13:51:35,923:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:35,924:INFO:Creating metrics dataframe
2025-03-31 13:51:35,951:INFO:Initializing AdaBoost Regressor
2025-03-31 13:51:35,951:INFO:Total runtime is 0.2157197952270508 minutes
2025-03-31 13:51:35,961:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:35,962:INFO:Initializing create_model()
2025-03-31 13:51:35,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:35,962:INFO:Checking exceptions
2025-03-31 13:51:35,962:INFO:Importing libraries
2025-03-31 13:51:35,962:INFO:Copying training dataset
2025-03-31 13:51:35,972:INFO:Defining folds
2025-03-31 13:51:35,972:INFO:Declaring metric variables
2025-03-31 13:51:35,979:INFO:Importing untrained model
2025-03-31 13:51:35,985:INFO:AdaBoost Regressor Imported successfully
2025-03-31 13:51:36,000:INFO:Starting cross validation
2025-03-31 13:51:36,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:39,236:INFO:Calculating mean and std
2025-03-31 13:51:39,238:INFO:Creating metrics dataframe
2025-03-31 13:51:39,242:INFO:Uploading results into container
2025-03-31 13:51:39,243:INFO:Uploading model into container now
2025-03-31 13:51:39,243:INFO:_master_model_container: 33
2025-03-31 13:51:39,243:INFO:_display_container: 5
2025-03-31 13:51:39,244:INFO:AdaBoostRegressor(random_state=123)
2025-03-31 13:51:39,244:INFO:create_model() successfully completed......................................
2025-03-31 13:51:39,306:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:39,307:INFO:Creating metrics dataframe
2025-03-31 13:51:39,327:INFO:Initializing Gradient Boosting Regressor
2025-03-31 13:51:39,327:INFO:Total runtime is 0.2719790856043498 minutes
2025-03-31 13:51:39,334:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:39,334:INFO:Initializing create_model()
2025-03-31 13:51:39,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:39,334:INFO:Checking exceptions
2025-03-31 13:51:39,334:INFO:Importing libraries
2025-03-31 13:51:39,334:INFO:Copying training dataset
2025-03-31 13:51:39,344:INFO:Defining folds
2025-03-31 13:51:39,344:INFO:Declaring metric variables
2025-03-31 13:51:39,351:INFO:Importing untrained model
2025-03-31 13:51:39,357:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:51:39,368:INFO:Starting cross validation
2025-03-31 13:51:39,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:57,097:INFO:Calculating mean and std
2025-03-31 13:51:57,098:INFO:Creating metrics dataframe
2025-03-31 13:51:57,099:INFO:Uploading results into container
2025-03-31 13:51:57,099:INFO:Uploading model into container now
2025-03-31 13:51:57,099:INFO:_master_model_container: 34
2025-03-31 13:51:57,099:INFO:_display_container: 5
2025-03-31 13:51:57,099:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:51:57,099:INFO:create_model() successfully completed......................................
2025-03-31 13:51:57,141:INFO:SubProcess create_model() end ==================================
2025-03-31 13:51:57,141:INFO:Creating metrics dataframe
2025-03-31 13:51:57,148:INFO:Initializing Light Gradient Boosting Machine
2025-03-31 13:51:57,148:INFO:Total runtime is 0.5689921418825785 minutes
2025-03-31 13:51:57,151:INFO:SubProcess create_model() called ==================================
2025-03-31 13:51:57,151:INFO:Initializing create_model()
2025-03-31 13:51:57,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:51:57,151:INFO:Checking exceptions
2025-03-31 13:51:57,151:INFO:Importing libraries
2025-03-31 13:51:57,151:INFO:Copying training dataset
2025-03-31 13:51:57,155:INFO:Defining folds
2025-03-31 13:51:57,155:INFO:Declaring metric variables
2025-03-31 13:51:57,157:INFO:Importing untrained model
2025-03-31 13:51:57,158:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-31 13:51:57,161:INFO:Starting cross validation
2025-03-31 13:51:57,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:51:57,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029975 seconds.
2025-03-31 13:51:57,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:51:57,224:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:51:57,224:INFO:[LightGBM] [Info] Number of data points in the train set: 16029, number of used features: 2
2025-03-31 13:51:57,229:INFO:[LightGBM] [Info] Start training from score 6.880591
2025-03-31 13:52:07,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028804 seconds.
2025-03-31 13:52:07,971:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:07,971:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:07,979:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:08,010:INFO:[LightGBM] [Info] Start training from score 6.875686
2025-03-31 13:52:10,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038984 seconds.
2025-03-31 13:52:10,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-31 13:52:10,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-31 13:52:10,008:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:10,016:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:10,032:INFO:[LightGBM] [Info] Start training from score 6.876981
2025-03-31 13:52:12,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2025-03-31 13:52:12,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:12,392:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:12,392:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:12,392:INFO:[LightGBM] [Info] Start training from score 6.877885
2025-03-31 13:52:14,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043399 seconds.
2025-03-31 13:52:14,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:14,757:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:14,761:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:14,773:INFO:[LightGBM] [Info] Start training from score 6.877402
2025-03-31 13:52:17,896:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041780 seconds.
2025-03-31 13:52:17,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:17,897:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:17,901:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:17,915:INFO:[LightGBM] [Info] Start training from score 6.867280
2025-03-31 13:52:23,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036982 seconds.
2025-03-31 13:52:23,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-31 13:52:23,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-31 13:52:23,259:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:23,264:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:23,279:INFO:[LightGBM] [Info] Start training from score 6.877480
2025-03-31 13:52:31,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042803 seconds.
2025-03-31 13:52:31,862:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:31,862:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:31,870:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:31,884:INFO:[LightGBM] [Info] Start training from score 6.886494
2025-03-31 13:52:38,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043146 seconds.
2025-03-31 13:52:38,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:38,034:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:38,044:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:38,056:INFO:[LightGBM] [Info] Start training from score 6.883016
2025-03-31 13:52:39,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030786 seconds.
2025-03-31 13:52:39,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-31 13:52:39,097:INFO:[LightGBM] [Info] Total Bins 510
2025-03-31 13:52:39,110:INFO:[LightGBM] [Info] Number of data points in the train set: 16030, number of used features: 2
2025-03-31 13:52:39,134:INFO:[LightGBM] [Info] Start training from score 6.879117
2025-03-31 13:52:41,613:INFO:Calculating mean and std
2025-03-31 13:52:41,614:INFO:Creating metrics dataframe
2025-03-31 13:52:41,616:INFO:Uploading results into container
2025-03-31 13:52:41,616:INFO:Uploading model into container now
2025-03-31 13:52:41,616:INFO:_master_model_container: 35
2025-03-31 13:52:41,617:INFO:_display_container: 5
2025-03-31 13:52:41,617:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-31 13:52:41,617:INFO:create_model() successfully completed......................................
2025-03-31 13:52:41,670:INFO:SubProcess create_model() end ==================================
2025-03-31 13:52:41,671:INFO:Creating metrics dataframe
2025-03-31 13:52:41,678:INFO:Initializing Dummy Regressor
2025-03-31 13:52:41,679:INFO:Total runtime is 1.311174770196279 minutes
2025-03-31 13:52:41,681:INFO:SubProcess create_model() called ==================================
2025-03-31 13:52:41,682:INFO:Initializing create_model()
2025-03-31 13:52:41,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a53465040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:52:41,682:INFO:Checking exceptions
2025-03-31 13:52:41,682:INFO:Importing libraries
2025-03-31 13:52:41,682:INFO:Copying training dataset
2025-03-31 13:52:41,685:INFO:Defining folds
2025-03-31 13:52:41,685:INFO:Declaring metric variables
2025-03-31 13:52:41,686:INFO:Importing untrained model
2025-03-31 13:52:41,688:INFO:Dummy Regressor Imported successfully
2025-03-31 13:52:41,691:INFO:Starting cross validation
2025-03-31 13:52:41,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:52:41,854:INFO:Calculating mean and std
2025-03-31 13:52:41,855:INFO:Creating metrics dataframe
2025-03-31 13:52:41,857:INFO:Uploading results into container
2025-03-31 13:52:41,857:INFO:Uploading model into container now
2025-03-31 13:52:41,858:INFO:_master_model_container: 36
2025-03-31 13:52:41,858:INFO:_display_container: 5
2025-03-31 13:52:41,858:INFO:DummyRegressor()
2025-03-31 13:52:41,858:INFO:create_model() successfully completed......................................
2025-03-31 13:52:41,905:INFO:SubProcess create_model() end ==================================
2025-03-31 13:52:41,906:INFO:Creating metrics dataframe
2025-03-31 13:52:41,910:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-31 13:52:41,914:INFO:Initializing create_model()
2025-03-31 13:52:41,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:52:41,914:INFO:Checking exceptions
2025-03-31 13:52:41,915:INFO:Importing libraries
2025-03-31 13:52:41,915:INFO:Copying training dataset
2025-03-31 13:52:41,918:INFO:Defining folds
2025-03-31 13:52:41,918:INFO:Declaring metric variables
2025-03-31 13:52:41,918:INFO:Importing untrained model
2025-03-31 13:52:41,918:INFO:Declaring custom model
2025-03-31 13:52:41,918:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:52:41,919:INFO:Cross validation set to False
2025-03-31 13:52:41,919:INFO:Fitting Model
2025-03-31 13:52:44,287:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:52:44,287:INFO:create_model() successfully completed......................................
2025-03-31 13:52:44,446:INFO:_master_model_container: 36
2025-03-31 13:52:44,446:INFO:_display_container: 5
2025-03-31 13:52:44,447:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:52:44,447:INFO:compare_models() successfully completed......................................
2025-03-31 13:52:44,448:INFO:Initializing tune_model()
2025-03-31 13:52:44,448:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>)
2025-03-31 13:52:44,448:INFO:Checking exceptions
2025-03-31 13:52:44,480:INFO:Copying training dataset
2025-03-31 13:52:44,488:INFO:Checking base model
2025-03-31 13:52:44,488:INFO:Base model : Gradient Boosting Regressor
2025-03-31 13:52:44,495:INFO:Declaring metric variables
2025-03-31 13:52:44,502:INFO:Defining Hyperparameters
2025-03-31 13:52:44,592:INFO:Tuning with n_jobs=-1
2025-03-31 13:52:44,592:INFO:Initializing RandomizedSearchCV
2025-03-31 13:53:17,050:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.15}
2025-03-31 13:53:17,050:INFO:Hyperparameter search completed
2025-03-31 13:53:17,050:INFO:SubProcess create_model() called ==================================
2025-03-31 13:53:17,051:INFO:Initializing create_model()
2025-03-31 13:53:17,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701a535a8c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 260, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_features': 1.0, 'max_depth': 9, 'learning_rate': 0.15})
2025-03-31 13:53:17,051:INFO:Checking exceptions
2025-03-31 13:53:17,051:INFO:Importing libraries
2025-03-31 13:53:17,051:INFO:Copying training dataset
2025-03-31 13:53:17,055:INFO:Defining folds
2025-03-31 13:53:17,055:INFO:Declaring metric variables
2025-03-31 13:53:17,057:INFO:Importing untrained model
2025-03-31 13:53:17,058:INFO:Declaring custom model
2025-03-31 13:53:17,060:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:53:17,064:INFO:Starting cross validation
2025-03-31 13:53:17,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:53:32,631:INFO:Calculating mean and std
2025-03-31 13:53:32,632:INFO:Creating metrics dataframe
2025-03-31 13:53:32,634:INFO:Finalizing model
2025-03-31 13:53:35,246:INFO:Uploading results into container
2025-03-31 13:53:35,247:INFO:Uploading model into container now
2025-03-31 13:53:35,247:INFO:_master_model_container: 37
2025-03-31 13:53:35,247:INFO:_display_container: 6
2025-03-31 13:53:35,248:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7)
2025-03-31 13:53:35,248:INFO:create_model() successfully completed......................................
2025-03-31 13:53:35,332:INFO:SubProcess create_model() end ==================================
2025-03-31 13:53:35,332:INFO:choose_better activated
2025-03-31 13:53:35,334:INFO:SubProcess create_model() called ==================================
2025-03-31 13:53:35,334:INFO:Initializing create_model()
2025-03-31 13:53:35,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:53:35,334:INFO:Checking exceptions
2025-03-31 13:53:35,335:INFO:Importing libraries
2025-03-31 13:53:35,336:INFO:Copying training dataset
2025-03-31 13:53:35,338:INFO:Defining folds
2025-03-31 13:53:35,338:INFO:Declaring metric variables
2025-03-31 13:53:35,338:INFO:Importing untrained model
2025-03-31 13:53:35,338:INFO:Declaring custom model
2025-03-31 13:53:35,339:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:53:35,339:INFO:Starting cross validation
2025-03-31 13:53:35,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-03-31 13:53:54,358:INFO:Calculating mean and std
2025-03-31 13:53:54,359:INFO:Creating metrics dataframe
2025-03-31 13:53:54,362:INFO:Finalizing model
2025-03-31 13:53:55,740:INFO:Uploading results into container
2025-03-31 13:53:55,741:INFO:Uploading model into container now
2025-03-31 13:53:55,741:INFO:_master_model_container: 38
2025-03-31 13:53:55,741:INFO:_display_container: 7
2025-03-31 13:53:55,741:INFO:GradientBoostingRegressor(random_state=123)
2025-03-31 13:53:55,741:INFO:create_model() successfully completed......................................
2025-03-31 13:53:55,781:INFO:SubProcess create_model() end ==================================
2025-03-31 13:53:55,781:INFO:GradientBoostingRegressor(random_state=123) result for RMSE is 0.1008
2025-03-31 13:53:55,782:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7) result for RMSE is 0.1001
2025-03-31 13:53:55,782:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7) is best model
2025-03-31 13:53:55,782:INFO:choose_better completed
2025-03-31 13:53:55,793:INFO:_master_model_container: 38
2025-03-31 13:53:55,793:INFO:_display_container: 6
2025-03-31 13:53:55,793:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7)
2025-03-31 13:53:55,793:INFO:tune_model() successfully completed......................................
2025-03-31 13:53:55,848:INFO:Initializing finalize_model()
2025-03-31 13:53:55,848:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-03-31 13:53:55,848:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7)
2025-03-31 13:53:55,850:INFO:Initializing create_model()
2025-03-31 13:53:55,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701a801f7c40>, estimator=GradientBoostingRegressor(learning_rate=0.15, max_depth=9, max_features=1.0,
                          min_impurity_decrease=0.2, min_samples_leaf=4,
                          min_samples_split=7, n_estimators=260,
                          random_state=123, subsample=0.7), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 13:53:55,850:INFO:Checking exceptions
2025-03-31 13:53:55,850:INFO:Importing libraries
2025-03-31 13:53:55,851:INFO:Copying training dataset
2025-03-31 13:53:55,851:INFO:Defining folds
2025-03-31 13:53:55,851:INFO:Declaring metric variables
2025-03-31 13:53:55,851:INFO:Importing untrained model
2025-03-31 13:53:55,851:INFO:Declaring custom model
2025-03-31 13:53:55,851:INFO:Gradient Boosting Regressor Imported successfully
2025-03-31 13:53:55,851:INFO:Cross validation set to False
2025-03-31 13:53:55,851:INFO:Fitting Model
2025-03-31 13:54:00,105:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15, max_depth=9,
                                           max_features=1.0,
                                           min_impurity_decrease=0.2,
                                           min_samples_leaf=4,
                                           min_samples_split=7,
                                           n_estimators=260, random_state=123,
                                           subsample=0.7))])
2025-03-31 13:54:00,105:INFO:create_model() successfully completed......................................
2025-03-31 13:54:00,161:INFO:_master_model_container: 38
2025-03-31 13:54:00,161:INFO:_display_container: 6
2025-03-31 13:54:00,164:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15, max_depth=9,
                                           max_features=1.0,
                                           min_impurity_decrease=0.2,
                                           min_samples_leaf=4,
                                           min_samples_split=7,
                                           n_estimators=260, random_state=123,
                                           subsample=0.7))])
2025-03-31 13:54:00,164:INFO:finalize_model() successfully completed......................................
2025-03-31 13:54:00,216:INFO:Initializing save_model()
2025-03-31 13:54:00,216:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15, max_depth=9,
                                           max_features=1.0,
                                           min_impurity_decrease=0.2,
                                           min_samples_leaf=4,
                                           min_samples_split=7,
                                           n_estimators=260, random_state=123,
                                           subsample=0.7))]), model_name=final_calibrated_depth_model_25, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-31 13:54:00,216:INFO:Adding model into prep_pipe
2025-03-31 13:54:00,216:WARNING:Only Model saved as it was a pipeline.
2025-03-31 13:54:00,224:INFO:final_calibrated_depth_model_25.pkl saved in current working directory
2025-03-31 13:54:00,228:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['depth'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.15, max_depth=9,
                                           max_features=1.0,
                                           min_impurity_decrease=0.2,
                                           min_samples_leaf=4,
                                           min_samples_split=7,
                                           n_estimators=260, random_state=123,
                                           subsample=0.7))])
2025-03-31 13:54:00,228:INFO:save_model() successfully completed......................................
2025-04-09 10:37:59,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:37:59,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:37:59,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:37:59,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,091:INFO:PyCaret RegressionExperiment
2025-04-09 10:38:05,091:INFO:Logging name: reg-default-name
2025-04-09 10:38:05,091:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-09 10:38:05,091:INFO:version 3.3.1
2025-04-09 10:38:05,091:INFO:Initializing setup()
2025-04-09 10:38:05,092:INFO:self.USI: 1330
2025-04-09 10:38:05,092:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'idx', 'seed', 'X', 'fold_groups_param', 'y', 'USI', 'y_train', 'html_param', 'gpu_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'memory', '_available_plots', 'transform_target_param', 'pipeline', 'X_train', 'log_plots_param', 'data', 'exp_id', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'y_test', 'target_param'}
2025-04-09 10:38:05,092:INFO:Checking environment
2025-04-09 10:38:05,092:INFO:python_version: 3.9.21
2025-04-09 10:38:05,092:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-04-09 10:38:05,092:INFO:machine: x86_64
2025-04-09 10:38:05,092:INFO:platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:38:05,092:INFO:Memory: svmem(total=33374547968, available=26427121664, percent=20.8, used=5402546176, free=18603954176, active=6858346496, inactive=5465939968, buffers=386236416, cached=8981811200, shared=1061928960, slab=1093435392)
2025-04-09 10:38:05,093:INFO:Physical Core: 24
2025-04-09 10:38:05,093:INFO:Logical Core: 32
2025-04-09 10:38:05,093:INFO:Checking libraries
2025-04-09 10:38:05,093:INFO:System:
2025-04-09 10:38:05,093:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-04-09 10:38:05,093:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-04-09 10:38:05,093:INFO:   machine: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:38:05,093:INFO:PyCaret required dependencies:
2025-04-09 10:38:05,136:INFO:                 pip: 25.0
2025-04-09 10:38:05,136:INFO:          setuptools: 75.8.0
2025-04-09 10:38:05,136:INFO:             pycaret: 3.3.1
2025-04-09 10:38:05,136:INFO:             IPython: 8.18.1
2025-04-09 10:38:05,136:INFO:          ipywidgets: 8.1.5
2025-04-09 10:38:05,136:INFO:                tqdm: 4.67.1
2025-04-09 10:38:05,136:INFO:               numpy: 1.26.4
2025-04-09 10:38:05,136:INFO:              pandas: 2.1.4
2025-04-09 10:38:05,137:INFO:              jinja2: 3.1.5
2025-04-09 10:38:05,137:INFO:               scipy: 1.11.4
2025-04-09 10:38:05,137:INFO:              joblib: 1.3.2
2025-04-09 10:38:05,137:INFO:             sklearn: 1.4.2
2025-04-09 10:38:05,137:INFO:                pyod: 2.0.3
2025-04-09 10:38:05,137:INFO:            imblearn: 0.12.4
2025-04-09 10:38:05,137:INFO:   category_encoders: 2.6.4
2025-04-09 10:38:05,137:INFO:            lightgbm: 4.6.0
2025-04-09 10:38:05,137:INFO:               numba: 0.60.0
2025-04-09 10:38:05,137:INFO:            requests: 2.32.3
2025-04-09 10:38:05,137:INFO:          matplotlib: 3.7.5
2025-04-09 10:38:05,137:INFO:          scikitplot: 0.3.7
2025-04-09 10:38:05,137:INFO:         yellowbrick: 1.5
2025-04-09 10:38:05,137:INFO:              plotly: 5.24.1
2025-04-09 10:38:05,137:INFO:    plotly-resampler: Not installed
2025-04-09 10:38:05,137:INFO:             kaleido: 0.2.1
2025-04-09 10:38:05,137:INFO:           schemdraw: 0.15
2025-04-09 10:38:05,137:INFO:         statsmodels: 0.14.4
2025-04-09 10:38:05,137:INFO:              sktime: 0.26.0
2025-04-09 10:38:05,137:INFO:               tbats: 1.1.3
2025-04-09 10:38:05,137:INFO:            pmdarima: 2.0.4
2025-04-09 10:38:05,137:INFO:              psutil: 7.0.0
2025-04-09 10:38:05,137:INFO:          markupsafe: 3.0.2
2025-04-09 10:38:05,137:INFO:             pickle5: Not installed
2025-04-09 10:38:05,137:INFO:         cloudpickle: 3.1.1
2025-04-09 10:38:05,137:INFO:         deprecation: 2.1.0
2025-04-09 10:38:05,137:INFO:              xxhash: 3.5.0
2025-04-09 10:38:05,137:INFO:           wurlitzer: 3.1.1
2025-04-09 10:38:05,137:INFO:PyCaret optional dependencies:
2025-04-09 10:38:05,160:INFO:                shap: Not installed
2025-04-09 10:38:05,160:INFO:           interpret: Not installed
2025-04-09 10:38:05,160:INFO:                umap: Not installed
2025-04-09 10:38:05,160:INFO:     ydata_profiling: Not installed
2025-04-09 10:38:05,160:INFO:  explainerdashboard: Not installed
2025-04-09 10:38:05,160:INFO:             autoviz: Not installed
2025-04-09 10:38:05,160:INFO:           fairlearn: Not installed
2025-04-09 10:38:05,160:INFO:          deepchecks: Not installed
2025-04-09 10:38:05,160:INFO:             xgboost: Not installed
2025-04-09 10:38:05,160:INFO:            catboost: Not installed
2025-04-09 10:38:05,160:INFO:              kmodes: Not installed
2025-04-09 10:38:05,160:INFO:             mlxtend: Not installed
2025-04-09 10:38:05,160:INFO:       statsforecast: Not installed
2025-04-09 10:38:05,160:INFO:        tune_sklearn: Not installed
2025-04-09 10:38:05,160:INFO:                 ray: Not installed
2025-04-09 10:38:05,160:INFO:            hyperopt: Not installed
2025-04-09 10:38:05,160:INFO:              optuna: Not installed
2025-04-09 10:38:05,160:INFO:               skopt: Not installed
2025-04-09 10:38:05,160:INFO:              mlflow: Not installed
2025-04-09 10:38:05,160:INFO:              gradio: Not installed
2025-04-09 10:38:05,160:INFO:             fastapi: Not installed
2025-04-09 10:38:05,160:INFO:             uvicorn: Not installed
2025-04-09 10:38:05,160:INFO:              m2cgen: Not installed
2025-04-09 10:38:05,160:INFO:           evidently: Not installed
2025-04-09 10:38:05,160:INFO:               fugue: Not installed
2025-04-09 10:38:05,160:INFO:           streamlit: Not installed
2025-04-09 10:38:05,160:INFO:             prophet: Not installed
2025-04-09 10:38:05,160:INFO:None
2025-04-09 10:38:05,160:INFO:Set up GPU usage.
2025-04-09 10:38:05,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,161:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-04-09 10:38:05,161:INFO:Set up data.
2025-04-09 10:38:05,172:INFO:Set up folding strategy.
2025-04-09 10:38:05,173:INFO:Set up train/test split.
2025-04-09 10:38:05,183:INFO:Set up index.
2025-04-09 10:38:05,183:INFO:Assigning column types.
2025-04-09 10:38:05,190:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-09 10:38:05,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,191:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:38:05,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,200:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:38:05,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,208:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:05,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:05,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:05,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:05,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,515:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,523:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,529:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,577:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-09 10:38:17,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,579:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,629:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,715:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-09 10:38:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,752:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:17,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:17,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:38:17,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,162:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-09 10:38:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-09 10:38:18,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:38:18,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,377:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-09 10:38:18,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,484:INFO:Preparing preprocessing pipeline...
2025-04-09 10:38:18,484:INFO:Set up simple imputation.
2025-04-09 10:38:18,486:INFO:Set up encoding of categorical features.
2025-04-09 10:38:18,486:INFO:Set up polynomial features.
2025-04-09 10:38:18,540:INFO:Finished creating preprocessing pipeline.
2025-04-09 10:38:18,551:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp', 'source_file'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('on...
                 TransformerWrapper(include=['source_file'],
                                    transformer=OneHotEncoder(cols=['source_file'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-04-09 10:38:18,551:INFO:Creating final display dataframe.
2025-04-09 10:38:18,732:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape         (155, 11)
4        Transformed data shape        (155, 190)
5   Transformed train set shape        (108, 190)
6    Transformed test set shape         (47, 190)
7              Numeric features                 8
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU              True
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              1330
2025-04-09 10:38:18,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:38:18,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:38:18,921:INFO:setup() successfully completed in 13.83s...............
2025-04-09 10:38:18,926:INFO:Initializing compare_models()
2025-04-09 10:38:18,926:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 10:38:18,926:INFO:Checking exceptions
2025-04-09 10:38:18,927:INFO:Preparing display monitor
2025-04-09 10:38:18,940:INFO:Initializing Linear Regression
2025-04-09 10:38:18,941:INFO:Total runtime is 1.9431114196777345e-06 minutes
2025-04-09 10:38:18,942:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:18,942:INFO:Initializing create_model()
2025-04-09 10:38:18,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:18,942:INFO:Checking exceptions
2025-04-09 10:38:18,942:INFO:Importing libraries
2025-04-09 10:38:18,942:INFO:Copying training dataset
2025-04-09 10:38:18,944:INFO:Defining folds
2025-04-09 10:38:18,944:INFO:Declaring metric variables
2025-04-09 10:38:18,945:INFO:Importing untrained model
2025-04-09 10:38:18,947:INFO:Linear Regression Imported successfully
2025-04-09 10:38:18,954:INFO:Starting cross validation
2025-04-09 10:38:18,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:19,864:INFO:Calculating mean and std
2025-04-09 10:38:19,865:INFO:Creating metrics dataframe
2025-04-09 10:38:19,867:INFO:Uploading results into container
2025-04-09 10:38:19,867:INFO:Uploading model into container now
2025-04-09 10:38:19,867:INFO:_master_model_container: 1
2025-04-09 10:38:19,867:INFO:_display_container: 2
2025-04-09 10:38:19,868:INFO:LinearRegression(n_jobs=-1)
2025-04-09 10:38:19,868:INFO:create_model() successfully completed......................................
2025-04-09 10:38:19,951:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:19,951:INFO:Creating metrics dataframe
2025-04-09 10:38:19,956:INFO:Initializing Lasso Regression
2025-04-09 10:38:19,956:INFO:Total runtime is 0.01692714691162109 minutes
2025-04-09 10:38:19,958:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:19,959:INFO:Initializing create_model()
2025-04-09 10:38:19,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:19,959:INFO:Checking exceptions
2025-04-09 10:38:19,959:INFO:Importing libraries
2025-04-09 10:38:19,959:INFO:Copying training dataset
2025-04-09 10:38:19,962:INFO:Defining folds
2025-04-09 10:38:19,962:INFO:Declaring metric variables
2025-04-09 10:38:19,964:INFO:Importing untrained model
2025-04-09 10:38:19,966:INFO:Lasso Regression Imported successfully
2025-04-09 10:38:19,970:INFO:Starting cross validation
2025-04-09 10:38:19,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:20,081:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.821e-02, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,192:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.623e-02, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,286:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e-02, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,379:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e-02, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,473:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-02, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,594:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.792e-02, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,688:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.844e-02, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,790:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e-02, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,891:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.870e-02, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:20,999:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:21,040:INFO:Calculating mean and std
2025-04-09 10:38:21,041:INFO:Creating metrics dataframe
2025-04-09 10:38:21,044:INFO:Uploading results into container
2025-04-09 10:38:21,047:INFO:Uploading model into container now
2025-04-09 10:38:21,048:INFO:_master_model_container: 2
2025-04-09 10:38:21,048:INFO:_display_container: 2
2025-04-09 10:38:21,048:INFO:Lasso(random_state=123)
2025-04-09 10:38:21,048:INFO:create_model() successfully completed......................................
2025-04-09 10:38:21,131:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:21,131:INFO:Creating metrics dataframe
2025-04-09 10:38:21,136:INFO:Initializing Ridge Regression
2025-04-09 10:38:21,136:INFO:Total runtime is 0.03660176992416382 minutes
2025-04-09 10:38:21,139:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:21,139:INFO:Initializing create_model()
2025-04-09 10:38:21,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:21,139:INFO:Checking exceptions
2025-04-09 10:38:21,139:INFO:Importing libraries
2025-04-09 10:38:21,139:INFO:Copying training dataset
2025-04-09 10:38:21,142:INFO:Defining folds
2025-04-09 10:38:21,142:INFO:Declaring metric variables
2025-04-09 10:38:21,144:INFO:Importing untrained model
2025-04-09 10:38:21,146:INFO:Ridge Regression Imported successfully
2025-04-09 10:38:21,150:INFO:Starting cross validation
2025-04-09 10:38:21,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:21,192:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,332:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,479:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,600:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,722:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,859:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:21,984:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:22,113:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:22,226:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:22,350:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:38:22,388:INFO:Calculating mean and std
2025-04-09 10:38:22,389:INFO:Creating metrics dataframe
2025-04-09 10:38:22,394:INFO:Uploading results into container
2025-04-09 10:38:22,394:INFO:Uploading model into container now
2025-04-09 10:38:22,394:INFO:_master_model_container: 3
2025-04-09 10:38:22,395:INFO:_display_container: 2
2025-04-09 10:38:22,395:INFO:Ridge(random_state=123)
2025-04-09 10:38:22,398:INFO:create_model() successfully completed......................................
2025-04-09 10:38:22,504:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:22,504:INFO:Creating metrics dataframe
2025-04-09 10:38:22,508:INFO:Initializing Elastic Net
2025-04-09 10:38:22,508:INFO:Total runtime is 0.05946309169133504 minutes
2025-04-09 10:38:22,510:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:22,510:INFO:Initializing create_model()
2025-04-09 10:38:22,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:22,510:INFO:Checking exceptions
2025-04-09 10:38:22,510:INFO:Importing libraries
2025-04-09 10:38:22,510:INFO:Copying training dataset
2025-04-09 10:38:22,513:INFO:Defining folds
2025-04-09 10:38:22,513:INFO:Declaring metric variables
2025-04-09 10:38:22,515:INFO:Importing untrained model
2025-04-09 10:38:22,516:INFO:Elastic Net Imported successfully
2025-04-09 10:38:22,519:INFO:Starting cross validation
2025-04-09 10:38:22,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:22,560:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e-02, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:22,682:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e-02, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:22,837:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e-02, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:22,975:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e-02, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,083:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e-02, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,189:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e-02, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,293:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e-02, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,392:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e-02, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,493:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e-02, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,590:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:38:23,621:INFO:Calculating mean and std
2025-04-09 10:38:23,623:INFO:Creating metrics dataframe
2025-04-09 10:38:23,625:INFO:Uploading results into container
2025-04-09 10:38:23,625:INFO:Uploading model into container now
2025-04-09 10:38:23,626:INFO:_master_model_container: 4
2025-04-09 10:38:23,626:INFO:_display_container: 2
2025-04-09 10:38:23,626:INFO:ElasticNet(random_state=123)
2025-04-09 10:38:23,627:INFO:create_model() successfully completed......................................
2025-04-09 10:38:23,698:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:23,698:INFO:Creating metrics dataframe
2025-04-09 10:38:23,705:INFO:Initializing Least Angle Regression
2025-04-09 10:38:23,706:INFO:Total runtime is 0.07942006190617878 minutes
2025-04-09 10:38:23,709:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:23,709:INFO:Initializing create_model()
2025-04-09 10:38:23,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:23,709:INFO:Checking exceptions
2025-04-09 10:38:23,709:INFO:Importing libraries
2025-04-09 10:38:23,709:INFO:Copying training dataset
2025-04-09 10:38:23,712:INFO:Defining folds
2025-04-09 10:38:23,712:INFO:Declaring metric variables
2025-04-09 10:38:23,715:INFO:Importing untrained model
2025-04-09 10:38:23,718:INFO:Least Angle Regression Imported successfully
2025-04-09 10:38:23,722:INFO:Starting cross validation
2025-04-09 10:38:23,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:25,017:INFO:Calculating mean and std
2025-04-09 10:38:25,019:INFO:Creating metrics dataframe
2025-04-09 10:38:25,021:INFO:Uploading results into container
2025-04-09 10:38:25,022:INFO:Uploading model into container now
2025-04-09 10:38:25,022:INFO:_master_model_container: 5
2025-04-09 10:38:25,022:INFO:_display_container: 2
2025-04-09 10:38:25,022:INFO:Lars(random_state=123)
2025-04-09 10:38:25,022:INFO:create_model() successfully completed......................................
2025-04-09 10:38:25,092:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:25,092:INFO:Creating metrics dataframe
2025-04-09 10:38:25,101:INFO:Initializing Lasso Least Angle Regression
2025-04-09 10:38:25,101:INFO:Total runtime is 0.10268059571584065 minutes
2025-04-09 10:38:25,104:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:25,105:INFO:Initializing create_model()
2025-04-09 10:38:25,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:25,105:INFO:Checking exceptions
2025-04-09 10:38:25,105:INFO:Importing libraries
2025-04-09 10:38:25,105:INFO:Copying training dataset
2025-04-09 10:38:25,108:INFO:Defining folds
2025-04-09 10:38:25,108:INFO:Declaring metric variables
2025-04-09 10:38:25,111:INFO:Importing untrained model
2025-04-09 10:38:25,113:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 10:38:25,118:INFO:Starting cross validation
2025-04-09 10:38:25,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:26,102:INFO:Calculating mean and std
2025-04-09 10:38:26,103:INFO:Creating metrics dataframe
2025-04-09 10:38:26,106:INFO:Uploading results into container
2025-04-09 10:38:26,107:INFO:Uploading model into container now
2025-04-09 10:38:26,107:INFO:_master_model_container: 6
2025-04-09 10:38:26,107:INFO:_display_container: 2
2025-04-09 10:38:26,108:INFO:LassoLars(random_state=123)
2025-04-09 10:38:26,108:INFO:create_model() successfully completed......................................
2025-04-09 10:38:26,189:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:26,189:INFO:Creating metrics dataframe
2025-04-09 10:38:26,196:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 10:38:26,196:INFO:Total runtime is 0.1209251840909322 minutes
2025-04-09 10:38:26,198:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:26,199:INFO:Initializing create_model()
2025-04-09 10:38:26,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:26,199:INFO:Checking exceptions
2025-04-09 10:38:26,199:INFO:Importing libraries
2025-04-09 10:38:26,199:INFO:Copying training dataset
2025-04-09 10:38:26,201:INFO:Defining folds
2025-04-09 10:38:26,201:INFO:Declaring metric variables
2025-04-09 10:38:26,204:INFO:Importing untrained model
2025-04-09 10:38:26,206:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 10:38:26,210:INFO:Starting cross validation
2025-04-09 10:38:26,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:27,034:INFO:Calculating mean and std
2025-04-09 10:38:27,034:INFO:Creating metrics dataframe
2025-04-09 10:38:27,037:INFO:Uploading results into container
2025-04-09 10:38:27,038:INFO:Uploading model into container now
2025-04-09 10:38:27,038:INFO:_master_model_container: 7
2025-04-09 10:38:27,039:INFO:_display_container: 2
2025-04-09 10:38:27,039:INFO:OrthogonalMatchingPursuit()
2025-04-09 10:38:27,039:INFO:create_model() successfully completed......................................
2025-04-09 10:38:27,108:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:27,108:INFO:Creating metrics dataframe
2025-04-09 10:38:27,117:INFO:Initializing Bayesian Ridge
2025-04-09 10:38:27,117:INFO:Total runtime is 0.13628237644831337 minutes
2025-04-09 10:38:27,121:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:27,121:INFO:Initializing create_model()
2025-04-09 10:38:27,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:27,121:INFO:Checking exceptions
2025-04-09 10:38:27,121:INFO:Importing libraries
2025-04-09 10:38:27,121:INFO:Copying training dataset
2025-04-09 10:38:27,124:INFO:Defining folds
2025-04-09 10:38:27,124:INFO:Declaring metric variables
2025-04-09 10:38:27,127:INFO:Importing untrained model
2025-04-09 10:38:27,129:INFO:Bayesian Ridge Imported successfully
2025-04-09 10:38:27,134:INFO:Starting cross validation
2025-04-09 10:38:27,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:28,416:INFO:Calculating mean and std
2025-04-09 10:38:28,418:INFO:Creating metrics dataframe
2025-04-09 10:38:28,423:INFO:Uploading results into container
2025-04-09 10:38:28,424:INFO:Uploading model into container now
2025-04-09 10:38:28,425:INFO:_master_model_container: 8
2025-04-09 10:38:28,426:INFO:_display_container: 2
2025-04-09 10:38:28,426:INFO:BayesianRidge()
2025-04-09 10:38:28,427:INFO:create_model() successfully completed......................................
2025-04-09 10:38:28,502:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:28,502:INFO:Creating metrics dataframe
2025-04-09 10:38:28,506:INFO:Initializing Passive Aggressive Regressor
2025-04-09 10:38:28,507:INFO:Total runtime is 0.15943570137023924 minutes
2025-04-09 10:38:28,508:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:28,509:INFO:Initializing create_model()
2025-04-09 10:38:28,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:28,509:INFO:Checking exceptions
2025-04-09 10:38:28,509:INFO:Importing libraries
2025-04-09 10:38:28,509:INFO:Copying training dataset
2025-04-09 10:38:28,511:INFO:Defining folds
2025-04-09 10:38:28,511:INFO:Declaring metric variables
2025-04-09 10:38:28,513:INFO:Importing untrained model
2025-04-09 10:38:28,514:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 10:38:28,517:INFO:Starting cross validation
2025-04-09 10:38:28,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:29,094:INFO:Calculating mean and std
2025-04-09 10:38:29,095:INFO:Creating metrics dataframe
2025-04-09 10:38:29,096:INFO:Uploading results into container
2025-04-09 10:38:29,096:INFO:Uploading model into container now
2025-04-09 10:38:29,097:INFO:_master_model_container: 9
2025-04-09 10:38:29,097:INFO:_display_container: 2
2025-04-09 10:38:29,097:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 10:38:29,097:INFO:create_model() successfully completed......................................
2025-04-09 10:38:29,143:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:29,143:INFO:Creating metrics dataframe
2025-04-09 10:38:29,147:INFO:Initializing Huber Regressor
2025-04-09 10:38:29,148:INFO:Total runtime is 0.17011904716491696 minutes
2025-04-09 10:38:29,149:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:29,149:INFO:Initializing create_model()
2025-04-09 10:38:29,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:29,149:INFO:Checking exceptions
2025-04-09 10:38:29,149:INFO:Importing libraries
2025-04-09 10:38:29,149:INFO:Copying training dataset
2025-04-09 10:38:29,151:INFO:Defining folds
2025-04-09 10:38:29,151:INFO:Declaring metric variables
2025-04-09 10:38:29,152:INFO:Importing untrained model
2025-04-09 10:38:29,154:INFO:Huber Regressor Imported successfully
2025-04-09 10:38:29,157:INFO:Starting cross validation
2025-04-09 10:38:29,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:29,213:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:29,351:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:29,486:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:29,611:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:29,760:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:29,923:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:30,047:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:30,196:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:30,389:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:38:30,564:INFO:Calculating mean and std
2025-04-09 10:38:30,565:INFO:Creating metrics dataframe
2025-04-09 10:38:30,568:INFO:Uploading results into container
2025-04-09 10:38:30,568:INFO:Uploading model into container now
2025-04-09 10:38:30,569:INFO:_master_model_container: 10
2025-04-09 10:38:30,569:INFO:_display_container: 2
2025-04-09 10:38:30,569:INFO:HuberRegressor()
2025-04-09 10:38:30,569:INFO:create_model() successfully completed......................................
2025-04-09 10:38:30,637:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:30,637:INFO:Creating metrics dataframe
2025-04-09 10:38:30,647:INFO:Initializing K Neighbors Regressor
2025-04-09 10:38:30,647:INFO:Total runtime is 0.19511295159657793 minutes
2025-04-09 10:38:30,650:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:30,651:INFO:Initializing create_model()
2025-04-09 10:38:30,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:30,651:INFO:Checking exceptions
2025-04-09 10:38:30,651:INFO:Importing libraries
2025-04-09 10:38:30,651:INFO:Copying training dataset
2025-04-09 10:38:30,654:INFO:Defining folds
2025-04-09 10:38:30,654:INFO:Declaring metric variables
2025-04-09 10:38:30,657:INFO:Importing untrained model
2025-04-09 10:38:30,660:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:38:30,665:INFO:Starting cross validation
2025-04-09 10:38:30,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:32,170:INFO:Calculating mean and std
2025-04-09 10:38:32,172:INFO:Creating metrics dataframe
2025-04-09 10:38:32,174:INFO:Uploading results into container
2025-04-09 10:38:32,175:INFO:Uploading model into container now
2025-04-09 10:38:32,175:INFO:_master_model_container: 11
2025-04-09 10:38:32,176:INFO:_display_container: 2
2025-04-09 10:38:32,176:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:38:32,176:INFO:create_model() successfully completed......................................
2025-04-09 10:38:32,277:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:32,278:INFO:Creating metrics dataframe
2025-04-09 10:38:32,302:INFO:Initializing Decision Tree Regressor
2025-04-09 10:38:32,302:INFO:Total runtime is 0.22268967231114703 minutes
2025-04-09 10:38:32,310:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:32,310:INFO:Initializing create_model()
2025-04-09 10:38:32,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:32,311:INFO:Checking exceptions
2025-04-09 10:38:32,311:INFO:Importing libraries
2025-04-09 10:38:32,311:INFO:Copying training dataset
2025-04-09 10:38:32,320:INFO:Defining folds
2025-04-09 10:38:32,321:INFO:Declaring metric variables
2025-04-09 10:38:32,327:INFO:Importing untrained model
2025-04-09 10:38:32,334:INFO:Decision Tree Regressor Imported successfully
2025-04-09 10:38:32,346:INFO:Starting cross validation
2025-04-09 10:38:32,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:32,760:INFO:Calculating mean and std
2025-04-09 10:38:32,761:INFO:Creating metrics dataframe
2025-04-09 10:38:32,762:INFO:Uploading results into container
2025-04-09 10:38:32,762:INFO:Uploading model into container now
2025-04-09 10:38:32,762:INFO:_master_model_container: 12
2025-04-09 10:38:32,762:INFO:_display_container: 2
2025-04-09 10:38:32,762:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 10:38:32,762:INFO:create_model() successfully completed......................................
2025-04-09 10:38:32,802:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:32,802:INFO:Creating metrics dataframe
2025-04-09 10:38:32,806:INFO:Initializing Random Forest Regressor
2025-04-09 10:38:32,806:INFO:Total runtime is 0.23109742403030392 minutes
2025-04-09 10:38:32,808:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:32,808:INFO:Initializing create_model()
2025-04-09 10:38:32,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:32,808:INFO:Checking exceptions
2025-04-09 10:38:32,808:INFO:Importing libraries
2025-04-09 10:38:32,808:INFO:Copying training dataset
2025-04-09 10:38:32,810:INFO:Defining folds
2025-04-09 10:38:32,810:INFO:Declaring metric variables
2025-04-09 10:38:32,811:INFO:Importing untrained model
2025-04-09 10:38:32,812:INFO:Random Forest Regressor Imported successfully
2025-04-09 10:38:32,815:INFO:Starting cross validation
2025-04-09 10:38:32,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:35,888:INFO:Calculating mean and std
2025-04-09 10:38:35,889:INFO:Creating metrics dataframe
2025-04-09 10:38:35,892:INFO:Uploading results into container
2025-04-09 10:38:35,893:INFO:Uploading model into container now
2025-04-09 10:38:35,893:INFO:_master_model_container: 13
2025-04-09 10:38:35,894:INFO:_display_container: 2
2025-04-09 10:38:35,894:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:38:35,894:INFO:create_model() successfully completed......................................
2025-04-09 10:38:35,976:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:35,976:INFO:Creating metrics dataframe
2025-04-09 10:38:35,992:INFO:Initializing Extra Trees Regressor
2025-04-09 10:38:35,992:INFO:Total runtime is 0.2841898639996846 minutes
2025-04-09 10:38:35,996:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:35,997:INFO:Initializing create_model()
2025-04-09 10:38:35,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:35,997:INFO:Checking exceptions
2025-04-09 10:38:35,997:INFO:Importing libraries
2025-04-09 10:38:35,997:INFO:Copying training dataset
2025-04-09 10:38:36,004:INFO:Defining folds
2025-04-09 10:38:36,004:INFO:Declaring metric variables
2025-04-09 10:38:36,009:INFO:Importing untrained model
2025-04-09 10:38:36,014:INFO:Extra Trees Regressor Imported successfully
2025-04-09 10:38:36,024:INFO:Starting cross validation
2025-04-09 10:38:36,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:38,660:INFO:Calculating mean and std
2025-04-09 10:38:38,661:INFO:Creating metrics dataframe
2025-04-09 10:38:38,664:INFO:Uploading results into container
2025-04-09 10:38:38,665:INFO:Uploading model into container now
2025-04-09 10:38:38,666:INFO:_master_model_container: 14
2025-04-09 10:38:38,666:INFO:_display_container: 2
2025-04-09 10:38:38,667:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:38:38,667:INFO:create_model() successfully completed......................................
2025-04-09 10:38:38,765:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:38,765:INFO:Creating metrics dataframe
2025-04-09 10:38:38,781:INFO:Initializing AdaBoost Regressor
2025-04-09 10:38:38,782:INFO:Total runtime is 0.330690578619639 minutes
2025-04-09 10:38:38,787:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:38,788:INFO:Initializing create_model()
2025-04-09 10:38:38,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:38,788:INFO:Checking exceptions
2025-04-09 10:38:38,788:INFO:Importing libraries
2025-04-09 10:38:38,788:INFO:Copying training dataset
2025-04-09 10:38:38,794:INFO:Defining folds
2025-04-09 10:38:38,794:INFO:Declaring metric variables
2025-04-09 10:38:38,800:INFO:Importing untrained model
2025-04-09 10:38:38,805:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:38:38,817:INFO:Starting cross validation
2025-04-09 10:38:38,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:39,706:INFO:Calculating mean and std
2025-04-09 10:38:39,707:INFO:Creating metrics dataframe
2025-04-09 10:38:39,708:INFO:Uploading results into container
2025-04-09 10:38:39,708:INFO:Uploading model into container now
2025-04-09 10:38:39,708:INFO:_master_model_container: 15
2025-04-09 10:38:39,708:INFO:_display_container: 2
2025-04-09 10:38:39,709:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:38:39,709:INFO:create_model() successfully completed......................................
2025-04-09 10:38:39,750:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:39,750:INFO:Creating metrics dataframe
2025-04-09 10:38:39,754:INFO:Initializing Gradient Boosting Regressor
2025-04-09 10:38:39,754:INFO:Total runtime is 0.3468999584515889 minutes
2025-04-09 10:38:39,756:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:39,756:INFO:Initializing create_model()
2025-04-09 10:38:39,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:39,756:INFO:Checking exceptions
2025-04-09 10:38:39,756:INFO:Importing libraries
2025-04-09 10:38:39,756:INFO:Copying training dataset
2025-04-09 10:38:39,758:INFO:Defining folds
2025-04-09 10:38:39,758:INFO:Declaring metric variables
2025-04-09 10:38:39,759:INFO:Importing untrained model
2025-04-09 10:38:39,761:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 10:38:39,763:INFO:Starting cross validation
2025-04-09 10:38:39,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:40,997:INFO:Calculating mean and std
2025-04-09 10:38:40,998:INFO:Creating metrics dataframe
2025-04-09 10:38:40,998:INFO:Uploading results into container
2025-04-09 10:38:40,999:INFO:Uploading model into container now
2025-04-09 10:38:40,999:INFO:_master_model_container: 16
2025-04-09 10:38:40,999:INFO:_display_container: 2
2025-04-09 10:38:40,999:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 10:38:40,999:INFO:create_model() successfully completed......................................
2025-04-09 10:38:41,039:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:41,039:INFO:Creating metrics dataframe
2025-04-09 10:38:41,044:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 10:38:41,044:INFO:Total runtime is 0.3683878819147745 minutes
2025-04-09 10:38:41,045:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:41,045:INFO:Initializing create_model()
2025-04-09 10:38:41,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:41,045:INFO:Checking exceptions
2025-04-09 10:38:41,045:INFO:Importing libraries
2025-04-09 10:38:41,045:INFO:Copying training dataset
2025-04-09 10:38:41,047:INFO:Defining folds
2025-04-09 10:38:41,047:INFO:Declaring metric variables
2025-04-09 10:38:41,048:INFO:Importing untrained model
2025-04-09 10:38:41,050:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 10:38:41,054:INFO:Starting cross validation
2025-04-09 10:38:41,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:41,109:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:41,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025197 seconds.
2025-04-09 10:38:41,145:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:41,146:INFO:[LightGBM] [Info] Total Bins 1164
2025-04-09 10:38:41,152:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:38:41,160:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 10:38:41,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:41,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,563:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:42,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2025-04-09 10:38:42,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:42,564:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 10:38:42,564:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:38:42,565:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 10:38:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,695:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:42,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028111 seconds.
2025-04-09 10:38:42,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:42,724:INFO:[LightGBM] [Info] Total Bins 1195
2025-04-09 10:38:42,734:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:38:42,743:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 10:38:42,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:42,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,028:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2025-04-09 10:38:43,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,029:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 10:38:43,029:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:38:43,029:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 10:38:43,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,111:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,112:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
2025-04-09 10:38:43,112:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,112:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 10:38:43,112:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:38:43,112:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 10:38:43,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,228:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024255 seconds.
2025-04-09 10:38:43,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,255:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 10:38:43,261:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:38:43,268:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 10:38:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,402:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
2025-04-09 10:38:43,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,403:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 10:38:43,403:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:38:43,404:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,460:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
2025-04-09 10:38:43,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,461:INFO:[LightGBM] [Info] Total Bins 1169
2025-04-09 10:38:43,461:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:38:43,461:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 10:38:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,526:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026075 seconds.
2025-04-09 10:38:43,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,553:INFO:[LightGBM] [Info] Total Bins 1166
2025-04-09 10:38:43,562:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 64
2025-04-09 10:38:43,569:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 10:38:43,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,811:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:38:43,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2025-04-09 10:38:43,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:38:43,812:INFO:[LightGBM] [Info] Total Bins 1174
2025-04-09 10:38:43,812:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 64
2025-04-09 10:38:43,812:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 10:38:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:38:43,846:INFO:Calculating mean and std
2025-04-09 10:38:43,847:INFO:Creating metrics dataframe
2025-04-09 10:38:43,848:INFO:Uploading results into container
2025-04-09 10:38:43,849:INFO:Uploading model into container now
2025-04-09 10:38:43,849:INFO:_master_model_container: 17
2025-04-09 10:38:43,849:INFO:_display_container: 2
2025-04-09 10:38:43,849:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:38:43,849:INFO:create_model() successfully completed......................................
2025-04-09 10:38:43,906:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:43,906:INFO:Creating metrics dataframe
2025-04-09 10:38:43,913:INFO:Initializing Dummy Regressor
2025-04-09 10:38:43,913:INFO:Total runtime is 0.41620949506759636 minutes
2025-04-09 10:38:43,915:INFO:SubProcess create_model() called ==================================
2025-04-09 10:38:43,915:INFO:Initializing create_model()
2025-04-09 10:38:43,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdf8790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:43,915:INFO:Checking exceptions
2025-04-09 10:38:43,915:INFO:Importing libraries
2025-04-09 10:38:43,915:INFO:Copying training dataset
2025-04-09 10:38:43,917:INFO:Defining folds
2025-04-09 10:38:43,917:INFO:Declaring metric variables
2025-04-09 10:38:43,919:INFO:Importing untrained model
2025-04-09 10:38:43,921:INFO:Dummy Regressor Imported successfully
2025-04-09 10:38:43,924:INFO:Starting cross validation
2025-04-09 10:38:43,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:38:44,385:INFO:Calculating mean and std
2025-04-09 10:38:44,385:INFO:Creating metrics dataframe
2025-04-09 10:38:44,386:INFO:Uploading results into container
2025-04-09 10:38:44,386:INFO:Uploading model into container now
2025-04-09 10:38:44,387:INFO:_master_model_container: 18
2025-04-09 10:38:44,387:INFO:_display_container: 2
2025-04-09 10:38:44,387:INFO:DummyRegressor()
2025-04-09 10:38:44,387:INFO:create_model() successfully completed......................................
2025-04-09 10:38:44,427:INFO:SubProcess create_model() end ==================================
2025-04-09 10:38:44,427:INFO:Creating metrics dataframe
2025-04-09 10:38:44,432:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 10:38:44,436:INFO:Initializing create_model()
2025-04-09 10:38:44,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046b1d9460>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:38:44,436:INFO:Checking exceptions
2025-04-09 10:38:44,437:INFO:Importing libraries
2025-04-09 10:38:44,437:INFO:Copying training dataset
2025-04-09 10:38:44,439:INFO:Defining folds
2025-04-09 10:38:44,439:INFO:Declaring metric variables
2025-04-09 10:38:44,439:INFO:Importing untrained model
2025-04-09 10:38:44,439:INFO:Declaring custom model
2025-04-09 10:38:44,439:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:38:44,440:INFO:Cross validation set to False
2025-04-09 10:38:44,440:INFO:Fitting Model
2025-04-09 10:38:44,513:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:38:44,513:INFO:create_model() successfully completed......................................
2025-04-09 10:38:44,564:INFO:_master_model_container: 18
2025-04-09 10:38:44,564:INFO:_display_container: 2
2025-04-09 10:38:44,564:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:38:44,564:INFO:compare_models() successfully completed......................................
2025-04-09 10:39:09,895:INFO:PyCaret RegressionExperiment
2025-04-09 10:39:09,895:INFO:Logging name: reg-default-name
2025-04-09 10:39:09,895:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-09 10:39:09,895:INFO:version 3.3.1
2025-04-09 10:39:09,895:INFO:Initializing setup()
2025-04-09 10:39:09,895:INFO:self.USI: e500
2025-04-09 10:39:09,896:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'idx', 'seed', 'X', 'fold_groups_param', 'y', 'USI', 'y_train', 'html_param', 'gpu_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'memory', '_available_plots', 'transform_target_param', 'pipeline', 'X_train', 'log_plots_param', 'data', 'exp_id', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'y_test', 'target_param'}
2025-04-09 10:39:09,896:INFO:Checking environment
2025-04-09 10:39:09,896:INFO:python_version: 3.9.21
2025-04-09 10:39:09,896:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-04-09 10:39:09,896:INFO:machine: x86_64
2025-04-09 10:39:09,896:INFO:platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:39:09,896:INFO:Memory: svmem(total=33374547968, available=26381328384, percent=21.0, used=5414449152, free=18534600704, active=6875521024, inactive=5468282880, buffers=387203072, cached=9038295040, shared=1095819264, slab=1095323648)
2025-04-09 10:39:09,897:INFO:Physical Core: 24
2025-04-09 10:39:09,897:INFO:Logical Core: 32
2025-04-09 10:39:09,898:INFO:Checking libraries
2025-04-09 10:39:09,898:INFO:System:
2025-04-09 10:39:09,898:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-04-09 10:39:09,898:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-04-09 10:39:09,898:INFO:   machine: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:39:09,898:INFO:PyCaret required dependencies:
2025-04-09 10:39:09,898:INFO:                 pip: 25.0
2025-04-09 10:39:09,898:INFO:          setuptools: 75.8.0
2025-04-09 10:39:09,898:INFO:             pycaret: 3.3.1
2025-04-09 10:39:09,898:INFO:             IPython: 8.18.1
2025-04-09 10:39:09,898:INFO:          ipywidgets: 8.1.5
2025-04-09 10:39:09,898:INFO:                tqdm: 4.67.1
2025-04-09 10:39:09,898:INFO:               numpy: 1.26.4
2025-04-09 10:39:09,898:INFO:              pandas: 2.1.4
2025-04-09 10:39:09,898:INFO:              jinja2: 3.1.5
2025-04-09 10:39:09,898:INFO:               scipy: 1.11.4
2025-04-09 10:39:09,898:INFO:              joblib: 1.3.2
2025-04-09 10:39:09,898:INFO:             sklearn: 1.4.2
2025-04-09 10:39:09,898:INFO:                pyod: 2.0.3
2025-04-09 10:39:09,898:INFO:            imblearn: 0.12.4
2025-04-09 10:39:09,898:INFO:   category_encoders: 2.6.4
2025-04-09 10:39:09,898:INFO:            lightgbm: 4.6.0
2025-04-09 10:39:09,898:INFO:               numba: 0.60.0
2025-04-09 10:39:09,898:INFO:            requests: 2.32.3
2025-04-09 10:39:09,898:INFO:          matplotlib: 3.7.5
2025-04-09 10:39:09,898:INFO:          scikitplot: 0.3.7
2025-04-09 10:39:09,899:INFO:         yellowbrick: 1.5
2025-04-09 10:39:09,899:INFO:              plotly: 5.24.1
2025-04-09 10:39:09,899:INFO:    plotly-resampler: Not installed
2025-04-09 10:39:09,899:INFO:             kaleido: 0.2.1
2025-04-09 10:39:09,899:INFO:           schemdraw: 0.15
2025-04-09 10:39:09,899:INFO:         statsmodels: 0.14.4
2025-04-09 10:39:09,899:INFO:              sktime: 0.26.0
2025-04-09 10:39:09,899:INFO:               tbats: 1.1.3
2025-04-09 10:39:09,899:INFO:            pmdarima: 2.0.4
2025-04-09 10:39:09,899:INFO:              psutil: 7.0.0
2025-04-09 10:39:09,899:INFO:          markupsafe: 3.0.2
2025-04-09 10:39:09,899:INFO:             pickle5: Not installed
2025-04-09 10:39:09,899:INFO:         cloudpickle: 3.1.1
2025-04-09 10:39:09,899:INFO:         deprecation: 2.1.0
2025-04-09 10:39:09,899:INFO:              xxhash: 3.5.0
2025-04-09 10:39:09,899:INFO:           wurlitzer: 3.1.1
2025-04-09 10:39:09,899:INFO:PyCaret optional dependencies:
2025-04-09 10:39:09,899:INFO:                shap: Not installed
2025-04-09 10:39:09,899:INFO:           interpret: Not installed
2025-04-09 10:39:09,899:INFO:                umap: Not installed
2025-04-09 10:39:09,899:INFO:     ydata_profiling: Not installed
2025-04-09 10:39:09,899:INFO:  explainerdashboard: Not installed
2025-04-09 10:39:09,899:INFO:             autoviz: Not installed
2025-04-09 10:39:09,899:INFO:           fairlearn: Not installed
2025-04-09 10:39:09,899:INFO:          deepchecks: Not installed
2025-04-09 10:39:09,899:INFO:             xgboost: Not installed
2025-04-09 10:39:09,899:INFO:            catboost: Not installed
2025-04-09 10:39:09,899:INFO:              kmodes: Not installed
2025-04-09 10:39:09,899:INFO:             mlxtend: Not installed
2025-04-09 10:39:09,899:INFO:       statsforecast: Not installed
2025-04-09 10:39:09,900:INFO:        tune_sklearn: Not installed
2025-04-09 10:39:09,900:INFO:                 ray: Not installed
2025-04-09 10:39:09,900:INFO:            hyperopt: Not installed
2025-04-09 10:39:09,900:INFO:              optuna: Not installed
2025-04-09 10:39:09,900:INFO:               skopt: Not installed
2025-04-09 10:39:09,900:INFO:              mlflow: Not installed
2025-04-09 10:39:09,900:INFO:              gradio: Not installed
2025-04-09 10:39:09,900:INFO:             fastapi: Not installed
2025-04-09 10:39:09,900:INFO:             uvicorn: Not installed
2025-04-09 10:39:09,900:INFO:              m2cgen: Not installed
2025-04-09 10:39:09,900:INFO:           evidently: Not installed
2025-04-09 10:39:09,900:INFO:               fugue: Not installed
2025-04-09 10:39:09,900:INFO:           streamlit: Not installed
2025-04-09 10:39:09,900:INFO:             prophet: Not installed
2025-04-09 10:39:09,900:INFO:None
2025-04-09 10:39:09,900:INFO:Set up GPU usage.
2025-04-09 10:39:09,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:09,900:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-04-09 10:39:09,900:INFO:Set up data.
2025-04-09 10:39:09,908:INFO:Set up folding strategy.
2025-04-09 10:39:09,908:INFO:Set up train/test split.
2025-04-09 10:39:09,914:INFO:Set up index.
2025-04-09 10:39:09,915:INFO:Assigning column types.
2025-04-09 10:39:09,923:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-09 10:39:09,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:09,924:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:39:09,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:09,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:39:09,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:09,942:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:09,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,076:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,151:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-09 10:39:10,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,161:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,349:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,375:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,442:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-09 10:39:10,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,798:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-09 10:39:10,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:10,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:10,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:10,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:11,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:39:11,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-09 10:39:11,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:11,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:39:11,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,325:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-09 10:39:11,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,522:INFO:Preparing preprocessing pipeline...
2025-04-09 10:39:11,522:INFO:Set up simple imputation.
2025-04-09 10:39:11,529:INFO:Set up encoding of categorical features.
2025-04-09 10:39:11,529:INFO:Set up polynomial features.
2025-04-09 10:39:11,667:INFO:Finished creating preprocessing pipeline.
2025-04-09 10:39:11,688:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp', 'source_file'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('on...
                 TransformerWrapper(include=['source_file'],
                                    transformer=OneHotEncoder(cols=['source_file'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-04-09 10:39:11,688:INFO:Creating final display dataframe.
2025-04-09 10:39:11,889:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape         (155, 11)
4        Transformed data shape        (155, 190)
5   Transformed train set shape        (108, 190)
6    Transformed test set shape         (47, 190)
7              Numeric features                 8
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU              True
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              e500
2025-04-09 10:39:11,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:11,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:11,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:39:12,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:12,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:39:12,214:INFO:setup() successfully completed in 2.32s...............
2025-04-09 10:39:14,659:INFO:Initializing compare_models()
2025-04-09 10:39:14,659:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 10:39:14,659:INFO:Checking exceptions
2025-04-09 10:39:14,661:INFO:Preparing display monitor
2025-04-09 10:39:14,678:INFO:Initializing Linear Regression
2025-04-09 10:39:14,678:INFO:Total runtime is 2.0384788513183595e-06 minutes
2025-04-09 10:39:14,680:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:14,681:INFO:Initializing create_model()
2025-04-09 10:39:14,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:14,681:INFO:Checking exceptions
2025-04-09 10:39:14,681:INFO:Importing libraries
2025-04-09 10:39:14,681:INFO:Copying training dataset
2025-04-09 10:39:14,686:INFO:Defining folds
2025-04-09 10:39:14,686:INFO:Declaring metric variables
2025-04-09 10:39:14,693:INFO:Importing untrained model
2025-04-09 10:39:14,700:INFO:Linear Regression Imported successfully
2025-04-09 10:39:14,714:INFO:Starting cross validation
2025-04-09 10:39:14,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:15,777:INFO:Calculating mean and std
2025-04-09 10:39:15,778:INFO:Creating metrics dataframe
2025-04-09 10:39:15,781:INFO:Uploading results into container
2025-04-09 10:39:15,782:INFO:Uploading model into container now
2025-04-09 10:39:15,783:INFO:_master_model_container: 1
2025-04-09 10:39:15,783:INFO:_display_container: 2
2025-04-09 10:39:15,783:INFO:LinearRegression(n_jobs=-1)
2025-04-09 10:39:15,783:INFO:create_model() successfully completed......................................
2025-04-09 10:39:15,863:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:15,863:INFO:Creating metrics dataframe
2025-04-09 10:39:15,868:INFO:Initializing Lasso Regression
2025-04-09 10:39:15,868:INFO:Total runtime is 0.019836143652598063 minutes
2025-04-09 10:39:15,871:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:15,871:INFO:Initializing create_model()
2025-04-09 10:39:15,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:15,871:INFO:Checking exceptions
2025-04-09 10:39:15,871:INFO:Importing libraries
2025-04-09 10:39:15,871:INFO:Copying training dataset
2025-04-09 10:39:15,874:INFO:Defining folds
2025-04-09 10:39:15,874:INFO:Declaring metric variables
2025-04-09 10:39:15,876:INFO:Importing untrained model
2025-04-09 10:39:15,879:INFO:Lasso Regression Imported successfully
2025-04-09 10:39:15,883:INFO:Starting cross validation
2025-04-09 10:39:15,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:15,964:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.821e-02, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,048:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.623e-02, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,144:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e-02, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,239:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e-02, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,334:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-02, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,429:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.792e-02, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,525:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.844e-02, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,620:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e-02, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,714:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.870e-02, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,803:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:16,825:INFO:Calculating mean and std
2025-04-09 10:39:16,826:INFO:Creating metrics dataframe
2025-04-09 10:39:16,828:INFO:Uploading results into container
2025-04-09 10:39:16,828:INFO:Uploading model into container now
2025-04-09 10:39:16,829:INFO:_master_model_container: 2
2025-04-09 10:39:16,829:INFO:_display_container: 2
2025-04-09 10:39:16,829:INFO:Lasso(random_state=123)
2025-04-09 10:39:16,829:INFO:create_model() successfully completed......................................
2025-04-09 10:39:16,894:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:16,894:INFO:Creating metrics dataframe
2025-04-09 10:39:16,901:INFO:Initializing Ridge Regression
2025-04-09 10:39:16,901:INFO:Total runtime is 0.03705788056055705 minutes
2025-04-09 10:39:16,905:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:16,905:INFO:Initializing create_model()
2025-04-09 10:39:16,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:16,905:INFO:Checking exceptions
2025-04-09 10:39:16,905:INFO:Importing libraries
2025-04-09 10:39:16,905:INFO:Copying training dataset
2025-04-09 10:39:16,911:INFO:Defining folds
2025-04-09 10:39:16,911:INFO:Declaring metric variables
2025-04-09 10:39:16,915:INFO:Importing untrained model
2025-04-09 10:39:16,918:INFO:Ridge Regression Imported successfully
2025-04-09 10:39:16,925:INFO:Starting cross validation
2025-04-09 10:39:16,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:16,990:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,100:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,229:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,313:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,406:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,503:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,600:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,697:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,788:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,876:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2025-04-09 10:39:17,909:INFO:Calculating mean and std
2025-04-09 10:39:17,911:INFO:Creating metrics dataframe
2025-04-09 10:39:17,912:INFO:Uploading results into container
2025-04-09 10:39:17,913:INFO:Uploading model into container now
2025-04-09 10:39:17,913:INFO:_master_model_container: 3
2025-04-09 10:39:17,913:INFO:_display_container: 2
2025-04-09 10:39:17,913:INFO:Ridge(random_state=123)
2025-04-09 10:39:17,914:INFO:create_model() successfully completed......................................
2025-04-09 10:39:17,984:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:17,984:INFO:Creating metrics dataframe
2025-04-09 10:39:17,992:INFO:Initializing Elastic Net
2025-04-09 10:39:17,992:INFO:Total runtime is 0.05523718992869059 minutes
2025-04-09 10:39:17,995:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:17,995:INFO:Initializing create_model()
2025-04-09 10:39:17,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:17,995:INFO:Checking exceptions
2025-04-09 10:39:17,995:INFO:Importing libraries
2025-04-09 10:39:17,995:INFO:Copying training dataset
2025-04-09 10:39:17,999:INFO:Defining folds
2025-04-09 10:39:17,999:INFO:Declaring metric variables
2025-04-09 10:39:18,001:INFO:Importing untrained model
2025-04-09 10:39:18,004:INFO:Elastic Net Imported successfully
2025-04-09 10:39:18,009:INFO:Starting cross validation
2025-04-09 10:39:18,010:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:18,084:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e-02, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,179:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e-02, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,277:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e-02, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,376:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e-02, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,478:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e-02, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,577:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e-02, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,679:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e-02, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,777:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e-02, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,873:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e-02, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,968:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:39:18,999:INFO:Calculating mean and std
2025-04-09 10:39:19,001:INFO:Creating metrics dataframe
2025-04-09 10:39:19,003:INFO:Uploading results into container
2025-04-09 10:39:19,003:INFO:Uploading model into container now
2025-04-09 10:39:19,004:INFO:_master_model_container: 4
2025-04-09 10:39:19,004:INFO:_display_container: 2
2025-04-09 10:39:19,004:INFO:ElasticNet(random_state=123)
2025-04-09 10:39:19,004:INFO:create_model() successfully completed......................................
2025-04-09 10:39:19,074:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:19,074:INFO:Creating metrics dataframe
2025-04-09 10:39:19,082:INFO:Initializing Least Angle Regression
2025-04-09 10:39:19,082:INFO:Total runtime is 0.07340354124704997 minutes
2025-04-09 10:39:19,086:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:19,086:INFO:Initializing create_model()
2025-04-09 10:39:19,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:19,086:INFO:Checking exceptions
2025-04-09 10:39:19,087:INFO:Importing libraries
2025-04-09 10:39:19,087:INFO:Copying training dataset
2025-04-09 10:39:19,090:INFO:Defining folds
2025-04-09 10:39:19,090:INFO:Declaring metric variables
2025-04-09 10:39:19,093:INFO:Importing untrained model
2025-04-09 10:39:19,096:INFO:Least Angle Regression Imported successfully
2025-04-09 10:39:19,102:INFO:Starting cross validation
2025-04-09 10:39:19,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:20,250:INFO:Calculating mean and std
2025-04-09 10:39:20,251:INFO:Creating metrics dataframe
2025-04-09 10:39:20,253:INFO:Uploading results into container
2025-04-09 10:39:20,254:INFO:Uploading model into container now
2025-04-09 10:39:20,254:INFO:_master_model_container: 5
2025-04-09 10:39:20,254:INFO:_display_container: 2
2025-04-09 10:39:20,254:INFO:Lars(random_state=123)
2025-04-09 10:39:20,255:INFO:create_model() successfully completed......................................
2025-04-09 10:39:20,323:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:20,324:INFO:Creating metrics dataframe
2025-04-09 10:39:20,333:INFO:Initializing Lasso Least Angle Regression
2025-04-09 10:39:20,333:INFO:Total runtime is 0.09424880743026734 minutes
2025-04-09 10:39:20,336:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:20,337:INFO:Initializing create_model()
2025-04-09 10:39:20,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:20,337:INFO:Checking exceptions
2025-04-09 10:39:20,337:INFO:Importing libraries
2025-04-09 10:39:20,337:INFO:Copying training dataset
2025-04-09 10:39:20,340:INFO:Defining folds
2025-04-09 10:39:20,340:INFO:Declaring metric variables
2025-04-09 10:39:20,343:INFO:Importing untrained model
2025-04-09 10:39:20,345:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 10:39:20,349:INFO:Starting cross validation
2025-04-09 10:39:20,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:21,242:INFO:Calculating mean and std
2025-04-09 10:39:21,243:INFO:Creating metrics dataframe
2025-04-09 10:39:21,245:INFO:Uploading results into container
2025-04-09 10:39:21,246:INFO:Uploading model into container now
2025-04-09 10:39:21,246:INFO:_master_model_container: 6
2025-04-09 10:39:21,246:INFO:_display_container: 2
2025-04-09 10:39:21,246:INFO:LassoLars(random_state=123)
2025-04-09 10:39:21,246:INFO:create_model() successfully completed......................................
2025-04-09 10:39:21,315:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:21,316:INFO:Creating metrics dataframe
2025-04-09 10:39:21,324:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 10:39:21,325:INFO:Total runtime is 0.11077709595362346 minutes
2025-04-09 10:39:21,328:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:21,328:INFO:Initializing create_model()
2025-04-09 10:39:21,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:21,328:INFO:Checking exceptions
2025-04-09 10:39:21,328:INFO:Importing libraries
2025-04-09 10:39:21,328:INFO:Copying training dataset
2025-04-09 10:39:21,331:INFO:Defining folds
2025-04-09 10:39:21,332:INFO:Declaring metric variables
2025-04-09 10:39:21,334:INFO:Importing untrained model
2025-04-09 10:39:21,337:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 10:39:21,343:INFO:Starting cross validation
2025-04-09 10:39:21,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:22,279:INFO:Calculating mean and std
2025-04-09 10:39:22,280:INFO:Creating metrics dataframe
2025-04-09 10:39:22,282:INFO:Uploading results into container
2025-04-09 10:39:22,283:INFO:Uploading model into container now
2025-04-09 10:39:22,283:INFO:_master_model_container: 7
2025-04-09 10:39:22,283:INFO:_display_container: 2
2025-04-09 10:39:22,283:INFO:OrthogonalMatchingPursuit()
2025-04-09 10:39:22,284:INFO:create_model() successfully completed......................................
2025-04-09 10:39:22,353:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:22,353:INFO:Creating metrics dataframe
2025-04-09 10:39:22,363:INFO:Initializing Bayesian Ridge
2025-04-09 10:39:22,363:INFO:Total runtime is 0.12808241446812949 minutes
2025-04-09 10:39:22,366:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:22,366:INFO:Initializing create_model()
2025-04-09 10:39:22,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:22,366:INFO:Checking exceptions
2025-04-09 10:39:22,366:INFO:Importing libraries
2025-04-09 10:39:22,366:INFO:Copying training dataset
2025-04-09 10:39:22,370:INFO:Defining folds
2025-04-09 10:39:22,370:INFO:Declaring metric variables
2025-04-09 10:39:22,372:INFO:Importing untrained model
2025-04-09 10:39:22,375:INFO:Bayesian Ridge Imported successfully
2025-04-09 10:39:22,380:INFO:Starting cross validation
2025-04-09 10:39:22,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:23,426:INFO:Calculating mean and std
2025-04-09 10:39:23,427:INFO:Creating metrics dataframe
2025-04-09 10:39:23,429:INFO:Uploading results into container
2025-04-09 10:39:23,432:INFO:Uploading model into container now
2025-04-09 10:39:23,432:INFO:_master_model_container: 8
2025-04-09 10:39:23,432:INFO:_display_container: 2
2025-04-09 10:39:23,433:INFO:BayesianRidge()
2025-04-09 10:39:23,433:INFO:create_model() successfully completed......................................
2025-04-09 10:39:23,536:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:23,537:INFO:Creating metrics dataframe
2025-04-09 10:39:23,542:INFO:Initializing Passive Aggressive Regressor
2025-04-09 10:39:23,542:INFO:Total runtime is 0.14772841135660808 minutes
2025-04-09 10:39:23,544:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:23,544:INFO:Initializing create_model()
2025-04-09 10:39:23,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:23,544:INFO:Checking exceptions
2025-04-09 10:39:23,544:INFO:Importing libraries
2025-04-09 10:39:23,544:INFO:Copying training dataset
2025-04-09 10:39:23,547:INFO:Defining folds
2025-04-09 10:39:23,547:INFO:Declaring metric variables
2025-04-09 10:39:23,549:INFO:Importing untrained model
2025-04-09 10:39:23,552:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 10:39:23,555:INFO:Starting cross validation
2025-04-09 10:39:23,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:24,006:INFO:Calculating mean and std
2025-04-09 10:39:24,007:INFO:Creating metrics dataframe
2025-04-09 10:39:24,007:INFO:Uploading results into container
2025-04-09 10:39:24,008:INFO:Uploading model into container now
2025-04-09 10:39:24,008:INFO:_master_model_container: 9
2025-04-09 10:39:24,008:INFO:_display_container: 2
2025-04-09 10:39:24,008:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 10:39:24,008:INFO:create_model() successfully completed......................................
2025-04-09 10:39:24,085:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:24,085:INFO:Creating metrics dataframe
2025-04-09 10:39:24,101:INFO:Initializing Huber Regressor
2025-04-09 10:39:24,101:INFO:Total runtime is 0.1570490598678589 minutes
2025-04-09 10:39:24,107:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:24,107:INFO:Initializing create_model()
2025-04-09 10:39:24,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:24,107:INFO:Checking exceptions
2025-04-09 10:39:24,108:INFO:Importing libraries
2025-04-09 10:39:24,108:INFO:Copying training dataset
2025-04-09 10:39:24,115:INFO:Defining folds
2025-04-09 10:39:24,116:INFO:Declaring metric variables
2025-04-09 10:39:24,121:INFO:Importing untrained model
2025-04-09 10:39:24,126:INFO:Huber Regressor Imported successfully
2025-04-09 10:39:24,136:INFO:Starting cross validation
2025-04-09 10:39:24,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:24,296:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:24,396:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:24,510:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:24,659:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:24,783:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:24,900:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:25,011:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:25,118:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:25,219:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:39:25,357:INFO:Calculating mean and std
2025-04-09 10:39:25,359:INFO:Creating metrics dataframe
2025-04-09 10:39:25,361:INFO:Uploading results into container
2025-04-09 10:39:25,361:INFO:Uploading model into container now
2025-04-09 10:39:25,362:INFO:_master_model_container: 10
2025-04-09 10:39:25,362:INFO:_display_container: 2
2025-04-09 10:39:25,362:INFO:HuberRegressor()
2025-04-09 10:39:25,362:INFO:create_model() successfully completed......................................
2025-04-09 10:39:25,426:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:25,427:INFO:Creating metrics dataframe
2025-04-09 10:39:25,436:INFO:Initializing K Neighbors Regressor
2025-04-09 10:39:25,436:INFO:Total runtime is 0.17930721044540404 minutes
2025-04-09 10:39:25,440:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:25,440:INFO:Initializing create_model()
2025-04-09 10:39:25,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:25,440:INFO:Checking exceptions
2025-04-09 10:39:25,440:INFO:Importing libraries
2025-04-09 10:39:25,440:INFO:Copying training dataset
2025-04-09 10:39:25,443:INFO:Defining folds
2025-04-09 10:39:25,443:INFO:Declaring metric variables
2025-04-09 10:39:25,446:INFO:Importing untrained model
2025-04-09 10:39:25,449:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:39:25,453:INFO:Starting cross validation
2025-04-09 10:39:25,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:26,090:INFO:Calculating mean and std
2025-04-09 10:39:26,091:INFO:Creating metrics dataframe
2025-04-09 10:39:26,092:INFO:Uploading results into container
2025-04-09 10:39:26,092:INFO:Uploading model into container now
2025-04-09 10:39:26,092:INFO:_master_model_container: 11
2025-04-09 10:39:26,093:INFO:_display_container: 2
2025-04-09 10:39:26,093:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:39:26,093:INFO:create_model() successfully completed......................................
2025-04-09 10:39:26,169:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:26,169:INFO:Creating metrics dataframe
2025-04-09 10:39:26,185:INFO:Initializing Decision Tree Regressor
2025-04-09 10:39:26,185:INFO:Total runtime is 0.19179081519444782 minutes
2025-04-09 10:39:26,192:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:26,193:INFO:Initializing create_model()
2025-04-09 10:39:26,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:26,193:INFO:Checking exceptions
2025-04-09 10:39:26,194:INFO:Importing libraries
2025-04-09 10:39:26,194:INFO:Copying training dataset
2025-04-09 10:39:26,204:INFO:Defining folds
2025-04-09 10:39:26,204:INFO:Declaring metric variables
2025-04-09 10:39:26,210:INFO:Importing untrained model
2025-04-09 10:39:26,218:INFO:Decision Tree Regressor Imported successfully
2025-04-09 10:39:26,233:INFO:Starting cross validation
2025-04-09 10:39:26,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:26,716:INFO:Calculating mean and std
2025-04-09 10:39:26,716:INFO:Creating metrics dataframe
2025-04-09 10:39:26,717:INFO:Uploading results into container
2025-04-09 10:39:26,717:INFO:Uploading model into container now
2025-04-09 10:39:26,718:INFO:_master_model_container: 12
2025-04-09 10:39:26,718:INFO:_display_container: 2
2025-04-09 10:39:26,718:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 10:39:26,718:INFO:create_model() successfully completed......................................
2025-04-09 10:39:26,757:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:26,757:INFO:Creating metrics dataframe
2025-04-09 10:39:26,761:INFO:Initializing Random Forest Regressor
2025-04-09 10:39:26,761:INFO:Total runtime is 0.20137752691904703 minutes
2025-04-09 10:39:26,762:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:26,762:INFO:Initializing create_model()
2025-04-09 10:39:26,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:26,762:INFO:Checking exceptions
2025-04-09 10:39:26,762:INFO:Importing libraries
2025-04-09 10:39:26,762:INFO:Copying training dataset
2025-04-09 10:39:26,764:INFO:Defining folds
2025-04-09 10:39:26,764:INFO:Declaring metric variables
2025-04-09 10:39:26,765:INFO:Importing untrained model
2025-04-09 10:39:26,767:INFO:Random Forest Regressor Imported successfully
2025-04-09 10:39:26,769:INFO:Starting cross validation
2025-04-09 10:39:26,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:29,771:INFO:Calculating mean and std
2025-04-09 10:39:29,773:INFO:Creating metrics dataframe
2025-04-09 10:39:29,775:INFO:Uploading results into container
2025-04-09 10:39:29,776:INFO:Uploading model into container now
2025-04-09 10:39:29,776:INFO:_master_model_container: 13
2025-04-09 10:39:29,776:INFO:_display_container: 2
2025-04-09 10:39:29,777:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:39:29,777:INFO:create_model() successfully completed......................................
2025-04-09 10:39:29,863:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:29,863:INFO:Creating metrics dataframe
2025-04-09 10:39:29,878:INFO:Initializing Extra Trees Regressor
2025-04-09 10:39:29,878:INFO:Total runtime is 0.25333258708318074 minutes
2025-04-09 10:39:29,884:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:29,884:INFO:Initializing create_model()
2025-04-09 10:39:29,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:29,884:INFO:Checking exceptions
2025-04-09 10:39:29,884:INFO:Importing libraries
2025-04-09 10:39:29,885:INFO:Copying training dataset
2025-04-09 10:39:29,892:INFO:Defining folds
2025-04-09 10:39:29,893:INFO:Declaring metric variables
2025-04-09 10:39:29,900:INFO:Importing untrained model
2025-04-09 10:39:29,907:INFO:Extra Trees Regressor Imported successfully
2025-04-09 10:39:29,918:INFO:Starting cross validation
2025-04-09 10:39:29,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:32,286:INFO:Calculating mean and std
2025-04-09 10:39:32,288:INFO:Creating metrics dataframe
2025-04-09 10:39:32,291:INFO:Uploading results into container
2025-04-09 10:39:32,292:INFO:Uploading model into container now
2025-04-09 10:39:32,292:INFO:_master_model_container: 14
2025-04-09 10:39:32,293:INFO:_display_container: 2
2025-04-09 10:39:32,293:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:39:32,293:INFO:create_model() successfully completed......................................
2025-04-09 10:39:32,374:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:32,374:INFO:Creating metrics dataframe
2025-04-09 10:39:32,384:INFO:Initializing AdaBoost Regressor
2025-04-09 10:39:32,384:INFO:Total runtime is 0.29509778022766114 minutes
2025-04-09 10:39:32,387:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:32,387:INFO:Initializing create_model()
2025-04-09 10:39:32,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:32,387:INFO:Checking exceptions
2025-04-09 10:39:32,387:INFO:Importing libraries
2025-04-09 10:39:32,387:INFO:Copying training dataset
2025-04-09 10:39:32,391:INFO:Defining folds
2025-04-09 10:39:32,391:INFO:Declaring metric variables
2025-04-09 10:39:32,394:INFO:Importing untrained model
2025-04-09 10:39:32,396:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:39:32,401:INFO:Starting cross validation
2025-04-09 10:39:32,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:33,418:INFO:Calculating mean and std
2025-04-09 10:39:33,418:INFO:Creating metrics dataframe
2025-04-09 10:39:33,419:INFO:Uploading results into container
2025-04-09 10:39:33,419:INFO:Uploading model into container now
2025-04-09 10:39:33,419:INFO:_master_model_container: 15
2025-04-09 10:39:33,419:INFO:_display_container: 2
2025-04-09 10:39:33,419:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:39:33,419:INFO:create_model() successfully completed......................................
2025-04-09 10:39:33,460:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:33,460:INFO:Creating metrics dataframe
2025-04-09 10:39:33,465:INFO:Initializing Gradient Boosting Regressor
2025-04-09 10:39:33,465:INFO:Total runtime is 0.31311557292938236 minutes
2025-04-09 10:39:33,466:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:33,467:INFO:Initializing create_model()
2025-04-09 10:39:33,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:33,467:INFO:Checking exceptions
2025-04-09 10:39:33,467:INFO:Importing libraries
2025-04-09 10:39:33,467:INFO:Copying training dataset
2025-04-09 10:39:33,468:INFO:Defining folds
2025-04-09 10:39:33,468:INFO:Declaring metric variables
2025-04-09 10:39:33,469:INFO:Importing untrained model
2025-04-09 10:39:33,471:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 10:39:33,474:INFO:Starting cross validation
2025-04-09 10:39:33,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:34,774:INFO:Calculating mean and std
2025-04-09 10:39:34,775:INFO:Creating metrics dataframe
2025-04-09 10:39:34,775:INFO:Uploading results into container
2025-04-09 10:39:34,776:INFO:Uploading model into container now
2025-04-09 10:39:34,776:INFO:_master_model_container: 16
2025-04-09 10:39:34,776:INFO:_display_container: 2
2025-04-09 10:39:34,776:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 10:39:34,776:INFO:create_model() successfully completed......................................
2025-04-09 10:39:34,815:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:34,815:INFO:Creating metrics dataframe
2025-04-09 10:39:34,820:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 10:39:34,820:INFO:Total runtime is 0.33569656610488896 minutes
2025-04-09 10:39:34,821:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:34,821:INFO:Initializing create_model()
2025-04-09 10:39:34,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:34,821:INFO:Checking exceptions
2025-04-09 10:39:34,821:INFO:Importing libraries
2025-04-09 10:39:34,821:INFO:Copying training dataset
2025-04-09 10:39:34,823:INFO:Defining folds
2025-04-09 10:39:34,823:INFO:Declaring metric variables
2025-04-09 10:39:34,824:INFO:Importing untrained model
2025-04-09 10:39:34,826:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 10:39:34,829:INFO:Starting cross validation
2025-04-09 10:39:34,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:34,889:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:34,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025917 seconds.
2025-04-09 10:39:34,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:34,918:INFO:[LightGBM] [Info] Total Bins 1164
2025-04-09 10:39:34,923:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:39:34,931:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 10:39:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,647:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:35,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2025-04-09 10:39:35,648:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:35,648:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 10:39:35,648:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:39:35,648:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 10:39:35,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,736:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:35,736:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-09 10:39:35,736:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:35,737:INFO:[LightGBM] [Info] Total Bins 1195
2025-04-09 10:39:35,737:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:39:35,737:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 10:39:35,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:35,823:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:35,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031972 seconds.
2025-04-09 10:39:35,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:35,856:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 10:39:35,862:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:39:35,869:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 10:39:35,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,100:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:36,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2025-04-09 10:39:36,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:36,101:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 10:39:36,101:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:39:36,101:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,172:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:36,198:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024930 seconds.
2025-04-09 10:39:36,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:36,198:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 10:39:36,205:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:39:36,214:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 10:39:36,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:36,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:37,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:38,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,970:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:39,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004366 seconds.
2025-04-09 10:39:39,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:39,977:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 10:39:39,977:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:39:39,978:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 10:39:39,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:39,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,119:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:40,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023093 seconds.
2025-04-09 10:39:40,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:40,145:INFO:[LightGBM] [Info] Total Bins 1169
2025-04-09 10:39:40,150:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 64
2025-04-09 10:39:40,157:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 10:39:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,300:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:40,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2025-04-09 10:39:40,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:39:40,301:INFO:[LightGBM] [Info] Total Bins 1166
2025-04-09 10:39:40,301:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 64
2025-04-09 10:39:40,301:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 10:39:40,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,408:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:39:40,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000120 seconds.
2025-04-09 10:39:40,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-09 10:39:40,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-09 10:39:40,411:INFO:[LightGBM] [Info] Total Bins 1174
2025-04-09 10:39:40,412:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 64
2025-04-09 10:39:40,412:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 10:39:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:39:40,482:INFO:Calculating mean and std
2025-04-09 10:39:40,484:INFO:Creating metrics dataframe
2025-04-09 10:39:40,486:INFO:Uploading results into container
2025-04-09 10:39:40,486:INFO:Uploading model into container now
2025-04-09 10:39:40,487:INFO:_master_model_container: 17
2025-04-09 10:39:40,487:INFO:_display_container: 2
2025-04-09 10:39:40,487:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:39:40,487:INFO:create_model() successfully completed......................................
2025-04-09 10:39:40,563:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:40,563:INFO:Creating metrics dataframe
2025-04-09 10:39:40,570:INFO:Initializing Dummy Regressor
2025-04-09 10:39:40,570:INFO:Total runtime is 0.4315335631370545 minutes
2025-04-09 10:39:40,572:INFO:SubProcess create_model() called ==================================
2025-04-09 10:39:40,572:INFO:Initializing create_model()
2025-04-09 10:39:40,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b30a910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:40,572:INFO:Checking exceptions
2025-04-09 10:39:40,572:INFO:Importing libraries
2025-04-09 10:39:40,572:INFO:Copying training dataset
2025-04-09 10:39:40,574:INFO:Defining folds
2025-04-09 10:39:40,575:INFO:Declaring metric variables
2025-04-09 10:39:40,576:INFO:Importing untrained model
2025-04-09 10:39:40,578:INFO:Dummy Regressor Imported successfully
2025-04-09 10:39:40,581:INFO:Starting cross validation
2025-04-09 10:39:40,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:39:41,289:INFO:Calculating mean and std
2025-04-09 10:39:41,290:INFO:Creating metrics dataframe
2025-04-09 10:39:41,292:INFO:Uploading results into container
2025-04-09 10:39:41,292:INFO:Uploading model into container now
2025-04-09 10:39:41,292:INFO:_master_model_container: 18
2025-04-09 10:39:41,292:INFO:_display_container: 2
2025-04-09 10:39:41,293:INFO:DummyRegressor()
2025-04-09 10:39:41,293:INFO:create_model() successfully completed......................................
2025-04-09 10:39:41,337:INFO:SubProcess create_model() end ==================================
2025-04-09 10:39:41,337:INFO:Creating metrics dataframe
2025-04-09 10:39:41,341:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 10:39:41,345:INFO:Initializing create_model()
2025-04-09 10:39:41,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7404685c4f10>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:39:41,345:INFO:Checking exceptions
2025-04-09 10:39:41,346:INFO:Importing libraries
2025-04-09 10:39:41,346:INFO:Copying training dataset
2025-04-09 10:39:41,348:INFO:Defining folds
2025-04-09 10:39:41,348:INFO:Declaring metric variables
2025-04-09 10:39:41,348:INFO:Importing untrained model
2025-04-09 10:39:41,348:INFO:Declaring custom model
2025-04-09 10:39:41,348:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:39:41,348:INFO:Cross validation set to False
2025-04-09 10:39:41,348:INFO:Fitting Model
2025-04-09 10:39:41,546:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:39:41,547:INFO:create_model() successfully completed......................................
2025-04-09 10:39:41,619:INFO:_master_model_container: 18
2025-04-09 10:39:41,619:INFO:_display_container: 2
2025-04-09 10:39:41,619:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:39:41,619:INFO:compare_models() successfully completed......................................
2025-04-09 10:40:47,705:INFO:PyCaret RegressionExperiment
2025-04-09 10:40:47,705:INFO:Logging name: reg-default-name
2025-04-09 10:40:47,705:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-09 10:40:47,705:INFO:version 3.3.1
2025-04-09 10:40:47,705:INFO:Initializing setup()
2025-04-09 10:40:47,705:INFO:self.USI: 750d
2025-04-09 10:40:47,705:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'idx', 'seed', 'X', 'fold_groups_param', 'y', 'USI', 'y_train', 'html_param', 'gpu_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'memory', '_available_plots', 'transform_target_param', 'pipeline', 'X_train', 'log_plots_param', 'data', 'exp_id', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'y_test', 'target_param'}
2025-04-09 10:40:47,705:INFO:Checking environment
2025-04-09 10:40:47,705:INFO:python_version: 3.9.21
2025-04-09 10:40:47,705:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-04-09 10:40:47,705:INFO:machine: x86_64
2025-04-09 10:40:47,705:INFO:platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:40:47,705:INFO:Memory: svmem(total=33374547968, available=26361606144, percent=21.0, used=5478092800, free=18513494016, active=6935379968, inactive=5469392896, buffers=387907584, cached=8995053568, shared=1051889664, slab=1095806976)
2025-04-09 10:40:47,706:INFO:Physical Core: 24
2025-04-09 10:40:47,706:INFO:Logical Core: 32
2025-04-09 10:40:47,706:INFO:Checking libraries
2025-04-09 10:40:47,706:INFO:System:
2025-04-09 10:40:47,706:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-04-09 10:40:47,706:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-04-09 10:40:47,706:INFO:   machine: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 10:40:47,706:INFO:PyCaret required dependencies:
2025-04-09 10:40:47,706:INFO:                 pip: 25.0
2025-04-09 10:40:47,706:INFO:          setuptools: 75.8.0
2025-04-09 10:40:47,706:INFO:             pycaret: 3.3.1
2025-04-09 10:40:47,706:INFO:             IPython: 8.18.1
2025-04-09 10:40:47,706:INFO:          ipywidgets: 8.1.5
2025-04-09 10:40:47,706:INFO:                tqdm: 4.67.1
2025-04-09 10:40:47,706:INFO:               numpy: 1.26.4
2025-04-09 10:40:47,706:INFO:              pandas: 2.1.4
2025-04-09 10:40:47,706:INFO:              jinja2: 3.1.5
2025-04-09 10:40:47,706:INFO:               scipy: 1.11.4
2025-04-09 10:40:47,706:INFO:              joblib: 1.3.2
2025-04-09 10:40:47,706:INFO:             sklearn: 1.4.2
2025-04-09 10:40:47,706:INFO:                pyod: 2.0.3
2025-04-09 10:40:47,706:INFO:            imblearn: 0.12.4
2025-04-09 10:40:47,706:INFO:   category_encoders: 2.6.4
2025-04-09 10:40:47,706:INFO:            lightgbm: 4.6.0
2025-04-09 10:40:47,706:INFO:               numba: 0.60.0
2025-04-09 10:40:47,706:INFO:            requests: 2.32.3
2025-04-09 10:40:47,706:INFO:          matplotlib: 3.7.5
2025-04-09 10:40:47,706:INFO:          scikitplot: 0.3.7
2025-04-09 10:40:47,706:INFO:         yellowbrick: 1.5
2025-04-09 10:40:47,706:INFO:              plotly: 5.24.1
2025-04-09 10:40:47,706:INFO:    plotly-resampler: Not installed
2025-04-09 10:40:47,706:INFO:             kaleido: 0.2.1
2025-04-09 10:40:47,706:INFO:           schemdraw: 0.15
2025-04-09 10:40:47,706:INFO:         statsmodels: 0.14.4
2025-04-09 10:40:47,706:INFO:              sktime: 0.26.0
2025-04-09 10:40:47,706:INFO:               tbats: 1.1.3
2025-04-09 10:40:47,706:INFO:            pmdarima: 2.0.4
2025-04-09 10:40:47,706:INFO:              psutil: 7.0.0
2025-04-09 10:40:47,706:INFO:          markupsafe: 3.0.2
2025-04-09 10:40:47,706:INFO:             pickle5: Not installed
2025-04-09 10:40:47,706:INFO:         cloudpickle: 3.1.1
2025-04-09 10:40:47,706:INFO:         deprecation: 2.1.0
2025-04-09 10:40:47,706:INFO:              xxhash: 3.5.0
2025-04-09 10:40:47,706:INFO:           wurlitzer: 3.1.1
2025-04-09 10:40:47,706:INFO:PyCaret optional dependencies:
2025-04-09 10:40:47,706:INFO:                shap: Not installed
2025-04-09 10:40:47,706:INFO:           interpret: Not installed
2025-04-09 10:40:47,706:INFO:                umap: Not installed
2025-04-09 10:40:47,706:INFO:     ydata_profiling: Not installed
2025-04-09 10:40:47,706:INFO:  explainerdashboard: Not installed
2025-04-09 10:40:47,706:INFO:             autoviz: Not installed
2025-04-09 10:40:47,706:INFO:           fairlearn: Not installed
2025-04-09 10:40:47,706:INFO:          deepchecks: Not installed
2025-04-09 10:40:47,706:INFO:             xgboost: Not installed
2025-04-09 10:40:47,706:INFO:            catboost: Not installed
2025-04-09 10:40:47,706:INFO:              kmodes: Not installed
2025-04-09 10:40:47,706:INFO:             mlxtend: Not installed
2025-04-09 10:40:47,706:INFO:       statsforecast: Not installed
2025-04-09 10:40:47,706:INFO:        tune_sklearn: Not installed
2025-04-09 10:40:47,707:INFO:                 ray: Not installed
2025-04-09 10:40:47,707:INFO:            hyperopt: Not installed
2025-04-09 10:40:47,707:INFO:              optuna: Not installed
2025-04-09 10:40:47,707:INFO:               skopt: Not installed
2025-04-09 10:40:47,707:INFO:              mlflow: Not installed
2025-04-09 10:40:47,707:INFO:              gradio: Not installed
2025-04-09 10:40:47,707:INFO:             fastapi: Not installed
2025-04-09 10:40:47,707:INFO:             uvicorn: Not installed
2025-04-09 10:40:47,707:INFO:              m2cgen: Not installed
2025-04-09 10:40:47,707:INFO:           evidently: Not installed
2025-04-09 10:40:47,707:INFO:               fugue: Not installed
2025-04-09 10:40:47,707:INFO:           streamlit: Not installed
2025-04-09 10:40:47,707:INFO:             prophet: Not installed
2025-04-09 10:40:47,707:INFO:None
2025-04-09 10:40:47,707:INFO:Set up GPU usage.
2025-04-09 10:40:47,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,707:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-04-09 10:40:47,707:INFO:Set up data.
2025-04-09 10:40:47,710:INFO:Set up folding strategy.
2025-04-09 10:40:47,710:INFO:Set up train/test split.
2025-04-09 10:40:47,711:INFO:Set up index.
2025-04-09 10:40:47,711:INFO:Assigning column types.
2025-04-09 10:40:47,713:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-09 10:40:47,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,717:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:47,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:47,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,837:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,842:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,848:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:47,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:47,898:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-09 10:40:47,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,900:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,903:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:47,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:47,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,006:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,009:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,036:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,058:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-09 10:40:48,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,311:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-09 10:40:48,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,427:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-09 10:40:48,427:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,427:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 10:40:48,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,646:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-09 10:40:48,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,761:INFO:Preparing preprocessing pipeline...
2025-04-09 10:40:48,761:INFO:Set up simple imputation.
2025-04-09 10:40:48,762:INFO:Set up encoding of categorical features.
2025-04-09 10:40:48,762:INFO:Set up polynomial features.
2025-04-09 10:40:48,785:INFO:Finished creating preprocessing pipeline.
2025-04-09 10:40:48,789:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-04-09 10:40:48,789:INFO:Creating final display dataframe.
2025-04-09 10:40:48,860:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape         (155, 10)
4        Transformed data shape         (155, 55)
5   Transformed train set shape         (108, 55)
6    Transformed test set shape          (47, 55)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU              True
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              750d
2025-04-09 10:40:48,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:48,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:48,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:49,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:49,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 10:40:49,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:49,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 10:40:49,010:INFO:setup() successfully completed in 1.31s...............
2025-04-09 10:40:51,167:INFO:Initializing compare_models()
2025-04-09 10:40:51,168:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 10:40:51,168:INFO:Checking exceptions
2025-04-09 10:40:51,172:INFO:Preparing display monitor
2025-04-09 10:40:51,216:INFO:Initializing Linear Regression
2025-04-09 10:40:51,216:INFO:Total runtime is 4.967053731282552e-06 minutes
2025-04-09 10:40:51,223:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:51,223:INFO:Initializing create_model()
2025-04-09 10:40:51,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:51,224:INFO:Checking exceptions
2025-04-09 10:40:51,224:INFO:Importing libraries
2025-04-09 10:40:51,224:INFO:Copying training dataset
2025-04-09 10:40:51,231:INFO:Defining folds
2025-04-09 10:40:51,231:INFO:Declaring metric variables
2025-04-09 10:40:51,238:INFO:Importing untrained model
2025-04-09 10:40:51,245:INFO:Linear Regression Imported successfully
2025-04-09 10:40:51,262:INFO:Starting cross validation
2025-04-09 10:40:51,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:51,621:INFO:Calculating mean and std
2025-04-09 10:40:51,621:INFO:Creating metrics dataframe
2025-04-09 10:40:51,622:INFO:Uploading results into container
2025-04-09 10:40:51,622:INFO:Uploading model into container now
2025-04-09 10:40:51,622:INFO:_master_model_container: 1
2025-04-09 10:40:51,622:INFO:_display_container: 2
2025-04-09 10:40:51,623:INFO:LinearRegression(n_jobs=-1)
2025-04-09 10:40:51,623:INFO:create_model() successfully completed......................................
2025-04-09 10:40:51,676:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:51,676:INFO:Creating metrics dataframe
2025-04-09 10:40:51,679:INFO:Initializing Lasso Regression
2025-04-09 10:40:51,679:INFO:Total runtime is 0.0077235420544942215 minutes
2025-04-09 10:40:51,681:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:51,681:INFO:Initializing create_model()
2025-04-09 10:40:51,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:51,681:INFO:Checking exceptions
2025-04-09 10:40:51,681:INFO:Importing libraries
2025-04-09 10:40:51,681:INFO:Copying training dataset
2025-04-09 10:40:51,683:INFO:Defining folds
2025-04-09 10:40:51,683:INFO:Declaring metric variables
2025-04-09 10:40:51,685:INFO:Importing untrained model
2025-04-09 10:40:51,687:INFO:Lasso Regression Imported successfully
2025-04-09 10:40:51,690:INFO:Starting cross validation
2025-04-09 10:40:51,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:51,717:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,742:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,770:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,795:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,825:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,849:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,874:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,901:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,925:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,950:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:51,959:INFO:Calculating mean and std
2025-04-09 10:40:51,959:INFO:Creating metrics dataframe
2025-04-09 10:40:51,960:INFO:Uploading results into container
2025-04-09 10:40:51,960:INFO:Uploading model into container now
2025-04-09 10:40:51,960:INFO:_master_model_container: 2
2025-04-09 10:40:51,960:INFO:_display_container: 2
2025-04-09 10:40:51,961:INFO:Lasso(random_state=123)
2025-04-09 10:40:51,961:INFO:create_model() successfully completed......................................
2025-04-09 10:40:52,007:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:52,007:INFO:Creating metrics dataframe
2025-04-09 10:40:52,010:INFO:Initializing Ridge Regression
2025-04-09 10:40:52,010:INFO:Total runtime is 0.013234821955362956 minutes
2025-04-09 10:40:52,012:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:52,012:INFO:Initializing create_model()
2025-04-09 10:40:52,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:52,012:INFO:Checking exceptions
2025-04-09 10:40:52,012:INFO:Importing libraries
2025-04-09 10:40:52,012:INFO:Copying training dataset
2025-04-09 10:40:52,014:INFO:Defining folds
2025-04-09 10:40:52,014:INFO:Declaring metric variables
2025-04-09 10:40:52,015:INFO:Importing untrained model
2025-04-09 10:40:52,017:INFO:Ridge Regression Imported successfully
2025-04-09 10:40:52,019:INFO:Starting cross validation
2025-04-09 10:40:52,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:52,039:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.5654e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,062:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.81945e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,084:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57492e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,107:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.61294e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,130:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6252e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,154:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57721e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,177:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57265e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,200:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.56553e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,223:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.51317e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,246:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.53625e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:40:52,255:INFO:Calculating mean and std
2025-04-09 10:40:52,255:INFO:Creating metrics dataframe
2025-04-09 10:40:52,256:INFO:Uploading results into container
2025-04-09 10:40:52,256:INFO:Uploading model into container now
2025-04-09 10:40:52,257:INFO:_master_model_container: 3
2025-04-09 10:40:52,257:INFO:_display_container: 2
2025-04-09 10:40:52,257:INFO:Ridge(random_state=123)
2025-04-09 10:40:52,257:INFO:create_model() successfully completed......................................
2025-04-09 10:40:52,304:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:52,304:INFO:Creating metrics dataframe
2025-04-09 10:40:52,307:INFO:Initializing Elastic Net
2025-04-09 10:40:52,307:INFO:Total runtime is 0.018191595872243248 minutes
2025-04-09 10:40:52,309:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:52,309:INFO:Initializing create_model()
2025-04-09 10:40:52,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:52,309:INFO:Checking exceptions
2025-04-09 10:40:52,309:INFO:Importing libraries
2025-04-09 10:40:52,309:INFO:Copying training dataset
2025-04-09 10:40:52,311:INFO:Defining folds
2025-04-09 10:40:52,311:INFO:Declaring metric variables
2025-04-09 10:40:52,312:INFO:Importing untrained model
2025-04-09 10:40:52,314:INFO:Elastic Net Imported successfully
2025-04-09 10:40:52,316:INFO:Starting cross validation
2025-04-09 10:40:52,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:52,337:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,363:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,390:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,414:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,440:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,466:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,492:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,517:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,543:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,568:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:40:52,578:INFO:Calculating mean and std
2025-04-09 10:40:52,579:INFO:Creating metrics dataframe
2025-04-09 10:40:52,580:INFO:Uploading results into container
2025-04-09 10:40:52,580:INFO:Uploading model into container now
2025-04-09 10:40:52,580:INFO:_master_model_container: 4
2025-04-09 10:40:52,580:INFO:_display_container: 2
2025-04-09 10:40:52,580:INFO:ElasticNet(random_state=123)
2025-04-09 10:40:52,580:INFO:create_model() successfully completed......................................
2025-04-09 10:40:52,626:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:52,626:INFO:Creating metrics dataframe
2025-04-09 10:40:52,630:INFO:Initializing Least Angle Regression
2025-04-09 10:40:52,630:INFO:Total runtime is 0.02356520493825277 minutes
2025-04-09 10:40:52,631:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:52,632:INFO:Initializing create_model()
2025-04-09 10:40:52,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:52,632:INFO:Checking exceptions
2025-04-09 10:40:52,632:INFO:Importing libraries
2025-04-09 10:40:52,632:INFO:Copying training dataset
2025-04-09 10:40:52,633:INFO:Defining folds
2025-04-09 10:40:52,633:INFO:Declaring metric variables
2025-04-09 10:40:52,635:INFO:Importing untrained model
2025-04-09 10:40:52,636:INFO:Least Angle Regression Imported successfully
2025-04-09 10:40:52,639:INFO:Starting cross validation
2025-04-09 10:40:52,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:52,672:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.030e+07, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,702:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.736e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,729:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.082e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.317e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,755:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=9.092e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,782:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.505e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,809:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=8.994e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.158e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,836:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.148e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,864:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.313e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,891:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.654e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,919:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=6.212e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.667e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:40:52,928:INFO:Calculating mean and std
2025-04-09 10:40:52,929:INFO:Creating metrics dataframe
2025-04-09 10:40:52,930:INFO:Uploading results into container
2025-04-09 10:40:52,930:INFO:Uploading model into container now
2025-04-09 10:40:52,930:INFO:_master_model_container: 5
2025-04-09 10:40:52,930:INFO:_display_container: 2
2025-04-09 10:40:52,930:INFO:Lars(random_state=123)
2025-04-09 10:40:52,931:INFO:create_model() successfully completed......................................
2025-04-09 10:40:52,978:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:52,978:INFO:Creating metrics dataframe
2025-04-09 10:40:52,981:INFO:Initializing Lasso Least Angle Regression
2025-04-09 10:40:52,981:INFO:Total runtime is 0.02942365407943726 minutes
2025-04-09 10:40:52,983:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:52,983:INFO:Initializing create_model()
2025-04-09 10:40:52,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:52,983:INFO:Checking exceptions
2025-04-09 10:40:52,983:INFO:Importing libraries
2025-04-09 10:40:52,983:INFO:Copying training dataset
2025-04-09 10:40:52,985:INFO:Defining folds
2025-04-09 10:40:52,985:INFO:Declaring metric variables
2025-04-09 10:40:52,986:INFO:Importing untrained model
2025-04-09 10:40:52,987:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 10:40:52,990:INFO:Starting cross validation
2025-04-09 10:40:52,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:53,245:INFO:Calculating mean and std
2025-04-09 10:40:53,245:INFO:Creating metrics dataframe
2025-04-09 10:40:53,246:INFO:Uploading results into container
2025-04-09 10:40:53,246:INFO:Uploading model into container now
2025-04-09 10:40:53,247:INFO:_master_model_container: 6
2025-04-09 10:40:53,247:INFO:_display_container: 2
2025-04-09 10:40:53,247:INFO:LassoLars(random_state=123)
2025-04-09 10:40:53,247:INFO:create_model() successfully completed......................................
2025-04-09 10:40:53,298:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:53,298:INFO:Creating metrics dataframe
2025-04-09 10:40:53,302:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 10:40:53,302:INFO:Total runtime is 0.03476536273956299 minutes
2025-04-09 10:40:53,303:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:53,304:INFO:Initializing create_model()
2025-04-09 10:40:53,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:53,304:INFO:Checking exceptions
2025-04-09 10:40:53,304:INFO:Importing libraries
2025-04-09 10:40:53,304:INFO:Copying training dataset
2025-04-09 10:40:53,305:INFO:Defining folds
2025-04-09 10:40:53,305:INFO:Declaring metric variables
2025-04-09 10:40:53,307:INFO:Importing untrained model
2025-04-09 10:40:53,308:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 10:40:53,311:INFO:Starting cross validation
2025-04-09 10:40:53,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:53,545:INFO:Calculating mean and std
2025-04-09 10:40:53,545:INFO:Creating metrics dataframe
2025-04-09 10:40:53,546:INFO:Uploading results into container
2025-04-09 10:40:53,546:INFO:Uploading model into container now
2025-04-09 10:40:53,547:INFO:_master_model_container: 7
2025-04-09 10:40:53,547:INFO:_display_container: 2
2025-04-09 10:40:53,547:INFO:OrthogonalMatchingPursuit()
2025-04-09 10:40:53,547:INFO:create_model() successfully completed......................................
2025-04-09 10:40:53,595:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:53,595:INFO:Creating metrics dataframe
2025-04-09 10:40:53,599:INFO:Initializing Bayesian Ridge
2025-04-09 10:40:53,599:INFO:Total runtime is 0.03971420526504517 minutes
2025-04-09 10:40:53,600:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:53,600:INFO:Initializing create_model()
2025-04-09 10:40:53,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:53,600:INFO:Checking exceptions
2025-04-09 10:40:53,600:INFO:Importing libraries
2025-04-09 10:40:53,600:INFO:Copying training dataset
2025-04-09 10:40:53,602:INFO:Defining folds
2025-04-09 10:40:53,602:INFO:Declaring metric variables
2025-04-09 10:40:53,604:INFO:Importing untrained model
2025-04-09 10:40:53,605:INFO:Bayesian Ridge Imported successfully
2025-04-09 10:40:53,608:INFO:Starting cross validation
2025-04-09 10:40:53,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:54,167:INFO:Calculating mean and std
2025-04-09 10:40:54,168:INFO:Creating metrics dataframe
2025-04-09 10:40:54,170:INFO:Uploading results into container
2025-04-09 10:40:54,171:INFO:Uploading model into container now
2025-04-09 10:40:54,172:INFO:_master_model_container: 8
2025-04-09 10:40:54,172:INFO:_display_container: 2
2025-04-09 10:40:54,172:INFO:BayesianRidge()
2025-04-09 10:40:54,172:INFO:create_model() successfully completed......................................
2025-04-09 10:40:54,241:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:54,241:INFO:Creating metrics dataframe
2025-04-09 10:40:54,251:INFO:Initializing Passive Aggressive Regressor
2025-04-09 10:40:54,251:INFO:Total runtime is 0.05058817863464356 minutes
2025-04-09 10:40:54,255:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:54,255:INFO:Initializing create_model()
2025-04-09 10:40:54,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:54,255:INFO:Checking exceptions
2025-04-09 10:40:54,256:INFO:Importing libraries
2025-04-09 10:40:54,256:INFO:Copying training dataset
2025-04-09 10:40:54,259:INFO:Defining folds
2025-04-09 10:40:54,259:INFO:Declaring metric variables
2025-04-09 10:40:54,262:INFO:Importing untrained model
2025-04-09 10:40:54,265:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 10:40:54,270:INFO:Starting cross validation
2025-04-09 10:40:54,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:54,512:INFO:Calculating mean and std
2025-04-09 10:40:54,512:INFO:Creating metrics dataframe
2025-04-09 10:40:54,513:INFO:Uploading results into container
2025-04-09 10:40:54,513:INFO:Uploading model into container now
2025-04-09 10:40:54,514:INFO:_master_model_container: 9
2025-04-09 10:40:54,514:INFO:_display_container: 2
2025-04-09 10:40:54,514:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 10:40:54,514:INFO:create_model() successfully completed......................................
2025-04-09 10:40:54,561:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:54,561:INFO:Creating metrics dataframe
2025-04-09 10:40:54,565:INFO:Initializing Huber Regressor
2025-04-09 10:40:54,565:INFO:Total runtime is 0.055810793240865075 minutes
2025-04-09 10:40:54,566:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:54,566:INFO:Initializing create_model()
2025-04-09 10:40:54,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:54,566:INFO:Checking exceptions
2025-04-09 10:40:54,566:INFO:Importing libraries
2025-04-09 10:40:54,566:INFO:Copying training dataset
2025-04-09 10:40:54,568:INFO:Defining folds
2025-04-09 10:40:54,568:INFO:Declaring metric variables
2025-04-09 10:40:54,569:INFO:Importing untrained model
2025-04-09 10:40:54,571:INFO:Huber Regressor Imported successfully
2025-04-09 10:40:54,574:INFO:Starting cross validation
2025-04-09 10:40:54,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:54,599:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,630:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,790:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,819:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,849:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,879:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,910:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,940:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,971:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:40:54,980:INFO:Calculating mean and std
2025-04-09 10:40:54,981:INFO:Creating metrics dataframe
2025-04-09 10:40:54,982:INFO:Uploading results into container
2025-04-09 10:40:54,982:INFO:Uploading model into container now
2025-04-09 10:40:54,982:INFO:_master_model_container: 10
2025-04-09 10:40:54,982:INFO:_display_container: 2
2025-04-09 10:40:54,982:INFO:HuberRegressor()
2025-04-09 10:40:54,982:INFO:create_model() successfully completed......................................
2025-04-09 10:40:55,029:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:55,029:INFO:Creating metrics dataframe
2025-04-09 10:40:55,033:INFO:Initializing K Neighbors Regressor
2025-04-09 10:40:55,033:INFO:Total runtime is 0.06361299753189087 minutes
2025-04-09 10:40:55,034:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:55,034:INFO:Initializing create_model()
2025-04-09 10:40:55,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:55,034:INFO:Checking exceptions
2025-04-09 10:40:55,034:INFO:Importing libraries
2025-04-09 10:40:55,034:INFO:Copying training dataset
2025-04-09 10:40:55,036:INFO:Defining folds
2025-04-09 10:40:55,036:INFO:Declaring metric variables
2025-04-09 10:40:55,037:INFO:Importing untrained model
2025-04-09 10:40:55,039:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:40:55,041:INFO:Starting cross validation
2025-04-09 10:40:55,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:55,410:INFO:Calculating mean and std
2025-04-09 10:40:55,410:INFO:Creating metrics dataframe
2025-04-09 10:40:55,411:INFO:Uploading results into container
2025-04-09 10:40:55,412:INFO:Uploading model into container now
2025-04-09 10:40:55,412:INFO:_master_model_container: 11
2025-04-09 10:40:55,412:INFO:_display_container: 2
2025-04-09 10:40:55,412:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:40:55,412:INFO:create_model() successfully completed......................................
2025-04-09 10:40:55,469:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:55,469:INFO:Creating metrics dataframe
2025-04-09 10:40:55,474:INFO:Initializing Decision Tree Regressor
2025-04-09 10:40:55,474:INFO:Total runtime is 0.07096112966537475 minutes
2025-04-09 10:40:55,475:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:55,475:INFO:Initializing create_model()
2025-04-09 10:40:55,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:55,475:INFO:Checking exceptions
2025-04-09 10:40:55,475:INFO:Importing libraries
2025-04-09 10:40:55,475:INFO:Copying training dataset
2025-04-09 10:40:55,477:INFO:Defining folds
2025-04-09 10:40:55,477:INFO:Declaring metric variables
2025-04-09 10:40:55,478:INFO:Importing untrained model
2025-04-09 10:40:55,480:INFO:Decision Tree Regressor Imported successfully
2025-04-09 10:40:55,484:INFO:Starting cross validation
2025-04-09 10:40:55,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:55,800:INFO:Calculating mean and std
2025-04-09 10:40:55,801:INFO:Creating metrics dataframe
2025-04-09 10:40:55,801:INFO:Uploading results into container
2025-04-09 10:40:55,802:INFO:Uploading model into container now
2025-04-09 10:40:55,802:INFO:_master_model_container: 12
2025-04-09 10:40:55,802:INFO:_display_container: 2
2025-04-09 10:40:55,802:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 10:40:55,802:INFO:create_model() successfully completed......................................
2025-04-09 10:40:55,847:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:55,847:INFO:Creating metrics dataframe
2025-04-09 10:40:55,851:INFO:Initializing Random Forest Regressor
2025-04-09 10:40:55,851:INFO:Total runtime is 0.07725814580917358 minutes
2025-04-09 10:40:55,853:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:55,853:INFO:Initializing create_model()
2025-04-09 10:40:55,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:55,853:INFO:Checking exceptions
2025-04-09 10:40:55,853:INFO:Importing libraries
2025-04-09 10:40:55,853:INFO:Copying training dataset
2025-04-09 10:40:55,855:INFO:Defining folds
2025-04-09 10:40:55,855:INFO:Declaring metric variables
2025-04-09 10:40:55,856:INFO:Importing untrained model
2025-04-09 10:40:55,857:INFO:Random Forest Regressor Imported successfully
2025-04-09 10:40:55,860:INFO:Starting cross validation
2025-04-09 10:40:55,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:40:59,777:INFO:Calculating mean and std
2025-04-09 10:40:59,779:INFO:Creating metrics dataframe
2025-04-09 10:40:59,782:INFO:Uploading results into container
2025-04-09 10:40:59,784:INFO:Uploading model into container now
2025-04-09 10:40:59,784:INFO:_master_model_container: 13
2025-04-09 10:40:59,784:INFO:_display_container: 2
2025-04-09 10:40:59,785:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:40:59,785:INFO:create_model() successfully completed......................................
2025-04-09 10:40:59,888:INFO:SubProcess create_model() end ==================================
2025-04-09 10:40:59,888:INFO:Creating metrics dataframe
2025-04-09 10:40:59,909:INFO:Initializing Extra Trees Regressor
2025-04-09 10:40:59,909:INFO:Total runtime is 0.14488209883371989 minutes
2025-04-09 10:40:59,916:INFO:SubProcess create_model() called ==================================
2025-04-09 10:40:59,917:INFO:Initializing create_model()
2025-04-09 10:40:59,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:40:59,917:INFO:Checking exceptions
2025-04-09 10:40:59,917:INFO:Importing libraries
2025-04-09 10:40:59,917:INFO:Copying training dataset
2025-04-09 10:40:59,926:INFO:Defining folds
2025-04-09 10:40:59,926:INFO:Declaring metric variables
2025-04-09 10:40:59,933:INFO:Importing untrained model
2025-04-09 10:40:59,940:INFO:Extra Trees Regressor Imported successfully
2025-04-09 10:40:59,955:INFO:Starting cross validation
2025-04-09 10:40:59,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:41:02,695:INFO:Calculating mean and std
2025-04-09 10:41:02,697:INFO:Creating metrics dataframe
2025-04-09 10:41:02,700:INFO:Uploading results into container
2025-04-09 10:41:02,702:INFO:Uploading model into container now
2025-04-09 10:41:02,702:INFO:_master_model_container: 14
2025-04-09 10:41:02,703:INFO:_display_container: 2
2025-04-09 10:41:02,703:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:41:02,703:INFO:create_model() successfully completed......................................
2025-04-09 10:41:02,796:INFO:SubProcess create_model() end ==================================
2025-04-09 10:41:02,797:INFO:Creating metrics dataframe
2025-04-09 10:41:02,811:INFO:Initializing AdaBoost Regressor
2025-04-09 10:41:02,812:INFO:Total runtime is 0.19326114654541016 minutes
2025-04-09 10:41:02,817:INFO:SubProcess create_model() called ==================================
2025-04-09 10:41:02,817:INFO:Initializing create_model()
2025-04-09 10:41:02,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:41:02,817:INFO:Checking exceptions
2025-04-09 10:41:02,817:INFO:Importing libraries
2025-04-09 10:41:02,817:INFO:Copying training dataset
2025-04-09 10:41:02,823:INFO:Defining folds
2025-04-09 10:41:02,824:INFO:Declaring metric variables
2025-04-09 10:41:02,828:INFO:Importing untrained model
2025-04-09 10:41:02,833:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:41:02,842:INFO:Starting cross validation
2025-04-09 10:41:02,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:41:03,737:INFO:Calculating mean and std
2025-04-09 10:41:03,737:INFO:Creating metrics dataframe
2025-04-09 10:41:03,738:INFO:Uploading results into container
2025-04-09 10:41:03,739:INFO:Uploading model into container now
2025-04-09 10:41:03,739:INFO:_master_model_container: 15
2025-04-09 10:41:03,739:INFO:_display_container: 2
2025-04-09 10:41:03,739:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:41:03,739:INFO:create_model() successfully completed......................................
2025-04-09 10:41:03,780:INFO:SubProcess create_model() end ==================================
2025-04-09 10:41:03,780:INFO:Creating metrics dataframe
2025-04-09 10:41:03,784:INFO:Initializing Gradient Boosting Regressor
2025-04-09 10:41:03,784:INFO:Total runtime is 0.20947181781133017 minutes
2025-04-09 10:41:03,786:INFO:SubProcess create_model() called ==================================
2025-04-09 10:41:03,786:INFO:Initializing create_model()
2025-04-09 10:41:03,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:41:03,786:INFO:Checking exceptions
2025-04-09 10:41:03,786:INFO:Importing libraries
2025-04-09 10:41:03,786:INFO:Copying training dataset
2025-04-09 10:41:03,788:INFO:Defining folds
2025-04-09 10:41:03,788:INFO:Declaring metric variables
2025-04-09 10:41:03,789:INFO:Importing untrained model
2025-04-09 10:41:03,790:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 10:41:03,793:INFO:Starting cross validation
2025-04-09 10:41:03,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:41:04,748:INFO:Calculating mean and std
2025-04-09 10:41:04,748:INFO:Creating metrics dataframe
2025-04-09 10:41:04,749:INFO:Uploading results into container
2025-04-09 10:41:04,749:INFO:Uploading model into container now
2025-04-09 10:41:04,750:INFO:_master_model_container: 16
2025-04-09 10:41:04,750:INFO:_display_container: 2
2025-04-09 10:41:04,750:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 10:41:04,750:INFO:create_model() successfully completed......................................
2025-04-09 10:41:04,791:INFO:SubProcess create_model() end ==================================
2025-04-09 10:41:04,791:INFO:Creating metrics dataframe
2025-04-09 10:41:04,795:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 10:41:04,795:INFO:Total runtime is 0.226323672135671 minutes
2025-04-09 10:41:04,797:INFO:SubProcess create_model() called ==================================
2025-04-09 10:41:04,797:INFO:Initializing create_model()
2025-04-09 10:41:04,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:41:04,797:INFO:Checking exceptions
2025-04-09 10:41:04,797:INFO:Importing libraries
2025-04-09 10:41:04,797:INFO:Copying training dataset
2025-04-09 10:41:04,799:INFO:Defining folds
2025-04-09 10:41:04,799:INFO:Declaring metric variables
2025-04-09 10:41:04,800:INFO:Importing untrained model
2025-04-09 10:41:04,802:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 10:41:04,804:INFO:Starting cross validation
2025-04-09 10:41:04,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:41:04,839:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:04,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025215 seconds.
2025-04-09 10:41:04,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:04,865:INFO:[LightGBM] [Info] Total Bins 1122
2025-04-09 10:41:04,872:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:04,879:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 10:41:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,987:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:04,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-09 10:41:04,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:04,987:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 10:41:04,988:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:04,988:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,059:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024306 seconds.
2025-04-09 10:41:05,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,085:INFO:[LightGBM] [Info] Total Bins 1152
2025-04-09 10:41:05,091:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,098:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 10:41:05,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,167:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-09 10:41:05,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,167:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 10:41:05,167:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,168:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,224:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2025-04-09 10:41:05,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,224:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 10:41:05,224:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,225:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 10:41:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,286:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2025-04-09 10:41:05,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,287:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 10:41:05,287:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,287:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 10:41:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,355:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026396 seconds.
2025-04-09 10:41:05,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,383:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 10:41:05,391:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,397:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 10:41:05,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,490:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002667 seconds.
2025-04-09 10:41:05,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-09 10:41:05,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-09 10:41:05,495:INFO:[LightGBM] [Info] Total Bins 1126
2025-04-09 10:41:05,495:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:41:05,496:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 10:41:05,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,558:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2025-04-09 10:41:05,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,559:INFO:[LightGBM] [Info] Total Bins 1123
2025-04-09 10:41:05,559:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:41:05,559:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 10:41:05,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,618:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:41:05,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2025-04-09 10:41:05,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:41:05,619:INFO:[LightGBM] [Info] Total Bins 1132
2025-04-09 10:41:05,620:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:41:05,620:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 10:41:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:41:05,660:INFO:Calculating mean and std
2025-04-09 10:41:05,661:INFO:Creating metrics dataframe
2025-04-09 10:41:05,663:INFO:Uploading results into container
2025-04-09 10:41:05,663:INFO:Uploading model into container now
2025-04-09 10:41:05,664:INFO:_master_model_container: 17
2025-04-09 10:41:05,664:INFO:_display_container: 2
2025-04-09 10:41:05,664:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:41:05,664:INFO:create_model() successfully completed......................................
2025-04-09 10:41:05,710:INFO:SubProcess create_model() end ==================================
2025-04-09 10:41:05,710:INFO:Creating metrics dataframe
2025-04-09 10:41:05,715:INFO:Initializing Dummy Regressor
2025-04-09 10:41:05,715:INFO:Total runtime is 0.24164659976959232 minutes
2025-04-09 10:41:05,717:INFO:SubProcess create_model() called ==================================
2025-04-09 10:41:05,717:INFO:Initializing create_model()
2025-04-09 10:41:05,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b311520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:41:05,717:INFO:Checking exceptions
2025-04-09 10:41:05,717:INFO:Importing libraries
2025-04-09 10:41:05,717:INFO:Copying training dataset
2025-04-09 10:41:05,720:INFO:Defining folds
2025-04-09 10:41:05,720:INFO:Declaring metric variables
2025-04-09 10:41:05,723:INFO:Importing untrained model
2025-04-09 10:41:05,728:INFO:Dummy Regressor Imported successfully
2025-04-09 10:41:05,737:INFO:Starting cross validation
2025-04-09 10:41:05,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:41:06,012:INFO:Calculating mean and std
2025-04-09 10:41:06,012:INFO:Creating metrics dataframe
2025-04-09 10:41:06,013:INFO:Uploading results into container
2025-04-09 10:41:06,013:INFO:Uploading model into container now
2025-04-09 10:41:06,013:INFO:_master_model_container: 18
2025-04-09 10:41:06,013:INFO:_display_container: 2
2025-04-09 10:41:06,014:INFO:DummyRegressor()
2025-04-09 10:41:06,014:INFO:create_model() successfully completed......................................
2025-04-09 10:41:06,054:INFO:SubProcess create_model() end ==================================
2025-04-09 10:41:06,054:INFO:Creating metrics dataframe
2025-04-09 10:41:06,059:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 10:41:06,063:INFO:Initializing create_model()
2025-04-09 10:41:06,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:41:06,063:INFO:Checking exceptions
2025-04-09 10:41:06,064:INFO:Importing libraries
2025-04-09 10:41:06,064:INFO:Copying training dataset
2025-04-09 10:41:06,065:INFO:Defining folds
2025-04-09 10:41:06,066:INFO:Declaring metric variables
2025-04-09 10:41:06,066:INFO:Importing untrained model
2025-04-09 10:41:06,066:INFO:Declaring custom model
2025-04-09 10:41:06,066:INFO:Elastic Net Imported successfully
2025-04-09 10:41:06,066:INFO:Cross validation set to False
2025-04-09 10:41:06,066:INFO:Fitting Model
2025-04-09 10:41:06,091:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e-01, tolerance: 1.897e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:41:06,092:INFO:ElasticNet(random_state=123)
2025-04-09 10:41:06,092:INFO:create_model() successfully completed......................................
2025-04-09 10:41:06,243:INFO:_master_model_container: 18
2025-04-09 10:41:06,244:INFO:_display_container: 2
2025-04-09 10:41:06,244:INFO:ElasticNet(random_state=123)
2025-04-09 10:41:06,244:INFO:compare_models() successfully completed......................................
2025-04-09 10:41:08,984:INFO:Initializing evaluate_model()
2025-04-09 10:41:08,984:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ElasticNet(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-09 10:41:09,008:INFO:Initializing plot_model()
2025-04-09 10:41:09,008:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ElasticNet(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, system=True)
2025-04-09 10:41:09,008:INFO:Checking exceptions
2025-04-09 10:41:09,011:INFO:Preloading libraries
2025-04-09 10:41:09,011:INFO:Copying training dataset
2025-04-09 10:41:09,012:INFO:Plot type: pipeline
2025-04-09 10:41:09,219:INFO:Visual Rendered Successfully
2025-04-09 10:41:09,308:INFO:plot_model() successfully completed......................................
2025-04-09 10:41:10,941:INFO:Initializing plot_model()
2025-04-09 10:41:10,941:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ElasticNet(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, system=True)
2025-04-09 10:41:10,941:INFO:Checking exceptions
2025-04-09 10:41:10,946:INFO:Preloading libraries
2025-04-09 10:41:10,947:INFO:Copying training dataset
2025-04-09 10:41:10,947:INFO:Plot type: residuals
2025-04-09 10:41:11,191:INFO:Fitting Model
2025-04-09 10:41:11,193:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names
  warnings.warn(

2025-04-09 10:41:11,271:INFO:Scoring test/hold-out set
2025-04-09 10:41:11,683:INFO:Visual Rendered Successfully
2025-04-09 10:41:11,737:INFO:plot_model() successfully completed......................................
2025-04-09 10:41:12,350:INFO:Initializing plot_model()
2025-04-09 10:41:12,350:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=ElasticNet(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, system=True)
2025-04-09 10:41:12,350:INFO:Checking exceptions
2025-04-09 10:41:12,356:INFO:Preloading libraries
2025-04-09 10:41:12,356:INFO:Copying training dataset
2025-04-09 10:41:12,356:INFO:Plot type: feature
2025-04-09 10:41:12,632:INFO:Visual Rendered Successfully
2025-04-09 10:41:12,683:INFO:plot_model() successfully completed......................................
2025-04-09 10:41:19,962:INFO:Initializing predict_model()
2025-04-09 10:41:19,963:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x74048fe370d0>)
2025-04-09 10:41:19,963:INFO:Checking exceptions
2025-04-09 10:41:19,963:INFO:Preloading libraries
2025-04-09 10:41:20,127:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-09 10:42:10,426:INFO:Initializing predict_model()
2025-04-09 10:42:10,426:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7404686b5ca0>)
2025-04-09 10:42:10,426:INFO:Checking exceptions
2025-04-09 10:42:10,426:INFO:Preloading libraries
2025-04-09 10:42:10,429:INFO:Set up data.
2025-04-09 10:42:10,435:INFO:Set up index.
2025-04-09 10:42:10,514:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-09 10:42:34,086:INFO:Initializing compare_models()
2025-04-09 10:42:34,087:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 10:42:34,087:INFO:Checking exceptions
2025-04-09 10:42:34,090:INFO:Preparing display monitor
2025-04-09 10:42:34,129:INFO:Initializing Linear Regression
2025-04-09 10:42:34,129:INFO:Total runtime is 4.9193700154622395e-06 minutes
2025-04-09 10:42:34,134:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:34,135:INFO:Initializing create_model()
2025-04-09 10:42:34,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:34,135:INFO:Checking exceptions
2025-04-09 10:42:34,135:INFO:Importing libraries
2025-04-09 10:42:34,135:INFO:Copying training dataset
2025-04-09 10:42:34,140:INFO:Defining folds
2025-04-09 10:42:34,140:INFO:Declaring metric variables
2025-04-09 10:42:34,144:INFO:Importing untrained model
2025-04-09 10:42:34,148:INFO:Linear Regression Imported successfully
2025-04-09 10:42:34,155:INFO:Starting cross validation
2025-04-09 10:42:34,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:34,509:INFO:Calculating mean and std
2025-04-09 10:42:34,510:INFO:Creating metrics dataframe
2025-04-09 10:42:34,510:INFO:Uploading results into container
2025-04-09 10:42:34,511:INFO:Uploading model into container now
2025-04-09 10:42:34,511:INFO:_master_model_container: 19
2025-04-09 10:42:34,511:INFO:_display_container: 5
2025-04-09 10:42:34,511:INFO:LinearRegression(n_jobs=-1)
2025-04-09 10:42:34,511:INFO:create_model() successfully completed......................................
2025-04-09 10:42:34,559:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:34,559:INFO:Creating metrics dataframe
2025-04-09 10:42:34,562:INFO:Initializing Lasso Regression
2025-04-09 10:42:34,562:INFO:Total runtime is 0.007214156786600749 minutes
2025-04-09 10:42:34,563:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:34,564:INFO:Initializing create_model()
2025-04-09 10:42:34,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:34,564:INFO:Checking exceptions
2025-04-09 10:42:34,564:INFO:Importing libraries
2025-04-09 10:42:34,564:INFO:Copying training dataset
2025-04-09 10:42:34,565:INFO:Defining folds
2025-04-09 10:42:34,565:INFO:Declaring metric variables
2025-04-09 10:42:34,567:INFO:Importing untrained model
2025-04-09 10:42:34,568:INFO:Lasso Regression Imported successfully
2025-04-09 10:42:34,570:INFO:Starting cross validation
2025-04-09 10:42:34,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:34,588:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,612:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,634:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,657:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,681:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,705:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,728:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,751:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,774:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,798:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:34,806:INFO:Calculating mean and std
2025-04-09 10:42:34,807:INFO:Creating metrics dataframe
2025-04-09 10:42:34,807:INFO:Uploading results into container
2025-04-09 10:42:34,808:INFO:Uploading model into container now
2025-04-09 10:42:34,808:INFO:_master_model_container: 20
2025-04-09 10:42:34,808:INFO:_display_container: 5
2025-04-09 10:42:34,808:INFO:Lasso(random_state=123)
2025-04-09 10:42:34,808:INFO:create_model() successfully completed......................................
2025-04-09 10:42:34,856:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:34,856:INFO:Creating metrics dataframe
2025-04-09 10:42:34,859:INFO:Initializing Ridge Regression
2025-04-09 10:42:34,859:INFO:Total runtime is 0.01216558615366618 minutes
2025-04-09 10:42:34,861:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:34,861:INFO:Initializing create_model()
2025-04-09 10:42:34,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:34,861:INFO:Checking exceptions
2025-04-09 10:42:34,861:INFO:Importing libraries
2025-04-09 10:42:34,861:INFO:Copying training dataset
2025-04-09 10:42:34,863:INFO:Defining folds
2025-04-09 10:42:34,863:INFO:Declaring metric variables
2025-04-09 10:42:34,864:INFO:Importing untrained model
2025-04-09 10:42:34,866:INFO:Ridge Regression Imported successfully
2025-04-09 10:42:34,868:INFO:Starting cross validation
2025-04-09 10:42:34,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:34,884:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.5654e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:34,906:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.81945e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:34,927:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57492e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:34,949:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.61294e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:34,970:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6252e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:34,991:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57721e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:35,013:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57265e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:35,034:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.56553e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:35,056:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.51317e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:35,078:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.53625e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:42:35,086:INFO:Calculating mean and std
2025-04-09 10:42:35,087:INFO:Creating metrics dataframe
2025-04-09 10:42:35,087:INFO:Uploading results into container
2025-04-09 10:42:35,087:INFO:Uploading model into container now
2025-04-09 10:42:35,088:INFO:_master_model_container: 21
2025-04-09 10:42:35,088:INFO:_display_container: 5
2025-04-09 10:42:35,088:INFO:Ridge(random_state=123)
2025-04-09 10:42:35,088:INFO:create_model() successfully completed......................................
2025-04-09 10:42:35,136:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:35,136:INFO:Creating metrics dataframe
2025-04-09 10:42:35,139:INFO:Initializing Elastic Net
2025-04-09 10:42:35,140:INFO:Total runtime is 0.016838844617207846 minutes
2025-04-09 10:42:35,141:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:35,141:INFO:Initializing create_model()
2025-04-09 10:42:35,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:35,141:INFO:Checking exceptions
2025-04-09 10:42:35,141:INFO:Importing libraries
2025-04-09 10:42:35,141:INFO:Copying training dataset
2025-04-09 10:42:35,143:INFO:Defining folds
2025-04-09 10:42:35,143:INFO:Declaring metric variables
2025-04-09 10:42:35,145:INFO:Importing untrained model
2025-04-09 10:42:35,146:INFO:Elastic Net Imported successfully
2025-04-09 10:42:35,149:INFO:Starting cross validation
2025-04-09 10:42:35,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:35,200:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,256:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,282:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,304:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,327:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,350:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,393:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,501:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,564:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,588:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:42:35,596:INFO:Calculating mean and std
2025-04-09 10:42:35,597:INFO:Creating metrics dataframe
2025-04-09 10:42:35,598:INFO:Uploading results into container
2025-04-09 10:42:35,598:INFO:Uploading model into container now
2025-04-09 10:42:35,598:INFO:_master_model_container: 22
2025-04-09 10:42:35,598:INFO:_display_container: 5
2025-04-09 10:42:35,599:INFO:ElasticNet(random_state=123)
2025-04-09 10:42:35,599:INFO:create_model() successfully completed......................................
2025-04-09 10:42:35,648:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:35,648:INFO:Creating metrics dataframe
2025-04-09 10:42:35,651:INFO:Initializing Least Angle Regression
2025-04-09 10:42:35,651:INFO:Total runtime is 0.025370919704437257 minutes
2025-04-09 10:42:35,653:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:35,653:INFO:Initializing create_model()
2025-04-09 10:42:35,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:35,653:INFO:Checking exceptions
2025-04-09 10:42:35,653:INFO:Importing libraries
2025-04-09 10:42:35,653:INFO:Copying training dataset
2025-04-09 10:42:35,655:INFO:Defining folds
2025-04-09 10:42:35,655:INFO:Declaring metric variables
2025-04-09 10:42:35,656:INFO:Importing untrained model
2025-04-09 10:42:35,657:INFO:Least Angle Regression Imported successfully
2025-04-09 10:42:35,660:INFO:Starting cross validation
2025-04-09 10:42:35,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:35,679:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.030e+07, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,706:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.736e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,731:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.082e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.317e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,756:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=9.092e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,781:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.505e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,806:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=8.994e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.158e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,831:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.148e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,856:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.313e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,881:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.654e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,907:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=6.212e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.667e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:42:35,917:INFO:Calculating mean and std
2025-04-09 10:42:35,917:INFO:Creating metrics dataframe
2025-04-09 10:42:35,918:INFO:Uploading results into container
2025-04-09 10:42:35,919:INFO:Uploading model into container now
2025-04-09 10:42:35,919:INFO:_master_model_container: 23
2025-04-09 10:42:35,919:INFO:_display_container: 5
2025-04-09 10:42:35,919:INFO:Lars(random_state=123)
2025-04-09 10:42:35,919:INFO:create_model() successfully completed......................................
2025-04-09 10:42:35,973:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:35,973:INFO:Creating metrics dataframe
2025-04-09 10:42:35,977:INFO:Initializing Lasso Least Angle Regression
2025-04-09 10:42:35,977:INFO:Total runtime is 0.030802520116170247 minutes
2025-04-09 10:42:35,979:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:35,979:INFO:Initializing create_model()
2025-04-09 10:42:35,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:35,979:INFO:Checking exceptions
2025-04-09 10:42:35,979:INFO:Importing libraries
2025-04-09 10:42:35,979:INFO:Copying training dataset
2025-04-09 10:42:35,981:INFO:Defining folds
2025-04-09 10:42:35,981:INFO:Declaring metric variables
2025-04-09 10:42:35,982:INFO:Importing untrained model
2025-04-09 10:42:35,984:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 10:42:35,986:INFO:Starting cross validation
2025-04-09 10:42:35,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:36,226:INFO:Calculating mean and std
2025-04-09 10:42:36,227:INFO:Creating metrics dataframe
2025-04-09 10:42:36,227:INFO:Uploading results into container
2025-04-09 10:42:36,228:INFO:Uploading model into container now
2025-04-09 10:42:36,228:INFO:_master_model_container: 24
2025-04-09 10:42:36,228:INFO:_display_container: 5
2025-04-09 10:42:36,228:INFO:LassoLars(random_state=123)
2025-04-09 10:42:36,228:INFO:create_model() successfully completed......................................
2025-04-09 10:42:36,278:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:36,278:INFO:Creating metrics dataframe
2025-04-09 10:42:36,282:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 10:42:36,282:INFO:Total runtime is 0.03587525685628255 minutes
2025-04-09 10:42:36,283:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:36,283:INFO:Initializing create_model()
2025-04-09 10:42:36,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:36,283:INFO:Checking exceptions
2025-04-09 10:42:36,283:INFO:Importing libraries
2025-04-09 10:42:36,283:INFO:Copying training dataset
2025-04-09 10:42:36,285:INFO:Defining folds
2025-04-09 10:42:36,285:INFO:Declaring metric variables
2025-04-09 10:42:36,286:INFO:Importing untrained model
2025-04-09 10:42:36,288:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 10:42:36,290:INFO:Starting cross validation
2025-04-09 10:42:36,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:36,512:INFO:Calculating mean and std
2025-04-09 10:42:36,513:INFO:Creating metrics dataframe
2025-04-09 10:42:36,514:INFO:Uploading results into container
2025-04-09 10:42:36,514:INFO:Uploading model into container now
2025-04-09 10:42:36,514:INFO:_master_model_container: 25
2025-04-09 10:42:36,514:INFO:_display_container: 5
2025-04-09 10:42:36,514:INFO:OrthogonalMatchingPursuit()
2025-04-09 10:42:36,514:INFO:create_model() successfully completed......................................
2025-04-09 10:42:36,562:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:36,562:INFO:Creating metrics dataframe
2025-04-09 10:42:36,566:INFO:Initializing Bayesian Ridge
2025-04-09 10:42:36,566:INFO:Total runtime is 0.040618860721588136 minutes
2025-04-09 10:42:36,568:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:36,568:INFO:Initializing create_model()
2025-04-09 10:42:36,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:36,568:INFO:Checking exceptions
2025-04-09 10:42:36,568:INFO:Importing libraries
2025-04-09 10:42:36,568:INFO:Copying training dataset
2025-04-09 10:42:36,570:INFO:Defining folds
2025-04-09 10:42:36,570:INFO:Declaring metric variables
2025-04-09 10:42:36,571:INFO:Importing untrained model
2025-04-09 10:42:36,572:INFO:Bayesian Ridge Imported successfully
2025-04-09 10:42:36,575:INFO:Starting cross validation
2025-04-09 10:42:36,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:37,106:INFO:Calculating mean and std
2025-04-09 10:42:37,108:INFO:Creating metrics dataframe
2025-04-09 10:42:37,110:INFO:Uploading results into container
2025-04-09 10:42:37,111:INFO:Uploading model into container now
2025-04-09 10:42:37,111:INFO:_master_model_container: 26
2025-04-09 10:42:37,111:INFO:_display_container: 5
2025-04-09 10:42:37,112:INFO:BayesianRidge()
2025-04-09 10:42:37,112:INFO:create_model() successfully completed......................................
2025-04-09 10:42:37,184:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:37,184:INFO:Creating metrics dataframe
2025-04-09 10:42:37,194:INFO:Initializing Passive Aggressive Regressor
2025-04-09 10:42:37,194:INFO:Total runtime is 0.05108372370402019 minutes
2025-04-09 10:42:37,197:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:37,198:INFO:Initializing create_model()
2025-04-09 10:42:37,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:37,198:INFO:Checking exceptions
2025-04-09 10:42:37,198:INFO:Importing libraries
2025-04-09 10:42:37,198:INFO:Copying training dataset
2025-04-09 10:42:37,201:INFO:Defining folds
2025-04-09 10:42:37,201:INFO:Declaring metric variables
2025-04-09 10:42:37,204:INFO:Importing untrained model
2025-04-09 10:42:37,206:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 10:42:37,211:INFO:Starting cross validation
2025-04-09 10:42:37,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:37,445:INFO:Calculating mean and std
2025-04-09 10:42:37,445:INFO:Creating metrics dataframe
2025-04-09 10:42:37,446:INFO:Uploading results into container
2025-04-09 10:42:37,446:INFO:Uploading model into container now
2025-04-09 10:42:37,447:INFO:_master_model_container: 27
2025-04-09 10:42:37,447:INFO:_display_container: 5
2025-04-09 10:42:37,447:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 10:42:37,447:INFO:create_model() successfully completed......................................
2025-04-09 10:42:37,494:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:37,494:INFO:Creating metrics dataframe
2025-04-09 10:42:37,498:INFO:Initializing Huber Regressor
2025-04-09 10:42:37,498:INFO:Total runtime is 0.05615323781967164 minutes
2025-04-09 10:42:37,500:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:37,500:INFO:Initializing create_model()
2025-04-09 10:42:37,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:37,500:INFO:Checking exceptions
2025-04-09 10:42:37,500:INFO:Importing libraries
2025-04-09 10:42:37,500:INFO:Copying training dataset
2025-04-09 10:42:37,502:INFO:Defining folds
2025-04-09 10:42:37,502:INFO:Declaring metric variables
2025-04-09 10:42:37,503:INFO:Importing untrained model
2025-04-09 10:42:37,505:INFO:Huber Regressor Imported successfully
2025-04-09 10:42:37,507:INFO:Starting cross validation
2025-04-09 10:42:37,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:37,532:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,562:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,620:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,650:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,679:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,709:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,739:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,768:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,798:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:42:37,808:INFO:Calculating mean and std
2025-04-09 10:42:37,808:INFO:Creating metrics dataframe
2025-04-09 10:42:37,809:INFO:Uploading results into container
2025-04-09 10:42:37,809:INFO:Uploading model into container now
2025-04-09 10:42:37,809:INFO:_master_model_container: 28
2025-04-09 10:42:37,810:INFO:_display_container: 5
2025-04-09 10:42:37,810:INFO:HuberRegressor()
2025-04-09 10:42:37,810:INFO:create_model() successfully completed......................................
2025-04-09 10:42:37,859:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:37,859:INFO:Creating metrics dataframe
2025-04-09 10:42:37,863:INFO:Initializing K Neighbors Regressor
2025-04-09 10:42:37,863:INFO:Total runtime is 0.06223810911178589 minutes
2025-04-09 10:42:37,865:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:37,865:INFO:Initializing create_model()
2025-04-09 10:42:37,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:37,865:INFO:Checking exceptions
2025-04-09 10:42:37,865:INFO:Importing libraries
2025-04-09 10:42:37,865:INFO:Copying training dataset
2025-04-09 10:42:37,867:INFO:Defining folds
2025-04-09 10:42:37,867:INFO:Declaring metric variables
2025-04-09 10:42:37,868:INFO:Importing untrained model
2025-04-09 10:42:37,870:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:42:37,872:INFO:Starting cross validation
2025-04-09 10:42:37,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:38,114:INFO:Calculating mean and std
2025-04-09 10:42:38,115:INFO:Creating metrics dataframe
2025-04-09 10:42:38,116:INFO:Uploading results into container
2025-04-09 10:42:38,116:INFO:Uploading model into container now
2025-04-09 10:42:38,116:INFO:_master_model_container: 29
2025-04-09 10:42:38,116:INFO:_display_container: 5
2025-04-09 10:42:38,116:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:42:38,116:INFO:create_model() successfully completed......................................
2025-04-09 10:42:38,168:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:38,168:INFO:Creating metrics dataframe
2025-04-09 10:42:38,173:INFO:Initializing Decision Tree Regressor
2025-04-09 10:42:38,173:INFO:Total runtime is 0.06739715735117595 minutes
2025-04-09 10:42:38,175:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:38,175:INFO:Initializing create_model()
2025-04-09 10:42:38,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:38,175:INFO:Checking exceptions
2025-04-09 10:42:38,175:INFO:Importing libraries
2025-04-09 10:42:38,175:INFO:Copying training dataset
2025-04-09 10:42:38,177:INFO:Defining folds
2025-04-09 10:42:38,177:INFO:Declaring metric variables
2025-04-09 10:42:38,178:INFO:Importing untrained model
2025-04-09 10:42:38,180:INFO:Decision Tree Regressor Imported successfully
2025-04-09 10:42:38,182:INFO:Starting cross validation
2025-04-09 10:42:38,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:38,796:INFO:Calculating mean and std
2025-04-09 10:42:38,796:INFO:Creating metrics dataframe
2025-04-09 10:42:38,797:INFO:Uploading results into container
2025-04-09 10:42:38,797:INFO:Uploading model into container now
2025-04-09 10:42:38,797:INFO:_master_model_container: 30
2025-04-09 10:42:38,797:INFO:_display_container: 5
2025-04-09 10:42:38,798:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 10:42:38,798:INFO:create_model() successfully completed......................................
2025-04-09 10:42:38,847:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:38,847:INFO:Creating metrics dataframe
2025-04-09 10:42:38,851:INFO:Initializing Random Forest Regressor
2025-04-09 10:42:38,851:INFO:Total runtime is 0.07869640588760377 minutes
2025-04-09 10:42:38,852:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:38,852:INFO:Initializing create_model()
2025-04-09 10:42:38,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:38,852:INFO:Checking exceptions
2025-04-09 10:42:38,852:INFO:Importing libraries
2025-04-09 10:42:38,853:INFO:Copying training dataset
2025-04-09 10:42:38,854:INFO:Defining folds
2025-04-09 10:42:38,854:INFO:Declaring metric variables
2025-04-09 10:42:38,855:INFO:Importing untrained model
2025-04-09 10:42:38,857:INFO:Random Forest Regressor Imported successfully
2025-04-09 10:42:38,860:INFO:Starting cross validation
2025-04-09 10:42:38,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:42,485:INFO:Calculating mean and std
2025-04-09 10:42:42,487:INFO:Creating metrics dataframe
2025-04-09 10:42:42,491:INFO:Uploading results into container
2025-04-09 10:42:42,492:INFO:Uploading model into container now
2025-04-09 10:42:42,493:INFO:_master_model_container: 31
2025-04-09 10:42:42,494:INFO:_display_container: 5
2025-04-09 10:42:42,494:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:42:42,494:INFO:create_model() successfully completed......................................
2025-04-09 10:42:42,598:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:42,599:INFO:Creating metrics dataframe
2025-04-09 10:42:42,619:INFO:Initializing Extra Trees Regressor
2025-04-09 10:42:42,619:INFO:Total runtime is 0.14150065978368126 minutes
2025-04-09 10:42:42,627:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:42,628:INFO:Initializing create_model()
2025-04-09 10:42:42,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:42,628:INFO:Checking exceptions
2025-04-09 10:42:42,628:INFO:Importing libraries
2025-04-09 10:42:42,628:INFO:Copying training dataset
2025-04-09 10:42:42,636:INFO:Defining folds
2025-04-09 10:42:42,637:INFO:Declaring metric variables
2025-04-09 10:42:42,643:INFO:Importing untrained model
2025-04-09 10:42:42,650:INFO:Extra Trees Regressor Imported successfully
2025-04-09 10:42:42,661:INFO:Starting cross validation
2025-04-09 10:42:42,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:44,893:INFO:Calculating mean and std
2025-04-09 10:42:44,895:INFO:Creating metrics dataframe
2025-04-09 10:42:44,899:INFO:Uploading results into container
2025-04-09 10:42:44,900:INFO:Uploading model into container now
2025-04-09 10:42:44,901:INFO:_master_model_container: 32
2025-04-09 10:42:44,901:INFO:_display_container: 5
2025-04-09 10:42:44,902:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:42:44,902:INFO:create_model() successfully completed......................................
2025-04-09 10:42:45,002:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:45,002:INFO:Creating metrics dataframe
2025-04-09 10:42:45,022:INFO:Initializing AdaBoost Regressor
2025-04-09 10:42:45,022:INFO:Total runtime is 0.18155349095662437 minutes
2025-04-09 10:42:45,027:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:45,028:INFO:Initializing create_model()
2025-04-09 10:42:45,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:45,028:INFO:Checking exceptions
2025-04-09 10:42:45,028:INFO:Importing libraries
2025-04-09 10:42:45,028:INFO:Copying training dataset
2025-04-09 10:42:45,034:INFO:Defining folds
2025-04-09 10:42:45,034:INFO:Declaring metric variables
2025-04-09 10:42:45,038:INFO:Importing untrained model
2025-04-09 10:42:45,043:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:42:45,051:INFO:Starting cross validation
2025-04-09 10:42:45,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:45,728:INFO:Calculating mean and std
2025-04-09 10:42:45,728:INFO:Creating metrics dataframe
2025-04-09 10:42:45,729:INFO:Uploading results into container
2025-04-09 10:42:45,729:INFO:Uploading model into container now
2025-04-09 10:42:45,730:INFO:_master_model_container: 33
2025-04-09 10:42:45,730:INFO:_display_container: 5
2025-04-09 10:42:45,730:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:42:45,730:INFO:create_model() successfully completed......................................
2025-04-09 10:42:45,765:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:45,765:INFO:Creating metrics dataframe
2025-04-09 10:42:45,770:INFO:Initializing Gradient Boosting Regressor
2025-04-09 10:42:45,770:INFO:Total runtime is 0.19401142994562787 minutes
2025-04-09 10:42:45,771:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:45,771:INFO:Initializing create_model()
2025-04-09 10:42:45,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:45,771:INFO:Checking exceptions
2025-04-09 10:42:45,771:INFO:Importing libraries
2025-04-09 10:42:45,771:INFO:Copying training dataset
2025-04-09 10:42:45,773:INFO:Defining folds
2025-04-09 10:42:45,773:INFO:Declaring metric variables
2025-04-09 10:42:45,774:INFO:Importing untrained model
2025-04-09 10:42:45,776:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 10:42:45,778:INFO:Starting cross validation
2025-04-09 10:42:45,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:46,789:INFO:Calculating mean and std
2025-04-09 10:42:46,789:INFO:Creating metrics dataframe
2025-04-09 10:42:46,790:INFO:Uploading results into container
2025-04-09 10:42:46,790:INFO:Uploading model into container now
2025-04-09 10:42:46,791:INFO:_master_model_container: 34
2025-04-09 10:42:46,791:INFO:_display_container: 5
2025-04-09 10:42:46,791:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 10:42:46,791:INFO:create_model() successfully completed......................................
2025-04-09 10:42:46,827:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:46,827:INFO:Creating metrics dataframe
2025-04-09 10:42:46,832:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 10:42:46,832:INFO:Total runtime is 0.21170891523361207 minutes
2025-04-09 10:42:46,833:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:46,833:INFO:Initializing create_model()
2025-04-09 10:42:46,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:46,833:INFO:Checking exceptions
2025-04-09 10:42:46,833:INFO:Importing libraries
2025-04-09 10:42:46,833:INFO:Copying training dataset
2025-04-09 10:42:46,835:INFO:Defining folds
2025-04-09 10:42:46,835:INFO:Declaring metric variables
2025-04-09 10:42:46,836:INFO:Importing untrained model
2025-04-09 10:42:46,838:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 10:42:46,840:INFO:Starting cross validation
2025-04-09 10:42:46,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:46,857:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:46,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2025-04-09 10:42:46,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:46,857:INFO:[LightGBM] [Info] Total Bins 1122
2025-04-09 10:42:46,857:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:46,858:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,891:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:46,891:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2025-04-09 10:42:46,891:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:46,892:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 10:42:46,892:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:46,892:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,933:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:46,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2025-04-09 10:42:46,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:46,933:INFO:[LightGBM] [Info] Total Bins 1152
2025-04-09 10:42:46,933:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:46,933:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 10:42:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:46,985:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:47,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032402 seconds.
2025-04-09 10:42:47,018:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:47,018:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 10:42:47,024:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:47,030:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 10:42:47,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:47,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:48,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:49,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:50,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,467:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2025-04-09 10:42:51,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,468:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 10:42:51,468:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:51,468:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 10:42:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,523:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2025-04-09 10:42:51,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,524:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 10:42:51,524:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:51,524:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 10:42:51,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,584:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
2025-04-09 10:42:51,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,584:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 10:42:51,584:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:51,585:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,640:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023424 seconds.
2025-04-09 10:42:51,664:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,664:INFO:[LightGBM] [Info] Total Bins 1126
2025-04-09 10:42:51,671:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:42:51,671:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54

2025-04-09 10:42:51,677:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 10:42:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,734:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2025-04-09 10:42:51,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,734:INFO:[LightGBM] [Info] Total Bins 1123
2025-04-09 10:42:51,734:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:42:51,734:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,844:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:42:51,845:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2025-04-09 10:42:51,845:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:42:51,845:INFO:[LightGBM] [Info] Total Bins 1132
2025-04-09 10:42:51,845:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:42:51,845:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 10:42:51,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:42:51,885:INFO:Calculating mean and std
2025-04-09 10:42:51,887:INFO:Creating metrics dataframe
2025-04-09 10:42:51,888:INFO:Uploading results into container
2025-04-09 10:42:51,889:INFO:Uploading model into container now
2025-04-09 10:42:51,889:INFO:_master_model_container: 35
2025-04-09 10:42:51,889:INFO:_display_container: 5
2025-04-09 10:42:51,890:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:42:51,890:INFO:create_model() successfully completed......................................
2025-04-09 10:42:51,950:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:51,950:INFO:Creating metrics dataframe
2025-04-09 10:42:51,955:INFO:Initializing Dummy Regressor
2025-04-09 10:42:51,955:INFO:Total runtime is 0.2970945874849955 minutes
2025-04-09 10:42:51,957:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:51,957:INFO:Initializing create_model()
2025-04-09 10:42:51,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404acdef430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:51,957:INFO:Checking exceptions
2025-04-09 10:42:51,957:INFO:Importing libraries
2025-04-09 10:42:51,957:INFO:Copying training dataset
2025-04-09 10:42:51,958:INFO:Defining folds
2025-04-09 10:42:51,959:INFO:Declaring metric variables
2025-04-09 10:42:51,960:INFO:Importing untrained model
2025-04-09 10:42:51,962:INFO:Dummy Regressor Imported successfully
2025-04-09 10:42:51,965:INFO:Starting cross validation
2025-04-09 10:42:51,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:52,255:INFO:Calculating mean and std
2025-04-09 10:42:52,255:INFO:Creating metrics dataframe
2025-04-09 10:42:52,256:INFO:Uploading results into container
2025-04-09 10:42:52,256:INFO:Uploading model into container now
2025-04-09 10:42:52,257:INFO:_master_model_container: 36
2025-04-09 10:42:52,257:INFO:_display_container: 5
2025-04-09 10:42:52,257:INFO:DummyRegressor()
2025-04-09 10:42:52,257:INFO:create_model() successfully completed......................................
2025-04-09 10:42:52,301:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:52,301:INFO:Creating metrics dataframe
2025-04-09 10:42:52,306:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 10:42:52,309:INFO:Initializing create_model()
2025-04-09 10:42:52,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:52,309:INFO:Checking exceptions
2025-04-09 10:42:52,310:INFO:Importing libraries
2025-04-09 10:42:52,310:INFO:Copying training dataset
2025-04-09 10:42:52,312:INFO:Defining folds
2025-04-09 10:42:52,312:INFO:Declaring metric variables
2025-04-09 10:42:52,312:INFO:Importing untrained model
2025-04-09 10:42:52,312:INFO:Declaring custom model
2025-04-09 10:42:52,312:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:42:52,312:INFO:Cross validation set to False
2025-04-09 10:42:52,312:INFO:Fitting Model
2025-04-09 10:42:52,328:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:42:52,328:INFO:create_model() successfully completed......................................
2025-04-09 10:42:52,384:INFO:_master_model_container: 36
2025-04-09 10:42:52,384:INFO:_display_container: 5
2025-04-09 10:42:52,385:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:42:52,385:INFO:compare_models() successfully completed......................................
2025-04-09 10:42:52,385:INFO:Initializing tune_model()
2025-04-09 10:42:52,385:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=50, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>)
2025-04-09 10:42:52,385:INFO:Checking exceptions
2025-04-09 10:42:52,392:INFO:Copying training dataset
2025-04-09 10:42:52,394:INFO:Checking base model
2025-04-09 10:42:52,394:INFO:Base model : K Neighbors Regressor
2025-04-09 10:42:52,396:INFO:Declaring metric variables
2025-04-09 10:42:52,398:INFO:Defining Hyperparameters
2025-04-09 10:42:52,486:INFO:Tuning with n_jobs=-1
2025-04-09 10:42:52,486:INFO:Initializing RandomizedSearchCV
2025-04-09 10:42:55,946:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 2, 'actual_estimator__metric': 'minkowski'}
2025-04-09 10:42:55,948:INFO:Hyperparameter search completed
2025-04-09 10:42:55,948:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:55,949:INFO:Initializing create_model()
2025-04-09 10:42:55,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7404685ddbb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'uniform', 'n_neighbors': 2, 'metric': 'minkowski'})
2025-04-09 10:42:55,949:INFO:Checking exceptions
2025-04-09 10:42:55,950:INFO:Importing libraries
2025-04-09 10:42:55,950:INFO:Copying training dataset
2025-04-09 10:42:55,956:INFO:Defining folds
2025-04-09 10:42:55,956:INFO:Declaring metric variables
2025-04-09 10:42:55,962:INFO:Importing untrained model
2025-04-09 10:42:55,962:INFO:Declaring custom model
2025-04-09 10:42:55,967:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:42:55,975:INFO:Starting cross validation
2025-04-09 10:42:55,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:56,392:INFO:Calculating mean and std
2025-04-09 10:42:56,393:INFO:Creating metrics dataframe
2025-04-09 10:42:56,395:INFO:Finalizing model
2025-04-09 10:42:56,410:INFO:Uploading results into container
2025-04-09 10:42:56,411:INFO:Uploading model into container now
2025-04-09 10:42:56,411:INFO:_master_model_container: 37
2025-04-09 10:42:56,411:INFO:_display_container: 6
2025-04-09 10:42:56,411:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:42:56,411:INFO:create_model() successfully completed......................................
2025-04-09 10:42:56,463:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:56,464:INFO:choose_better activated
2025-04-09 10:42:56,466:INFO:SubProcess create_model() called ==================================
2025-04-09 10:42:56,467:INFO:Initializing create_model()
2025-04-09 10:42:56,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:56,467:INFO:Checking exceptions
2025-04-09 10:42:56,468:INFO:Importing libraries
2025-04-09 10:42:56,469:INFO:Copying training dataset
2025-04-09 10:42:56,472:INFO:Defining folds
2025-04-09 10:42:56,473:INFO:Declaring metric variables
2025-04-09 10:42:56,473:INFO:Importing untrained model
2025-04-09 10:42:56,473:INFO:Declaring custom model
2025-04-09 10:42:56,473:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:42:56,474:INFO:Starting cross validation
2025-04-09 10:42:56,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:42:56,834:INFO:Calculating mean and std
2025-04-09 10:42:56,835:INFO:Creating metrics dataframe
2025-04-09 10:42:56,839:INFO:Finalizing model
2025-04-09 10:42:56,896:INFO:Uploading results into container
2025-04-09 10:42:56,896:INFO:Uploading model into container now
2025-04-09 10:42:56,897:INFO:_master_model_container: 38
2025-04-09 10:42:56,897:INFO:_display_container: 7
2025-04-09 10:42:56,897:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:42:56,897:INFO:create_model() successfully completed......................................
2025-04-09 10:42:56,991:INFO:SubProcess create_model() end ==================================
2025-04-09 10:42:56,992:INFO:KNeighborsRegressor(n_jobs=-1) result for RMSE is 0.0209
2025-04-09 10:42:56,992:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) result for RMSE is 0.0158
2025-04-09 10:42:56,992:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) is best model
2025-04-09 10:42:56,993:INFO:choose_better completed
2025-04-09 10:42:57,006:INFO:_master_model_container: 38
2025-04-09 10:42:57,006:INFO:_display_container: 6
2025-04-09 10:42:57,006:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:42:57,006:INFO:tune_model() successfully completed......................................
2025-04-09 10:42:57,094:INFO:Initializing finalize_model()
2025-04-09 10:42:57,094:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-09 10:42:57,094:INFO:Finalizing KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:42:57,097:INFO:Initializing create_model()
2025-04-09 10:42:57,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:42:57,097:INFO:Checking exceptions
2025-04-09 10:42:57,098:INFO:Importing libraries
2025-04-09 10:42:57,098:INFO:Copying training dataset
2025-04-09 10:42:57,099:INFO:Defining folds
2025-04-09 10:42:57,099:INFO:Declaring metric variables
2025-04-09 10:42:57,099:INFO:Importing untrained model
2025-04-09 10:42:57,099:INFO:Declaring custom model
2025-04-09 10:42:57,099:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:42:57,100:INFO:Cross validation set to False
2025-04-09 10:42:57,100:INFO:Fitting Model
2025-04-09 10:42:57,123:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:42:57,123:INFO:create_model() successfully completed......................................
2025-04-09 10:42:57,160:INFO:_master_model_container: 38
2025-04-09 10:42:57,160:INFO:_display_container: 6
2025-04-09 10:42:57,164:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:42:57,164:INFO:finalize_model() successfully completed......................................
2025-04-09 10:42:57,206:INFO:Initializing save_model()
2025-04-09 10:42:57,206:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))]), model_name=final_calibrated_depth_model_25, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-09 10:42:57,206:INFO:Adding model into prep_pipe
2025-04-09 10:42:57,206:WARNING:Only Model saved as it was a pipeline.
2025-04-09 10:42:57,208:INFO:final_calibrated_depth_model_25.pkl saved in current working directory
2025-04-09 10:42:57,213:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:42:57,213:INFO:save_model() successfully completed......................................
2025-04-09 10:43:57,503:INFO:Initializing compare_models()
2025-04-09 10:43:57,503:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 10:43:57,503:INFO:Checking exceptions
2025-04-09 10:43:57,507:INFO:Preparing display monitor
2025-04-09 10:43:57,534:INFO:Initializing Linear Regression
2025-04-09 10:43:57,535:INFO:Total runtime is 4.343191782633463e-06 minutes
2025-04-09 10:43:57,538:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:57,539:INFO:Initializing create_model()
2025-04-09 10:43:57,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:57,539:INFO:Checking exceptions
2025-04-09 10:43:57,539:INFO:Importing libraries
2025-04-09 10:43:57,539:INFO:Copying training dataset
2025-04-09 10:43:57,543:INFO:Defining folds
2025-04-09 10:43:57,543:INFO:Declaring metric variables
2025-04-09 10:43:57,546:INFO:Importing untrained model
2025-04-09 10:43:57,549:INFO:Linear Regression Imported successfully
2025-04-09 10:43:57,555:INFO:Starting cross validation
2025-04-09 10:43:57,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:57,897:INFO:Calculating mean and std
2025-04-09 10:43:57,897:INFO:Creating metrics dataframe
2025-04-09 10:43:57,897:INFO:Uploading results into container
2025-04-09 10:43:57,898:INFO:Uploading model into container now
2025-04-09 10:43:57,898:INFO:_master_model_container: 39
2025-04-09 10:43:57,898:INFO:_display_container: 7
2025-04-09 10:43:57,898:INFO:LinearRegression(n_jobs=-1)
2025-04-09 10:43:57,898:INFO:create_model() successfully completed......................................
2025-04-09 10:43:57,946:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:57,947:INFO:Creating metrics dataframe
2025-04-09 10:43:57,950:INFO:Initializing Lasso Regression
2025-04-09 10:43:57,950:INFO:Total runtime is 0.006924863656361898 minutes
2025-04-09 10:43:57,951:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:57,952:INFO:Initializing create_model()
2025-04-09 10:43:57,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:57,952:INFO:Checking exceptions
2025-04-09 10:43:57,952:INFO:Importing libraries
2025-04-09 10:43:57,952:INFO:Copying training dataset
2025-04-09 10:43:57,953:INFO:Defining folds
2025-04-09 10:43:57,953:INFO:Declaring metric variables
2025-04-09 10:43:57,955:INFO:Importing untrained model
2025-04-09 10:43:57,956:INFO:Lasso Regression Imported successfully
2025-04-09 10:43:57,959:INFO:Starting cross validation
2025-04-09 10:43:57,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:57,978:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,002:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,056:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,108:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,132:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,154:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,178:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,202:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,225:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,248:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,257:INFO:Calculating mean and std
2025-04-09 10:43:58,258:INFO:Creating metrics dataframe
2025-04-09 10:43:58,258:INFO:Uploading results into container
2025-04-09 10:43:58,259:INFO:Uploading model into container now
2025-04-09 10:43:58,259:INFO:_master_model_container: 40
2025-04-09 10:43:58,259:INFO:_display_container: 7
2025-04-09 10:43:58,259:INFO:Lasso(random_state=123)
2025-04-09 10:43:58,259:INFO:create_model() successfully completed......................................
2025-04-09 10:43:58,310:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:58,310:INFO:Creating metrics dataframe
2025-04-09 10:43:58,313:INFO:Initializing Ridge Regression
2025-04-09 10:43:58,313:INFO:Total runtime is 0.012975231806437174 minutes
2025-04-09 10:43:58,314:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:58,315:INFO:Initializing create_model()
2025-04-09 10:43:58,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:58,315:INFO:Checking exceptions
2025-04-09 10:43:58,315:INFO:Importing libraries
2025-04-09 10:43:58,315:INFO:Copying training dataset
2025-04-09 10:43:58,316:INFO:Defining folds
2025-04-09 10:43:58,316:INFO:Declaring metric variables
2025-04-09 10:43:58,317:INFO:Importing untrained model
2025-04-09 10:43:58,319:INFO:Ridge Regression Imported successfully
2025-04-09 10:43:58,321:INFO:Starting cross validation
2025-04-09 10:43:58,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:58,337:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.5654e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,359:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.81945e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,380:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57492e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,401:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.61294e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,423:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6252e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,444:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57721e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,466:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57265e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,487:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.56553e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,508:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.51317e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,529:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.53625e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 10:43:58,538:INFO:Calculating mean and std
2025-04-09 10:43:58,538:INFO:Creating metrics dataframe
2025-04-09 10:43:58,539:INFO:Uploading results into container
2025-04-09 10:43:58,539:INFO:Uploading model into container now
2025-04-09 10:43:58,539:INFO:_master_model_container: 41
2025-04-09 10:43:58,539:INFO:_display_container: 7
2025-04-09 10:43:58,539:INFO:Ridge(random_state=123)
2025-04-09 10:43:58,539:INFO:create_model() successfully completed......................................
2025-04-09 10:43:58,587:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:58,587:INFO:Creating metrics dataframe
2025-04-09 10:43:58,590:INFO:Initializing Elastic Net
2025-04-09 10:43:58,591:INFO:Total runtime is 0.017600953578948975 minutes
2025-04-09 10:43:58,592:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:58,592:INFO:Initializing create_model()
2025-04-09 10:43:58,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:58,592:INFO:Checking exceptions
2025-04-09 10:43:58,592:INFO:Importing libraries
2025-04-09 10:43:58,592:INFO:Copying training dataset
2025-04-09 10:43:58,594:INFO:Defining folds
2025-04-09 10:43:58,594:INFO:Declaring metric variables
2025-04-09 10:43:58,595:INFO:Importing untrained model
2025-04-09 10:43:58,597:INFO:Elastic Net Imported successfully
2025-04-09 10:43:58,599:INFO:Starting cross validation
2025-04-09 10:43:58,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:58,617:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,641:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,665:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,688:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,711:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,734:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,758:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,781:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,804:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,828:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 10:43:58,836:INFO:Calculating mean and std
2025-04-09 10:43:58,837:INFO:Creating metrics dataframe
2025-04-09 10:43:58,838:INFO:Uploading results into container
2025-04-09 10:43:58,838:INFO:Uploading model into container now
2025-04-09 10:43:58,838:INFO:_master_model_container: 42
2025-04-09 10:43:58,838:INFO:_display_container: 7
2025-04-09 10:43:58,838:INFO:ElasticNet(random_state=123)
2025-04-09 10:43:58,838:INFO:create_model() successfully completed......................................
2025-04-09 10:43:58,888:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:58,888:INFO:Creating metrics dataframe
2025-04-09 10:43:58,892:INFO:Initializing Least Angle Regression
2025-04-09 10:43:58,892:INFO:Total runtime is 0.02262575626373291 minutes
2025-04-09 10:43:58,893:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:58,894:INFO:Initializing create_model()
2025-04-09 10:43:58,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:58,894:INFO:Checking exceptions
2025-04-09 10:43:58,894:INFO:Importing libraries
2025-04-09 10:43:58,894:INFO:Copying training dataset
2025-04-09 10:43:58,895:INFO:Defining folds
2025-04-09 10:43:58,895:INFO:Declaring metric variables
2025-04-09 10:43:58,896:INFO:Importing untrained model
2025-04-09 10:43:58,898:INFO:Least Angle Regression Imported successfully
2025-04-09 10:43:58,900:INFO:Starting cross validation
2025-04-09 10:43:58,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:58,920:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.030e+07, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:58,947:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.736e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:58,972:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.082e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.317e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:58,998:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=9.092e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,024:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.505e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,049:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=8.994e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.158e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,075:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.148e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,100:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.313e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,126:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.654e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,151:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=6.212e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.667e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 10:43:59,167:INFO:Calculating mean and std
2025-04-09 10:43:59,168:INFO:Creating metrics dataframe
2025-04-09 10:43:59,171:INFO:Uploading results into container
2025-04-09 10:43:59,172:INFO:Uploading model into container now
2025-04-09 10:43:59,173:INFO:_master_model_container: 43
2025-04-09 10:43:59,173:INFO:_display_container: 7
2025-04-09 10:43:59,173:INFO:Lars(random_state=123)
2025-04-09 10:43:59,173:INFO:create_model() successfully completed......................................
2025-04-09 10:43:59,253:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:59,253:INFO:Creating metrics dataframe
2025-04-09 10:43:59,260:INFO:Initializing Lasso Least Angle Regression
2025-04-09 10:43:59,260:INFO:Total runtime is 0.02876263459523519 minutes
2025-04-09 10:43:59,266:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:59,267:INFO:Initializing create_model()
2025-04-09 10:43:59,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:59,267:INFO:Checking exceptions
2025-04-09 10:43:59,267:INFO:Importing libraries
2025-04-09 10:43:59,267:INFO:Copying training dataset
2025-04-09 10:43:59,277:INFO:Defining folds
2025-04-09 10:43:59,277:INFO:Declaring metric variables
2025-04-09 10:43:59,283:INFO:Importing untrained model
2025-04-09 10:43:59,291:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 10:43:59,305:INFO:Starting cross validation
2025-04-09 10:43:59,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:43:59,702:INFO:Calculating mean and std
2025-04-09 10:43:59,703:INFO:Creating metrics dataframe
2025-04-09 10:43:59,704:INFO:Uploading results into container
2025-04-09 10:43:59,704:INFO:Uploading model into container now
2025-04-09 10:43:59,704:INFO:_master_model_container: 44
2025-04-09 10:43:59,704:INFO:_display_container: 7
2025-04-09 10:43:59,704:INFO:LassoLars(random_state=123)
2025-04-09 10:43:59,704:INFO:create_model() successfully completed......................................
2025-04-09 10:43:59,783:INFO:SubProcess create_model() end ==================================
2025-04-09 10:43:59,783:INFO:Creating metrics dataframe
2025-04-09 10:43:59,794:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 10:43:59,794:INFO:Total runtime is 0.037652897834777835 minutes
2025-04-09 10:43:59,798:INFO:SubProcess create_model() called ==================================
2025-04-09 10:43:59,798:INFO:Initializing create_model()
2025-04-09 10:43:59,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:43:59,798:INFO:Checking exceptions
2025-04-09 10:43:59,798:INFO:Importing libraries
2025-04-09 10:43:59,799:INFO:Copying training dataset
2025-04-09 10:43:59,804:INFO:Defining folds
2025-04-09 10:43:59,804:INFO:Declaring metric variables
2025-04-09 10:43:59,811:INFO:Importing untrained model
2025-04-09 10:43:59,818:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 10:43:59,832:INFO:Starting cross validation
2025-04-09 10:43:59,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:00,252:INFO:Calculating mean and std
2025-04-09 10:44:00,252:INFO:Creating metrics dataframe
2025-04-09 10:44:00,253:INFO:Uploading results into container
2025-04-09 10:44:00,254:INFO:Uploading model into container now
2025-04-09 10:44:00,254:INFO:_master_model_container: 45
2025-04-09 10:44:00,254:INFO:_display_container: 7
2025-04-09 10:44:00,254:INFO:OrthogonalMatchingPursuit()
2025-04-09 10:44:00,254:INFO:create_model() successfully completed......................................
2025-04-09 10:44:00,301:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:00,302:INFO:Creating metrics dataframe
2025-04-09 10:44:00,305:INFO:Initializing Bayesian Ridge
2025-04-09 10:44:00,305:INFO:Total runtime is 0.04618226289749146 minutes
2025-04-09 10:44:00,307:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:00,307:INFO:Initializing create_model()
2025-04-09 10:44:00,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:00,307:INFO:Checking exceptions
2025-04-09 10:44:00,307:INFO:Importing libraries
2025-04-09 10:44:00,307:INFO:Copying training dataset
2025-04-09 10:44:00,309:INFO:Defining folds
2025-04-09 10:44:00,309:INFO:Declaring metric variables
2025-04-09 10:44:00,310:INFO:Importing untrained model
2025-04-09 10:44:00,312:INFO:Bayesian Ridge Imported successfully
2025-04-09 10:44:00,315:INFO:Starting cross validation
2025-04-09 10:44:00,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:00,916:INFO:Calculating mean and std
2025-04-09 10:44:00,917:INFO:Creating metrics dataframe
2025-04-09 10:44:00,919:INFO:Uploading results into container
2025-04-09 10:44:00,920:INFO:Uploading model into container now
2025-04-09 10:44:00,920:INFO:_master_model_container: 46
2025-04-09 10:44:00,920:INFO:_display_container: 7
2025-04-09 10:44:00,920:INFO:BayesianRidge()
2025-04-09 10:44:00,921:INFO:create_model() successfully completed......................................
2025-04-09 10:44:00,994:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:00,994:INFO:Creating metrics dataframe
2025-04-09 10:44:01,005:INFO:Initializing Passive Aggressive Regressor
2025-04-09 10:44:01,005:INFO:Total runtime is 0.05783829291661581 minutes
2025-04-09 10:44:01,008:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:01,008:INFO:Initializing create_model()
2025-04-09 10:44:01,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:01,008:INFO:Checking exceptions
2025-04-09 10:44:01,008:INFO:Importing libraries
2025-04-09 10:44:01,008:INFO:Copying training dataset
2025-04-09 10:44:01,012:INFO:Defining folds
2025-04-09 10:44:01,012:INFO:Declaring metric variables
2025-04-09 10:44:01,015:INFO:Importing untrained model
2025-04-09 10:44:01,018:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 10:44:01,026:INFO:Starting cross validation
2025-04-09 10:44:01,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:01,408:INFO:Calculating mean and std
2025-04-09 10:44:01,408:INFO:Creating metrics dataframe
2025-04-09 10:44:01,410:INFO:Uploading results into container
2025-04-09 10:44:01,410:INFO:Uploading model into container now
2025-04-09 10:44:01,410:INFO:_master_model_container: 47
2025-04-09 10:44:01,410:INFO:_display_container: 7
2025-04-09 10:44:01,410:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 10:44:01,410:INFO:create_model() successfully completed......................................
2025-04-09 10:44:01,459:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:01,459:INFO:Creating metrics dataframe
2025-04-09 10:44:01,463:INFO:Initializing Huber Regressor
2025-04-09 10:44:01,463:INFO:Total runtime is 0.06548110644022624 minutes
2025-04-09 10:44:01,465:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:01,465:INFO:Initializing create_model()
2025-04-09 10:44:01,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:01,465:INFO:Checking exceptions
2025-04-09 10:44:01,465:INFO:Importing libraries
2025-04-09 10:44:01,465:INFO:Copying training dataset
2025-04-09 10:44:01,467:INFO:Defining folds
2025-04-09 10:44:01,467:INFO:Declaring metric variables
2025-04-09 10:44:01,468:INFO:Importing untrained model
2025-04-09 10:44:01,470:INFO:Huber Regressor Imported successfully
2025-04-09 10:44:01,472:INFO:Starting cross validation
2025-04-09 10:44:01,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:01,495:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,525:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,581:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,610:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,639:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,668:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,698:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,726:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,755:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 10:44:01,765:INFO:Calculating mean and std
2025-04-09 10:44:01,765:INFO:Creating metrics dataframe
2025-04-09 10:44:01,766:INFO:Uploading results into container
2025-04-09 10:44:01,766:INFO:Uploading model into container now
2025-04-09 10:44:01,767:INFO:_master_model_container: 48
2025-04-09 10:44:01,767:INFO:_display_container: 7
2025-04-09 10:44:01,767:INFO:HuberRegressor()
2025-04-09 10:44:01,767:INFO:create_model() successfully completed......................................
2025-04-09 10:44:01,815:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:01,815:INFO:Creating metrics dataframe
2025-04-09 10:44:01,819:INFO:Initializing K Neighbors Regressor
2025-04-09 10:44:01,819:INFO:Total runtime is 0.07141699393590292 minutes
2025-04-09 10:44:01,821:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:01,821:INFO:Initializing create_model()
2025-04-09 10:44:01,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:01,821:INFO:Checking exceptions
2025-04-09 10:44:01,821:INFO:Importing libraries
2025-04-09 10:44:01,821:INFO:Copying training dataset
2025-04-09 10:44:01,823:INFO:Defining folds
2025-04-09 10:44:01,823:INFO:Declaring metric variables
2025-04-09 10:44:01,824:INFO:Importing untrained model
2025-04-09 10:44:01,826:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:44:01,828:INFO:Starting cross validation
2025-04-09 10:44:01,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:02,517:INFO:Calculating mean and std
2025-04-09 10:44:02,517:INFO:Creating metrics dataframe
2025-04-09 10:44:02,518:INFO:Uploading results into container
2025-04-09 10:44:02,519:INFO:Uploading model into container now
2025-04-09 10:44:02,519:INFO:_master_model_container: 49
2025-04-09 10:44:02,519:INFO:_display_container: 7
2025-04-09 10:44:02,519:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:44:02,519:INFO:create_model() successfully completed......................................
2025-04-09 10:44:02,567:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:02,567:INFO:Creating metrics dataframe
2025-04-09 10:44:02,572:INFO:Initializing Decision Tree Regressor
2025-04-09 10:44:02,572:INFO:Total runtime is 0.08395522038141887 minutes
2025-04-09 10:44:02,573:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:02,573:INFO:Initializing create_model()
2025-04-09 10:44:02,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:02,573:INFO:Checking exceptions
2025-04-09 10:44:02,573:INFO:Importing libraries
2025-04-09 10:44:02,574:INFO:Copying training dataset
2025-04-09 10:44:02,575:INFO:Defining folds
2025-04-09 10:44:02,575:INFO:Declaring metric variables
2025-04-09 10:44:02,577:INFO:Importing untrained model
2025-04-09 10:44:02,578:INFO:Decision Tree Regressor Imported successfully
2025-04-09 10:44:02,581:INFO:Starting cross validation
2025-04-09 10:44:02,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:03,176:INFO:Calculating mean and std
2025-04-09 10:44:03,176:INFO:Creating metrics dataframe
2025-04-09 10:44:03,177:INFO:Uploading results into container
2025-04-09 10:44:03,177:INFO:Uploading model into container now
2025-04-09 10:44:03,178:INFO:_master_model_container: 50
2025-04-09 10:44:03,178:INFO:_display_container: 7
2025-04-09 10:44:03,178:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 10:44:03,178:INFO:create_model() successfully completed......................................
2025-04-09 10:44:03,226:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:03,226:INFO:Creating metrics dataframe
2025-04-09 10:44:03,230:INFO:Initializing Random Forest Regressor
2025-04-09 10:44:03,231:INFO:Total runtime is 0.09493437210718791 minutes
2025-04-09 10:44:03,232:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:03,232:INFO:Initializing create_model()
2025-04-09 10:44:03,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:03,232:INFO:Checking exceptions
2025-04-09 10:44:03,232:INFO:Importing libraries
2025-04-09 10:44:03,232:INFO:Copying training dataset
2025-04-09 10:44:03,234:INFO:Defining folds
2025-04-09 10:44:03,234:INFO:Declaring metric variables
2025-04-09 10:44:03,235:INFO:Importing untrained model
2025-04-09 10:44:03,237:INFO:Random Forest Regressor Imported successfully
2025-04-09 10:44:03,239:INFO:Starting cross validation
2025-04-09 10:44:03,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:07,203:INFO:Calculating mean and std
2025-04-09 10:44:07,206:INFO:Creating metrics dataframe
2025-04-09 10:44:07,209:INFO:Uploading results into container
2025-04-09 10:44:07,210:INFO:Uploading model into container now
2025-04-09 10:44:07,211:INFO:_master_model_container: 51
2025-04-09 10:44:07,211:INFO:_display_container: 7
2025-04-09 10:44:07,212:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:44:07,212:INFO:create_model() successfully completed......................................
2025-04-09 10:44:07,318:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:07,318:INFO:Creating metrics dataframe
2025-04-09 10:44:07,341:INFO:Initializing Extra Trees Regressor
2025-04-09 10:44:07,341:INFO:Total runtime is 0.16343988180160524 minutes
2025-04-09 10:44:07,348:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:07,349:INFO:Initializing create_model()
2025-04-09 10:44:07,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:07,349:INFO:Checking exceptions
2025-04-09 10:44:07,349:INFO:Importing libraries
2025-04-09 10:44:07,349:INFO:Copying training dataset
2025-04-09 10:44:07,358:INFO:Defining folds
2025-04-09 10:44:07,358:INFO:Declaring metric variables
2025-04-09 10:44:07,366:INFO:Importing untrained model
2025-04-09 10:44:07,372:INFO:Extra Trees Regressor Imported successfully
2025-04-09 10:44:07,384:INFO:Starting cross validation
2025-04-09 10:44:07,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:10,527:INFO:Calculating mean and std
2025-04-09 10:44:10,529:INFO:Creating metrics dataframe
2025-04-09 10:44:10,533:INFO:Uploading results into container
2025-04-09 10:44:10,534:INFO:Uploading model into container now
2025-04-09 10:44:10,536:INFO:_master_model_container: 52
2025-04-09 10:44:10,536:INFO:_display_container: 7
2025-04-09 10:44:10,537:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:44:10,537:INFO:create_model() successfully completed......................................
2025-04-09 10:44:10,641:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:10,641:INFO:Creating metrics dataframe
2025-04-09 10:44:10,662:INFO:Initializing AdaBoost Regressor
2025-04-09 10:44:10,662:INFO:Total runtime is 0.21879548231760662 minutes
2025-04-09 10:44:10,669:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:10,670:INFO:Initializing create_model()
2025-04-09 10:44:10,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:10,670:INFO:Checking exceptions
2025-04-09 10:44:10,671:INFO:Importing libraries
2025-04-09 10:44:10,671:INFO:Copying training dataset
2025-04-09 10:44:10,679:INFO:Defining folds
2025-04-09 10:44:10,680:INFO:Declaring metric variables
2025-04-09 10:44:10,687:INFO:Importing untrained model
2025-04-09 10:44:10,694:INFO:AdaBoost Regressor Imported successfully
2025-04-09 10:44:10,707:INFO:Starting cross validation
2025-04-09 10:44:10,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:11,784:INFO:Calculating mean and std
2025-04-09 10:44:11,784:INFO:Creating metrics dataframe
2025-04-09 10:44:11,785:INFO:Uploading results into container
2025-04-09 10:44:11,785:INFO:Uploading model into container now
2025-04-09 10:44:11,786:INFO:_master_model_container: 53
2025-04-09 10:44:11,786:INFO:_display_container: 7
2025-04-09 10:44:11,786:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 10:44:11,786:INFO:create_model() successfully completed......................................
2025-04-09 10:44:11,834:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:11,835:INFO:Creating metrics dataframe
2025-04-09 10:44:11,839:INFO:Initializing Gradient Boosting Regressor
2025-04-09 10:44:11,839:INFO:Total runtime is 0.2384120543797811 minutes
2025-04-09 10:44:11,841:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:11,841:INFO:Initializing create_model()
2025-04-09 10:44:11,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:11,841:INFO:Checking exceptions
2025-04-09 10:44:11,841:INFO:Importing libraries
2025-04-09 10:44:11,841:INFO:Copying training dataset
2025-04-09 10:44:11,842:INFO:Defining folds
2025-04-09 10:44:11,843:INFO:Declaring metric variables
2025-04-09 10:44:11,844:INFO:Importing untrained model
2025-04-09 10:44:11,845:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 10:44:11,848:INFO:Starting cross validation
2025-04-09 10:44:11,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:12,912:INFO:Calculating mean and std
2025-04-09 10:44:12,913:INFO:Creating metrics dataframe
2025-04-09 10:44:12,914:INFO:Uploading results into container
2025-04-09 10:44:12,914:INFO:Uploading model into container now
2025-04-09 10:44:12,914:INFO:_master_model_container: 54
2025-04-09 10:44:12,914:INFO:_display_container: 7
2025-04-09 10:44:12,914:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 10:44:12,914:INFO:create_model() successfully completed......................................
2025-04-09 10:44:12,962:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:12,962:INFO:Creating metrics dataframe
2025-04-09 10:44:12,966:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 10:44:12,966:INFO:Total runtime is 0.2571975072224935 minutes
2025-04-09 10:44:12,968:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:12,968:INFO:Initializing create_model()
2025-04-09 10:44:12,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:12,968:INFO:Checking exceptions
2025-04-09 10:44:12,968:INFO:Importing libraries
2025-04-09 10:44:12,968:INFO:Copying training dataset
2025-04-09 10:44:12,970:INFO:Defining folds
2025-04-09 10:44:12,970:INFO:Declaring metric variables
2025-04-09 10:44:12,971:INFO:Importing untrained model
2025-04-09 10:44:12,972:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 10:44:12,975:INFO:Starting cross validation
2025-04-09 10:44:12,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:12,994:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:12,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-04-09 10:44:12,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:12,994:INFO:[LightGBM] [Info] Total Bins 1122
2025-04-09 10:44:12,994:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:12,995:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 10:44:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:12,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,071:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:13,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030368 seconds.
2025-04-09 10:44:13,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:13,103:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 10:44:13,110:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:13,118:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 10:44:13,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,219:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:13,219:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2025-04-09 10:44:13,219:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:13,220:INFO:[LightGBM] [Info] Total Bins 1152
2025-04-09 10:44:13,220:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:13,220:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,298:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:13,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033502 seconds.
2025-04-09 10:44:13,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:13,332:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 10:44:13,339:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:13,347:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 10:44:13,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,869:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:13,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2025-04-09 10:44:13,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:13,870:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 10:44:13,870:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:13,870:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,947:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:13,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.
2025-04-09 10:44:13,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-09 10:44:13,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-09 10:44:13,955:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 10:44:13,955:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:13,956:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 10:44:13,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,030:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:14,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2025-04-09 10:44:14,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:14,031:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 10:44:14,031:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:14,031:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 10:44:14,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,102:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:14,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2025-04-09 10:44:14,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:14,102:INFO:[LightGBM] [Info] Total Bins 1126
2025-04-09 10:44:14,103:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 10:44:14,103:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 10:44:14,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,170:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:14,171:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-04-09 10:44:14,171:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:14,172:INFO:[LightGBM] [Info] Total Bins 1123
2025-04-09 10:44:14,172:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:44:14,172:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 10:44:14,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,257:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 10:44:14,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2025-04-09 10:44:14,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 10:44:14,258:INFO:[LightGBM] [Info] Total Bins 1132
2025-04-09 10:44:14,258:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 10:44:14,258:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 10:44:14,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 10:44:14,294:INFO:Calculating mean and std
2025-04-09 10:44:14,295:INFO:Creating metrics dataframe
2025-04-09 10:44:14,297:INFO:Uploading results into container
2025-04-09 10:44:14,297:INFO:Uploading model into container now
2025-04-09 10:44:14,297:INFO:_master_model_container: 55
2025-04-09 10:44:14,297:INFO:_display_container: 7
2025-04-09 10:44:14,298:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 10:44:14,298:INFO:create_model() successfully completed......................................
2025-04-09 10:44:14,360:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:14,360:INFO:Creating metrics dataframe
2025-04-09 10:44:14,364:INFO:Initializing Dummy Regressor
2025-04-09 10:44:14,364:INFO:Total runtime is 0.28049915631612143 minutes
2025-04-09 10:44:14,366:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:14,366:INFO:Initializing create_model()
2025-04-09 10:44:14,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b1a1c70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:14,366:INFO:Checking exceptions
2025-04-09 10:44:14,366:INFO:Importing libraries
2025-04-09 10:44:14,366:INFO:Copying training dataset
2025-04-09 10:44:14,367:INFO:Defining folds
2025-04-09 10:44:14,368:INFO:Declaring metric variables
2025-04-09 10:44:14,369:INFO:Importing untrained model
2025-04-09 10:44:14,370:INFO:Dummy Regressor Imported successfully
2025-04-09 10:44:14,372:INFO:Starting cross validation
2025-04-09 10:44:14,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:14,596:INFO:Calculating mean and std
2025-04-09 10:44:14,596:INFO:Creating metrics dataframe
2025-04-09 10:44:14,597:INFO:Uploading results into container
2025-04-09 10:44:14,598:INFO:Uploading model into container now
2025-04-09 10:44:14,598:INFO:_master_model_container: 56
2025-04-09 10:44:14,598:INFO:_display_container: 7
2025-04-09 10:44:14,598:INFO:DummyRegressor()
2025-04-09 10:44:14,598:INFO:create_model() successfully completed......................................
2025-04-09 10:44:14,648:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:14,648:INFO:Creating metrics dataframe
2025-04-09 10:44:14,653:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 10:44:14,657:INFO:Initializing create_model()
2025-04-09 10:44:14,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:14,657:INFO:Checking exceptions
2025-04-09 10:44:14,658:INFO:Importing libraries
2025-04-09 10:44:14,658:INFO:Copying training dataset
2025-04-09 10:44:14,660:INFO:Defining folds
2025-04-09 10:44:14,660:INFO:Declaring metric variables
2025-04-09 10:44:14,660:INFO:Importing untrained model
2025-04-09 10:44:14,660:INFO:Declaring custom model
2025-04-09 10:44:14,660:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:44:14,660:INFO:Cross validation set to False
2025-04-09 10:44:14,660:INFO:Fitting Model
2025-04-09 10:44:14,676:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:44:14,676:INFO:create_model() successfully completed......................................
2025-04-09 10:44:14,845:INFO:_master_model_container: 56
2025-04-09 10:44:14,846:INFO:_display_container: 7
2025-04-09 10:44:14,846:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:44:14,846:INFO:compare_models() successfully completed......................................
2025-04-09 10:44:14,847:INFO:Initializing tune_model()
2025-04-09 10:44:14,847:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=50, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>)
2025-04-09 10:44:14,847:INFO:Checking exceptions
2025-04-09 10:44:14,876:INFO:Copying training dataset
2025-04-09 10:44:14,881:INFO:Checking base model
2025-04-09 10:44:14,881:INFO:Base model : K Neighbors Regressor
2025-04-09 10:44:14,888:INFO:Declaring metric variables
2025-04-09 10:44:14,895:INFO:Defining Hyperparameters
2025-04-09 10:44:14,999:INFO:Tuning with n_jobs=-1
2025-04-09 10:44:14,999:INFO:Initializing RandomizedSearchCV
2025-04-09 10:44:16,447:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 2, 'actual_estimator__metric': 'minkowski'}
2025-04-09 10:44:16,447:INFO:Hyperparameter search completed
2025-04-09 10:44:16,447:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:16,447:INFO:Initializing create_model()
2025-04-09 10:44:16,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74046b188d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'uniform', 'n_neighbors': 2, 'metric': 'minkowski'})
2025-04-09 10:44:16,447:INFO:Checking exceptions
2025-04-09 10:44:16,447:INFO:Importing libraries
2025-04-09 10:44:16,447:INFO:Copying training dataset
2025-04-09 10:44:16,449:INFO:Defining folds
2025-04-09 10:44:16,450:INFO:Declaring metric variables
2025-04-09 10:44:16,452:INFO:Importing untrained model
2025-04-09 10:44:16,452:INFO:Declaring custom model
2025-04-09 10:44:16,454:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:44:16,460:INFO:Starting cross validation
2025-04-09 10:44:16,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:17,399:INFO:Calculating mean and std
2025-04-09 10:44:17,401:INFO:Creating metrics dataframe
2025-04-09 10:44:17,407:INFO:Finalizing model
2025-04-09 10:44:17,446:INFO:Uploading results into container
2025-04-09 10:44:17,447:INFO:Uploading model into container now
2025-04-09 10:44:17,447:INFO:_master_model_container: 57
2025-04-09 10:44:17,447:INFO:_display_container: 8
2025-04-09 10:44:17,447:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:44:17,447:INFO:create_model() successfully completed......................................
2025-04-09 10:44:17,502:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:17,502:INFO:choose_better activated
2025-04-09 10:44:17,504:INFO:SubProcess create_model() called ==================================
2025-04-09 10:44:17,504:INFO:Initializing create_model()
2025-04-09 10:44:17,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:17,504:INFO:Checking exceptions
2025-04-09 10:44:17,505:INFO:Importing libraries
2025-04-09 10:44:17,505:INFO:Copying training dataset
2025-04-09 10:44:17,507:INFO:Defining folds
2025-04-09 10:44:17,507:INFO:Declaring metric variables
2025-04-09 10:44:17,507:INFO:Importing untrained model
2025-04-09 10:44:17,507:INFO:Declaring custom model
2025-04-09 10:44:17,507:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:44:17,507:INFO:Starting cross validation
2025-04-09 10:44:17,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 10:44:17,886:INFO:Calculating mean and std
2025-04-09 10:44:17,886:INFO:Creating metrics dataframe
2025-04-09 10:44:17,887:INFO:Finalizing model
2025-04-09 10:44:17,900:INFO:Uploading results into container
2025-04-09 10:44:17,900:INFO:Uploading model into container now
2025-04-09 10:44:17,901:INFO:_master_model_container: 58
2025-04-09 10:44:17,901:INFO:_display_container: 9
2025-04-09 10:44:17,901:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 10:44:17,901:INFO:create_model() successfully completed......................................
2025-04-09 10:44:17,976:INFO:SubProcess create_model() end ==================================
2025-04-09 10:44:17,977:INFO:KNeighborsRegressor(n_jobs=-1) result for RMSE is 0.0209
2025-04-09 10:44:17,977:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) result for RMSE is 0.0158
2025-04-09 10:44:17,977:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) is best model
2025-04-09 10:44:17,977:INFO:choose_better completed
2025-04-09 10:44:17,985:INFO:_master_model_container: 58
2025-04-09 10:44:17,986:INFO:_display_container: 8
2025-04-09 10:44:17,986:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:44:17,986:INFO:tune_model() successfully completed......................................
2025-04-09 10:44:18,086:INFO:Initializing finalize_model()
2025-04-09 10:44:18,086:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-09 10:44:18,086:INFO:Finalizing KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 10:44:18,090:INFO:Initializing create_model()
2025-04-09 10:44:18,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 10:44:18,090:INFO:Checking exceptions
2025-04-09 10:44:18,092:INFO:Importing libraries
2025-04-09 10:44:18,092:INFO:Copying training dataset
2025-04-09 10:44:18,093:INFO:Defining folds
2025-04-09 10:44:18,093:INFO:Declaring metric variables
2025-04-09 10:44:18,093:INFO:Importing untrained model
2025-04-09 10:44:18,093:INFO:Declaring custom model
2025-04-09 10:44:18,094:INFO:K Neighbors Regressor Imported successfully
2025-04-09 10:44:18,095:INFO:Cross validation set to False
2025-04-09 10:44:18,095:INFO:Fitting Model
2025-04-09 10:44:18,146:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:44:18,146:INFO:create_model() successfully completed......................................
2025-04-09 10:44:18,243:INFO:_master_model_container: 58
2025-04-09 10:44:18,244:INFO:_display_container: 8
2025-04-09 10:44:18,255:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:44:18,255:INFO:finalize_model() successfully completed......................................
2025-04-09 10:44:18,315:INFO:Initializing save_model()
2025-04-09 10:44:18,315:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))]), model_name=final_calibrated_depth_model_outdoor, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-09 10:44:18,315:INFO:Adding model into prep_pipe
2025-04-09 10:44:18,315:WARNING:Only Model saved as it was a pipeline.
2025-04-09 10:44:18,317:INFO:final_calibrated_depth_model_outdoor.pkl saved in current working directory
2025-04-09 10:44:18,320:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 10:44:18,320:INFO:save_model() successfully completed......................................
2025-04-09 11:15:59,089:INFO:Initializing compare_models()
2025-04-09 11:15:59,089:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 11:15:59,089:INFO:Checking exceptions
2025-04-09 11:15:59,093:INFO:Preparing display monitor
2025-04-09 11:15:59,129:INFO:Initializing Linear Regression
2025-04-09 11:15:59,129:INFO:Total runtime is 3.8226445515950525e-06 minutes
2025-04-09 11:15:59,133:INFO:SubProcess create_model() called ==================================
2025-04-09 11:15:59,134:INFO:Initializing create_model()
2025-04-09 11:15:59,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:15:59,134:INFO:Checking exceptions
2025-04-09 11:15:59,134:INFO:Importing libraries
2025-04-09 11:15:59,134:INFO:Copying training dataset
2025-04-09 11:15:59,138:INFO:Defining folds
2025-04-09 11:15:59,138:INFO:Declaring metric variables
2025-04-09 11:15:59,141:INFO:Importing untrained model
2025-04-09 11:15:59,145:INFO:Linear Regression Imported successfully
2025-04-09 11:15:59,151:INFO:Starting cross validation
2025-04-09 11:15:59,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:15:59,494:INFO:Calculating mean and std
2025-04-09 11:15:59,494:INFO:Creating metrics dataframe
2025-04-09 11:15:59,495:INFO:Uploading results into container
2025-04-09 11:15:59,495:INFO:Uploading model into container now
2025-04-09 11:15:59,495:INFO:_master_model_container: 59
2025-04-09 11:15:59,495:INFO:_display_container: 9
2025-04-09 11:15:59,495:INFO:LinearRegression(n_jobs=-1)
2025-04-09 11:15:59,495:INFO:create_model() successfully completed......................................
2025-04-09 11:15:59,547:INFO:SubProcess create_model() end ==================================
2025-04-09 11:15:59,547:INFO:Creating metrics dataframe
2025-04-09 11:15:59,550:INFO:Initializing Lasso Regression
2025-04-09 11:15:59,550:INFO:Total runtime is 0.007022674878438314 minutes
2025-04-09 11:15:59,552:INFO:SubProcess create_model() called ==================================
2025-04-09 11:15:59,552:INFO:Initializing create_model()
2025-04-09 11:15:59,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:15:59,552:INFO:Checking exceptions
2025-04-09 11:15:59,552:INFO:Importing libraries
2025-04-09 11:15:59,552:INFO:Copying training dataset
2025-04-09 11:15:59,554:INFO:Defining folds
2025-04-09 11:15:59,554:INFO:Declaring metric variables
2025-04-09 11:15:59,555:INFO:Importing untrained model
2025-04-09 11:15:59,556:INFO:Lasso Regression Imported successfully
2025-04-09 11:15:59,559:INFO:Starting cross validation
2025-04-09 11:15:59,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:15:59,578:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,603:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,628:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,653:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,678:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,703:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,727:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,751:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,776:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,799:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:15:59,809:INFO:Calculating mean and std
2025-04-09 11:15:59,809:INFO:Creating metrics dataframe
2025-04-09 11:15:59,810:INFO:Uploading results into container
2025-04-09 11:15:59,810:INFO:Uploading model into container now
2025-04-09 11:15:59,810:INFO:_master_model_container: 60
2025-04-09 11:15:59,810:INFO:_display_container: 9
2025-04-09 11:15:59,810:INFO:Lasso(random_state=123)
2025-04-09 11:15:59,810:INFO:create_model() successfully completed......................................
2025-04-09 11:15:59,858:INFO:SubProcess create_model() end ==================================
2025-04-09 11:15:59,858:INFO:Creating metrics dataframe
2025-04-09 11:15:59,861:INFO:Initializing Ridge Regression
2025-04-09 11:15:59,861:INFO:Total runtime is 0.01220557689666748 minutes
2025-04-09 11:15:59,863:INFO:SubProcess create_model() called ==================================
2025-04-09 11:15:59,863:INFO:Initializing create_model()
2025-04-09 11:15:59,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:15:59,863:INFO:Checking exceptions
2025-04-09 11:15:59,863:INFO:Importing libraries
2025-04-09 11:15:59,863:INFO:Copying training dataset
2025-04-09 11:15:59,865:INFO:Defining folds
2025-04-09 11:15:59,865:INFO:Declaring metric variables
2025-04-09 11:15:59,866:INFO:Importing untrained model
2025-04-09 11:15:59,868:INFO:Ridge Regression Imported successfully
2025-04-09 11:15:59,870:INFO:Starting cross validation
2025-04-09 11:15:59,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:15:59,887:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.5654e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:15:59,910:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.81945e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:15:59,931:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57492e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:15:59,954:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.61294e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,000:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6252e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,093:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57721e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,129:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.57265e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,149:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.56553e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,169:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.51317e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,190:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.53625e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:16:00,199:INFO:Calculating mean and std
2025-04-09 11:16:00,199:INFO:Creating metrics dataframe
2025-04-09 11:16:00,200:INFO:Uploading results into container
2025-04-09 11:16:00,200:INFO:Uploading model into container now
2025-04-09 11:16:00,201:INFO:_master_model_container: 61
2025-04-09 11:16:00,201:INFO:_display_container: 9
2025-04-09 11:16:00,201:INFO:Ridge(random_state=123)
2025-04-09 11:16:00,201:INFO:create_model() successfully completed......................................
2025-04-09 11:16:00,252:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:00,252:INFO:Creating metrics dataframe
2025-04-09 11:16:00,255:INFO:Initializing Elastic Net
2025-04-09 11:16:00,255:INFO:Total runtime is 0.01877379814783732 minutes
2025-04-09 11:16:00,257:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:00,257:INFO:Initializing create_model()
2025-04-09 11:16:00,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:00,257:INFO:Checking exceptions
2025-04-09 11:16:00,257:INFO:Importing libraries
2025-04-09 11:16:00,257:INFO:Copying training dataset
2025-04-09 11:16:00,259:INFO:Defining folds
2025-04-09 11:16:00,259:INFO:Declaring metric variables
2025-04-09 11:16:00,260:INFO:Importing untrained model
2025-04-09 11:16:00,261:INFO:Elastic Net Imported successfully
2025-04-09 11:16:00,264:INFO:Starting cross validation
2025-04-09 11:16:00,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:00,289:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,380:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,483:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,586:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,637:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,659:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,681:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,704:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,727:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,750:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:16:00,759:INFO:Calculating mean and std
2025-04-09 11:16:00,759:INFO:Creating metrics dataframe
2025-04-09 11:16:00,760:INFO:Uploading results into container
2025-04-09 11:16:00,760:INFO:Uploading model into container now
2025-04-09 11:16:00,761:INFO:_master_model_container: 62
2025-04-09 11:16:00,761:INFO:_display_container: 9
2025-04-09 11:16:00,761:INFO:ElasticNet(random_state=123)
2025-04-09 11:16:00,761:INFO:create_model() successfully completed......................................
2025-04-09 11:16:00,811:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:00,812:INFO:Creating metrics dataframe
2025-04-09 11:16:00,815:INFO:Initializing Least Angle Regression
2025-04-09 11:16:00,815:INFO:Total runtime is 0.028098928928375243 minutes
2025-04-09 11:16:00,816:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:00,816:INFO:Initializing create_model()
2025-04-09 11:16:00,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:00,816:INFO:Checking exceptions
2025-04-09 11:16:00,816:INFO:Importing libraries
2025-04-09 11:16:00,816:INFO:Copying training dataset
2025-04-09 11:16:00,818:INFO:Defining folds
2025-04-09 11:16:00,818:INFO:Declaring metric variables
2025-04-09 11:16:00,819:INFO:Importing untrained model
2025-04-09 11:16:00,821:INFO:Least Angle Regression Imported successfully
2025-04-09 11:16:00,823:INFO:Starting cross validation
2025-04-09 11:16:00,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:00,858:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.030e+07, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:00,962:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.736e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:00,996:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.082e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.317e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,021:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=9.092e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,047:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.505e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,072:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=8.994e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.158e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,098:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.148e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,124:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.313e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,150:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.654e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,176:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=6.212e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 3.667e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:16:01,186:INFO:Calculating mean and std
2025-04-09 11:16:01,186:INFO:Creating metrics dataframe
2025-04-09 11:16:01,187:INFO:Uploading results into container
2025-04-09 11:16:01,187:INFO:Uploading model into container now
2025-04-09 11:16:01,187:INFO:_master_model_container: 63
2025-04-09 11:16:01,187:INFO:_display_container: 9
2025-04-09 11:16:01,188:INFO:Lars(random_state=123)
2025-04-09 11:16:01,188:INFO:create_model() successfully completed......................................
2025-04-09 11:16:01,238:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:01,238:INFO:Creating metrics dataframe
2025-04-09 11:16:01,241:INFO:Initializing Lasso Least Angle Regression
2025-04-09 11:16:01,241:INFO:Total runtime is 0.035204561551411946 minutes
2025-04-09 11:16:01,243:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:01,243:INFO:Initializing create_model()
2025-04-09 11:16:01,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:01,243:INFO:Checking exceptions
2025-04-09 11:16:01,243:INFO:Importing libraries
2025-04-09 11:16:01,243:INFO:Copying training dataset
2025-04-09 11:16:01,245:INFO:Defining folds
2025-04-09 11:16:01,245:INFO:Declaring metric variables
2025-04-09 11:16:01,246:INFO:Importing untrained model
2025-04-09 11:16:01,247:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 11:16:01,250:INFO:Starting cross validation
2025-04-09 11:16:01,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:01,497:INFO:Calculating mean and std
2025-04-09 11:16:01,498:INFO:Creating metrics dataframe
2025-04-09 11:16:01,499:INFO:Uploading results into container
2025-04-09 11:16:01,499:INFO:Uploading model into container now
2025-04-09 11:16:01,499:INFO:_master_model_container: 64
2025-04-09 11:16:01,499:INFO:_display_container: 9
2025-04-09 11:16:01,499:INFO:LassoLars(random_state=123)
2025-04-09 11:16:01,499:INFO:create_model() successfully completed......................................
2025-04-09 11:16:01,550:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:01,550:INFO:Creating metrics dataframe
2025-04-09 11:16:01,554:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 11:16:01,554:INFO:Total runtime is 0.04041591882705688 minutes
2025-04-09 11:16:01,555:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:01,556:INFO:Initializing create_model()
2025-04-09 11:16:01,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:01,556:INFO:Checking exceptions
2025-04-09 11:16:01,556:INFO:Importing libraries
2025-04-09 11:16:01,556:INFO:Copying training dataset
2025-04-09 11:16:01,557:INFO:Defining folds
2025-04-09 11:16:01,557:INFO:Declaring metric variables
2025-04-09 11:16:01,559:INFO:Importing untrained model
2025-04-09 11:16:01,560:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 11:16:01,563:INFO:Starting cross validation
2025-04-09 11:16:01,564:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:01,789:INFO:Calculating mean and std
2025-04-09 11:16:01,789:INFO:Creating metrics dataframe
2025-04-09 11:16:01,790:INFO:Uploading results into container
2025-04-09 11:16:01,791:INFO:Uploading model into container now
2025-04-09 11:16:01,791:INFO:_master_model_container: 65
2025-04-09 11:16:01,791:INFO:_display_container: 9
2025-04-09 11:16:01,791:INFO:OrthogonalMatchingPursuit()
2025-04-09 11:16:01,791:INFO:create_model() successfully completed......................................
2025-04-09 11:16:01,843:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:01,843:INFO:Creating metrics dataframe
2025-04-09 11:16:01,850:INFO:Initializing Bayesian Ridge
2025-04-09 11:16:01,850:INFO:Total runtime is 0.04534622430801392 minutes
2025-04-09 11:16:01,853:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:01,854:INFO:Initializing create_model()
2025-04-09 11:16:01,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:01,854:INFO:Checking exceptions
2025-04-09 11:16:01,854:INFO:Importing libraries
2025-04-09 11:16:01,854:INFO:Copying training dataset
2025-04-09 11:16:01,858:INFO:Defining folds
2025-04-09 11:16:01,858:INFO:Declaring metric variables
2025-04-09 11:16:01,861:INFO:Importing untrained model
2025-04-09 11:16:01,865:INFO:Bayesian Ridge Imported successfully
2025-04-09 11:16:01,872:INFO:Starting cross validation
2025-04-09 11:16:01,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:02,460:INFO:Calculating mean and std
2025-04-09 11:16:02,461:INFO:Creating metrics dataframe
2025-04-09 11:16:02,463:INFO:Uploading results into container
2025-04-09 11:16:02,464:INFO:Uploading model into container now
2025-04-09 11:16:02,464:INFO:_master_model_container: 66
2025-04-09 11:16:02,464:INFO:_display_container: 9
2025-04-09 11:16:02,464:INFO:BayesianRidge()
2025-04-09 11:16:02,464:INFO:create_model() successfully completed......................................
2025-04-09 11:16:02,540:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:02,540:INFO:Creating metrics dataframe
2025-04-09 11:16:02,551:INFO:Initializing Passive Aggressive Regressor
2025-04-09 11:16:02,551:INFO:Total runtime is 0.057030538717905685 minutes
2025-04-09 11:16:02,554:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:02,554:INFO:Initializing create_model()
2025-04-09 11:16:02,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:02,554:INFO:Checking exceptions
2025-04-09 11:16:02,554:INFO:Importing libraries
2025-04-09 11:16:02,554:INFO:Copying training dataset
2025-04-09 11:16:02,557:INFO:Defining folds
2025-04-09 11:16:02,557:INFO:Declaring metric variables
2025-04-09 11:16:02,560:INFO:Importing untrained model
2025-04-09 11:16:02,563:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 11:16:02,568:INFO:Starting cross validation
2025-04-09 11:16:02,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:02,904:INFO:Calculating mean and std
2025-04-09 11:16:02,904:INFO:Creating metrics dataframe
2025-04-09 11:16:02,905:INFO:Uploading results into container
2025-04-09 11:16:02,906:INFO:Uploading model into container now
2025-04-09 11:16:02,906:INFO:_master_model_container: 67
2025-04-09 11:16:02,906:INFO:_display_container: 9
2025-04-09 11:16:02,906:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 11:16:02,906:INFO:create_model() successfully completed......................................
2025-04-09 11:16:02,955:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:02,956:INFO:Creating metrics dataframe
2025-04-09 11:16:02,959:INFO:Initializing Huber Regressor
2025-04-09 11:16:02,959:INFO:Total runtime is 0.06384056011835734 minutes
2025-04-09 11:16:02,961:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:02,961:INFO:Initializing create_model()
2025-04-09 11:16:02,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:02,961:INFO:Checking exceptions
2025-04-09 11:16:02,961:INFO:Importing libraries
2025-04-09 11:16:02,961:INFO:Copying training dataset
2025-04-09 11:16:02,963:INFO:Defining folds
2025-04-09 11:16:02,963:INFO:Declaring metric variables
2025-04-09 11:16:02,964:INFO:Importing untrained model
2025-04-09 11:16:02,966:INFO:Huber Regressor Imported successfully
2025-04-09 11:16:02,970:INFO:Starting cross validation
2025-04-09 11:16:02,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:03,036:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,160:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,227:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,256:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,284:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,313:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,344:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,373:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,402:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:16:03,412:INFO:Calculating mean and std
2025-04-09 11:16:03,412:INFO:Creating metrics dataframe
2025-04-09 11:16:03,413:INFO:Uploading results into container
2025-04-09 11:16:03,414:INFO:Uploading model into container now
2025-04-09 11:16:03,414:INFO:_master_model_container: 68
2025-04-09 11:16:03,414:INFO:_display_container: 9
2025-04-09 11:16:03,414:INFO:HuberRegressor()
2025-04-09 11:16:03,414:INFO:create_model() successfully completed......................................
2025-04-09 11:16:03,465:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:03,465:INFO:Creating metrics dataframe
2025-04-09 11:16:03,469:INFO:Initializing K Neighbors Regressor
2025-04-09 11:16:03,469:INFO:Total runtime is 0.07233580350875854 minutes
2025-04-09 11:16:03,471:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:03,471:INFO:Initializing create_model()
2025-04-09 11:16:03,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:03,471:INFO:Checking exceptions
2025-04-09 11:16:03,471:INFO:Importing libraries
2025-04-09 11:16:03,471:INFO:Copying training dataset
2025-04-09 11:16:03,473:INFO:Defining folds
2025-04-09 11:16:03,473:INFO:Declaring metric variables
2025-04-09 11:16:03,474:INFO:Importing untrained model
2025-04-09 11:16:03,476:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:16:03,478:INFO:Starting cross validation
2025-04-09 11:16:03,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:04,175:INFO:Calculating mean and std
2025-04-09 11:16:04,176:INFO:Creating metrics dataframe
2025-04-09 11:16:04,177:INFO:Uploading results into container
2025-04-09 11:16:04,177:INFO:Uploading model into container now
2025-04-09 11:16:04,177:INFO:_master_model_container: 69
2025-04-09 11:16:04,177:INFO:_display_container: 9
2025-04-09 11:16:04,177:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:16:04,178:INFO:create_model() successfully completed......................................
2025-04-09 11:16:04,229:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:04,229:INFO:Creating metrics dataframe
2025-04-09 11:16:04,234:INFO:Initializing Decision Tree Regressor
2025-04-09 11:16:04,234:INFO:Total runtime is 0.08507678111394246 minutes
2025-04-09 11:16:04,235:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:04,235:INFO:Initializing create_model()
2025-04-09 11:16:04,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:04,236:INFO:Checking exceptions
2025-04-09 11:16:04,236:INFO:Importing libraries
2025-04-09 11:16:04,236:INFO:Copying training dataset
2025-04-09 11:16:04,237:INFO:Defining folds
2025-04-09 11:16:04,237:INFO:Declaring metric variables
2025-04-09 11:16:04,239:INFO:Importing untrained model
2025-04-09 11:16:04,240:INFO:Decision Tree Regressor Imported successfully
2025-04-09 11:16:04,243:INFO:Starting cross validation
2025-04-09 11:16:04,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:04,666:INFO:Calculating mean and std
2025-04-09 11:16:04,666:INFO:Creating metrics dataframe
2025-04-09 11:16:04,667:INFO:Uploading results into container
2025-04-09 11:16:04,667:INFO:Uploading model into container now
2025-04-09 11:16:04,667:INFO:_master_model_container: 70
2025-04-09 11:16:04,667:INFO:_display_container: 9
2025-04-09 11:16:04,668:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 11:16:04,668:INFO:create_model() successfully completed......................................
2025-04-09 11:16:04,718:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:04,718:INFO:Creating metrics dataframe
2025-04-09 11:16:04,722:INFO:Initializing Random Forest Regressor
2025-04-09 11:16:04,722:INFO:Total runtime is 0.09321995178858439 minutes
2025-04-09 11:16:04,724:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:04,724:INFO:Initializing create_model()
2025-04-09 11:16:04,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:04,724:INFO:Checking exceptions
2025-04-09 11:16:04,724:INFO:Importing libraries
2025-04-09 11:16:04,724:INFO:Copying training dataset
2025-04-09 11:16:04,725:INFO:Defining folds
2025-04-09 11:16:04,726:INFO:Declaring metric variables
2025-04-09 11:16:04,727:INFO:Importing untrained model
2025-04-09 11:16:04,728:INFO:Random Forest Regressor Imported successfully
2025-04-09 11:16:04,731:INFO:Starting cross validation
2025-04-09 11:16:04,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:08,715:INFO:Calculating mean and std
2025-04-09 11:16:08,717:INFO:Creating metrics dataframe
2025-04-09 11:16:08,721:INFO:Uploading results into container
2025-04-09 11:16:08,722:INFO:Uploading model into container now
2025-04-09 11:16:08,723:INFO:_master_model_container: 71
2025-04-09 11:16:08,723:INFO:_display_container: 9
2025-04-09 11:16:08,724:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:16:08,724:INFO:create_model() successfully completed......................................
2025-04-09 11:16:08,825:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:08,826:INFO:Creating metrics dataframe
2025-04-09 11:16:08,846:INFO:Initializing Extra Trees Regressor
2025-04-09 11:16:08,847:INFO:Total runtime is 0.16196155150731406 minutes
2025-04-09 11:16:08,853:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:08,854:INFO:Initializing create_model()
2025-04-09 11:16:08,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:08,854:INFO:Checking exceptions
2025-04-09 11:16:08,854:INFO:Importing libraries
2025-04-09 11:16:08,855:INFO:Copying training dataset
2025-04-09 11:16:08,863:INFO:Defining folds
2025-04-09 11:16:08,863:INFO:Declaring metric variables
2025-04-09 11:16:08,870:INFO:Importing untrained model
2025-04-09 11:16:08,878:INFO:Extra Trees Regressor Imported successfully
2025-04-09 11:16:08,891:INFO:Starting cross validation
2025-04-09 11:16:08,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:11,879:INFO:Calculating mean and std
2025-04-09 11:16:11,881:INFO:Creating metrics dataframe
2025-04-09 11:16:11,885:INFO:Uploading results into container
2025-04-09 11:16:11,886:INFO:Uploading model into container now
2025-04-09 11:16:11,887:INFO:_master_model_container: 72
2025-04-09 11:16:11,887:INFO:_display_container: 9
2025-04-09 11:16:11,888:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:16:11,888:INFO:create_model() successfully completed......................................
2025-04-09 11:16:11,992:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:11,992:INFO:Creating metrics dataframe
2025-04-09 11:16:12,009:INFO:Initializing AdaBoost Regressor
2025-04-09 11:16:12,010:INFO:Total runtime is 0.2146777391433716 minutes
2025-04-09 11:16:12,016:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:12,016:INFO:Initializing create_model()
2025-04-09 11:16:12,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:12,016:INFO:Checking exceptions
2025-04-09 11:16:12,016:INFO:Importing libraries
2025-04-09 11:16:12,016:INFO:Copying training dataset
2025-04-09 11:16:12,024:INFO:Defining folds
2025-04-09 11:16:12,025:INFO:Declaring metric variables
2025-04-09 11:16:12,030:INFO:Importing untrained model
2025-04-09 11:16:12,037:INFO:AdaBoost Regressor Imported successfully
2025-04-09 11:16:12,049:INFO:Starting cross validation
2025-04-09 11:16:12,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:12,806:INFO:Calculating mean and std
2025-04-09 11:16:12,806:INFO:Creating metrics dataframe
2025-04-09 11:16:12,807:INFO:Uploading results into container
2025-04-09 11:16:12,808:INFO:Uploading model into container now
2025-04-09 11:16:12,808:INFO:_master_model_container: 73
2025-04-09 11:16:12,808:INFO:_display_container: 9
2025-04-09 11:16:12,808:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 11:16:12,808:INFO:create_model() successfully completed......................................
2025-04-09 11:16:12,857:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:12,857:INFO:Creating metrics dataframe
2025-04-09 11:16:12,862:INFO:Initializing Gradient Boosting Regressor
2025-04-09 11:16:12,862:INFO:Total runtime is 0.2288796067237854 minutes
2025-04-09 11:16:12,863:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:12,863:INFO:Initializing create_model()
2025-04-09 11:16:12,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:12,863:INFO:Checking exceptions
2025-04-09 11:16:12,863:INFO:Importing libraries
2025-04-09 11:16:12,863:INFO:Copying training dataset
2025-04-09 11:16:12,865:INFO:Defining folds
2025-04-09 11:16:12,865:INFO:Declaring metric variables
2025-04-09 11:16:12,867:INFO:Importing untrained model
2025-04-09 11:16:12,868:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:16:12,871:INFO:Starting cross validation
2025-04-09 11:16:12,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:14,080:INFO:Calculating mean and std
2025-04-09 11:16:14,081:INFO:Creating metrics dataframe
2025-04-09 11:16:14,082:INFO:Uploading results into container
2025-04-09 11:16:14,082:INFO:Uploading model into container now
2025-04-09 11:16:14,082:INFO:_master_model_container: 74
2025-04-09 11:16:14,082:INFO:_display_container: 9
2025-04-09 11:16:14,083:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:16:14,083:INFO:create_model() successfully completed......................................
2025-04-09 11:16:14,132:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:14,132:INFO:Creating metrics dataframe
2025-04-09 11:16:14,137:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 11:16:14,137:INFO:Total runtime is 0.25013571977615356 minutes
2025-04-09 11:16:14,139:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:14,139:INFO:Initializing create_model()
2025-04-09 11:16:14,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:14,139:INFO:Checking exceptions
2025-04-09 11:16:14,139:INFO:Importing libraries
2025-04-09 11:16:14,139:INFO:Copying training dataset
2025-04-09 11:16:14,141:INFO:Defining folds
2025-04-09 11:16:14,141:INFO:Declaring metric variables
2025-04-09 11:16:14,142:INFO:Importing untrained model
2025-04-09 11:16:14,144:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 11:16:14,146:INFO:Starting cross validation
2025-04-09 11:16:14,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:14,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2025-04-09 11:16:14,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,179:INFO:[LightGBM] [Info] Total Bins 1122
2025-04-09 11:16:14,179:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,180:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 11:16:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,260:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034245 seconds.
2025-04-09 11:16:14,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,296:INFO:[LightGBM] [Info] Total Bins 1146
2025-04-09 11:16:14,302:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,309:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 11:16:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2025-04-09 11:16:14,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,399:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-09 11:16:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,399:INFO:[LightGBM] [Info] Total Bins 1152
2025-04-09 11:16:14,400:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,400:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,480:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
2025-04-09 11:16:14,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,482:INFO:[LightGBM] [Info] Total Bins 1130
2025-04-09 11:16:14,483:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,483:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 11:16:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,558:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-09 11:16:14,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,559:INFO:[LightGBM] [Info] Total Bins 1145
2025-04-09 11:16:14,559:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,559:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 11:16:14,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,617:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2025-04-09 11:16:14,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,619:INFO:[LightGBM] [Info] Total Bins 1129
2025-04-09 11:16:14,619:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,619:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 11:16:14,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,708:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031109 seconds.
2025-04-09 11:16:14,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,740:INFO:[LightGBM] [Info] Total Bins 1134
2025-04-09 11:16:14,746:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,746:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 11:16:14,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,807:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2025-04-09 11:16:14,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,808:INFO:[LightGBM] [Info] Total Bins 1126
2025-04-09 11:16:14,808:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 54
2025-04-09 11:16:14,808:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 11:16:14,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,870:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-09 11:16:14,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,871:INFO:[LightGBM] [Info] Total Bins 1123
2025-04-09 11:16:14,871:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 11:16:14,871:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,935:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:16:14,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2025-04-09 11:16:14,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:16:14,936:INFO:[LightGBM] [Info] Total Bins 1132
2025-04-09 11:16:14,936:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 54
2025-04-09 11:16:14,936:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:16:14,980:INFO:Calculating mean and std
2025-04-09 11:16:14,981:INFO:Creating metrics dataframe
2025-04-09 11:16:14,982:INFO:Uploading results into container
2025-04-09 11:16:14,983:INFO:Uploading model into container now
2025-04-09 11:16:14,983:INFO:_master_model_container: 75
2025-04-09 11:16:14,983:INFO:_display_container: 9
2025-04-09 11:16:14,983:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:16:14,983:INFO:create_model() successfully completed......................................
2025-04-09 11:16:15,036:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:15,036:INFO:Creating metrics dataframe
2025-04-09 11:16:15,041:INFO:Initializing Dummy Regressor
2025-04-09 11:16:15,041:INFO:Total runtime is 0.26520188252131144 minutes
2025-04-09 11:16:15,043:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:15,043:INFO:Initializing create_model()
2025-04-09 11:16:15,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468714820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:15,043:INFO:Checking exceptions
2025-04-09 11:16:15,043:INFO:Importing libraries
2025-04-09 11:16:15,043:INFO:Copying training dataset
2025-04-09 11:16:15,045:INFO:Defining folds
2025-04-09 11:16:15,045:INFO:Declaring metric variables
2025-04-09 11:16:15,046:INFO:Importing untrained model
2025-04-09 11:16:15,047:INFO:Dummy Regressor Imported successfully
2025-04-09 11:16:15,050:INFO:Starting cross validation
2025-04-09 11:16:15,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:15,355:INFO:Calculating mean and std
2025-04-09 11:16:15,356:INFO:Creating metrics dataframe
2025-04-09 11:16:15,357:INFO:Uploading results into container
2025-04-09 11:16:15,357:INFO:Uploading model into container now
2025-04-09 11:16:15,357:INFO:_master_model_container: 76
2025-04-09 11:16:15,357:INFO:_display_container: 9
2025-04-09 11:16:15,357:INFO:DummyRegressor()
2025-04-09 11:16:15,357:INFO:create_model() successfully completed......................................
2025-04-09 11:16:15,407:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:15,407:INFO:Creating metrics dataframe
2025-04-09 11:16:15,412:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 11:16:15,416:INFO:Initializing create_model()
2025-04-09 11:16:15,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:15,416:INFO:Checking exceptions
2025-04-09 11:16:15,417:INFO:Importing libraries
2025-04-09 11:16:15,417:INFO:Copying training dataset
2025-04-09 11:16:15,418:INFO:Defining folds
2025-04-09 11:16:15,418:INFO:Declaring metric variables
2025-04-09 11:16:15,418:INFO:Importing untrained model
2025-04-09 11:16:15,418:INFO:Declaring custom model
2025-04-09 11:16:15,419:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:16:15,419:INFO:Cross validation set to False
2025-04-09 11:16:15,419:INFO:Fitting Model
2025-04-09 11:16:15,433:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:16:15,433:INFO:create_model() successfully completed......................................
2025-04-09 11:16:15,494:INFO:_master_model_container: 76
2025-04-09 11:16:15,494:INFO:_display_container: 9
2025-04-09 11:16:15,494:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:16:15,494:INFO:compare_models() successfully completed......................................
2025-04-09 11:16:15,495:INFO:Initializing tune_model()
2025-04-09 11:16:15,495:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=50, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>)
2025-04-09 11:16:15,495:INFO:Checking exceptions
2025-04-09 11:16:15,501:INFO:Copying training dataset
2025-04-09 11:16:15,502:INFO:Checking base model
2025-04-09 11:16:15,503:INFO:Base model : K Neighbors Regressor
2025-04-09 11:16:15,504:INFO:Declaring metric variables
2025-04-09 11:16:15,506:INFO:Defining Hyperparameters
2025-04-09 11:16:15,558:INFO:Tuning with n_jobs=-1
2025-04-09 11:16:15,558:INFO:Initializing RandomizedSearchCV
2025-04-09 11:16:19,464:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 2, 'actual_estimator__metric': 'minkowski'}
2025-04-09 11:16:19,466:INFO:Hyperparameter search completed
2025-04-09 11:16:19,466:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:19,467:INFO:Initializing create_model()
2025-04-09 11:16:19,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x740468838be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'uniform', 'n_neighbors': 2, 'metric': 'minkowski'})
2025-04-09 11:16:19,468:INFO:Checking exceptions
2025-04-09 11:16:19,468:INFO:Importing libraries
2025-04-09 11:16:19,468:INFO:Copying training dataset
2025-04-09 11:16:19,477:INFO:Defining folds
2025-04-09 11:16:19,477:INFO:Declaring metric variables
2025-04-09 11:16:19,485:INFO:Importing untrained model
2025-04-09 11:16:19,485:INFO:Declaring custom model
2025-04-09 11:16:19,492:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:16:19,506:INFO:Starting cross validation
2025-04-09 11:16:19,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:19,997:INFO:Calculating mean and std
2025-04-09 11:16:19,997:INFO:Creating metrics dataframe
2025-04-09 11:16:20,000:INFO:Finalizing model
2025-04-09 11:16:20,019:INFO:Uploading results into container
2025-04-09 11:16:20,019:INFO:Uploading model into container now
2025-04-09 11:16:20,020:INFO:_master_model_container: 77
2025-04-09 11:16:20,020:INFO:_display_container: 10
2025-04-09 11:16:20,020:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 11:16:20,020:INFO:create_model() successfully completed......................................
2025-04-09 11:16:20,106:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:20,106:INFO:choose_better activated
2025-04-09 11:16:20,109:INFO:SubProcess create_model() called ==================================
2025-04-09 11:16:20,109:INFO:Initializing create_model()
2025-04-09 11:16:20,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:20,109:INFO:Checking exceptions
2025-04-09 11:16:20,110:INFO:Importing libraries
2025-04-09 11:16:20,110:INFO:Copying training dataset
2025-04-09 11:16:20,112:INFO:Defining folds
2025-04-09 11:16:20,112:INFO:Declaring metric variables
2025-04-09 11:16:20,112:INFO:Importing untrained model
2025-04-09 11:16:20,112:INFO:Declaring custom model
2025-04-09 11:16:20,112:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:16:20,112:INFO:Starting cross validation
2025-04-09 11:16:20,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:16:20,350:INFO:Calculating mean and std
2025-04-09 11:16:20,351:INFO:Creating metrics dataframe
2025-04-09 11:16:20,352:INFO:Finalizing model
2025-04-09 11:16:20,367:INFO:Uploading results into container
2025-04-09 11:16:20,368:INFO:Uploading model into container now
2025-04-09 11:16:20,368:INFO:_master_model_container: 78
2025-04-09 11:16:20,368:INFO:_display_container: 11
2025-04-09 11:16:20,368:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:16:20,368:INFO:create_model() successfully completed......................................
2025-04-09 11:16:20,418:INFO:SubProcess create_model() end ==================================
2025-04-09 11:16:20,418:INFO:KNeighborsRegressor(n_jobs=-1) result for RMSE is 0.0209
2025-04-09 11:16:20,419:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) result for RMSE is 0.0158
2025-04-09 11:16:20,419:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2) is best model
2025-04-09 11:16:20,419:INFO:choose_better completed
2025-04-09 11:16:20,423:INFO:_master_model_container: 78
2025-04-09 11:16:20,423:INFO:_display_container: 10
2025-04-09 11:16:20,423:INFO:KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 11:16:20,423:INFO:tune_model() successfully completed......................................
2025-04-09 11:16:20,478:INFO:Initializing finalize_model()
2025-04-09 11:16:20,478:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-09 11:16:20,479:INFO:Finalizing KNeighborsRegressor(n_jobs=-1, n_neighbors=2)
2025-04-09 11:16:20,480:INFO:Initializing create_model()
2025-04-09 11:16:20,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=KNeighborsRegressor(n_jobs=-1, n_neighbors=2), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:16:20,480:INFO:Checking exceptions
2025-04-09 11:16:20,481:INFO:Importing libraries
2025-04-09 11:16:20,481:INFO:Copying training dataset
2025-04-09 11:16:20,481:INFO:Defining folds
2025-04-09 11:16:20,481:INFO:Declaring metric variables
2025-04-09 11:16:20,481:INFO:Importing untrained model
2025-04-09 11:16:20,481:INFO:Declaring custom model
2025-04-09 11:16:20,481:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:16:20,482:INFO:Cross validation set to False
2025-04-09 11:16:20,482:INFO:Fitting Model
2025-04-09 11:16:20,499:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 11:16:20,499:INFO:create_model() successfully completed......................................
2025-04-09 11:16:20,547:INFO:_master_model_container: 78
2025-04-09 11:16:20,547:INFO:_display_container: 10
2025-04-09 11:16:20,551:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 11:16:20,551:INFO:finalize_model() successfully completed......................................
2025-04-09 11:16:20,606:INFO:Initializing save_model()
2025-04-09 11:16:20,606:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))]), model_name=final_calibrated_depth_model_outdoor, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-09 11:16:20,606:INFO:Adding model into prep_pipe
2025-04-09 11:16:20,606:WARNING:Only Model saved as it was a pipeline.
2025-04-09 11:16:20,608:INFO:final_calibrated_depth_model_outdoor.pkl saved in current working directory
2025-04-09 11:16:20,611:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Frame', 'X_min', 'Y_min', 'X_max',
                                             'Y_max', 'Confidence',
                                             'Average_Depth_m', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Timestamp'],
                                    transformer=TargetEncoder(cols=['Timestamp'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 KNeighborsRegressor(n_jobs=-1, n_neighbors=2))])
2025-04-09 11:16:20,611:INFO:save_model() successfully completed......................................
2025-04-09 11:16:20,692:INFO:Initializing load_model()
2025-04-09 11:16:20,693:INFO:load_model(model_name=final_calibrated_depth_model_outdoor, platform=None, authentication=None, verbose=True)
2025-04-09 11:18:43,236:INFO:Initializing predict_model()
2025-04-09 11:18:43,236:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74046898e6a0>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x740468b479d0>)
2025-04-09 11:18:43,236:INFO:Checking exceptions
2025-04-09 11:18:43,236:INFO:Preloading libraries
2025-04-09 11:18:43,240:INFO:Set up data.
2025-04-09 11:18:43,246:INFO:Set up index.
2025-04-09 11:33:38,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,365:INFO:PyCaret RegressionExperiment
2025-04-09 11:33:38,365:INFO:Logging name: reg-default-name
2025-04-09 11:33:38,365:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-09 11:33:38,365:INFO:version 3.3.1
2025-04-09 11:33:38,365:INFO:Initializing setup()
2025-04-09 11:33:38,365:INFO:self.USI: f9e6
2025-04-09 11:33:38,365:INFO:self._variable_keys: {'_available_plots', 'y_train', 'html_param', 'n_jobs_param', 'transform_target_param', 'gpu_n_jobs_param', 'idx', 'gpu_param', 'logging_param', 'exp_name_log', 'target_param', 'X', 'fold_shuffle_param', 'USI', 'X_train', 'seed', 'fold_generator', 'y', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'exp_id', 'data', 'y_test', 'pipeline', 'X_test', 'memory'}
2025-04-09 11:33:38,366:INFO:Checking environment
2025-04-09 11:33:38,366:INFO:python_version: 3.9.21
2025-04-09 11:33:38,366:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-04-09 11:33:38,366:INFO:machine: x86_64
2025-04-09 11:33:38,366:INFO:platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 11:33:38,366:INFO:Memory: svmem(total=33374547968, available=28420124672, percent=14.8, used=3729977344, free=25707356160, active=4379131904, inactive=1595195392, buffers=214122496, cached=3723091968, shared=741031936, slab=585408512)
2025-04-09 11:33:38,368:INFO:Physical Core: 24
2025-04-09 11:33:38,368:INFO:Logical Core: 32
2025-04-09 11:33:38,368:INFO:Checking libraries
2025-04-09 11:33:38,369:INFO:System:
2025-04-09 11:33:38,369:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-04-09 11:33:38,369:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-04-09 11:33:38,369:INFO:   machine: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-09 11:33:38,369:INFO:PyCaret required dependencies:
2025-04-09 11:33:38,418:INFO:                 pip: 25.0
2025-04-09 11:33:38,418:INFO:          setuptools: 75.8.0
2025-04-09 11:33:38,418:INFO:             pycaret: 3.3.1
2025-04-09 11:33:38,418:INFO:             IPython: 8.18.1
2025-04-09 11:33:38,418:INFO:          ipywidgets: 8.1.5
2025-04-09 11:33:38,418:INFO:                tqdm: 4.67.1
2025-04-09 11:33:38,418:INFO:               numpy: 1.26.4
2025-04-09 11:33:38,418:INFO:              pandas: 2.1.4
2025-04-09 11:33:38,418:INFO:              jinja2: 3.1.5
2025-04-09 11:33:38,418:INFO:               scipy: 1.11.4
2025-04-09 11:33:38,418:INFO:              joblib: 1.3.2
2025-04-09 11:33:38,418:INFO:             sklearn: 1.4.2
2025-04-09 11:33:38,418:INFO:                pyod: 2.0.3
2025-04-09 11:33:38,418:INFO:            imblearn: 0.12.4
2025-04-09 11:33:38,418:INFO:   category_encoders: 2.6.4
2025-04-09 11:33:38,418:INFO:            lightgbm: 4.6.0
2025-04-09 11:33:38,418:INFO:               numba: 0.60.0
2025-04-09 11:33:38,418:INFO:            requests: 2.32.3
2025-04-09 11:33:38,418:INFO:          matplotlib: 3.7.5
2025-04-09 11:33:38,419:INFO:          scikitplot: 0.3.7
2025-04-09 11:33:38,419:INFO:         yellowbrick: 1.5
2025-04-09 11:33:38,419:INFO:              plotly: 5.24.1
2025-04-09 11:33:38,419:INFO:    plotly-resampler: Not installed
2025-04-09 11:33:38,419:INFO:             kaleido: 0.2.1
2025-04-09 11:33:38,419:INFO:           schemdraw: 0.15
2025-04-09 11:33:38,419:INFO:         statsmodels: 0.14.4
2025-04-09 11:33:38,419:INFO:              sktime: 0.26.0
2025-04-09 11:33:38,419:INFO:               tbats: 1.1.3
2025-04-09 11:33:38,419:INFO:            pmdarima: 2.0.4
2025-04-09 11:33:38,419:INFO:              psutil: 7.0.0
2025-04-09 11:33:38,419:INFO:          markupsafe: 3.0.2
2025-04-09 11:33:38,419:INFO:             pickle5: Not installed
2025-04-09 11:33:38,419:INFO:         cloudpickle: 3.1.1
2025-04-09 11:33:38,419:INFO:         deprecation: 2.1.0
2025-04-09 11:33:38,419:INFO:              xxhash: 3.5.0
2025-04-09 11:33:38,419:INFO:           wurlitzer: 3.1.1
2025-04-09 11:33:38,419:INFO:PyCaret optional dependencies:
2025-04-09 11:33:38,445:INFO:                shap: Not installed
2025-04-09 11:33:38,445:INFO:           interpret: Not installed
2025-04-09 11:33:38,445:INFO:                umap: Not installed
2025-04-09 11:33:38,445:INFO:     ydata_profiling: Not installed
2025-04-09 11:33:38,445:INFO:  explainerdashboard: Not installed
2025-04-09 11:33:38,445:INFO:             autoviz: Not installed
2025-04-09 11:33:38,445:INFO:           fairlearn: Not installed
2025-04-09 11:33:38,445:INFO:          deepchecks: Not installed
2025-04-09 11:33:38,445:INFO:             xgboost: Not installed
2025-04-09 11:33:38,445:INFO:            catboost: Not installed
2025-04-09 11:33:38,445:INFO:              kmodes: Not installed
2025-04-09 11:33:38,445:INFO:             mlxtend: Not installed
2025-04-09 11:33:38,445:INFO:       statsforecast: Not installed
2025-04-09 11:33:38,445:INFO:        tune_sklearn: Not installed
2025-04-09 11:33:38,445:INFO:                 ray: Not installed
2025-04-09 11:33:38,445:INFO:            hyperopt: Not installed
2025-04-09 11:33:38,445:INFO:              optuna: Not installed
2025-04-09 11:33:38,445:INFO:               skopt: Not installed
2025-04-09 11:33:38,446:INFO:              mlflow: Not installed
2025-04-09 11:33:38,446:INFO:              gradio: Not installed
2025-04-09 11:33:38,446:INFO:             fastapi: Not installed
2025-04-09 11:33:38,446:INFO:             uvicorn: Not installed
2025-04-09 11:33:38,446:INFO:              m2cgen: Not installed
2025-04-09 11:33:38,446:INFO:           evidently: Not installed
2025-04-09 11:33:38,446:INFO:               fugue: Not installed
2025-04-09 11:33:38,446:INFO:           streamlit: Not installed
2025-04-09 11:33:38,446:INFO:             prophet: Not installed
2025-04-09 11:33:38,446:INFO:None
2025-04-09 11:33:38,446:INFO:Set up GPU usage.
2025-04-09 11:33:38,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,446:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-04-09 11:33:38,446:INFO:Set up data.
2025-04-09 11:33:38,455:INFO:Set up folding strategy.
2025-04-09 11:33:38,455:INFO:Set up train/test split.
2025-04-09 11:33:38,463:INFO:Set up index.
2025-04-09 11:33:38,463:INFO:Assigning column types.
2025-04-09 11:33:38,471:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-09 11:33:38,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,471:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 11:33:38,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,481:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 11:33:38,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:38,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:38,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:38,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:38,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,041:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,046:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,187:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-09 11:33:51,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,238:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,286:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-09 11:33:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,349:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,500:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-09 11:33:51,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,739:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-09 11:33:51,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:51,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:51,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:51,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-09 11:33:52,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,113:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-09 11:33:52,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,614:INFO:Preparing preprocessing pipeline...
2025-04-09 11:33:52,614:INFO:Set up simple imputation.
2025-04-09 11:33:52,614:INFO:Set up polynomial features.
2025-04-09 11:33:52,670:INFO:Finished creating preprocessing pipeline.
2025-04-09 11:33:52,678:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-04-09 11:33:52,679:INFO:Creating final display dataframe.
2025-04-09 11:33:52,730:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape          (155, 8)
4        Transformed data shape         (155, 36)
5   Transformed train set shape         (108, 36)
6    Transformed test set shape          (47, 36)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              f9e6
2025-04-09 11:33:52,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,767:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-09 11:33:52,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-09 11:33:52,841:INFO:setup() successfully completed in 14.48s...............
2025-04-09 11:33:52,845:INFO:Initializing compare_models()
2025-04-09 11:33:52,845:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 11:33:52,846:INFO:Checking exceptions
2025-04-09 11:33:52,847:INFO:Preparing display monitor
2025-04-09 11:33:52,864:INFO:Initializing Linear Regression
2025-04-09 11:33:52,864:INFO:Total runtime is 2.491474151611328e-06 minutes
2025-04-09 11:33:52,866:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:52,866:INFO:Initializing create_model()
2025-04-09 11:33:52,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:52,866:INFO:Checking exceptions
2025-04-09 11:33:52,866:INFO:Importing libraries
2025-04-09 11:33:52,866:INFO:Copying training dataset
2025-04-09 11:33:52,868:INFO:Defining folds
2025-04-09 11:33:52,869:INFO:Declaring metric variables
2025-04-09 11:33:52,871:INFO:Importing untrained model
2025-04-09 11:33:52,875:INFO:Linear Regression Imported successfully
2025-04-09 11:33:52,884:INFO:Starting cross validation
2025-04-09 11:33:52,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:53,165:INFO:Calculating mean and std
2025-04-09 11:33:53,166:INFO:Creating metrics dataframe
2025-04-09 11:33:53,169:INFO:Uploading results into container
2025-04-09 11:33:53,170:INFO:Uploading model into container now
2025-04-09 11:33:53,171:INFO:_master_model_container: 1
2025-04-09 11:33:53,171:INFO:_display_container: 2
2025-04-09 11:33:53,171:INFO:LinearRegression(n_jobs=-1)
2025-04-09 11:33:53,171:INFO:create_model() successfully completed......................................
2025-04-09 11:33:53,257:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:53,257:INFO:Creating metrics dataframe
2025-04-09 11:33:53,264:INFO:Initializing Lasso Regression
2025-04-09 11:33:53,264:INFO:Total runtime is 0.006676538785298666 minutes
2025-04-09 11:33:53,267:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:53,267:INFO:Initializing create_model()
2025-04-09 11:33:53,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:53,267:INFO:Checking exceptions
2025-04-09 11:33:53,267:INFO:Importing libraries
2025-04-09 11:33:53,267:INFO:Copying training dataset
2025-04-09 11:33:53,270:INFO:Defining folds
2025-04-09 11:33:53,270:INFO:Declaring metric variables
2025-04-09 11:33:53,272:INFO:Importing untrained model
2025-04-09 11:33:53,274:INFO:Lasso Regression Imported successfully
2025-04-09 11:33:53,278:INFO:Starting cross validation
2025-04-09 11:33:53,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:53,299:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,324:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,370:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,410:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,432:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,445:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,465:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,516:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,562:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,608:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,626:INFO:Calculating mean and std
2025-04-09 11:33:53,626:INFO:Creating metrics dataframe
2025-04-09 11:33:53,630:INFO:Uploading results into container
2025-04-09 11:33:53,630:INFO:Uploading model into container now
2025-04-09 11:33:53,631:INFO:_master_model_container: 2
2025-04-09 11:33:53,631:INFO:_display_container: 2
2025-04-09 11:33:53,632:INFO:Lasso(random_state=123)
2025-04-09 11:33:53,632:INFO:create_model() successfully completed......................................
2025-04-09 11:33:53,704:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:53,704:INFO:Creating metrics dataframe
2025-04-09 11:33:53,708:INFO:Initializing Ridge Regression
2025-04-09 11:33:53,708:INFO:Total runtime is 0.014076586564381918 minutes
2025-04-09 11:33:53,710:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:53,710:INFO:Initializing create_model()
2025-04-09 11:33:53,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:53,710:INFO:Checking exceptions
2025-04-09 11:33:53,710:INFO:Importing libraries
2025-04-09 11:33:53,710:INFO:Copying training dataset
2025-04-09 11:33:53,712:INFO:Defining folds
2025-04-09 11:33:53,712:INFO:Declaring metric variables
2025-04-09 11:33:53,713:INFO:Importing untrained model
2025-04-09 11:33:53,714:INFO:Ridge Regression Imported successfully
2025-04-09 11:33:53,717:INFO:Starting cross validation
2025-04-09 11:33:53,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:53,725:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.83501e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,733:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.99565e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,741:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.98533e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,750:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.74825e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,759:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.06537e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,768:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.01696e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,776:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.69617e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,785:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.94072e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,793:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6569e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,802:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.08078e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:33:53,806:INFO:Calculating mean and std
2025-04-09 11:33:53,806:INFO:Creating metrics dataframe
2025-04-09 11:33:53,807:INFO:Uploading results into container
2025-04-09 11:33:53,807:INFO:Uploading model into container now
2025-04-09 11:33:53,807:INFO:_master_model_container: 3
2025-04-09 11:33:53,807:INFO:_display_container: 2
2025-04-09 11:33:53,807:INFO:Ridge(random_state=123)
2025-04-09 11:33:53,807:INFO:create_model() successfully completed......................................
2025-04-09 11:33:53,856:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:53,856:INFO:Creating metrics dataframe
2025-04-09 11:33:53,859:INFO:Initializing Elastic Net
2025-04-09 11:33:53,859:INFO:Total runtime is 0.016596337159474693 minutes
2025-04-09 11:33:53,861:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:53,861:INFO:Initializing create_model()
2025-04-09 11:33:53,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:53,861:INFO:Checking exceptions
2025-04-09 11:33:53,861:INFO:Importing libraries
2025-04-09 11:33:53,861:INFO:Copying training dataset
2025-04-09 11:33:53,863:INFO:Defining folds
2025-04-09 11:33:53,863:INFO:Declaring metric variables
2025-04-09 11:33:53,864:INFO:Importing untrained model
2025-04-09 11:33:53,866:INFO:Elastic Net Imported successfully
2025-04-09 11:33:53,868:INFO:Starting cross validation
2025-04-09 11:33:53,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:53,877:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,888:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,900:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,911:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,922:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,933:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,944:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,955:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,966:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,977:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:33:53,982:INFO:Calculating mean and std
2025-04-09 11:33:53,982:INFO:Creating metrics dataframe
2025-04-09 11:33:53,983:INFO:Uploading results into container
2025-04-09 11:33:53,984:INFO:Uploading model into container now
2025-04-09 11:33:53,984:INFO:_master_model_container: 4
2025-04-09 11:33:53,984:INFO:_display_container: 2
2025-04-09 11:33:53,984:INFO:ElasticNet(random_state=123)
2025-04-09 11:33:53,984:INFO:create_model() successfully completed......................................
2025-04-09 11:33:54,031:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:54,031:INFO:Creating metrics dataframe
2025-04-09 11:33:54,035:INFO:Initializing Least Angle Regression
2025-04-09 11:33:54,035:INFO:Total runtime is 0.01952873468399048 minutes
2025-04-09 11:33:54,037:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:54,037:INFO:Initializing create_model()
2025-04-09 11:33:54,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:54,037:INFO:Checking exceptions
2025-04-09 11:33:54,037:INFO:Importing libraries
2025-04-09 11:33:54,037:INFO:Copying training dataset
2025-04-09 11:33:54,038:INFO:Defining folds
2025-04-09 11:33:54,038:INFO:Declaring metric variables
2025-04-09 11:33:54,040:INFO:Importing untrained model
2025-04-09 11:33:54,041:INFO:Least Angle Regression Imported successfully
2025-04-09 11:33:54,044:INFO:Starting cross validation
2025-04-09 11:33:54,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:54,053:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.956e-05, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,065:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.084e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,079:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.444e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,092:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.329e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,104:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.858e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,116:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.245e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.871e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,127:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.124e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,137:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.974e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,147:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.586e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,158:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.021e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.546e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:33:54,162:INFO:Calculating mean and std
2025-04-09 11:33:54,162:INFO:Creating metrics dataframe
2025-04-09 11:33:54,163:INFO:Uploading results into container
2025-04-09 11:33:54,164:INFO:Uploading model into container now
2025-04-09 11:33:54,164:INFO:_master_model_container: 5
2025-04-09 11:33:54,164:INFO:_display_container: 2
2025-04-09 11:33:54,164:INFO:Lars(random_state=123)
2025-04-09 11:33:54,164:INFO:create_model() successfully completed......................................
2025-04-09 11:33:54,212:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:54,212:INFO:Creating metrics dataframe
2025-04-09 11:33:54,216:INFO:Initializing Lasso Least Angle Regression
2025-04-09 11:33:54,216:INFO:Total runtime is 0.02254015604654948 minutes
2025-04-09 11:33:54,217:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:54,218:INFO:Initializing create_model()
2025-04-09 11:33:54,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:54,218:INFO:Checking exceptions
2025-04-09 11:33:54,218:INFO:Importing libraries
2025-04-09 11:33:54,218:INFO:Copying training dataset
2025-04-09 11:33:54,219:INFO:Defining folds
2025-04-09 11:33:54,219:INFO:Declaring metric variables
2025-04-09 11:33:54,220:INFO:Importing untrained model
2025-04-09 11:33:54,222:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 11:33:54,224:INFO:Starting cross validation
2025-04-09 11:33:54,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:54,331:INFO:Calculating mean and std
2025-04-09 11:33:54,331:INFO:Creating metrics dataframe
2025-04-09 11:33:54,332:INFO:Uploading results into container
2025-04-09 11:33:54,333:INFO:Uploading model into container now
2025-04-09 11:33:54,333:INFO:_master_model_container: 6
2025-04-09 11:33:54,333:INFO:_display_container: 2
2025-04-09 11:33:54,333:INFO:LassoLars(random_state=123)
2025-04-09 11:33:54,333:INFO:create_model() successfully completed......................................
2025-04-09 11:33:54,378:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:54,378:INFO:Creating metrics dataframe
2025-04-09 11:33:54,382:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 11:33:54,382:INFO:Total runtime is 0.025305779774983727 minutes
2025-04-09 11:33:54,384:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:54,384:INFO:Initializing create_model()
2025-04-09 11:33:54,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:54,384:INFO:Checking exceptions
2025-04-09 11:33:54,384:INFO:Importing libraries
2025-04-09 11:33:54,384:INFO:Copying training dataset
2025-04-09 11:33:54,385:INFO:Defining folds
2025-04-09 11:33:54,385:INFO:Declaring metric variables
2025-04-09 11:33:54,387:INFO:Importing untrained model
2025-04-09 11:33:54,388:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 11:33:54,391:INFO:Starting cross validation
2025-04-09 11:33:54,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:54,579:INFO:Calculating mean and std
2025-04-09 11:33:54,580:INFO:Creating metrics dataframe
2025-04-09 11:33:54,580:INFO:Uploading results into container
2025-04-09 11:33:54,581:INFO:Uploading model into container now
2025-04-09 11:33:54,581:INFO:_master_model_container: 7
2025-04-09 11:33:54,581:INFO:_display_container: 2
2025-04-09 11:33:54,581:INFO:OrthogonalMatchingPursuit()
2025-04-09 11:33:54,581:INFO:create_model() successfully completed......................................
2025-04-09 11:33:54,671:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:54,671:INFO:Creating metrics dataframe
2025-04-09 11:33:54,687:INFO:Initializing Bayesian Ridge
2025-04-09 11:33:54,688:INFO:Total runtime is 0.030400649706522627 minutes
2025-04-09 11:33:54,695:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:54,695:INFO:Initializing create_model()
2025-04-09 11:33:54,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:54,696:INFO:Checking exceptions
2025-04-09 11:33:54,696:INFO:Importing libraries
2025-04-09 11:33:54,696:INFO:Copying training dataset
2025-04-09 11:33:54,704:INFO:Defining folds
2025-04-09 11:33:54,704:INFO:Declaring metric variables
2025-04-09 11:33:54,711:INFO:Importing untrained model
2025-04-09 11:33:54,718:INFO:Bayesian Ridge Imported successfully
2025-04-09 11:33:54,735:INFO:Starting cross validation
2025-04-09 11:33:54,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:54,962:INFO:Calculating mean and std
2025-04-09 11:33:54,963:INFO:Creating metrics dataframe
2025-04-09 11:33:54,963:INFO:Uploading results into container
2025-04-09 11:33:54,964:INFO:Uploading model into container now
2025-04-09 11:33:54,964:INFO:_master_model_container: 8
2025-04-09 11:33:54,964:INFO:_display_container: 2
2025-04-09 11:33:54,964:INFO:BayesianRidge()
2025-04-09 11:33:54,964:INFO:create_model() successfully completed......................................
2025-04-09 11:33:55,008:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:55,009:INFO:Creating metrics dataframe
2025-04-09 11:33:55,012:INFO:Initializing Passive Aggressive Regressor
2025-04-09 11:33:55,013:INFO:Total runtime is 0.03581663767496745 minutes
2025-04-09 11:33:55,014:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:55,014:INFO:Initializing create_model()
2025-04-09 11:33:55,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:55,015:INFO:Checking exceptions
2025-04-09 11:33:55,015:INFO:Importing libraries
2025-04-09 11:33:55,015:INFO:Copying training dataset
2025-04-09 11:33:55,016:INFO:Defining folds
2025-04-09 11:33:55,016:INFO:Declaring metric variables
2025-04-09 11:33:55,018:INFO:Importing untrained model
2025-04-09 11:33:55,019:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 11:33:55,022:INFO:Starting cross validation
2025-04-09 11:33:55,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:55,297:INFO:Calculating mean and std
2025-04-09 11:33:55,298:INFO:Creating metrics dataframe
2025-04-09 11:33:55,298:INFO:Uploading results into container
2025-04-09 11:33:55,299:INFO:Uploading model into container now
2025-04-09 11:33:55,299:INFO:_master_model_container: 9
2025-04-09 11:33:55,299:INFO:_display_container: 2
2025-04-09 11:33:55,299:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 11:33:55,299:INFO:create_model() successfully completed......................................
2025-04-09 11:33:55,344:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:55,344:INFO:Creating metrics dataframe
2025-04-09 11:33:55,348:INFO:Initializing Huber Regressor
2025-04-09 11:33:55,348:INFO:Total runtime is 0.041403321425120036 minutes
2025-04-09 11:33:55,349:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:55,349:INFO:Initializing create_model()
2025-04-09 11:33:55,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:55,349:INFO:Checking exceptions
2025-04-09 11:33:55,349:INFO:Importing libraries
2025-04-09 11:33:55,349:INFO:Copying training dataset
2025-04-09 11:33:55,351:INFO:Defining folds
2025-04-09 11:33:55,351:INFO:Declaring metric variables
2025-04-09 11:33:55,352:INFO:Importing untrained model
2025-04-09 11:33:55,354:INFO:Huber Regressor Imported successfully
2025-04-09 11:33:55,356:INFO:Starting cross validation
2025-04-09 11:33:55,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:55,380:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:33:55,442:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:33:55,457:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:33:55,520:INFO:Calculating mean and std
2025-04-09 11:33:55,521:INFO:Creating metrics dataframe
2025-04-09 11:33:55,522:INFO:Uploading results into container
2025-04-09 11:33:55,522:INFO:Uploading model into container now
2025-04-09 11:33:55,522:INFO:_master_model_container: 10
2025-04-09 11:33:55,522:INFO:_display_container: 2
2025-04-09 11:33:55,522:INFO:HuberRegressor()
2025-04-09 11:33:55,522:INFO:create_model() successfully completed......................................
2025-04-09 11:33:55,566:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:55,567:INFO:Creating metrics dataframe
2025-04-09 11:33:55,570:INFO:Initializing K Neighbors Regressor
2025-04-09 11:33:55,571:INFO:Total runtime is 0.04511714776357015 minutes
2025-04-09 11:33:55,572:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:55,572:INFO:Initializing create_model()
2025-04-09 11:33:55,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:55,572:INFO:Checking exceptions
2025-04-09 11:33:55,572:INFO:Importing libraries
2025-04-09 11:33:55,572:INFO:Copying training dataset
2025-04-09 11:33:55,574:INFO:Defining folds
2025-04-09 11:33:55,574:INFO:Declaring metric variables
2025-04-09 11:33:55,575:INFO:Importing untrained model
2025-04-09 11:33:55,576:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:33:55,579:INFO:Starting cross validation
2025-04-09 11:33:55,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:55,844:INFO:Calculating mean and std
2025-04-09 11:33:55,845:INFO:Creating metrics dataframe
2025-04-09 11:33:55,847:INFO:Uploading results into container
2025-04-09 11:33:55,848:INFO:Uploading model into container now
2025-04-09 11:33:55,848:INFO:_master_model_container: 11
2025-04-09 11:33:55,848:INFO:_display_container: 2
2025-04-09 11:33:55,849:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:33:55,849:INFO:create_model() successfully completed......................................
2025-04-09 11:33:55,905:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:55,905:INFO:Creating metrics dataframe
2025-04-09 11:33:55,909:INFO:Initializing Decision Tree Regressor
2025-04-09 11:33:55,910:INFO:Total runtime is 0.05076673030853271 minutes
2025-04-09 11:33:55,912:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:55,912:INFO:Initializing create_model()
2025-04-09 11:33:55,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:55,912:INFO:Checking exceptions
2025-04-09 11:33:55,912:INFO:Importing libraries
2025-04-09 11:33:55,912:INFO:Copying training dataset
2025-04-09 11:33:55,913:INFO:Defining folds
2025-04-09 11:33:55,913:INFO:Declaring metric variables
2025-04-09 11:33:55,915:INFO:Importing untrained model
2025-04-09 11:33:55,917:INFO:Decision Tree Regressor Imported successfully
2025-04-09 11:33:55,919:INFO:Starting cross validation
2025-04-09 11:33:55,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:56,040:INFO:Calculating mean and std
2025-04-09 11:33:56,040:INFO:Creating metrics dataframe
2025-04-09 11:33:56,041:INFO:Uploading results into container
2025-04-09 11:33:56,042:INFO:Uploading model into container now
2025-04-09 11:33:56,042:INFO:_master_model_container: 12
2025-04-09 11:33:56,042:INFO:_display_container: 2
2025-04-09 11:33:56,042:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 11:33:56,042:INFO:create_model() successfully completed......................................
2025-04-09 11:33:56,119:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:56,119:INFO:Creating metrics dataframe
2025-04-09 11:33:56,139:INFO:Initializing Random Forest Regressor
2025-04-09 11:33:56,140:INFO:Total runtime is 0.05460073153177897 minutes
2025-04-09 11:33:56,146:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:56,147:INFO:Initializing create_model()
2025-04-09 11:33:56,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:56,147:INFO:Checking exceptions
2025-04-09 11:33:56,147:INFO:Importing libraries
2025-04-09 11:33:56,147:INFO:Copying training dataset
2025-04-09 11:33:56,156:INFO:Defining folds
2025-04-09 11:33:56,156:INFO:Declaring metric variables
2025-04-09 11:33:56,163:INFO:Importing untrained model
2025-04-09 11:33:56,170:INFO:Random Forest Regressor Imported successfully
2025-04-09 11:33:56,183:INFO:Starting cross validation
2025-04-09 11:33:56,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:33:59,698:INFO:Calculating mean and std
2025-04-09 11:33:59,700:INFO:Creating metrics dataframe
2025-04-09 11:33:59,704:INFO:Uploading results into container
2025-04-09 11:33:59,705:INFO:Uploading model into container now
2025-04-09 11:33:59,706:INFO:_master_model_container: 13
2025-04-09 11:33:59,706:INFO:_display_container: 2
2025-04-09 11:33:59,706:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:33:59,707:INFO:create_model() successfully completed......................................
2025-04-09 11:33:59,801:INFO:SubProcess create_model() end ==================================
2025-04-09 11:33:59,801:INFO:Creating metrics dataframe
2025-04-09 11:33:59,826:INFO:Initializing Extra Trees Regressor
2025-04-09 11:33:59,826:INFO:Total runtime is 0.11604121128718058 minutes
2025-04-09 11:33:59,835:INFO:SubProcess create_model() called ==================================
2025-04-09 11:33:59,836:INFO:Initializing create_model()
2025-04-09 11:33:59,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:33:59,836:INFO:Checking exceptions
2025-04-09 11:33:59,836:INFO:Importing libraries
2025-04-09 11:33:59,836:INFO:Copying training dataset
2025-04-09 11:33:59,846:INFO:Defining folds
2025-04-09 11:33:59,846:INFO:Declaring metric variables
2025-04-09 11:33:59,854:INFO:Importing untrained model
2025-04-09 11:33:59,862:INFO:Extra Trees Regressor Imported successfully
2025-04-09 11:33:59,876:INFO:Starting cross validation
2025-04-09 11:33:59,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:02,443:INFO:Calculating mean and std
2025-04-09 11:34:02,445:INFO:Creating metrics dataframe
2025-04-09 11:34:02,449:INFO:Uploading results into container
2025-04-09 11:34:02,450:INFO:Uploading model into container now
2025-04-09 11:34:02,450:INFO:_master_model_container: 14
2025-04-09 11:34:02,451:INFO:_display_container: 2
2025-04-09 11:34:02,451:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:34:02,451:INFO:create_model() successfully completed......................................
2025-04-09 11:34:02,544:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:02,544:INFO:Creating metrics dataframe
2025-04-09 11:34:02,569:INFO:Initializing AdaBoost Regressor
2025-04-09 11:34:02,569:INFO:Total runtime is 0.1617594281832377 minutes
2025-04-09 11:34:02,576:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:02,577:INFO:Initializing create_model()
2025-04-09 11:34:02,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:02,577:INFO:Checking exceptions
2025-04-09 11:34:02,577:INFO:Importing libraries
2025-04-09 11:34:02,577:INFO:Copying training dataset
2025-04-09 11:34:02,585:INFO:Defining folds
2025-04-09 11:34:02,586:INFO:Declaring metric variables
2025-04-09 11:34:02,593:INFO:Importing untrained model
2025-04-09 11:34:02,601:INFO:AdaBoost Regressor Imported successfully
2025-04-09 11:34:02,614:INFO:Starting cross validation
2025-04-09 11:34:02,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:03,251:INFO:Calculating mean and std
2025-04-09 11:34:03,252:INFO:Creating metrics dataframe
2025-04-09 11:34:03,253:INFO:Uploading results into container
2025-04-09 11:34:03,253:INFO:Uploading model into container now
2025-04-09 11:34:03,253:INFO:_master_model_container: 15
2025-04-09 11:34:03,253:INFO:_display_container: 2
2025-04-09 11:34:03,253:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 11:34:03,253:INFO:create_model() successfully completed......................................
2025-04-09 11:34:03,300:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:03,300:INFO:Creating metrics dataframe
2025-04-09 11:34:03,305:INFO:Initializing Gradient Boosting Regressor
2025-04-09 11:34:03,305:INFO:Total runtime is 0.17402008374532063 minutes
2025-04-09 11:34:03,306:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:03,306:INFO:Initializing create_model()
2025-04-09 11:34:03,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:03,306:INFO:Checking exceptions
2025-04-09 11:34:03,306:INFO:Importing libraries
2025-04-09 11:34:03,306:INFO:Copying training dataset
2025-04-09 11:34:03,308:INFO:Defining folds
2025-04-09 11:34:03,308:INFO:Declaring metric variables
2025-04-09 11:34:03,309:INFO:Importing untrained model
2025-04-09 11:34:03,311:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:03,314:INFO:Starting cross validation
2025-04-09 11:34:03,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:04,232:INFO:Calculating mean and std
2025-04-09 11:34:04,233:INFO:Creating metrics dataframe
2025-04-09 11:34:04,234:INFO:Uploading results into container
2025-04-09 11:34:04,234:INFO:Uploading model into container now
2025-04-09 11:34:04,234:INFO:_master_model_container: 16
2025-04-09 11:34:04,234:INFO:_display_container: 2
2025-04-09 11:34:04,235:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:04,235:INFO:create_model() successfully completed......................................
2025-04-09 11:34:04,280:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:04,280:INFO:Creating metrics dataframe
2025-04-09 11:34:04,285:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 11:34:04,285:INFO:Total runtime is 0.19036016861597696 minutes
2025-04-09 11:34:04,287:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:04,287:INFO:Initializing create_model()
2025-04-09 11:34:04,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:04,287:INFO:Checking exceptions
2025-04-09 11:34:04,287:INFO:Importing libraries
2025-04-09 11:34:04,287:INFO:Copying training dataset
2025-04-09 11:34:04,289:INFO:Defining folds
2025-04-09 11:34:04,289:INFO:Declaring metric variables
2025-04-09 11:34:04,290:INFO:Importing untrained model
2025-04-09 11:34:04,292:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 11:34:04,294:INFO:Starting cross validation
2025-04-09 11:34:04,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:04,322:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:04,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031437 seconds.
2025-04-09 11:34:04,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:04,364:INFO:[LightGBM] [Info] Total Bins 675
2025-04-09 11:34:04,370:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:04,377:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 11:34:04,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:04,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:04,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:04,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:04,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:04,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:05,970:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:06,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038268 seconds.
2025-04-09 11:34:06,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:06,009:INFO:[LightGBM] [Info] Total Bins 696
2025-04-09 11:34:06,015:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:06,024:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 11:34:06,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:06,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:07,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,423:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:08,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031182 seconds.
2025-04-09 11:34:08,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:08,455:INFO:[LightGBM] [Info] Total Bins 702
2025-04-09 11:34:08,461:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:08,469:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 11:34:08,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,679:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:08,714:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035314 seconds.
2025-04-09 11:34:08,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:08,715:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:08,722:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:08,729:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 11:34:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:08,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,355:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:09,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008895 seconds.
2025-04-09 11:34:09,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-09 11:34:09,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-09 11:34:09,371:INFO:[LightGBM] [Info] Total Bins 702
2025-04-09 11:34:09,371:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:09,371:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 11:34:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,453:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:09,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035210 seconds.
2025-04-09 11:34:09,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:09,489:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:09,496:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:09,506:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 11:34:09,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:09,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:10,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,014:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:11,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029262 seconds.
2025-04-09 11:34:11,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:11,044:INFO:[LightGBM] [Info] Total Bins 695
2025-04-09 11:34:11,051:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:11,062:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 11:34:11,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,557:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:11,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034196 seconds.
2025-04-09 11:34:11,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:11,592:INFO:[LightGBM] [Info] Total Bins 684
2025-04-09 11:34:11,601:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:11,608:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 11:34:11,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:11,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,114:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:12,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032286 seconds.
2025-04-09 11:34:12,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:12,147:INFO:[LightGBM] [Info] Total Bins 678
2025-04-09 11:34:12,156:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-09 11:34:12,164:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 11:34:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:12,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:13,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,416:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:14,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033945 seconds.
2025-04-09 11:34:14,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:14,451:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:14,456:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-09 11:34:14,464:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 11:34:14,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:14,606:INFO:Calculating mean and std
2025-04-09 11:34:14,607:INFO:Creating metrics dataframe
2025-04-09 11:34:14,610:INFO:Uploading results into container
2025-04-09 11:34:14,610:INFO:Uploading model into container now
2025-04-09 11:34:14,610:INFO:_master_model_container: 17
2025-04-09 11:34:14,611:INFO:_display_container: 2
2025-04-09 11:34:14,611:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:34:14,611:INFO:create_model() successfully completed......................................
2025-04-09 11:34:14,692:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:14,692:INFO:Creating metrics dataframe
2025-04-09 11:34:14,714:INFO:Initializing Dummy Regressor
2025-04-09 11:34:14,715:INFO:Total runtime is 0.3641830921173096 minutes
2025-04-09 11:34:14,722:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:14,723:INFO:Initializing create_model()
2025-04-09 11:34:14,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f561233b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:14,724:INFO:Checking exceptions
2025-04-09 11:34:14,724:INFO:Importing libraries
2025-04-09 11:34:14,724:INFO:Copying training dataset
2025-04-09 11:34:14,731:INFO:Defining folds
2025-04-09 11:34:14,732:INFO:Declaring metric variables
2025-04-09 11:34:14,739:INFO:Importing untrained model
2025-04-09 11:34:14,748:INFO:Dummy Regressor Imported successfully
2025-04-09 11:34:14,762:INFO:Starting cross validation
2025-04-09 11:34:14,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:15,023:INFO:Calculating mean and std
2025-04-09 11:34:15,025:INFO:Creating metrics dataframe
2025-04-09 11:34:15,028:INFO:Uploading results into container
2025-04-09 11:34:15,029:INFO:Uploading model into container now
2025-04-09 11:34:15,030:INFO:_master_model_container: 18
2025-04-09 11:34:15,030:INFO:_display_container: 2
2025-04-09 11:34:15,030:INFO:DummyRegressor()
2025-04-09 11:34:15,030:INFO:create_model() successfully completed......................................
2025-04-09 11:34:15,097:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:15,097:INFO:Creating metrics dataframe
2025-04-09 11:34:15,102:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 11:34:15,106:INFO:Initializing create_model()
2025-04-09 11:34:15,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:15,106:INFO:Checking exceptions
2025-04-09 11:34:15,107:INFO:Importing libraries
2025-04-09 11:34:15,107:INFO:Copying training dataset
2025-04-09 11:34:15,108:INFO:Defining folds
2025-04-09 11:34:15,108:INFO:Declaring metric variables
2025-04-09 11:34:15,108:INFO:Importing untrained model
2025-04-09 11:34:15,108:INFO:Declaring custom model
2025-04-09 11:34:15,109:INFO:Linear Regression Imported successfully
2025-04-09 11:34:15,109:INFO:Cross validation set to False
2025-04-09 11:34:15,109:INFO:Fitting Model
2025-04-09 11:34:15,114:INFO:LinearRegression(n_jobs=-1)
2025-04-09 11:34:15,114:INFO:create_model() successfully completed......................................
2025-04-09 11:34:15,217:INFO:_master_model_container: 18
2025-04-09 11:34:15,217:INFO:_display_container: 2
2025-04-09 11:34:15,217:INFO:LinearRegression(n_jobs=-1)
2025-04-09 11:34:15,217:INFO:compare_models() successfully completed......................................
2025-04-09 11:34:15,292:INFO:Initializing evaluate_model()
2025-04-09 11:34:15,292:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-09 11:34:15,324:INFO:Initializing plot_model()
2025-04-09 11:34:15,325:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, system=True)
2025-04-09 11:34:15,325:INFO:Checking exceptions
2025-04-09 11:34:15,328:INFO:Preloading libraries
2025-04-09 11:34:15,329:INFO:Copying training dataset
2025-04-09 11:34:15,329:INFO:Plot type: pipeline
2025-04-09 11:34:15,513:INFO:Visual Rendered Successfully
2025-04-09 11:34:15,561:INFO:plot_model() successfully completed......................................
2025-04-09 11:34:15,577:INFO:Initializing plot_model()
2025-04-09 11:34:15,577:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, system=True)
2025-04-09 11:34:15,577:INFO:Checking exceptions
2025-04-09 11:34:15,580:INFO:Preloading libraries
2025-04-09 11:34:15,580:INFO:Copying training dataset
2025-04-09 11:34:15,580:INFO:Plot type: residuals
2025-04-09 11:34:15,699:INFO:Fitting Model
2025-04-09 11:34:15,700:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-09 11:34:15,737:INFO:Scoring test/hold-out set
2025-04-09 11:34:16,246:INFO:Visual Rendered Successfully
2025-04-09 11:34:16,347:INFO:plot_model() successfully completed......................................
2025-04-09 11:34:16,369:INFO:Initializing plot_model()
2025-04-09 11:34:16,369:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, system=True)
2025-04-09 11:34:16,369:INFO:Checking exceptions
2025-04-09 11:34:16,377:INFO:Preloading libraries
2025-04-09 11:34:16,378:INFO:Copying training dataset
2025-04-09 11:34:16,378:INFO:Plot type: feature
2025-04-09 11:34:16,739:INFO:Visual Rendered Successfully
2025-04-09 11:34:16,835:INFO:plot_model() successfully completed......................................
2025-04-09 11:34:16,900:INFO:Initializing predict_model()
2025-04-09 11:34:16,901:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x75f548315e50>)
2025-04-09 11:34:16,901:INFO:Checking exceptions
2025-04-09 11:34:16,902:INFO:Preloading libraries
2025-04-09 11:34:16,983:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-09 11:34:17,102:INFO:Initializing predict_model()
2025-04-09 11:34:17,102:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x75f5485acca0>)
2025-04-09 11:34:17,102:INFO:Checking exceptions
2025-04-09 11:34:17,102:INFO:Preloading libraries
2025-04-09 11:34:17,107:INFO:Set up data.
2025-04-09 11:34:17,115:INFO:Set up index.
2025-04-09 11:34:17,151:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-09 11:34:17,478:INFO:Initializing compare_models()
2025-04-09 11:34:17,479:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-09 11:34:17,479:INFO:Checking exceptions
2025-04-09 11:34:17,483:INFO:Preparing display monitor
2025-04-09 11:34:17,524:INFO:Initializing Linear Regression
2025-04-09 11:34:17,524:INFO:Total runtime is 5.018711090087891e-06 minutes
2025-04-09 11:34:17,530:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:17,531:INFO:Initializing create_model()
2025-04-09 11:34:17,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:17,531:INFO:Checking exceptions
2025-04-09 11:34:17,531:INFO:Importing libraries
2025-04-09 11:34:17,531:INFO:Copying training dataset
2025-04-09 11:34:17,539:INFO:Defining folds
2025-04-09 11:34:17,539:INFO:Declaring metric variables
2025-04-09 11:34:17,545:INFO:Importing untrained model
2025-04-09 11:34:17,552:INFO:Linear Regression Imported successfully
2025-04-09 11:34:17,566:INFO:Starting cross validation
2025-04-09 11:34:17,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:17,761:INFO:Calculating mean and std
2025-04-09 11:34:17,761:INFO:Creating metrics dataframe
2025-04-09 11:34:17,762:INFO:Uploading results into container
2025-04-09 11:34:17,762:INFO:Uploading model into container now
2025-04-09 11:34:17,762:INFO:_master_model_container: 19
2025-04-09 11:34:17,762:INFO:_display_container: 5
2025-04-09 11:34:17,762:INFO:LinearRegression(n_jobs=-1)
2025-04-09 11:34:17,762:INFO:create_model() successfully completed......................................
2025-04-09 11:34:17,850:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:17,850:INFO:Creating metrics dataframe
2025-04-09 11:34:17,864:INFO:Initializing Lasso Regression
2025-04-09 11:34:17,864:INFO:Total runtime is 0.005668286482493083 minutes
2025-04-09 11:34:17,871:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:17,872:INFO:Initializing create_model()
2025-04-09 11:34:17,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:17,873:INFO:Checking exceptions
2025-04-09 11:34:17,873:INFO:Importing libraries
2025-04-09 11:34:17,873:INFO:Copying training dataset
2025-04-09 11:34:17,879:INFO:Defining folds
2025-04-09 11:34:17,879:INFO:Declaring metric variables
2025-04-09 11:34:17,886:INFO:Importing untrained model
2025-04-09 11:34:17,893:INFO:Lasso Regression Imported successfully
2025-04-09 11:34:17,907:INFO:Starting cross validation
2025-04-09 11:34:17,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:17,942:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:17,967:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:17,981:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:17,990:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:17,999:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,008:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,017:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,027:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,036:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,046:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,050:INFO:Calculating mean and std
2025-04-09 11:34:18,050:INFO:Creating metrics dataframe
2025-04-09 11:34:18,051:INFO:Uploading results into container
2025-04-09 11:34:18,051:INFO:Uploading model into container now
2025-04-09 11:34:18,051:INFO:_master_model_container: 20
2025-04-09 11:34:18,051:INFO:_display_container: 5
2025-04-09 11:34:18,052:INFO:Lasso(random_state=123)
2025-04-09 11:34:18,052:INFO:create_model() successfully completed......................................
2025-04-09 11:34:18,097:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:18,097:INFO:Creating metrics dataframe
2025-04-09 11:34:18,101:INFO:Initializing Ridge Regression
2025-04-09 11:34:18,101:INFO:Total runtime is 0.0096091628074646 minutes
2025-04-09 11:34:18,102:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:18,102:INFO:Initializing create_model()
2025-04-09 11:34:18,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:18,102:INFO:Checking exceptions
2025-04-09 11:34:18,102:INFO:Importing libraries
2025-04-09 11:34:18,102:INFO:Copying training dataset
2025-04-09 11:34:18,104:INFO:Defining folds
2025-04-09 11:34:18,104:INFO:Declaring metric variables
2025-04-09 11:34:18,105:INFO:Importing untrained model
2025-04-09 11:34:18,107:INFO:Ridge Regression Imported successfully
2025-04-09 11:34:18,110:INFO:Starting cross validation
2025-04-09 11:34:18,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:18,117:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.83501e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,127:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.99565e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,136:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.98533e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,145:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.74825e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,153:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.06537e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,162:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.01696e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,170:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.69617e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,179:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.94072e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,188:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6569e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,196:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.08078e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-09 11:34:18,201:INFO:Calculating mean and std
2025-04-09 11:34:18,201:INFO:Creating metrics dataframe
2025-04-09 11:34:18,201:INFO:Uploading results into container
2025-04-09 11:34:18,202:INFO:Uploading model into container now
2025-04-09 11:34:18,202:INFO:_master_model_container: 21
2025-04-09 11:34:18,202:INFO:_display_container: 5
2025-04-09 11:34:18,202:INFO:Ridge(random_state=123)
2025-04-09 11:34:18,202:INFO:create_model() successfully completed......................................
2025-04-09 11:34:18,259:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:18,260:INFO:Creating metrics dataframe
2025-04-09 11:34:18,269:INFO:Initializing Elastic Net
2025-04-09 11:34:18,270:INFO:Total runtime is 0.012428458531697592 minutes
2025-04-09 11:34:18,279:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:18,279:INFO:Initializing create_model()
2025-04-09 11:34:18,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:18,280:INFO:Checking exceptions
2025-04-09 11:34:18,280:INFO:Importing libraries
2025-04-09 11:34:18,280:INFO:Copying training dataset
2025-04-09 11:34:18,287:INFO:Defining folds
2025-04-09 11:34:18,287:INFO:Declaring metric variables
2025-04-09 11:34:18,293:INFO:Importing untrained model
2025-04-09 11:34:18,303:INFO:Elastic Net Imported successfully
2025-04-09 11:34:18,317:INFO:Starting cross validation
2025-04-09 11:34:18,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:18,352:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,396:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,427:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,445:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,456:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,465:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,474:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,483:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,493:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,502:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-09 11:34:18,506:INFO:Calculating mean and std
2025-04-09 11:34:18,507:INFO:Creating metrics dataframe
2025-04-09 11:34:18,508:INFO:Uploading results into container
2025-04-09 11:34:18,508:INFO:Uploading model into container now
2025-04-09 11:34:18,508:INFO:_master_model_container: 22
2025-04-09 11:34:18,508:INFO:_display_container: 5
2025-04-09 11:34:18,508:INFO:ElasticNet(random_state=123)
2025-04-09 11:34:18,508:INFO:create_model() successfully completed......................................
2025-04-09 11:34:18,556:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:18,556:INFO:Creating metrics dataframe
2025-04-09 11:34:18,559:INFO:Initializing Least Angle Regression
2025-04-09 11:34:18,559:INFO:Total runtime is 0.017256112893422444 minutes
2025-04-09 11:34:18,561:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:18,561:INFO:Initializing create_model()
2025-04-09 11:34:18,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:18,561:INFO:Checking exceptions
2025-04-09 11:34:18,561:INFO:Importing libraries
2025-04-09 11:34:18,561:INFO:Copying training dataset
2025-04-09 11:34:18,562:INFO:Defining folds
2025-04-09 11:34:18,562:INFO:Declaring metric variables
2025-04-09 11:34:18,564:INFO:Importing untrained model
2025-04-09 11:34:18,565:INFO:Least Angle Regression Imported successfully
2025-04-09 11:34:18,568:INFO:Starting cross validation
2025-04-09 11:34:18,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:18,577:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.956e-05, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,616:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.084e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,666:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.444e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,713:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.329e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,750:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.858e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,769:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.245e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.871e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,811:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.124e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,857:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.974e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,903:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.586e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,949:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.021e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.546e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-09 11:34:18,963:INFO:Calculating mean and std
2025-04-09 11:34:18,964:INFO:Creating metrics dataframe
2025-04-09 11:34:18,967:INFO:Uploading results into container
2025-04-09 11:34:18,968:INFO:Uploading model into container now
2025-04-09 11:34:18,968:INFO:_master_model_container: 23
2025-04-09 11:34:18,968:INFO:_display_container: 5
2025-04-09 11:34:18,969:INFO:Lars(random_state=123)
2025-04-09 11:34:18,969:INFO:create_model() successfully completed......................................
2025-04-09 11:34:19,023:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:19,023:INFO:Creating metrics dataframe
2025-04-09 11:34:19,027:INFO:Initializing Lasso Least Angle Regression
2025-04-09 11:34:19,027:INFO:Total runtime is 0.025044004122416176 minutes
2025-04-09 11:34:19,028:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:19,028:INFO:Initializing create_model()
2025-04-09 11:34:19,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:19,028:INFO:Checking exceptions
2025-04-09 11:34:19,028:INFO:Importing libraries
2025-04-09 11:34:19,028:INFO:Copying training dataset
2025-04-09 11:34:19,030:INFO:Defining folds
2025-04-09 11:34:19,030:INFO:Declaring metric variables
2025-04-09 11:34:19,031:INFO:Importing untrained model
2025-04-09 11:34:19,032:INFO:Lasso Least Angle Regression Imported successfully
2025-04-09 11:34:19,036:INFO:Starting cross validation
2025-04-09 11:34:19,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:19,297:INFO:Calculating mean and std
2025-04-09 11:34:19,297:INFO:Creating metrics dataframe
2025-04-09 11:34:19,298:INFO:Uploading results into container
2025-04-09 11:34:19,298:INFO:Uploading model into container now
2025-04-09 11:34:19,299:INFO:_master_model_container: 24
2025-04-09 11:34:19,299:INFO:_display_container: 5
2025-04-09 11:34:19,299:INFO:LassoLars(random_state=123)
2025-04-09 11:34:19,299:INFO:create_model() successfully completed......................................
2025-04-09 11:34:19,358:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:19,358:INFO:Creating metrics dataframe
2025-04-09 11:34:19,362:INFO:Initializing Orthogonal Matching Pursuit
2025-04-09 11:34:19,362:INFO:Total runtime is 0.030639676253000892 minutes
2025-04-09 11:34:19,364:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:19,364:INFO:Initializing create_model()
2025-04-09 11:34:19,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:19,364:INFO:Checking exceptions
2025-04-09 11:34:19,364:INFO:Importing libraries
2025-04-09 11:34:19,364:INFO:Copying training dataset
2025-04-09 11:34:19,366:INFO:Defining folds
2025-04-09 11:34:19,366:INFO:Declaring metric variables
2025-04-09 11:34:19,367:INFO:Importing untrained model
2025-04-09 11:34:19,369:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-09 11:34:19,371:INFO:Starting cross validation
2025-04-09 11:34:19,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:19,496:INFO:Calculating mean and std
2025-04-09 11:34:19,496:INFO:Creating metrics dataframe
2025-04-09 11:34:19,497:INFO:Uploading results into container
2025-04-09 11:34:19,498:INFO:Uploading model into container now
2025-04-09 11:34:19,498:INFO:_master_model_container: 25
2025-04-09 11:34:19,498:INFO:_display_container: 5
2025-04-09 11:34:19,498:INFO:OrthogonalMatchingPursuit()
2025-04-09 11:34:19,498:INFO:create_model() successfully completed......................................
2025-04-09 11:34:19,581:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:19,581:INFO:Creating metrics dataframe
2025-04-09 11:34:19,598:INFO:Initializing Bayesian Ridge
2025-04-09 11:34:19,599:INFO:Total runtime is 0.03457589944203694 minutes
2025-04-09 11:34:19,606:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:19,607:INFO:Initializing create_model()
2025-04-09 11:34:19,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:19,607:INFO:Checking exceptions
2025-04-09 11:34:19,607:INFO:Importing libraries
2025-04-09 11:34:19,608:INFO:Copying training dataset
2025-04-09 11:34:19,615:INFO:Defining folds
2025-04-09 11:34:19,616:INFO:Declaring metric variables
2025-04-09 11:34:19,622:INFO:Importing untrained model
2025-04-09 11:34:19,629:INFO:Bayesian Ridge Imported successfully
2025-04-09 11:34:19,643:INFO:Starting cross validation
2025-04-09 11:34:19,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:19,856:INFO:Calculating mean and std
2025-04-09 11:34:19,857:INFO:Creating metrics dataframe
2025-04-09 11:34:19,860:INFO:Uploading results into container
2025-04-09 11:34:19,860:INFO:Uploading model into container now
2025-04-09 11:34:19,861:INFO:_master_model_container: 26
2025-04-09 11:34:19,861:INFO:_display_container: 5
2025-04-09 11:34:19,862:INFO:BayesianRidge()
2025-04-09 11:34:19,862:INFO:create_model() successfully completed......................................
2025-04-09 11:34:19,955:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:19,956:INFO:Creating metrics dataframe
2025-04-09 11:34:19,970:INFO:Initializing Passive Aggressive Regressor
2025-04-09 11:34:19,971:INFO:Total runtime is 0.04077435731887817 minutes
2025-04-09 11:34:19,976:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:19,976:INFO:Initializing create_model()
2025-04-09 11:34:19,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:19,976:INFO:Checking exceptions
2025-04-09 11:34:19,977:INFO:Importing libraries
2025-04-09 11:34:19,977:INFO:Copying training dataset
2025-04-09 11:34:19,983:INFO:Defining folds
2025-04-09 11:34:19,983:INFO:Declaring metric variables
2025-04-09 11:34:19,988:INFO:Importing untrained model
2025-04-09 11:34:19,993:INFO:Passive Aggressive Regressor Imported successfully
2025-04-09 11:34:20,002:INFO:Starting cross validation
2025-04-09 11:34:20,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:20,296:INFO:Calculating mean and std
2025-04-09 11:34:20,296:INFO:Creating metrics dataframe
2025-04-09 11:34:20,297:INFO:Uploading results into container
2025-04-09 11:34:20,297:INFO:Uploading model into container now
2025-04-09 11:34:20,298:INFO:_master_model_container: 27
2025-04-09 11:34:20,298:INFO:_display_container: 5
2025-04-09 11:34:20,298:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-09 11:34:20,298:INFO:create_model() successfully completed......................................
2025-04-09 11:34:20,344:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:20,344:INFO:Creating metrics dataframe
2025-04-09 11:34:20,348:INFO:Initializing Huber Regressor
2025-04-09 11:34:20,348:INFO:Total runtime is 0.04707229932149251 minutes
2025-04-09 11:34:20,350:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:20,350:INFO:Initializing create_model()
2025-04-09 11:34:20,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:20,350:INFO:Checking exceptions
2025-04-09 11:34:20,350:INFO:Importing libraries
2025-04-09 11:34:20,350:INFO:Copying training dataset
2025-04-09 11:34:20,351:INFO:Defining folds
2025-04-09 11:34:20,351:INFO:Declaring metric variables
2025-04-09 11:34:20,353:INFO:Importing untrained model
2025-04-09 11:34:20,354:INFO:Huber Regressor Imported successfully
2025-04-09 11:34:20,357:INFO:Starting cross validation
2025-04-09 11:34:20,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:20,380:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:34:20,595:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:34:20,610:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-09 11:34:20,670:INFO:Calculating mean and std
2025-04-09 11:34:20,670:INFO:Creating metrics dataframe
2025-04-09 11:34:20,671:INFO:Uploading results into container
2025-04-09 11:34:20,671:INFO:Uploading model into container now
2025-04-09 11:34:20,672:INFO:_master_model_container: 28
2025-04-09 11:34:20,672:INFO:_display_container: 5
2025-04-09 11:34:20,672:INFO:HuberRegressor()
2025-04-09 11:34:20,672:INFO:create_model() successfully completed......................................
2025-04-09 11:34:20,719:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:20,719:INFO:Creating metrics dataframe
2025-04-09 11:34:20,723:INFO:Initializing K Neighbors Regressor
2025-04-09 11:34:20,723:INFO:Total runtime is 0.05332362651824951 minutes
2025-04-09 11:34:20,725:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:20,725:INFO:Initializing create_model()
2025-04-09 11:34:20,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:20,725:INFO:Checking exceptions
2025-04-09 11:34:20,725:INFO:Importing libraries
2025-04-09 11:34:20,725:INFO:Copying training dataset
2025-04-09 11:34:20,727:INFO:Defining folds
2025-04-09 11:34:20,727:INFO:Declaring metric variables
2025-04-09 11:34:20,728:INFO:Importing untrained model
2025-04-09 11:34:20,729:INFO:K Neighbors Regressor Imported successfully
2025-04-09 11:34:20,731:INFO:Starting cross validation
2025-04-09 11:34:20,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:20,862:INFO:Calculating mean and std
2025-04-09 11:34:20,863:INFO:Creating metrics dataframe
2025-04-09 11:34:20,864:INFO:Uploading results into container
2025-04-09 11:34:20,864:INFO:Uploading model into container now
2025-04-09 11:34:20,864:INFO:_master_model_container: 29
2025-04-09 11:34:20,865:INFO:_display_container: 5
2025-04-09 11:34:20,865:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-09 11:34:20,865:INFO:create_model() successfully completed......................................
2025-04-09 11:34:20,922:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:20,922:INFO:Creating metrics dataframe
2025-04-09 11:34:20,929:INFO:Initializing Decision Tree Regressor
2025-04-09 11:34:20,929:INFO:Total runtime is 0.05675307512283325 minutes
2025-04-09 11:34:20,932:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:20,933:INFO:Initializing create_model()
2025-04-09 11:34:20,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:20,933:INFO:Checking exceptions
2025-04-09 11:34:20,933:INFO:Importing libraries
2025-04-09 11:34:20,933:INFO:Copying training dataset
2025-04-09 11:34:20,937:INFO:Defining folds
2025-04-09 11:34:20,937:INFO:Declaring metric variables
2025-04-09 11:34:20,942:INFO:Importing untrained model
2025-04-09 11:34:20,948:INFO:Decision Tree Regressor Imported successfully
2025-04-09 11:34:20,964:INFO:Starting cross validation
2025-04-09 11:34:20,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:21,148:INFO:Calculating mean and std
2025-04-09 11:34:21,149:INFO:Creating metrics dataframe
2025-04-09 11:34:21,150:INFO:Uploading results into container
2025-04-09 11:34:21,150:INFO:Uploading model into container now
2025-04-09 11:34:21,150:INFO:_master_model_container: 30
2025-04-09 11:34:21,150:INFO:_display_container: 5
2025-04-09 11:34:21,150:INFO:DecisionTreeRegressor(random_state=123)
2025-04-09 11:34:21,150:INFO:create_model() successfully completed......................................
2025-04-09 11:34:21,195:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:21,195:INFO:Creating metrics dataframe
2025-04-09 11:34:21,199:INFO:Initializing Random Forest Regressor
2025-04-09 11:34:21,199:INFO:Total runtime is 0.06125658353169759 minutes
2025-04-09 11:34:21,201:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:21,201:INFO:Initializing create_model()
2025-04-09 11:34:21,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:21,201:INFO:Checking exceptions
2025-04-09 11:34:21,201:INFO:Importing libraries
2025-04-09 11:34:21,201:INFO:Copying training dataset
2025-04-09 11:34:21,202:INFO:Defining folds
2025-04-09 11:34:21,202:INFO:Declaring metric variables
2025-04-09 11:34:21,204:INFO:Importing untrained model
2025-04-09 11:34:21,205:INFO:Random Forest Regressor Imported successfully
2025-04-09 11:34:21,208:INFO:Starting cross validation
2025-04-09 11:34:21,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:24,564:INFO:Calculating mean and std
2025-04-09 11:34:24,566:INFO:Creating metrics dataframe
2025-04-09 11:34:24,569:INFO:Uploading results into container
2025-04-09 11:34:24,571:INFO:Uploading model into container now
2025-04-09 11:34:24,572:INFO:_master_model_container: 31
2025-04-09 11:34:24,572:INFO:_display_container: 5
2025-04-09 11:34:24,572:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:34:24,572:INFO:create_model() successfully completed......................................
2025-04-09 11:34:24,667:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:24,667:INFO:Creating metrics dataframe
2025-04-09 11:34:24,687:INFO:Initializing Extra Trees Regressor
2025-04-09 11:34:24,687:INFO:Total runtime is 0.11939047574996949 minutes
2025-04-09 11:34:24,695:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:24,696:INFO:Initializing create_model()
2025-04-09 11:34:24,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:24,696:INFO:Checking exceptions
2025-04-09 11:34:24,696:INFO:Importing libraries
2025-04-09 11:34:24,697:INFO:Copying training dataset
2025-04-09 11:34:24,705:INFO:Defining folds
2025-04-09 11:34:24,705:INFO:Declaring metric variables
2025-04-09 11:34:24,712:INFO:Importing untrained model
2025-04-09 11:34:24,718:INFO:Extra Trees Regressor Imported successfully
2025-04-09 11:34:24,731:INFO:Starting cross validation
2025-04-09 11:34:24,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:27,014:INFO:Calculating mean and std
2025-04-09 11:34:27,016:INFO:Creating metrics dataframe
2025-04-09 11:34:27,020:INFO:Uploading results into container
2025-04-09 11:34:27,022:INFO:Uploading model into container now
2025-04-09 11:34:27,022:INFO:_master_model_container: 32
2025-04-09 11:34:27,022:INFO:_display_container: 5
2025-04-09 11:34:27,023:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:34:27,023:INFO:create_model() successfully completed......................................
2025-04-09 11:34:27,108:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:27,108:INFO:Creating metrics dataframe
2025-04-09 11:34:27,131:INFO:Initializing AdaBoost Regressor
2025-04-09 11:34:27,131:INFO:Total runtime is 0.16011823415756227 minutes
2025-04-09 11:34:27,139:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:27,139:INFO:Initializing create_model()
2025-04-09 11:34:27,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:27,140:INFO:Checking exceptions
2025-04-09 11:34:27,140:INFO:Importing libraries
2025-04-09 11:34:27,140:INFO:Copying training dataset
2025-04-09 11:34:27,148:INFO:Defining folds
2025-04-09 11:34:27,148:INFO:Declaring metric variables
2025-04-09 11:34:27,155:INFO:Importing untrained model
2025-04-09 11:34:27,162:INFO:AdaBoost Regressor Imported successfully
2025-04-09 11:34:27,174:INFO:Starting cross validation
2025-04-09 11:34:27,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:27,903:INFO:Calculating mean and std
2025-04-09 11:34:27,904:INFO:Creating metrics dataframe
2025-04-09 11:34:27,905:INFO:Uploading results into container
2025-04-09 11:34:27,905:INFO:Uploading model into container now
2025-04-09 11:34:27,905:INFO:_master_model_container: 33
2025-04-09 11:34:27,905:INFO:_display_container: 5
2025-04-09 11:34:27,905:INFO:AdaBoostRegressor(random_state=123)
2025-04-09 11:34:27,905:INFO:create_model() successfully completed......................................
2025-04-09 11:34:27,951:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:27,951:INFO:Creating metrics dataframe
2025-04-09 11:34:27,955:INFO:Initializing Gradient Boosting Regressor
2025-04-09 11:34:27,955:INFO:Total runtime is 0.17385376691818238 minutes
2025-04-09 11:34:27,957:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:27,957:INFO:Initializing create_model()
2025-04-09 11:34:27,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:27,957:INFO:Checking exceptions
2025-04-09 11:34:27,957:INFO:Importing libraries
2025-04-09 11:34:27,957:INFO:Copying training dataset
2025-04-09 11:34:27,958:INFO:Defining folds
2025-04-09 11:34:27,958:INFO:Declaring metric variables
2025-04-09 11:34:27,960:INFO:Importing untrained model
2025-04-09 11:34:27,961:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:27,964:INFO:Starting cross validation
2025-04-09 11:34:27,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:28,881:INFO:Calculating mean and std
2025-04-09 11:34:28,882:INFO:Creating metrics dataframe
2025-04-09 11:34:28,883:INFO:Uploading results into container
2025-04-09 11:34:28,883:INFO:Uploading model into container now
2025-04-09 11:34:28,883:INFO:_master_model_container: 34
2025-04-09 11:34:28,883:INFO:_display_container: 5
2025-04-09 11:34:28,883:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:28,883:INFO:create_model() successfully completed......................................
2025-04-09 11:34:28,930:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:28,930:INFO:Creating metrics dataframe
2025-04-09 11:34:28,935:INFO:Initializing Light Gradient Boosting Machine
2025-04-09 11:34:28,935:INFO:Total runtime is 0.19018383026123048 minutes
2025-04-09 11:34:28,937:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:28,937:INFO:Initializing create_model()
2025-04-09 11:34:28,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:28,937:INFO:Checking exceptions
2025-04-09 11:34:28,937:INFO:Importing libraries
2025-04-09 11:34:28,937:INFO:Copying training dataset
2025-04-09 11:34:28,938:INFO:Defining folds
2025-04-09 11:34:28,938:INFO:Declaring metric variables
2025-04-09 11:34:28,939:INFO:Importing untrained model
2025-04-09 11:34:28,942:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-09 11:34:28,945:INFO:Starting cross validation
2025-04-09 11:34:28,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:28,967:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:28,993:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026210 seconds.
2025-04-09 11:34:28,993:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:28,994:INFO:[LightGBM] [Info] Total Bins 675
2025-04-09 11:34:28,999:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:29,007:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-09 11:34:29,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,124:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:29,149:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025293 seconds.
2025-04-09 11:34:29,149:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:29,150:INFO:[LightGBM] [Info] Total Bins 696
2025-04-09 11:34:29,155:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:29,161:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-09 11:34:29,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:29,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,719:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:30,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023087 seconds.
2025-04-09 11:34:30,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:30,743:INFO:[LightGBM] [Info] Total Bins 702
2025-04-09 11:34:30,748:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:30,757:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-09 11:34:30,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:30,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,185:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:32,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026939 seconds.
2025-04-09 11:34:32,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:32,213:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:32,218:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:32,224:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-09 11:34:32,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,790:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:32,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025859 seconds.
2025-04-09 11:34:32,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:32,817:INFO:[LightGBM] [Info] Total Bins 702
2025-04-09 11:34:32,826:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:32,832:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-09 11:34:32,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:32,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:33,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,201:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:34,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026829 seconds.
2025-04-09 11:34:34,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:34,229:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:34,234:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:34,240:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-09 11:34:34,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,795:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:34,823:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027768 seconds.
2025-04-09 11:34:34,823:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:34,824:INFO:[LightGBM] [Info] Total Bins 695
2025-04-09 11:34:34,829:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:34,835:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-09 11:34:34,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:34,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:35,883:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:35,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024975 seconds.
2025-04-09 11:34:35,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:35,909:INFO:[LightGBM] [Info] Total Bins 684
2025-04-09 11:34:35,914:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-09 11:34:35,920:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-09 11:34:36,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:36,948:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:36,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025195 seconds.
2025-04-09 11:34:36,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:36,974:INFO:[LightGBM] [Info] Total Bins 678
2025-04-09 11:34:36,979:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-09 11:34:36,985:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-09 11:34:37,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,907:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-09 11:34:37,932:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025008 seconds.
2025-04-09 11:34:37,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-09 11:34:37,933:INFO:[LightGBM] [Info] Total Bins 686
2025-04-09 11:34:37,940:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-09 11:34:37,946:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-09 11:34:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:37,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-09 11:34:38,046:INFO:Calculating mean and std
2025-04-09 11:34:38,047:INFO:Creating metrics dataframe
2025-04-09 11:34:38,050:INFO:Uploading results into container
2025-04-09 11:34:38,051:INFO:Uploading model into container now
2025-04-09 11:34:38,052:INFO:_master_model_container: 35
2025-04-09 11:34:38,052:INFO:_display_container: 5
2025-04-09 11:34:38,052:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-09 11:34:38,052:INFO:create_model() successfully completed......................................
2025-04-09 11:34:38,138:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:38,138:INFO:Creating metrics dataframe
2025-04-09 11:34:38,154:INFO:Initializing Dummy Regressor
2025-04-09 11:34:38,154:INFO:Total runtime is 0.34383249282836914 minutes
2025-04-09 11:34:38,159:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:38,160:INFO:Initializing create_model()
2025-04-09 11:34:38,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f54819aa90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:38,160:INFO:Checking exceptions
2025-04-09 11:34:38,160:INFO:Importing libraries
2025-04-09 11:34:38,160:INFO:Copying training dataset
2025-04-09 11:34:38,168:INFO:Defining folds
2025-04-09 11:34:38,168:INFO:Declaring metric variables
2025-04-09 11:34:38,175:INFO:Importing untrained model
2025-04-09 11:34:38,181:INFO:Dummy Regressor Imported successfully
2025-04-09 11:34:38,193:INFO:Starting cross validation
2025-04-09 11:34:38,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:38,454:INFO:Calculating mean and std
2025-04-09 11:34:38,454:INFO:Creating metrics dataframe
2025-04-09 11:34:38,455:INFO:Uploading results into container
2025-04-09 11:34:38,456:INFO:Uploading model into container now
2025-04-09 11:34:38,456:INFO:_master_model_container: 36
2025-04-09 11:34:38,456:INFO:_display_container: 5
2025-04-09 11:34:38,456:INFO:DummyRegressor()
2025-04-09 11:34:38,456:INFO:create_model() successfully completed......................................
2025-04-09 11:34:38,496:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:38,496:INFO:Creating metrics dataframe
2025-04-09 11:34:38,501:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-09 11:34:38,505:INFO:Initializing create_model()
2025-04-09 11:34:38,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:38,505:INFO:Checking exceptions
2025-04-09 11:34:38,506:INFO:Importing libraries
2025-04-09 11:34:38,506:INFO:Copying training dataset
2025-04-09 11:34:38,508:INFO:Defining folds
2025-04-09 11:34:38,508:INFO:Declaring metric variables
2025-04-09 11:34:38,508:INFO:Importing untrained model
2025-04-09 11:34:38,508:INFO:Declaring custom model
2025-04-09 11:34:38,508:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:38,508:INFO:Cross validation set to False
2025-04-09 11:34:38,508:INFO:Fitting Model
2025-04-09 11:34:38,564:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:38,564:INFO:create_model() successfully completed......................................
2025-04-09 11:34:38,621:INFO:_master_model_container: 36
2025-04-09 11:34:38,621:INFO:_display_container: 5
2025-04-09 11:34:38,621:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:38,621:INFO:compare_models() successfully completed......................................
2025-04-09 11:34:38,622:INFO:Initializing tune_model()
2025-04-09 11:34:38,622:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>)
2025-04-09 11:34:38,622:INFO:Checking exceptions
2025-04-09 11:34:38,635:INFO:Copying training dataset
2025-04-09 11:34:38,640:INFO:Checking base model
2025-04-09 11:34:38,640:INFO:Base model : Gradient Boosting Regressor
2025-04-09 11:34:38,647:INFO:Declaring metric variables
2025-04-09 11:34:38,656:INFO:Defining Hyperparameters
2025-04-09 11:34:38,764:INFO:Tuning with n_jobs=-1
2025-04-09 11:34:38,764:INFO:Initializing RandomizedSearchCV
2025-04-09 11:34:46,553:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.15}
2025-04-09 11:34:46,556:INFO:Hyperparameter search completed
2025-04-09 11:34:46,556:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:46,557:INFO:Initializing create_model()
2025-04-09 11:34:46,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x75f57649fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1.0, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 5, 'learning_rate': 0.15})
2025-04-09 11:34:46,557:INFO:Checking exceptions
2025-04-09 11:34:46,558:INFO:Importing libraries
2025-04-09 11:34:46,559:INFO:Copying training dataset
2025-04-09 11:34:46,567:INFO:Defining folds
2025-04-09 11:34:46,567:INFO:Declaring metric variables
2025-04-09 11:34:46,576:INFO:Importing untrained model
2025-04-09 11:34:46,577:INFO:Declaring custom model
2025-04-09 11:34:46,590:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:46,605:INFO:Starting cross validation
2025-04-09 11:34:46,607:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:48,178:INFO:Calculating mean and std
2025-04-09 11:34:48,179:INFO:Creating metrics dataframe
2025-04-09 11:34:48,184:INFO:Finalizing model
2025-04-09 11:34:48,425:INFO:Uploading results into container
2025-04-09 11:34:48,426:INFO:Uploading model into container now
2025-04-09 11:34:48,426:INFO:_master_model_container: 37
2025-04-09 11:34:48,426:INFO:_display_container: 6
2025-04-09 11:34:48,427:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=5, max_features=1.0,
                          min_impurity_decrease=0.002, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=200,
                          random_state=123)
2025-04-09 11:34:48,427:INFO:create_model() successfully completed......................................
2025-04-09 11:34:48,505:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:48,505:INFO:choose_better activated
2025-04-09 11:34:48,509:INFO:SubProcess create_model() called ==================================
2025-04-09 11:34:48,509:INFO:Initializing create_model()
2025-04-09 11:34:48,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:48,509:INFO:Checking exceptions
2025-04-09 11:34:48,515:INFO:Importing libraries
2025-04-09 11:34:48,515:INFO:Copying training dataset
2025-04-09 11:34:48,525:INFO:Defining folds
2025-04-09 11:34:48,525:INFO:Declaring metric variables
2025-04-09 11:34:48,525:INFO:Importing untrained model
2025-04-09 11:34:48,525:INFO:Declaring custom model
2025-04-09 11:34:48,527:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:48,527:INFO:Starting cross validation
2025-04-09 11:34:48,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-09 11:34:49,432:INFO:Calculating mean and std
2025-04-09 11:34:49,432:INFO:Creating metrics dataframe
2025-04-09 11:34:49,433:INFO:Finalizing model
2025-04-09 11:34:49,500:INFO:Uploading results into container
2025-04-09 11:34:49,500:INFO:Uploading model into container now
2025-04-09 11:34:49,501:INFO:_master_model_container: 38
2025-04-09 11:34:49,501:INFO:_display_container: 7
2025-04-09 11:34:49,501:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:49,501:INFO:create_model() successfully completed......................................
2025-04-09 11:34:49,552:INFO:SubProcess create_model() end ==================================
2025-04-09 11:34:49,553:INFO:GradientBoostingRegressor(random_state=123) result for RMSE is 0.0089
2025-04-09 11:34:49,553:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=5, max_features=1.0,
                          min_impurity_decrease=0.002, min_samples_leaf=2,
                          min_samples_split=10, n_estimators=200,
                          random_state=123) result for RMSE is 0.0187
2025-04-09 11:34:49,553:INFO:GradientBoostingRegressor(random_state=123) is best model
2025-04-09 11:34:49,553:INFO:choose_better completed
2025-04-09 11:34:49,553:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-09 11:34:49,558:INFO:_master_model_container: 38
2025-04-09 11:34:49,558:INFO:_display_container: 6
2025-04-09 11:34:49,559:INFO:GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:49,559:INFO:tune_model() successfully completed......................................
2025-04-09 11:34:49,643:INFO:Initializing finalize_model()
2025-04-09 11:34:49,643:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-09 11:34:49,644:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2025-04-09 11:34:49,650:INFO:Initializing create_model()
2025-04-09 11:34:49,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-04-09 11:34:49,650:INFO:Checking exceptions
2025-04-09 11:34:49,653:INFO:Importing libraries
2025-04-09 11:34:49,654:INFO:Copying training dataset
2025-04-09 11:34:49,654:INFO:Defining folds
2025-04-09 11:34:49,654:INFO:Declaring metric variables
2025-04-09 11:34:49,655:INFO:Importing untrained model
2025-04-09 11:34:49,655:INFO:Declaring custom model
2025-04-09 11:34:49,656:INFO:Gradient Boosting Regressor Imported successfully
2025-04-09 11:34:49,658:INFO:Cross validation set to False
2025-04-09 11:34:49,658:INFO:Fitting Model
2025-04-09 11:34:49,782:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2025-04-09 11:34:49,782:INFO:create_model() successfully completed......................................
2025-04-09 11:34:49,824:INFO:_master_model_container: 38
2025-04-09 11:34:49,824:INFO:_display_container: 6
2025-04-09 11:34:49,827:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2025-04-09 11:34:49,827:INFO:finalize_model() successfully completed......................................
2025-04-09 11:34:49,878:INFO:Initializing save_model()
2025-04-09 11:34:49,878:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), model_name=final_calibrated_depth_model_outdoor_v2, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-09 11:34:49,878:INFO:Adding model into prep_pipe
2025-04-09 11:34:49,878:WARNING:Only Model saved as it was a pipeline.
2025-04-09 11:34:49,882:INFO:final_calibrated_depth_model_outdoor_v2.pkl saved in current working directory
2025-04-09 11:34:49,885:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2025-04-09 11:34:49,885:INFO:save_model() successfully completed......................................
2025-04-09 11:34:49,965:INFO:Initializing load_model()
2025-04-09 11:34:49,965:INFO:load_model(model_name=final_calibrated_depth_model_outdoor, platform=None, authentication=None, verbose=True)
2025-04-09 11:34:50,023:INFO:Initializing predict_model()
2025-04-09 11:34:50,023:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x75f5484804c0>)
2025-04-09 11:34:50,023:INFO:Checking exceptions
2025-04-09 11:34:50,023:INFO:Preloading libraries
2025-04-09 11:34:50,027:INFO:Set up data.
2025-04-09 11:34:50,032:INFO:Set up index.
2025-04-09 11:38:21,012:INFO:Initializing load_model()
2025-04-09 11:38:21,012:INFO:load_model(model_name=final_calibrated_depth_model_outdoor_2, platform=None, authentication=None, verbose=True)
2025-04-09 11:38:26,806:INFO:Initializing load_model()
2025-04-09 11:38:26,807:INFO:load_model(model_name=final_calibrated_depth_model_outdoor_V2, platform=None, authentication=None, verbose=True)
2025-04-09 11:38:35,630:INFO:Initializing load_model()
2025-04-09 11:38:35,631:INFO:load_model(model_name=final_calibrated_depth_model_outdoor_v2, platform=None, authentication=None, verbose=True)
2025-04-09 11:38:36,850:INFO:Initializing predict_model()
2025-04-09 11:38:36,851:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x75f576e78b20>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x75f5311f7d30>)
2025-04-09 11:38:36,851:INFO:Checking exceptions
2025-04-09 11:38:36,851:INFO:Preloading libraries
2025-04-09 11:38:36,854:INFO:Set up data.
2025-04-09 11:38:36,859:INFO:Set up index.
2025-04-10 09:53:58,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,671:INFO:PyCaret RegressionExperiment
2025-04-10 09:53:58,671:INFO:Logging name: reg-default-name
2025-04-10 09:53:58,672:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-10 09:53:58,672:INFO:version 3.3.1
2025-04-10 09:53:58,672:INFO:Initializing setup()
2025-04-10 09:53:58,672:INFO:self.USI: 3026
2025-04-10 09:53:58,672:INFO:self._variable_keys: {'memory', 'y_train', 'log_plots_param', 'y', 'gpu_param', 'USI', 'seed', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'logging_param', 'X', 'pipeline', '_ml_usecase', 'n_jobs_param', 'X_test', 'target_param', 'idx', 'html_param', 'fold_generator', 'data', 'fold_groups_param', 'y_test', 'transform_target_param', 'exp_id', 'fold_shuffle_param', 'exp_name_log'}
2025-04-10 09:53:58,672:INFO:Checking environment
2025-04-10 09:53:58,672:INFO:python_version: 3.9.21
2025-04-10 09:53:58,672:INFO:python_build: ('main', 'Dec 11 2024 16:24:11')
2025-04-10 09:53:58,672:INFO:machine: x86_64
2025-04-10 09:53:58,672:INFO:platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-10 09:53:58,672:INFO:Memory: svmem(total=33374547968, available=26043535360, percent=22.0, used=5575397376, free=9334788096, active=7428427776, inactive=13783269376, buffers=311713792, cached=18152648704, shared=1272606720, slab=1170898944)
2025-04-10 09:53:58,672:INFO:Physical Core: 24
2025-04-10 09:53:58,672:INFO:Logical Core: 32
2025-04-10 09:53:58,672:INFO:Checking libraries
2025-04-10 09:53:58,672:INFO:System:
2025-04-10 09:53:58,672:INFO:    python: 3.9.21 (main, Dec 11 2024, 16:24:11)  [GCC 11.2.0]
2025-04-10 09:53:58,672:INFO:executable: /home/lworakan/miniconda3/envs/pycaret3_9/bin/python
2025-04-10 09:53:58,672:INFO:   machine: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
2025-04-10 09:53:58,672:INFO:PyCaret required dependencies:
2025-04-10 09:53:58,698:INFO:                 pip: 25.0
2025-04-10 09:53:58,698:INFO:          setuptools: 75.8.0
2025-04-10 09:53:58,698:INFO:             pycaret: 3.3.1
2025-04-10 09:53:58,698:INFO:             IPython: 8.18.1
2025-04-10 09:53:58,698:INFO:          ipywidgets: 8.1.5
2025-04-10 09:53:58,698:INFO:                tqdm: 4.67.1
2025-04-10 09:53:58,698:INFO:               numpy: 1.26.4
2025-04-10 09:53:58,698:INFO:              pandas: 2.1.4
2025-04-10 09:53:58,698:INFO:              jinja2: 3.1.5
2025-04-10 09:53:58,698:INFO:               scipy: 1.11.4
2025-04-10 09:53:58,698:INFO:              joblib: 1.3.2
2025-04-10 09:53:58,698:INFO:             sklearn: 1.4.2
2025-04-10 09:53:58,698:INFO:                pyod: 2.0.3
2025-04-10 09:53:58,698:INFO:            imblearn: 0.12.4
2025-04-10 09:53:58,698:INFO:   category_encoders: 2.6.4
2025-04-10 09:53:58,698:INFO:            lightgbm: 4.6.0
2025-04-10 09:53:58,698:INFO:               numba: 0.60.0
2025-04-10 09:53:58,698:INFO:            requests: 2.32.3
2025-04-10 09:53:58,698:INFO:          matplotlib: 3.7.5
2025-04-10 09:53:58,698:INFO:          scikitplot: 0.3.7
2025-04-10 09:53:58,698:INFO:         yellowbrick: 1.5
2025-04-10 09:53:58,698:INFO:              plotly: 5.24.1
2025-04-10 09:53:58,698:INFO:    plotly-resampler: Not installed
2025-04-10 09:53:58,698:INFO:             kaleido: 0.2.1
2025-04-10 09:53:58,698:INFO:           schemdraw: 0.15
2025-04-10 09:53:58,698:INFO:         statsmodels: 0.14.4
2025-04-10 09:53:58,698:INFO:              sktime: 0.26.0
2025-04-10 09:53:58,698:INFO:               tbats: 1.1.3
2025-04-10 09:53:58,698:INFO:            pmdarima: 2.0.4
2025-04-10 09:53:58,698:INFO:              psutil: 7.0.0
2025-04-10 09:53:58,698:INFO:          markupsafe: 3.0.2
2025-04-10 09:53:58,698:INFO:             pickle5: Not installed
2025-04-10 09:53:58,698:INFO:         cloudpickle: 3.1.1
2025-04-10 09:53:58,698:INFO:         deprecation: 2.1.0
2025-04-10 09:53:58,698:INFO:              xxhash: 3.5.0
2025-04-10 09:53:58,698:INFO:           wurlitzer: 3.1.1
2025-04-10 09:53:58,698:INFO:PyCaret optional dependencies:
2025-04-10 09:53:58,710:INFO:                shap: Not installed
2025-04-10 09:53:58,710:INFO:           interpret: Not installed
2025-04-10 09:53:58,710:INFO:                umap: Not installed
2025-04-10 09:53:58,710:INFO:     ydata_profiling: Not installed
2025-04-10 09:53:58,710:INFO:  explainerdashboard: Not installed
2025-04-10 09:53:58,710:INFO:             autoviz: Not installed
2025-04-10 09:53:58,710:INFO:           fairlearn: Not installed
2025-04-10 09:53:58,710:INFO:          deepchecks: Not installed
2025-04-10 09:53:58,710:INFO:             xgboost: Not installed
2025-04-10 09:53:58,710:INFO:            catboost: Not installed
2025-04-10 09:53:58,710:INFO:              kmodes: Not installed
2025-04-10 09:53:58,710:INFO:             mlxtend: Not installed
2025-04-10 09:53:58,710:INFO:       statsforecast: Not installed
2025-04-10 09:53:58,710:INFO:        tune_sklearn: Not installed
2025-04-10 09:53:58,710:INFO:                 ray: Not installed
2025-04-10 09:53:58,710:INFO:            hyperopt: Not installed
2025-04-10 09:53:58,710:INFO:              optuna: Not installed
2025-04-10 09:53:58,710:INFO:               skopt: Not installed
2025-04-10 09:53:58,710:INFO:              mlflow: Not installed
2025-04-10 09:53:58,710:INFO:              gradio: Not installed
2025-04-10 09:53:58,710:INFO:             fastapi: Not installed
2025-04-10 09:53:58,710:INFO:             uvicorn: Not installed
2025-04-10 09:53:58,710:INFO:              m2cgen: Not installed
2025-04-10 09:53:58,710:INFO:           evidently: Not installed
2025-04-10 09:53:58,710:INFO:               fugue: Not installed
2025-04-10 09:53:58,710:INFO:           streamlit: Not installed
2025-04-10 09:53:58,710:INFO:             prophet: Not installed
2025-04-10 09:53:58,710:INFO:None
2025-04-10 09:53:58,710:INFO:Set up GPU usage.
2025-04-10 09:53:58,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,710:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-04-10 09:53:58,710:INFO:Set up data.
2025-04-10 09:53:58,715:INFO:Set up folding strategy.
2025-04-10 09:53:58,715:INFO:Set up train/test split.
2025-04-10 09:53:58,719:INFO:Set up index.
2025-04-10 09:53:58,719:INFO:Assigning column types.
2025-04-10 09:53:58,722:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-10 09:53:58,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,722:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-10 09:53:58,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,726:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-10 09:53:58,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:53:58,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:53:58,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:53:58,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:53:58,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:10,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:10,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,810:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-10 09:54:10,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,814:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-10 09:54:10,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,819:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:54:10,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:10,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,984:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:10,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:10,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:10,993:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-10 09:54:10,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:10,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,005:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,021:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,134:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,165:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,165:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,168:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,338:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-10 09:54:11,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,609:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:11,823:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-10 09:54:11,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:11,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:11,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:12,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,204:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-10 09:54:12,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,208:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-10 09:54:12,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,305:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:12,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-10 09:54:12,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,455:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-10 09:54:12,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,557:INFO:Preparing preprocessing pipeline...
2025-04-10 09:54:12,557:INFO:Set up simple imputation.
2025-04-10 09:54:12,557:INFO:Set up polynomial features.
2025-04-10 09:54:12,568:INFO:Finished creating preprocessing pipeline.
2025-04-10 09:54:12,570:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))])
2025-04-10 09:54:12,570:INFO:Creating final display dataframe.
2025-04-10 09:54:12,616:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      ground_truth
2                   Target type        Regression
3           Original data shape          (155, 8)
4        Transformed data shape         (155, 36)
5   Transformed train set shape         (108, 36)
6    Transformed test set shape          (47, 36)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              3026
2025-04-10 09:54:12,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-10 09:54:12,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-10 09:54:12,727:INFO:setup() successfully completed in 14.06s...............
2025-04-10 09:54:12,732:INFO:Initializing compare_models()
2025-04-10 09:54:12,733:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-10 09:54:12,733:INFO:Checking exceptions
2025-04-10 09:54:12,735:INFO:Preparing display monitor
2025-04-10 09:54:12,748:INFO:Initializing Linear Regression
2025-04-10 09:54:12,748:INFO:Total runtime is 2.7855237325032553e-06 minutes
2025-04-10 09:54:12,750:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:12,750:INFO:Initializing create_model()
2025-04-10 09:54:12,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:12,750:INFO:Checking exceptions
2025-04-10 09:54:12,750:INFO:Importing libraries
2025-04-10 09:54:12,750:INFO:Copying training dataset
2025-04-10 09:54:12,753:INFO:Defining folds
2025-04-10 09:54:12,753:INFO:Declaring metric variables
2025-04-10 09:54:12,756:INFO:Importing untrained model
2025-04-10 09:54:12,759:INFO:Linear Regression Imported successfully
2025-04-10 09:54:12,769:INFO:Starting cross validation
2025-04-10 09:54:12,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:12,965:INFO:Calculating mean and std
2025-04-10 09:54:12,965:INFO:Creating metrics dataframe
2025-04-10 09:54:12,966:INFO:Uploading results into container
2025-04-10 09:54:12,966:INFO:Uploading model into container now
2025-04-10 09:54:12,966:INFO:_master_model_container: 1
2025-04-10 09:54:12,966:INFO:_display_container: 2
2025-04-10 09:54:12,966:INFO:LinearRegression(n_jobs=-1)
2025-04-10 09:54:12,966:INFO:create_model() successfully completed......................................
2025-04-10 09:54:13,010:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:13,010:INFO:Creating metrics dataframe
2025-04-10 09:54:13,014:INFO:Initializing Lasso Regression
2025-04-10 09:54:13,014:INFO:Total runtime is 0.0044353683789571125 minutes
2025-04-10 09:54:13,015:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:13,015:INFO:Initializing create_model()
2025-04-10 09:54:13,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:13,015:INFO:Checking exceptions
2025-04-10 09:54:13,015:INFO:Importing libraries
2025-04-10 09:54:13,015:INFO:Copying training dataset
2025-04-10 09:54:13,017:INFO:Defining folds
2025-04-10 09:54:13,017:INFO:Declaring metric variables
2025-04-10 09:54:13,018:INFO:Importing untrained model
2025-04-10 09:54:13,019:INFO:Lasso Regression Imported successfully
2025-04-10 09:54:13,022:INFO:Starting cross validation
2025-04-10 09:54:13,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:13,051:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,093:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,121:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,140:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,156:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,167:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,209:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,255:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,296:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,342:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e-01, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,359:INFO:Calculating mean and std
2025-04-10 09:54:13,360:INFO:Creating metrics dataframe
2025-04-10 09:54:13,363:INFO:Uploading results into container
2025-04-10 09:54:13,364:INFO:Uploading model into container now
2025-04-10 09:54:13,365:INFO:_master_model_container: 2
2025-04-10 09:54:13,365:INFO:_display_container: 2
2025-04-10 09:54:13,365:INFO:Lasso(random_state=123)
2025-04-10 09:54:13,365:INFO:create_model() successfully completed......................................
2025-04-10 09:54:13,460:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:13,460:INFO:Creating metrics dataframe
2025-04-10 09:54:13,475:INFO:Initializing Ridge Regression
2025-04-10 09:54:13,476:INFO:Total runtime is 0.012134567896525065 minutes
2025-04-10 09:54:13,484:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:13,485:INFO:Initializing create_model()
2025-04-10 09:54:13,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:13,485:INFO:Checking exceptions
2025-04-10 09:54:13,485:INFO:Importing libraries
2025-04-10 09:54:13,485:INFO:Copying training dataset
2025-04-10 09:54:13,492:INFO:Defining folds
2025-04-10 09:54:13,493:INFO:Declaring metric variables
2025-04-10 09:54:13,499:INFO:Importing untrained model
2025-04-10 09:54:13,507:INFO:Ridge Regression Imported successfully
2025-04-10 09:54:13,520:INFO:Starting cross validation
2025-04-10 09:54:13,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:13,562:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.83501e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,606:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.99565e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,643:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.98533e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,681:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.74825e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,718:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.06537e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,744:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.01696e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,782:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.69617e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,820:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.94072e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,857:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.6569e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,879:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.08078e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-04-10 09:54:13,887:INFO:Calculating mean and std
2025-04-10 09:54:13,887:INFO:Creating metrics dataframe
2025-04-10 09:54:13,889:INFO:Uploading results into container
2025-04-10 09:54:13,889:INFO:Uploading model into container now
2025-04-10 09:54:13,890:INFO:_master_model_container: 3
2025-04-10 09:54:13,890:INFO:_display_container: 2
2025-04-10 09:54:13,890:INFO:Ridge(random_state=123)
2025-04-10 09:54:13,890:INFO:create_model() successfully completed......................................
2025-04-10 09:54:13,937:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:13,937:INFO:Creating metrics dataframe
2025-04-10 09:54:13,941:INFO:Initializing Elastic Net
2025-04-10 09:54:13,941:INFO:Total runtime is 0.019886759916941325 minutes
2025-04-10 09:54:13,942:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:13,942:INFO:Initializing create_model()
2025-04-10 09:54:13,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:13,942:INFO:Checking exceptions
2025-04-10 09:54:13,942:INFO:Importing libraries
2025-04-10 09:54:13,942:INFO:Copying training dataset
2025-04-10 09:54:13,944:INFO:Defining folds
2025-04-10 09:54:13,944:INFO:Declaring metric variables
2025-04-10 09:54:13,945:INFO:Importing untrained model
2025-04-10 09:54:13,946:INFO:Elastic Net Imported successfully
2025-04-10 09:54:13,949:INFO:Starting cross validation
2025-04-10 09:54:13,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:13,957:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e-01, tolerance: 1.706e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,966:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e-01, tolerance: 1.665e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,976:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e-01, tolerance: 1.655e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,987:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-01, tolerance: 1.714e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:13,997:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-01, tolerance: 1.690e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,027:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 1.692e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,077:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e-01, tolerance: 1.801e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,123:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 1.658e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,170:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e-01, tolerance: 1.687e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,216:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e-02, tolerance: 1.792e-02
  model = cd_fast.enet_coordinate_descent(

2025-04-10 09:54:14,234:INFO:Calculating mean and std
2025-04-10 09:54:14,236:INFO:Creating metrics dataframe
2025-04-10 09:54:14,239:INFO:Uploading results into container
2025-04-10 09:54:14,240:INFO:Uploading model into container now
2025-04-10 09:54:14,241:INFO:_master_model_container: 4
2025-04-10 09:54:14,241:INFO:_display_container: 2
2025-04-10 09:54:14,242:INFO:ElasticNet(random_state=123)
2025-04-10 09:54:14,242:INFO:create_model() successfully completed......................................
2025-04-10 09:54:14,326:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:14,326:INFO:Creating metrics dataframe
2025-04-10 09:54:14,333:INFO:Initializing Least Angle Regression
2025-04-10 09:54:14,333:INFO:Total runtime is 0.02641980250676473 minutes
2025-04-10 09:54:14,336:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:14,336:INFO:Initializing create_model()
2025-04-10 09:54:14,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:14,336:INFO:Checking exceptions
2025-04-10 09:54:14,336:INFO:Importing libraries
2025-04-10 09:54:14,336:INFO:Copying training dataset
2025-04-10 09:54:14,339:INFO:Defining folds
2025-04-10 09:54:14,339:INFO:Declaring metric variables
2025-04-10 09:54:14,342:INFO:Importing untrained model
2025-04-10 09:54:14,344:INFO:Least Angle Regression Imported successfully
2025-04-10 09:54:14,347:INFO:Starting cross validation
2025-04-10 09:54:14,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:14,367:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.956e-05, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.613e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,397:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.084e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.715e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,417:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.444e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,430:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.329e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.141e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,440:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.858e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.473e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,452:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.245e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.871e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,463:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.124e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.742e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,476:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.974e-02, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.313e-10. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,492:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.586e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.485e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,503:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.021e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.546e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-10 09:54:14,508:INFO:Calculating mean and std
2025-04-10 09:54:14,508:INFO:Creating metrics dataframe
2025-04-10 09:54:14,509:INFO:Uploading results into container
2025-04-10 09:54:14,510:INFO:Uploading model into container now
2025-04-10 09:54:14,510:INFO:_master_model_container: 5
2025-04-10 09:54:14,510:INFO:_display_container: 2
2025-04-10 09:54:14,510:INFO:Lars(random_state=123)
2025-04-10 09:54:14,510:INFO:create_model() successfully completed......................................
2025-04-10 09:54:14,595:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:14,595:INFO:Creating metrics dataframe
2025-04-10 09:54:14,605:INFO:Initializing Lasso Least Angle Regression
2025-04-10 09:54:14,606:INFO:Total runtime is 0.030966933568318686 minutes
2025-04-10 09:54:14,610:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:14,611:INFO:Initializing create_model()
2025-04-10 09:54:14,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:14,611:INFO:Checking exceptions
2025-04-10 09:54:14,611:INFO:Importing libraries
2025-04-10 09:54:14,611:INFO:Copying training dataset
2025-04-10 09:54:14,617:INFO:Defining folds
2025-04-10 09:54:14,617:INFO:Declaring metric variables
2025-04-10 09:54:14,623:INFO:Importing untrained model
2025-04-10 09:54:14,629:INFO:Lasso Least Angle Regression Imported successfully
2025-04-10 09:54:14,639:INFO:Starting cross validation
2025-04-10 09:54:14,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:15,119:INFO:Calculating mean and std
2025-04-10 09:54:15,120:INFO:Creating metrics dataframe
2025-04-10 09:54:15,124:INFO:Uploading results into container
2025-04-10 09:54:15,125:INFO:Uploading model into container now
2025-04-10 09:54:15,126:INFO:_master_model_container: 6
2025-04-10 09:54:15,126:INFO:_display_container: 2
2025-04-10 09:54:15,127:INFO:LassoLars(random_state=123)
2025-04-10 09:54:15,127:INFO:create_model() successfully completed......................................
2025-04-10 09:54:15,207:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:15,207:INFO:Creating metrics dataframe
2025-04-10 09:54:15,213:INFO:Initializing Orthogonal Matching Pursuit
2025-04-10 09:54:15,213:INFO:Total runtime is 0.04108765125274658 minutes
2025-04-10 09:54:15,215:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:15,215:INFO:Initializing create_model()
2025-04-10 09:54:15,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:15,215:INFO:Checking exceptions
2025-04-10 09:54:15,215:INFO:Importing libraries
2025-04-10 09:54:15,215:INFO:Copying training dataset
2025-04-10 09:54:15,218:INFO:Defining folds
2025-04-10 09:54:15,218:INFO:Declaring metric variables
2025-04-10 09:54:15,222:INFO:Importing untrained model
2025-04-10 09:54:15,229:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-10 09:54:15,246:INFO:Starting cross validation
2025-04-10 09:54:15,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:15,395:INFO:Calculating mean and std
2025-04-10 09:54:15,395:INFO:Creating metrics dataframe
2025-04-10 09:54:15,396:INFO:Uploading results into container
2025-04-10 09:54:15,396:INFO:Uploading model into container now
2025-04-10 09:54:15,397:INFO:_master_model_container: 7
2025-04-10 09:54:15,397:INFO:_display_container: 2
2025-04-10 09:54:15,397:INFO:OrthogonalMatchingPursuit()
2025-04-10 09:54:15,397:INFO:create_model() successfully completed......................................
2025-04-10 09:54:15,441:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:15,441:INFO:Creating metrics dataframe
2025-04-10 09:54:15,445:INFO:Initializing Bayesian Ridge
2025-04-10 09:54:15,445:INFO:Total runtime is 0.04495479265848796 minutes
2025-04-10 09:54:15,446:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:15,446:INFO:Initializing create_model()
2025-04-10 09:54:15,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:15,447:INFO:Checking exceptions
2025-04-10 09:54:15,447:INFO:Importing libraries
2025-04-10 09:54:15,447:INFO:Copying training dataset
2025-04-10 09:54:15,448:INFO:Defining folds
2025-04-10 09:54:15,448:INFO:Declaring metric variables
2025-04-10 09:54:15,449:INFO:Importing untrained model
2025-04-10 09:54:15,451:INFO:Bayesian Ridge Imported successfully
2025-04-10 09:54:15,453:INFO:Starting cross validation
2025-04-10 09:54:15,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:15,765:INFO:Calculating mean and std
2025-04-10 09:54:15,767:INFO:Creating metrics dataframe
2025-04-10 09:54:15,771:INFO:Uploading results into container
2025-04-10 09:54:15,772:INFO:Uploading model into container now
2025-04-10 09:54:15,772:INFO:_master_model_container: 8
2025-04-10 09:54:15,773:INFO:_display_container: 2
2025-04-10 09:54:15,773:INFO:BayesianRidge()
2025-04-10 09:54:15,774:INFO:create_model() successfully completed......................................
2025-04-10 09:54:15,849:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:15,849:INFO:Creating metrics dataframe
2025-04-10 09:54:15,854:INFO:Initializing Passive Aggressive Regressor
2025-04-10 09:54:15,854:INFO:Total runtime is 0.05176963806152344 minutes
2025-04-10 09:54:15,855:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:15,855:INFO:Initializing create_model()
2025-04-10 09:54:15,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:15,855:INFO:Checking exceptions
2025-04-10 09:54:15,855:INFO:Importing libraries
2025-04-10 09:54:15,856:INFO:Copying training dataset
2025-04-10 09:54:15,857:INFO:Defining folds
2025-04-10 09:54:15,857:INFO:Declaring metric variables
2025-04-10 09:54:15,859:INFO:Importing untrained model
2025-04-10 09:54:15,861:INFO:Passive Aggressive Regressor Imported successfully
2025-04-10 09:54:15,869:INFO:Starting cross validation
2025-04-10 09:54:15,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:16,077:INFO:Calculating mean and std
2025-04-10 09:54:16,077:INFO:Creating metrics dataframe
2025-04-10 09:54:16,078:INFO:Uploading results into container
2025-04-10 09:54:16,079:INFO:Uploading model into container now
2025-04-10 09:54:16,079:INFO:_master_model_container: 9
2025-04-10 09:54:16,079:INFO:_display_container: 2
2025-04-10 09:54:16,079:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-10 09:54:16,079:INFO:create_model() successfully completed......................................
2025-04-10 09:54:16,124:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:16,124:INFO:Creating metrics dataframe
2025-04-10 09:54:16,128:INFO:Initializing Huber Regressor
2025-04-10 09:54:16,128:INFO:Total runtime is 0.056339363257090255 minutes
2025-04-10 09:54:16,130:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:16,130:INFO:Initializing create_model()
2025-04-10 09:54:16,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:16,130:INFO:Checking exceptions
2025-04-10 09:54:16,130:INFO:Importing libraries
2025-04-10 09:54:16,130:INFO:Copying training dataset
2025-04-10 09:54:16,131:INFO:Defining folds
2025-04-10 09:54:16,131:INFO:Declaring metric variables
2025-04-10 09:54:16,133:INFO:Importing untrained model
2025-04-10 09:54:16,134:INFO:Huber Regressor Imported successfully
2025-04-10 09:54:16,137:INFO:Starting cross validation
2025-04-10 09:54:16,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:16,187:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-10 09:54:16,340:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-10 09:54:16,354:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-10 09:54:16,416:INFO:Calculating mean and std
2025-04-10 09:54:16,416:INFO:Creating metrics dataframe
2025-04-10 09:54:16,417:INFO:Uploading results into container
2025-04-10 09:54:16,417:INFO:Uploading model into container now
2025-04-10 09:54:16,418:INFO:_master_model_container: 10
2025-04-10 09:54:16,418:INFO:_display_container: 2
2025-04-10 09:54:16,418:INFO:HuberRegressor()
2025-04-10 09:54:16,418:INFO:create_model() successfully completed......................................
2025-04-10 09:54:16,477:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:16,478:INFO:Creating metrics dataframe
2025-04-10 09:54:16,486:INFO:Initializing K Neighbors Regressor
2025-04-10 09:54:16,487:INFO:Total runtime is 0.062318948904673266 minutes
2025-04-10 09:54:16,490:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:16,490:INFO:Initializing create_model()
2025-04-10 09:54:16,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:16,490:INFO:Checking exceptions
2025-04-10 09:54:16,490:INFO:Importing libraries
2025-04-10 09:54:16,490:INFO:Copying training dataset
2025-04-10 09:54:16,493:INFO:Defining folds
2025-04-10 09:54:16,493:INFO:Declaring metric variables
2025-04-10 09:54:16,497:INFO:Importing untrained model
2025-04-10 09:54:16,502:INFO:K Neighbors Regressor Imported successfully
2025-04-10 09:54:16,513:INFO:Starting cross validation
2025-04-10 09:54:16,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:16,855:INFO:Calculating mean and std
2025-04-10 09:54:16,856:INFO:Creating metrics dataframe
2025-04-10 09:54:16,857:INFO:Uploading results into container
2025-04-10 09:54:16,857:INFO:Uploading model into container now
2025-04-10 09:54:16,858:INFO:_master_model_container: 11
2025-04-10 09:54:16,858:INFO:_display_container: 2
2025-04-10 09:54:16,859:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-10 09:54:16,859:INFO:create_model() successfully completed......................................
2025-04-10 09:54:16,909:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:16,909:INFO:Creating metrics dataframe
2025-04-10 09:54:16,914:INFO:Initializing Decision Tree Regressor
2025-04-10 09:54:16,914:INFO:Total runtime is 0.06943434874216717 minutes
2025-04-10 09:54:16,915:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:16,915:INFO:Initializing create_model()
2025-04-10 09:54:16,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:16,915:INFO:Checking exceptions
2025-04-10 09:54:16,915:INFO:Importing libraries
2025-04-10 09:54:16,915:INFO:Copying training dataset
2025-04-10 09:54:16,917:INFO:Defining folds
2025-04-10 09:54:16,917:INFO:Declaring metric variables
2025-04-10 09:54:16,918:INFO:Importing untrained model
2025-04-10 09:54:16,920:INFO:Decision Tree Regressor Imported successfully
2025-04-10 09:54:16,922:INFO:Starting cross validation
2025-04-10 09:54:16,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:17,243:INFO:Calculating mean and std
2025-04-10 09:54:17,244:INFO:Creating metrics dataframe
2025-04-10 09:54:17,245:INFO:Uploading results into container
2025-04-10 09:54:17,245:INFO:Uploading model into container now
2025-04-10 09:54:17,246:INFO:_master_model_container: 12
2025-04-10 09:54:17,246:INFO:_display_container: 2
2025-04-10 09:54:17,246:INFO:DecisionTreeRegressor(random_state=123)
2025-04-10 09:54:17,246:INFO:create_model() successfully completed......................................
2025-04-10 09:54:17,288:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:17,289:INFO:Creating metrics dataframe
2025-04-10 09:54:17,293:INFO:Initializing Random Forest Regressor
2025-04-10 09:54:17,293:INFO:Total runtime is 0.0757569710413615 minutes
2025-04-10 09:54:17,295:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:17,295:INFO:Initializing create_model()
2025-04-10 09:54:17,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:17,295:INFO:Checking exceptions
2025-04-10 09:54:17,295:INFO:Importing libraries
2025-04-10 09:54:17,295:INFO:Copying training dataset
2025-04-10 09:54:17,296:INFO:Defining folds
2025-04-10 09:54:17,296:INFO:Declaring metric variables
2025-04-10 09:54:17,298:INFO:Importing untrained model
2025-04-10 09:54:17,299:INFO:Random Forest Regressor Imported successfully
2025-04-10 09:54:17,302:INFO:Starting cross validation
2025-04-10 09:54:17,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:20,376:INFO:Calculating mean and std
2025-04-10 09:54:20,378:INFO:Creating metrics dataframe
2025-04-10 09:54:20,380:INFO:Uploading results into container
2025-04-10 09:54:20,381:INFO:Uploading model into container now
2025-04-10 09:54:20,382:INFO:_master_model_container: 13
2025-04-10 09:54:20,382:INFO:_display_container: 2
2025-04-10 09:54:20,383:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-10 09:54:20,383:INFO:create_model() successfully completed......................................
2025-04-10 09:54:20,477:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:20,477:INFO:Creating metrics dataframe
2025-04-10 09:54:20,498:INFO:Initializing Extra Trees Regressor
2025-04-10 09:54:20,498:INFO:Total runtime is 0.12917433579762777 minutes
2025-04-10 09:54:20,505:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:20,506:INFO:Initializing create_model()
2025-04-10 09:54:20,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:20,506:INFO:Checking exceptions
2025-04-10 09:54:20,507:INFO:Importing libraries
2025-04-10 09:54:20,507:INFO:Copying training dataset
2025-04-10 09:54:20,516:INFO:Defining folds
2025-04-10 09:54:20,517:INFO:Declaring metric variables
2025-04-10 09:54:20,525:INFO:Importing untrained model
2025-04-10 09:54:20,532:INFO:Extra Trees Regressor Imported successfully
2025-04-10 09:54:20,546:INFO:Starting cross validation
2025-04-10 09:54:20,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:22,948:INFO:Calculating mean and std
2025-04-10 09:54:22,950:INFO:Creating metrics dataframe
2025-04-10 09:54:22,953:INFO:Uploading results into container
2025-04-10 09:54:22,955:INFO:Uploading model into container now
2025-04-10 09:54:22,955:INFO:_master_model_container: 14
2025-04-10 09:54:22,955:INFO:_display_container: 2
2025-04-10 09:54:22,956:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-10 09:54:22,956:INFO:create_model() successfully completed......................................
2025-04-10 09:54:23,052:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:23,052:INFO:Creating metrics dataframe
2025-04-10 09:54:23,073:INFO:Initializing AdaBoost Regressor
2025-04-10 09:54:23,073:INFO:Total runtime is 0.17209576368331908 minutes
2025-04-10 09:54:23,081:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:23,081:INFO:Initializing create_model()
2025-04-10 09:54:23,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:23,082:INFO:Checking exceptions
2025-04-10 09:54:23,082:INFO:Importing libraries
2025-04-10 09:54:23,082:INFO:Copying training dataset
2025-04-10 09:54:23,090:INFO:Defining folds
2025-04-10 09:54:23,090:INFO:Declaring metric variables
2025-04-10 09:54:23,098:INFO:Importing untrained model
2025-04-10 09:54:23,105:INFO:AdaBoost Regressor Imported successfully
2025-04-10 09:54:23,121:INFO:Starting cross validation
2025-04-10 09:54:23,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:23,808:INFO:Calculating mean and std
2025-04-10 09:54:23,808:INFO:Creating metrics dataframe
2025-04-10 09:54:23,810:INFO:Uploading results into container
2025-04-10 09:54:23,810:INFO:Uploading model into container now
2025-04-10 09:54:23,810:INFO:_master_model_container: 15
2025-04-10 09:54:23,810:INFO:_display_container: 2
2025-04-10 09:54:23,810:INFO:AdaBoostRegressor(random_state=123)
2025-04-10 09:54:23,810:INFO:create_model() successfully completed......................................
2025-04-10 09:54:23,861:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:23,861:INFO:Creating metrics dataframe
2025-04-10 09:54:23,866:INFO:Initializing Gradient Boosting Regressor
2025-04-10 09:54:23,866:INFO:Total runtime is 0.1853044629096985 minutes
2025-04-10 09:54:23,868:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:23,868:INFO:Initializing create_model()
2025-04-10 09:54:23,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:23,868:INFO:Checking exceptions
2025-04-10 09:54:23,868:INFO:Importing libraries
2025-04-10 09:54:23,868:INFO:Copying training dataset
2025-04-10 09:54:23,870:INFO:Defining folds
2025-04-10 09:54:23,870:INFO:Declaring metric variables
2025-04-10 09:54:23,871:INFO:Importing untrained model
2025-04-10 09:54:23,872:INFO:Gradient Boosting Regressor Imported successfully
2025-04-10 09:54:23,875:INFO:Starting cross validation
2025-04-10 09:54:23,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:24,530:INFO:Calculating mean and std
2025-04-10 09:54:24,531:INFO:Creating metrics dataframe
2025-04-10 09:54:24,532:INFO:Uploading results into container
2025-04-10 09:54:24,532:INFO:Uploading model into container now
2025-04-10 09:54:24,532:INFO:_master_model_container: 16
2025-04-10 09:54:24,532:INFO:_display_container: 2
2025-04-10 09:54:24,532:INFO:GradientBoostingRegressor(random_state=123)
2025-04-10 09:54:24,532:INFO:create_model() successfully completed......................................
2025-04-10 09:54:24,578:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:24,578:INFO:Creating metrics dataframe
2025-04-10 09:54:24,583:INFO:Initializing Light Gradient Boosting Machine
2025-04-10 09:54:24,583:INFO:Total runtime is 0.19726347923278809 minutes
2025-04-10 09:54:24,585:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:24,585:INFO:Initializing create_model()
2025-04-10 09:54:24,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:24,585:INFO:Checking exceptions
2025-04-10 09:54:24,585:INFO:Importing libraries
2025-04-10 09:54:24,585:INFO:Copying training dataset
2025-04-10 09:54:24,587:INFO:Defining folds
2025-04-10 09:54:24,587:INFO:Declaring metric variables
2025-04-10 09:54:24,588:INFO:Importing untrained model
2025-04-10 09:54:24,590:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-10 09:54:24,592:INFO:Starting cross validation
2025-04-10 09:54:24,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:24,612:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:24,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029873 seconds.
2025-04-10 09:54:24,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:24,653:INFO:[LightGBM] [Info] Total Bins 675
2025-04-10 09:54:24,659:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:24,667:INFO:[LightGBM] [Info] Start training from score 5.149485
2025-04-10 09:54:24,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:24,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:25,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,351:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:26,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032375 seconds.
2025-04-10 09:54:26,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:26,384:INFO:[LightGBM] [Info] Total Bins 696
2025-04-10 09:54:26,392:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:26,399:INFO:[LightGBM] [Info] Start training from score 5.144330
2025-04-10 09:54:26,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:26,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,630:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:27,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033545 seconds.
2025-04-10 09:54:27,664:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:27,665:INFO:[LightGBM] [Info] Total Bins 702
2025-04-10 09:54:27,672:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:27,678:INFO:[LightGBM] [Info] Start training from score 5.103093
2025-04-10 09:54:27,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:27,975:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:28,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040864 seconds.
2025-04-10 09:54:28,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:28,017:INFO:[LightGBM] [Info] Total Bins 686
2025-04-10 09:54:28,019:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:28,026:INFO:[LightGBM] [Info] Start training from score 5.211340
2025-04-10 09:54:28,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,285:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:28,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027870 seconds.
2025-04-10 09:54:28,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:28,314:INFO:[LightGBM] [Info] Total Bins 702
2025-04-10 09:54:28,321:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:28,328:INFO:[LightGBM] [Info] Start training from score 5.231959
2025-04-10 09:54:28,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:28,899:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:28,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025935 seconds.
2025-04-10 09:54:28,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:28,926:INFO:[LightGBM] [Info] Total Bins 686
2025-04-10 09:54:28,932:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:28,939:INFO:[LightGBM] [Info] Start training from score 5.154639
2025-04-10 09:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,450:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:29,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029642 seconds.
2025-04-10 09:54:29,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:29,481:INFO:[LightGBM] [Info] Total Bins 695
2025-04-10 09:54:29,486:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:29,493:INFO:[LightGBM] [Info] Start training from score 5.180412
2025-04-10 09:54:29,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,746:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:29,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030018 seconds.
2025-04-10 09:54:29,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:29,777:INFO:[LightGBM] [Info] Total Bins 684
2025-04-10 09:54:29,784:INFO:[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 35
2025-04-10 09:54:29,790:INFO:[LightGBM] [Info] Start training from score 5.134021
2025-04-10 09:54:29,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:29,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,030:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:30,062:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028659 seconds.
2025-04-10 09:54:30,062:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:30,063:INFO:[LightGBM] [Info] Total Bins 678
2025-04-10 09:54:30,071:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-10 09:54:30,082:INFO:[LightGBM] [Info] Start training from score 5.091837
2025-04-10 09:54:30,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:30,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,627:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-04-10 09:54:31,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027840 seconds.
2025-04-10 09:54:31,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-10 09:54:31,656:INFO:[LightGBM] [Info] Total Bins 686
2025-04-10 09:54:31,665:INFO:[LightGBM] [Info] Number of data points in the train set: 98, number of used features: 35
2025-04-10 09:54:31,673:INFO:[LightGBM] [Info] Start training from score 5.127551
2025-04-10 09:54:31,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:31,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-10 09:54:32,196:INFO:Calculating mean and std
2025-04-10 09:54:32,198:INFO:Creating metrics dataframe
2025-04-10 09:54:32,201:INFO:Uploading results into container
2025-04-10 09:54:32,202:INFO:Uploading model into container now
2025-04-10 09:54:32,203:INFO:_master_model_container: 17
2025-04-10 09:54:32,203:INFO:_display_container: 2
2025-04-10 09:54:32,203:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-10 09:54:32,203:INFO:create_model() successfully completed......................................
2025-04-10 09:54:32,268:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:32,268:INFO:Creating metrics dataframe
2025-04-10 09:54:32,276:INFO:Initializing Dummy Regressor
2025-04-10 09:54:32,276:INFO:Total runtime is 0.32547990083694456 minutes
2025-04-10 09:54:32,279:INFO:SubProcess create_model() called ==================================
2025-04-10 09:54:32,280:INFO:Initializing create_model()
2025-04-10 09:54:32,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7885052c0f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:32,280:INFO:Checking exceptions
2025-04-10 09:54:32,280:INFO:Importing libraries
2025-04-10 09:54:32,280:INFO:Copying training dataset
2025-04-10 09:54:32,283:INFO:Defining folds
2025-04-10 09:54:32,283:INFO:Declaring metric variables
2025-04-10 09:54:32,285:INFO:Importing untrained model
2025-04-10 09:54:32,288:INFO:Dummy Regressor Imported successfully
2025-04-10 09:54:32,296:INFO:Starting cross validation
2025-04-10 09:54:32,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-04-10 09:54:32,520:INFO:Calculating mean and std
2025-04-10 09:54:32,521:INFO:Creating metrics dataframe
2025-04-10 09:54:32,523:INFO:Uploading results into container
2025-04-10 09:54:32,523:INFO:Uploading model into container now
2025-04-10 09:54:32,523:INFO:_master_model_container: 18
2025-04-10 09:54:32,523:INFO:_display_container: 2
2025-04-10 09:54:32,523:INFO:DummyRegressor()
2025-04-10 09:54:32,523:INFO:create_model() successfully completed......................................
2025-04-10 09:54:32,610:INFO:SubProcess create_model() end ==================================
2025-04-10 09:54:32,610:INFO:Creating metrics dataframe
2025-04-10 09:54:32,635:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-10 09:54:32,649:INFO:Initializing create_model()
2025-04-10 09:54:32,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:32,650:INFO:Checking exceptions
2025-04-10 09:54:32,653:INFO:Importing libraries
2025-04-10 09:54:32,653:INFO:Copying training dataset
2025-04-10 09:54:32,659:INFO:Defining folds
2025-04-10 09:54:32,660:INFO:Declaring metric variables
2025-04-10 09:54:32,660:INFO:Importing untrained model
2025-04-10 09:54:32,660:INFO:Declaring custom model
2025-04-10 09:54:32,661:INFO:Linear Regression Imported successfully
2025-04-10 09:54:32,662:INFO:Cross validation set to False
2025-04-10 09:54:32,662:INFO:Fitting Model
2025-04-10 09:54:32,684:INFO:LinearRegression(n_jobs=-1)
2025-04-10 09:54:32,684:INFO:create_model() successfully completed......................................
2025-04-10 09:54:32,823:INFO:_master_model_container: 18
2025-04-10 09:54:32,823:INFO:_display_container: 2
2025-04-10 09:54:32,824:INFO:LinearRegression(n_jobs=-1)
2025-04-10 09:54:32,824:INFO:compare_models() successfully completed......................................
2025-04-10 09:54:32,875:INFO:Initializing evaluate_model()
2025-04-10 09:54:32,876:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-10 09:54:32,895:INFO:Initializing plot_model()
2025-04-10 09:54:32,896:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, system=True)
2025-04-10 09:54:32,896:INFO:Checking exceptions
2025-04-10 09:54:32,900:INFO:Preloading libraries
2025-04-10 09:54:32,901:INFO:Copying training dataset
2025-04-10 09:54:32,901:INFO:Plot type: pipeline
2025-04-10 09:54:33,050:INFO:Visual Rendered Successfully
2025-04-10 09:54:33,093:INFO:plot_model() successfully completed......................................
2025-04-10 09:54:33,113:INFO:Initializing plot_model()
2025-04-10 09:54:33,113:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, system=True)
2025-04-10 09:54:33,113:INFO:Checking exceptions
2025-04-10 09:54:33,117:INFO:Preloading libraries
2025-04-10 09:54:33,117:INFO:Copying training dataset
2025-04-10 09:54:33,117:INFO:Plot type: residuals
2025-04-10 09:54:33,196:INFO:Fitting Model
2025-04-10 09:54:33,197:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-10 09:54:33,213:INFO:Scoring test/hold-out set
2025-04-10 09:54:33,460:INFO:Visual Rendered Successfully
2025-04-10 09:54:33,507:INFO:plot_model() successfully completed......................................
2025-04-10 09:54:33,520:INFO:Initializing plot_model()
2025-04-10 09:54:33,520:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, system=True)
2025-04-10 09:54:33,520:INFO:Checking exceptions
2025-04-10 09:54:33,524:INFO:Preloading libraries
2025-04-10 09:54:33,524:INFO:Copying training dataset
2025-04-10 09:54:33,524:INFO:Plot type: feature
2025-04-10 09:54:33,717:INFO:Visual Rendered Successfully
2025-04-10 09:54:33,792:INFO:plot_model() successfully completed......................................
2025-04-10 09:54:33,829:INFO:Initializing predict_model()
2025-04-10 09:54:33,830:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7884da3774c0>)
2025-04-10 09:54:33,830:INFO:Checking exceptions
2025-04-10 09:54:33,830:INFO:Preloading libraries
2025-04-10 09:54:33,902:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-10 09:54:33,989:INFO:Initializing predict_model()
2025-04-10 09:54:33,990:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7884da4f89d0>)
2025-04-10 09:54:33,990:INFO:Checking exceptions
2025-04-10 09:54:33,990:INFO:Preloading libraries
2025-04-10 09:54:33,991:INFO:Set up data.
2025-04-10 09:54:33,995:INFO:Set up index.
2025-04-10 09:54:34,008:WARNING:/home/lworakan/miniconda3/envs/pycaret3_9/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-10 09:54:57,554:INFO:Initializing finalize_model()
2025-04-10 09:54:57,555:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-10 09:54:57,555:INFO:Finalizing LinearRegression(n_jobs=-1)
2025-04-10 09:54:57,561:INFO:Initializing create_model()
2025-04-10 09:54:57,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x78851a517970>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-04-10 09:54:57,561:INFO:Checking exceptions
2025-04-10 09:54:57,564:INFO:Importing libraries
2025-04-10 09:54:57,565:INFO:Copying training dataset
2025-04-10 09:54:57,565:INFO:Defining folds
2025-04-10 09:54:57,565:INFO:Declaring metric variables
2025-04-10 09:54:57,566:INFO:Importing untrained model
2025-04-10 09:54:57,566:INFO:Declaring custom model
2025-04-10 09:54:57,566:INFO:Linear Regression Imported successfully
2025-04-10 09:54:57,568:INFO:Cross validation set to False
2025-04-10 09:54:57,568:INFO:Fitting Model
2025-04-10 09:54:57,601:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator', LinearRegression(n_jobs=-1))])
2025-04-10 09:54:57,601:INFO:create_model() successfully completed......................................
2025-04-10 09:54:57,695:INFO:_master_model_container: 18
2025-04-10 09:54:57,695:INFO:_display_container: 4
2025-04-10 09:54:57,702:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator', LinearRegression(n_jobs=-1))])
2025-04-10 09:54:57,702:INFO:finalize_model() successfully completed......................................
2025-04-10 09:54:57,755:INFO:Initializing save_model()
2025-04-10 09:54:57,755:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator', LinearRegression(n_jobs=-1))]), model_name=final_calibrated_depth_model_outdoor_v2_linear, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-10 09:54:57,755:INFO:Adding model into prep_pipe
2025-04-10 09:54:57,755:WARNING:Only Model saved as it was a pipeline.
2025-04-10 09:54:57,756:INFO:final_calibrated_depth_model_outdoor_v2_linear.pkl saved in current working directory
2025-04-10 09:54:57,758:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['X_min', 'Y_min', 'X_max', 'Y_max',
                                             'Confidence', 'Average_Depth_m',
                                             'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('actual_estimator', LinearRegression(n_jobs=-1))])
2025-04-10 09:54:57,758:INFO:save_model() successfully completed......................................
