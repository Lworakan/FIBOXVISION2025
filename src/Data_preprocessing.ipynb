{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ../data904/camera_trackingHuman_45M.csv\n",
      "Processed ../data904/camera_trackingHuman_5M.csv\n",
      "Processed ../data904/camera_trackingHuman_55M.csv\n",
      "Processed ../data904/camera_trackingHuman_60M.csv\n",
      "Processed ../data904/camera_trackingHuman_65M.csv\n",
      "Processed ../data904/camera_trackingHuman_70M.csv\n",
      "Processed ../data904/camera_trackingHuman_75M.csv\n",
      "\n",
      "Successfully merged 7 files into ../data904/merged_detections_testset.csv\n",
      "Total rows in merged file: 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49586/3534764082.py:54: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat(all_dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define ground truth values corresponding to each file\n",
    "# ground_truth_values = ['3.5', '4.0', '4.5', '5.0', '5.5', '6.0', '6.5', '7.0', '7.5']\n",
    "\n",
    "ground_truth_values = ['4.5', '5.0', '5.5', '6.0', '6.5', '7.0', '7.5']\n",
    "# Input directory and file names\n",
    "input_dir = '../data904'\n",
    "# file_names = [\n",
    "#     'realsense_detections3500', 'realsense_detections4000', 'realsense_detections4500',\n",
    "#     'realsense_detections5000', 'realsense_detections5500', 'realsense_detections6000',\n",
    "#     'realsense_detections6500', 'realsense_detections7000', 'realsense_detections7500'\n",
    "# ]\n",
    "\n",
    "file_names = ['camera_trackingHuman_45M', 'camera_trackingHuman_5M', 'camera_trackingHuman_55M', \n",
    "              'camera_trackingHuman_60M', 'camera_trackingHuman_65M', 'camera_trackingHuman_70M', \n",
    "              'camera_trackingHuman_75M']\n",
    "# Output file for the merged data\n",
    "output_file = os.path.join(input_dir, 'merged_detections_testset.csv')\n",
    "\n",
    "# Step 1: First update each file with its ground truth value\n",
    "all_dataframes = []\n",
    "\n",
    "for idx, base_name in enumerate(file_names):\n",
    "    csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "    ground_truth = ground_truth_values[idx]\n",
    "    \n",
    "    if not os.path.exists(csv_file_path):\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Add ground truth column if it doesn't exist\n",
    "        if 'ground_truth' not in df.columns:\n",
    "            df['ground_truth'] = ground_truth\n",
    "        \n",
    "        # Add source filename column for tracking\n",
    "        df['source_file'] = base_name\n",
    "        \n",
    "        # Append to our list of dataframes\n",
    "        all_dataframes.append(df)\n",
    "        \n",
    "        print(f\"Processed {csv_file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file_path}: {str(e)}\")\n",
    "\n",
    "# Step 2: Concatenate all dataframes\n",
    "if all_dataframes:\n",
    "    merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Step 3: Save the merged dataframe to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully merged {len(all_dataframes)} files into {output_file}\")\n",
    "    print(f\"Total rows in merged file: {len(merged_df)}\")\n",
    "else:\n",
    "    print(\"No data to merge. Please check the input files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lworakan/Documents/GitHub/FIBOXVISION2025/src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lworakan/Documents/GitHub/FIBOXVISION2025/src'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line in ../data904/realsense_detections3500.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections3500.csv → ../data904/realsense_detections3500.csv with ground_truth = 3.5\n",
      "Skipping line in ../data904/realsense_detections4000.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections4000.csv → ../data904/realsense_detections4000.csv with ground_truth = 4.0\n",
      "Skipping line in ../data904/realsense_detections4500.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections4500.csv → ../data904/realsense_detections4500.csv with ground_truth = 4.5\n",
      "Skipping line in ../data904/realsense_detections5000.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections5000.csv → ../data904/realsense_detections5000.csv with ground_truth = 5.0\n",
      "Skipping line in ../data904/realsense_detections5500.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections5500.csv → ../data904/realsense_detections5500.csv with ground_truth = 5.5\n",
      "Skipping line in ../data904/realsense_detections6000.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections6000.csv → ../data904/realsense_detections6000.csv with ground_truth = 6.0\n",
      "Skipping line in ../data904/realsense_detections6500.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections6500.csv → ../data904/realsense_detections6500.csv with ground_truth = 6.5\n",
      "Skipping line in ../data904/realsense_detections7000.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections7000.csv → ../data904/realsense_detections7000.csv with ground_truth = 7.0\n",
      "Skipping line in ../data904/realsense_detections7500.csv due to unexpected format: Timestamp,Frame,X_min,Y_min,X_max,Y_max,Confidence,Average_Depth_m,area,ground_truth\n",
      "Converted: ../data904/realsense_detections7500.csv → ../data904/realsense_detections7500.csv with ground_truth = 7.5\n",
      "All files successfully merged into ../data904/merged_output.csv!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# input_dir = '../Callback'\n",
    "\n",
    "# ground_truth_values = ['9','8.75','8.5','8','7.75', '7.5','7.25', '7','6.75','6.5', '6.25', '6','5.75', '5.5', '5.25','5', '4.75', '4.5', '4.25', '4']\n",
    "\n",
    "# input_dir = '../Callback'\n",
    "# file_names = ['Day2_9_depth_measurements','Day2_8_7_5_depth_measurements','Day2_8_5_depth_measurements' , 'Day2_8_depth_measurements', 'Day2_7_7_5_depth_measurements', 'Day2_7_5_depth_measurements', 'Day2_7_2_5_depth_measurements','Day2_7_depth_measurements', 'Day2_6_7_5_depth_measurements', 'Day2_6_5_depth_measurements', 'Day2_6_2_5_depth_measurements', 'Day2_6_depth_measurements'\n",
    "#               , 'Day2_5_7_5_depth_measurements', 'Day2_5_5_depth_measurements', 'Day2_5_2_5_depth_measurements', 'Day2_5_depth_measurements', 'Day2_4_7_5_depth_measurements', 'Day2_4_5_depth_measurements', 'Day2_4_2_5_depth_measurements', 'Day2_4_depth_measurements']\n",
    "\n",
    "# Ensure the number of filenames matches the number of ground truth values\n",
    "if len(file_names) != len(ground_truth_values):\n",
    "    raise ValueError(\"Mismatch between number of filenames and ground truth values.\")\n",
    "\n",
    "# headers = [\n",
    "#     'timestamp', 'x', 'y', 'w','h','depth',\n",
    "#     'gyro_data.x', 'gyro_data.y', 'gyro_data.z',\n",
    "#     'accel_data.x', 'accel_data.y', 'accel_data.z',\n",
    "#     'ground_truth'\n",
    "# ]\n",
    "\n",
    "\n",
    "# List to store all dataframes for merging\n",
    "all_dataframes = []\n",
    "\n",
    "# Process each file\n",
    "for idx, base_name in enumerate(file_names):\n",
    "    txt_file_path = os.path.join(input_dir, base_name + '.txt')\n",
    "    ground_truth = ground_truth_values[idx]  # Assign corresponding ground truth value\n",
    "\n",
    "    if not os.path.exists(txt_file_path):\n",
    "        print(f\"File not found: {txt_file_path}\")\n",
    "        continue\n",
    "    # Read the .txt file and prepare data for the .csv\n",
    "    csv_data = []\n",
    "    with open(txt_file_path, 'r') as txt_file:\n",
    "        for line in txt_file:\n",
    "            # Assuming each line contains 10 comma-separated values\n",
    "            data = line.strip().split(',')\n",
    "            if len(data) == 12:  # Ensure correct data format\n",
    "                data.append(ground_truth)  # Add the ground truth value\n",
    "                csv_data.append(data)\n",
    "            else:\n",
    "                print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n",
    "\n",
    "    # Define the output .csv file path\n",
    "    csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "\n",
    "    # Write data to the .csv file\n",
    "    with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)  # Write headers\n",
    "        writer.writerows(csv_data)  # Write data rows\n",
    "\n",
    "    print(f\"Converted: {txt_file_path} → {csv_file_path} with ground_truth = {ground_truth}\")\n",
    "\n",
    "    # Read the CSV file into a dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    all_dataframes.append(df)\n",
    "\n",
    "# Merge all CSVs into one dataframe\n",
    "merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Define the output merged CSV file path\n",
    "merged_csv_path = os.path.join(input_dir, 'merged_output.csv')\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(f\"All files successfully merged into {merged_csv_path}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line in ../Callback/Day2_4_depth_measurements.txt due to unexpected format: 2025-03-07 02:23:18.777023,320,240,20,20,4.286235203585238,-0.004792673978954554,-0.006391395349055529,0.0021293016616255045,0.3040061295032501,-9.169217109680176,0.06864655017852783\n"
     ]
    }
   ],
   "source": [
    "if len(data) == 10:  # Ensure correct data format\n",
    "    data.append(ground_truth)  # Add the ground truth value\n",
    "    csv_data.append(data)\n",
    "else:\n",
    "    print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: ../Callback/m8_1_depth_measurements.txt → ../Callback/m8_1_depth_measurements.csv with ground_truth = 8.0\n",
      "Converted: ../Callback/7.5_depth_measurements.txt → ../Callback/7.5_depth_measurements.csv with ground_truth = 7.5\n",
      "Converted: ../Callback/7_depth_measurements.txt → ../Callback/7_depth_measurements.csv with ground_truth = 7.0\n",
      "Converted: ../Callback/m_65_depth_measurements.txt → ../Callback/m_65_depth_measurements.csv with ground_truth = 6.5\n",
      "File not found: ../Callback/m6_depth_measurements.txt\n",
      "Converted: ../Callback/m_5_5depth_measurements.txt → ../Callback/m_5_5depth_measurements.csv with ground_truth = 5.5\n",
      "Converted: ../Callback/m_5_depth_measurements.txt → ../Callback/m_5_depth_measurements.csv with ground_truth = 5.0\n",
      "Converted: ../Callback/m_4_5_depth_measurements.txt → ../Callback/m_4_5_depth_measurements.csv with ground_truth = 4.5\n",
      "Converted: ../Callback/m_4_depth_measurements.txt → ../Callback/m_4_depth_measurements.csv with ground_truth = 4.0\n",
      "Converted: ../Callback/m3_5_depth_measurements.txt → ../Callback/m3_5_depth_measurements.csv with ground_truth = 3.5\n",
      "Converted: ../Callback/m_3_depth_measurements.txt → ../Callback/m_3_depth_measurements.csv with ground_truth = 3.0\n",
      "All files successfully merged into ../Callback/merged_output.csv!\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define ground truth values corresponding to each file\n",
    "# ground_truth_values = ['8', '7.5', '7', '6.5', '6', '5.5', '5', '4.5', '4', '3.5', '3']\n",
    "\n",
    "# # List of filenames without extensions\n",
    "# file_names = [\n",
    "#     'm8_1_depth_measurements', '7.5_depth_measurements', '7_depth_measurements', \n",
    "#     'm_65_depth_measurements', 'm6_depth_measurements', 'm_5_5depth_measurements', \n",
    "#     'm_5_depth_measurements', 'm_4_5_depth_measurements', 'm_4_depth_measurements', \n",
    "#     'm3_5_depth_measurements', 'm_3_depth_measurements'\n",
    "# ]\n",
    "\n",
    "# # Define the input directory\n",
    "# input_dir = '../Callback'\n",
    "\n",
    "# # Ensure the number of filenames matches the number of ground truth values\n",
    "# if len(file_names) != len(ground_truth_values):\n",
    "#     raise ValueError(\"Mismatch between number of filenames and ground truth values.\")\n",
    "\n",
    "# # Define the headers\n",
    "# headers = [\n",
    "#     'timestamp', 'x', 'y', 'depth',\n",
    "#     'gyro_data.x', 'gyro_data.y', 'gyro_data.z',\n",
    "#     'accel_data.x', 'accel_data.y', 'accel_data.z',\n",
    "#     'ground_truth', 'error'\n",
    "# ]\n",
    "\n",
    "# # List to store all dataframes for merging\n",
    "# all_dataframes = []\n",
    "\n",
    "# # Process each file\n",
    "# for idx, base_name in enumerate(file_names):\n",
    "#     txt_file_path = os.path.join(input_dir, base_name + '.txt')\n",
    "#     ground_truth = float(ground_truth_values[idx])  # Assign corresponding ground truth value\n",
    "\n",
    "#     if not os.path.exists(txt_file_path):\n",
    "#         print(f\"File not found: {txt_file_path}\")\n",
    "#         continue\n",
    "\n",
    "#     # Read the .txt file and prepare data for the .csv\n",
    "#     csv_data = []\n",
    "#     with open(txt_file_path, 'r') as txt_file:\n",
    "#         for line in txt_file:\n",
    "#             # Assuming each line contains 10 comma-separated values\n",
    "#             data = line.strip().split(',')\n",
    "#             if len(data) == 10:  # Ensure correct data format\n",
    "#                 depth_value = float(data[3])  # Convert depth to float\n",
    "#                 error_value = depth_value - ground_truth  # Calculate error\n",
    "#                 data.append(str(ground_truth))  # Add the ground truth value\n",
    "#                 data.append(str(error_value))  # Add the error value\n",
    "#                 csv_data.append(data)\n",
    "#             else:\n",
    "#                 print(f\"Skipping line in {txt_file_path} due to unexpected format: {line.strip()}\")\n",
    "\n",
    "#     # Define the output .csv file path\n",
    "#     csv_file_path = os.path.join(input_dir, base_name + '.csv')\n",
    "\n",
    "#     # Write data to the .csv file\n",
    "#     with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#         writer = csv.writer(csv_file)\n",
    "#         writer.writerow(headers)  # Write headers\n",
    "#         writer.writerows(csv_data)  # Write data rows\n",
    "\n",
    "#     print(f\"Converted: {txt_file_path} → {csv_file_path} with ground_truth = {ground_truth}\")\n",
    "\n",
    "#     # Read the CSV file into a dataframe\n",
    "#     df = pd.read_csv(csv_file_path)\n",
    "#     all_dataframes.append(df)\n",
    "\n",
    "# # Merge all CSVs into one dataframe\n",
    "# merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# # Define the output merged CSV file path\n",
    "# merged_csv_path = os.path.join(input_dir, 'merged_output.csv')\n",
    "\n",
    "# # Save the merged dataframe to a CSV file\n",
    "# merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "# print(f\"All files successfully merged into {merged_csv_path}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
